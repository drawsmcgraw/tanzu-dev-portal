<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>VMware Tanzu Developer Center – Kubernetes</title>
    <link>/guides/kubernetes/</link>
    <description>Recent content in Kubernetes on VMware Tanzu Developer Center</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/guides/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      
      <title>Guides: Controlling Ingress with Contour</title>
      
      <link>/guides/kubernetes/controlling-ingress-with-contour/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/controlling-ingress-with-contour/</guid>
      <description>

        
        &lt;p&gt;In Kubernetes, Ingress is a set of routing rules that define how external traffic is routed to an application inside a Kubernetes cluster. An Ingress controller watches for changes to objects in the cluster and then wires together a data path for each request to be resolved. An Ingress controller processes the requests for resources, provides transport layer security (TLS) termination, and performs other functions.&lt;/p&gt;
&lt;p&gt;Ingress is an important component of Kubernetes because it cleanly separates an application from how it is accessed. A cluster administrator enables access to the application through the Ingress controller, while the application developer focuses on the application itself. Ingress, and the Ingress Controller, provide the glue that tie the two together.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://projectcontour.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Contour&lt;/a&gt; is an open source Kubernetes &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Ingress controller&lt;/a&gt; that acts as a control plane for the Envoy edge and service proxy (see below).​ Contour supports dynamic configuration updates and multi-team ingress delegation while maintaining a lightweight profile.&lt;/p&gt;
&lt;p&gt;Contour is built for Kubernetes to empower you to quickly deploy cloud native applications by using the flexible IngressRoute API. Contour deploys the Envoy proxy as a reverse proxy and load balancer.&lt;/p&gt;
&lt;h3 id=&#34;what-is-envoy&#34;&gt;What Is Envoy?&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/what_is_envoy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Envoy&lt;/a&gt; is a Layer 7 (application layer) bus for proxy and communication in modern service-oriented architectures, such as Kubernetes clusters. Envoy strives to make the network transparent to applications while maximizing observability to ease troubleshooting.&lt;/p&gt;
&lt;h2 id=&#34;what-problems-does-contour-solve&#34;&gt;What Problems Does Contour Solve?&lt;/h2&gt;
&lt;p&gt;One of the most critical needs when running workloads at scale on Kubernetes is efficient and smooth traffic Ingress management at the application layer. Getting an application up and running is not the entire story; the app still needs a way for users to access it. Contour was designed to fill this operational gap.&lt;/p&gt;
&lt;h2 id=&#34;benefits-of-using-contour&#34;&gt;Benefits of Using Contour&lt;/h2&gt;
&lt;p&gt;Here are some of the benefits of using Contour:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Quickly deploy and integrate Envoy with a simple installation mechanism&lt;/li&gt;
&lt;li&gt;Safely support Ingress in multi-team Kubernetes clusters&lt;/li&gt;
&lt;li&gt;Cleanly integrate with the Kubernetes object model&lt;/li&gt;
&lt;li&gt;Dynamically update the Ingress configuration without dropped connections&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;keep-learning&#34;&gt;Keep Learning&lt;/h2&gt;
&lt;p&gt;Ingress and Ingress controllers remain an active topic in Kubernetes. Watch this short video for an &lt;a href=&#34;https://kube.academy/lessons/introduction-to-ingress&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Introduction to Ingress&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Contour Ingress controller has become popular because of features such as the ability to do blue-green deployments using &lt;a href=&#34;https://tanzu.vmware.com/content/blog/deploying-new-app-versions-by-using-blue-green-deployments-with-contour-s-ingressroute&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Contour’s IngressRoute&lt;/a&gt;. This &lt;a href=&#34;https://www.youtube.com/watch?v=xUJbTnN3Dmw&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;video&lt;/a&gt; also explains blue-green deployments. This &lt;a href=&#34;/guides/kubernetes/harbor-gs/&#34;&gt;guide&lt;/a&gt; provides an example of deploying Contour in conjunction with Harbor, an open source registry for containers and Helm charts.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Kubernetes Monitoring Overview</title>
      
      <link>/guides/kubernetes/observability-kubernetes-monitoring-overview/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/observability-kubernetes-monitoring-overview/</guid>
      <description>

        
        &lt;p&gt;Observability is a key element of cloud native application architectures. Most modern applications are distributed in nature, with a collection of multiple modules that communicate with each other via APIs. Anytime a problem occurs you need to be able to see when and where failures happened. And you need to measure failures to establish a profile or baseline against which deviations from normal operation can be identified and addressed. As such, monitoring, feature-rich metrics, alerting tools, and data visualization frameworks are a key element of successful cloud native applications.&lt;/p&gt;
&lt;p&gt;This guide provides an overview of monitoring tools for Kubernetes environments.&lt;/p&gt;
&lt;h2 id=&#34;how-is-monitoring-apps-on-kubernetes-different&#34;&gt;How Is Monitoring Apps on Kubernetes Different?&lt;/h2&gt;
&lt;p&gt;Containerized systems such as Kubernetes present new monitoring challenges versus virtual-machine-based compute environments. These differences include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The ephemeral nature of containers&lt;/li&gt;
&lt;li&gt;An increased density of objects, services, and metrics within a given node&lt;/li&gt;
&lt;li&gt;A focus on services, rather than machines&lt;/li&gt;
&lt;li&gt;More diverse consumers of monitoring data&lt;/li&gt;
&lt;li&gt;Changes in the software development lifecycle&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As monolithic apps are refactored into microservices and orchestrated with Kubernetes, requirements for monitoring those apps change. To start, instrumentation to capture application data needs to be at a container level, at scale, across thousands of endpoints. Because Kubernetes workloads are ephemeral by default and can start or stop at any time, application monitoring must be dynamic and aware of Kubernetes labels and namespaces. A consistent set of rules or alerts must be applied to all pods, new and old.&lt;/p&gt;
&lt;p&gt;Observability should always be a consideration when you’re developing new apps or refactoring existing ones. Maintaining a common layer of baseline metrics that applies to all apps and infrastructure while incorporating custom metrics is extremely desirable. Adding a new metric based on user feedback should NOT trigger a major replumb of your monitoring stack.&lt;/p&gt;
&lt;h2 id=&#34;monitoring-resource-consumption-and-preventing-infiltration&#34;&gt;Monitoring Resource Consumption and Preventing Infiltration&lt;/h2&gt;
&lt;p&gt;How can you protect your Kubernetes system from hijackers and infiltrators? Here are some suggestions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Monitor cluster and network utilization&lt;/li&gt;
&lt;li&gt;Monitor for suspicious activity and analyze failed login and RBAC events&lt;/li&gt;
&lt;li&gt;Monitor configurations, such as dashboard access, for risks and vulnerabilities&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The NIST document, &lt;a href=&#34;https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8176.pdf&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Security Assurance Requirements for Linux Application Container Deployments&lt;/a&gt; sets forth security requirements and countermeasures to help meet the recommendations of the &lt;a href=&#34;https://csrc.nist.gov/publications/detail/sp/800-190/final&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;NIST Application Container Security Guide&lt;/a&gt; when containerized applications are deployed in production environments. According to NIST, you should log and monitor resource consumption of containers to ensure availability of critical resources.&lt;/p&gt;
&lt;h3 id=&#34;security-monitoring-and-auditing&#34;&gt;Security monitoring and auditing&lt;/h3&gt;
&lt;p&gt;The proper security monitoring for your cluster depends largely on the amount of time and staffing you have to respond to alerts and keep an eye on things. As a general rule, you shouldn&amp;rsquo;t spend time building security monitoring systems that you don&amp;rsquo;t have the time to maintain and tune. Start with the real-time (alert-based) and periodic (audit review) analyst or operator workflows you want to enable, and build the monitoring platform you need to enable those workflows.&lt;/p&gt;
&lt;h3 id=&#34;logging&#34;&gt;Logging&lt;/h3&gt;
&lt;p&gt;The bedrock of security monitoring is logging. You should generally capture application logs, host-level logs, Kubernetes API audit logs, and cloud-provider logs (if applicable). There are well-established patterns for implementing log aggregation on common cluster configurations.&lt;/p&gt;
&lt;p&gt;Centralized logging is an essential part of any enterprise Kubernetes deployment. Configuring and maintaining a real-time high-performance central repository for log collection can ease the day-to-day operations of tracking what went wrong and its impact. Effective central logging also helps development teams quickly observe application logs to characterize application performance. Security compliance and auditing often require a company to maintain digital trails of who did what and when. In most cases, a robust logging solution is the most efficient way to satisfy these requirements&lt;/p&gt;
&lt;p&gt;For security auditing purposes, consider streaming your logs to an external location with append-only access from within your cluster. For example, on AWS, you can create an S3 bucket in an isolated AWS account and give append-only access to your cluster log aggregator. This ensures your logs cannot be tampered with, even in the case of a total cluster compromise.&lt;/p&gt;
&lt;h5 id=&#34;log-aggregation&#34;&gt;Log Aggregation&lt;/h5&gt;
&lt;p&gt;An effective log aggregator must support the processing of events from thousands of endpoints, the ability to accommodate real-time queries, and a superior analytics engine to provide intelligent metrics to solve complex technical and business problems. You have the option to implement log aggregation using a number of popular open source or commercial logging analytics solutions, such as Elasticsearch, Fluentd, Kibana, or Splunk. Each solution has a set of strengths and weaknesses.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.fluentd.org&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Fluentd&lt;/a&gt; is an open-source data collector for unified logging. &lt;a href=&#34;https://fluentbit.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Fluent Bit&lt;/a&gt; is a lightweight data forwarder for Fluentd. Fluentd is used to create a unified logging layer to collect and process data. Fluent Bit is for forwarding data from the edge to Fluentd aggregators. Fluentd and Fluent Bit can collect logging data and push it to an output destination, such as &lt;a href=&#34;https://www.elastic.co&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Elasticsearch&lt;/a&gt;, which is a distributed search and analytics engine that lets data engineers query unstructured, structured, and time-series data.&lt;/p&gt;
&lt;h3 id=&#34;network-monitoring&#34;&gt;Network monitoring&lt;/h3&gt;
&lt;p&gt;Network-based security monitoring tools, such as a network intrusion detection system (IDS) and web application firewalls, may work nearly out of the box, but making them work well takes some effort. The biggest hurdle is that many tools expect IP addresses to be a useful context for events. To integrate these tools with Kubernetes, consider enriching the collected events with Kubernetes &lt;code&gt;namespace&lt;/code&gt;, &lt;code&gt;pod name&lt;/code&gt;, and &lt;code&gt;pod label&lt;/code&gt; metadata. This adds valuable context to the event that you can use for alerting or manual review and can make these traditional tools even more powerful in a Kubernetes cluster than in a traditional environment. Some monitoring tools can collect Kubernetes metadata, but you can also write custom event enrichment code to add this kind of metadata integration to those that don&amp;rsquo;t.&lt;/p&gt;
&lt;h3 id=&#34;host-event-monitoring&#34;&gt;Host event monitoring&lt;/h3&gt;
&lt;p&gt;It&amp;rsquo;s also possible to run a host-based IDS, such as file integrity monitoring and Linux system call logging (for example, auditd), directly with Kubernetes, but the results are hard to manage because the workload running on any particular node varies from hour to hour as applications deploy and Kubernetes orchestrates pods.&lt;/p&gt;
&lt;p&gt;To make sense of host-based events, you&amp;rsquo;ll again want to consider extending your existing tools to include Kubernetes pod or container metadata in the context of captured events. Systems such as &lt;a href=&#34;https://sysdig.com/opensource/falco/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Sysdig Falco&lt;/a&gt; include this context out of the box.&lt;/p&gt;
&lt;h3 id=&#34;prometheus-and-grafana&#34;&gt;Prometheus and Grafana&lt;/h3&gt;
&lt;p&gt;The open-source community is converging on &lt;a href=&#34;https://prometheus.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus&lt;/a&gt; as a preferred solution for Kubernetes monitoring. The ability to address evolving requirements of Kubernetes while including a rich set of language-specific client libraries gives Prometheus an advantage.&lt;/p&gt;
&lt;p&gt;Prometheus excels at monitoring multidimensional data, including time-series data, and it is hosted by the Cloud Native Computing Foundation, of which VMware is a member. &lt;a href=&#34;https://grafana.com&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Grafana&lt;/a&gt; is an open-source metrics dashboard commonly used with Prometheus to display data.&lt;/p&gt;
&lt;h3 id=&#34;wavefront&#34;&gt;Wavefront&lt;/h3&gt;
&lt;p&gt;Kubernetes can be integrated with Wavefront (VMware Tanzu Observability) to efficiently monitor containers at enterprise scale. Wavefront delivers monitoring and analytics throughout a cloud native stack for always-on metrics as a service.Wavefront gives developers and DevOps real-time visibility into the operations and performance of containerized workloads and Kubernetes clusters.&lt;/p&gt;
&lt;h2 id=&#34;keep-learning&#34;&gt;Keep Learning&lt;/h2&gt;
&lt;p&gt;KubeAcademy offers a course on &lt;a href=&#34;https://kube.academy/courses/introduction-to-observability&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes observability&lt;/a&gt; where you can learn more about many of the topics mentioned above. For a practical guide on how to get started with Prometheus and Grafana, be sure to read &lt;a href=&#34;/guides/kubernetes/prometheus-grafana-p1/&#34;&gt;Prometheus and Grafana: Gathering Metrics from Kubernetes&lt;/a&gt;. Spring Boot users will also want to check out &lt;a href=&#34;/guides/spring/spring-prometheus/&#34;&gt;Prometheus and Grafana: Gathering Metrics from Spring Boot on Kubernetes&lt;/a&gt; to learn how to gather metrics from Spring applications. The guides &lt;a href=&#34;/guides/microservices/distributed-tracing&#34;&gt;Implementing Distributed Tracing&lt;/a&gt; and &lt;a href=&#34;/guides/spring/spring-zipkin/&#34;&gt;Getting Started with Zipkin and Spring Boot&lt;/a&gt; can help you improve observability for microservices applications.&lt;/p&gt;
&lt;p&gt;If you’re considering Wavefront, be sure and read &lt;a href=&#34;/guides/kubernetes/monitoring-at-scale-wavefront&#34;&gt;Monitoring Containers at Scale with Wavefront&lt;/a&gt; and &lt;a href=&#34;/guides/spring/spring-wavefront-gs/&#34;&gt;Wavefront for Spring Boot: Getting Started&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: What is Kubernetes?</title>
      
      <link>/guides/kubernetes/what-is-kubernetes/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/what-is-kubernetes/</guid>
      <description>

        
        &lt;p&gt;Containers accelerate development pipelines by removing the need to build, test and validate application code across multiple operating systems. They also help simplify application operations by being portable across multiple hosts and cloud platforms. However, an application running in a container still needs management. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What happens if a running container has a problem or dies?&lt;/li&gt;
&lt;li&gt;How do you expose containers running on host to external/ingress traffic?&lt;/li&gt;
&lt;li&gt;How do you determine AND scale the number of containers when application workloads increase?&lt;/li&gt;
&lt;li&gt;How can you isolate two containers on the same host such that they cannot talk to each other?&lt;/li&gt;
&lt;li&gt;How do you migrate containers from one host to another for host maintenance?&lt;/li&gt;
&lt;li&gt;How can containers share common config data?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A microservices application may be spread across multiple services backed by multiple containers, increasing complexity. A platform that can orchestrate, manage and define dependencies and configs for containerized applications becomes necessary for production systems.&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-kubernetes&#34;&gt;Introduction to Kubernetes&lt;/h2&gt;
&lt;p&gt;Kubernetes helps orchestrate containerized applications to run on a cluster of hosts. It&amp;rsquo;s a system that automates the deployment and management of containerized applications on a given cloud platform or on-premises infrastructure. Kubernetes manages workload distribution for containerized applications across a cluster of hosts and will dynamically roll out the container networking, routing and ingress needed for applications running in containers. It can also allocate storage and persistent volumes to running containers, provides a way to inject global config variables, implements auto-scaling, and maintains the desired state for applications.&lt;/p&gt;
&lt;p&gt;The Kubernetes API lets users define the desired end state of their applications via logical constructs like deployments, replicasets, config-maps, services etc. Kubernetes is highly extensible and portable, meaning it can run in a wide range of environments and can be used in conjunction with other technologies. There is a rapidly expanding Kubernetes ecosystem with projects that provide a wide range of different functionality.&lt;/p&gt;
&lt;p&gt;The Cloud Native Computing Foundation (CNCF) maintains an &lt;a href=&#34;https://landscape.cncf.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Interactive Landscape&lt;/a&gt; to keep track of everything going on. VMware Tanzu is an active sponsor and contributor for many &lt;a href=&#34;https://tanzu.vmware.com/open-source&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;open source projects&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;solving-container-challenges&#34;&gt;Solving Container Challenges&lt;/h2&gt;
&lt;p&gt;Kubernetes solves these challenges by automating the deployment and management of containerized applications. It manages everything necessary to optimize the use of computing resources and scales containers on demand.&lt;/p&gt;
&lt;p&gt;Kubernetes coordinates clusters of nodes to provide integration, orchestration, scaling, fault tolerance, and communications for running containers. It operates using the concept of pods, which are scheduling units that can include one or more containers and are distributed among nodes to provide high availability.&lt;/p&gt;
&lt;p&gt;In addition to scheduling deployment and automating the management of containerized applications, a key benefit of Kubernetes is that it maintains the desired state of an application as specified by an administrator. It does this using a declarative text file (YAML) that defines the desired state for a containerized application. If a container/pod dies it is automatically restarted, providing a built in level of resilience.&lt;/p&gt;
&lt;p&gt;Kubernetes uses various resource constructs to work with containers. These resources help define simple tasks such as how many instances of a container to run at all times, how to trigger auto-scaling, how to route ingress traffic to a set of container images, or how to define a &lt;a href=&#34;https://tanzu.vmware.com/content/blog/exploring-kube-apiserver-load-balancers-for-on-premises-kubernetes-clusters&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;load balancer&lt;/a&gt; to distribute traffic between multiple container images.&lt;/p&gt;
&lt;h2 id=&#34;keep-learning&#34;&gt;Keep Learning&lt;/h2&gt;
&lt;p&gt;If you haven’t already, check out our &lt;a href=&#34;/guides/containers/what-are-containers&#34;&gt;introduction to containers&lt;/a&gt;, and refer to the guides and resources on our &lt;a href=&#34;/topics/kubernetes/&#34;&gt;Kubernetes topic page&lt;/a&gt; to go deeper. The &lt;a href=&#34;/workshops/lab-k8s-fundamentals/&#34;&gt;Kubernetes Fundamentals workshop&lt;/a&gt; provides a quick, hands-on introduction, as well as the &lt;a href=&#34;https://kube.academy/courses/getting-started&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Getting Started with Kubernetes&lt;/a&gt; course on &lt;a href=&#34;https://kube.academy/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;KubeAcademy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After you feel comfortable with Kubernetes concepts, you can also learn about combining the Docker container platform with Kubernetes to develop &lt;a href=&#34;/topics/microservices&#34;&gt;microservices&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Admission Control</title>
      
      <link>/guides/kubernetes/platform-security-admission-control/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/platform-security-admission-control/</guid>
      <description>

        
        &lt;p&gt;This document details the philosophy and methods for implementing admission
control in a Kubernetes cluster, such as Tanzu Kubernetes Grid (TKG). It covers
architectural considerations, tooling choices, and best practices. This document
represents how the VMware field team approaches admission control in enterprise
Kubernetes environments.&lt;/p&gt;
&lt;p&gt;Each section covers architectural recommendations and, at times, configuration
for each concern. At a high-level, the key recommendations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unless mutation or external interaction is required, OPA Gatekeeper can often
be the best solution.&lt;/li&gt;
&lt;li&gt;Be aware that admission controllers sit in the critical path to the API
server, so consider this bottleneck carefully.&lt;/li&gt;
&lt;li&gt;If writing a controller, consider the trade-off between frameworks and
familiar language stacks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;When objects are applied to the Kubernetes API server they go through a series
of steps before being committed to etcd (the persistent datastore). The whole
flow is illustrated below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/diagrams/admission-control-ra-architecture.png&#34; alt=&#34;Admission Control Architecture&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;There are many admission controllers that are built in to Kubernetes to provide
common functionality. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ServiceAccount&lt;/code&gt; - Responsible for injecting the default service account into
pods where necessary.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ResourceQuota&lt;/code&gt; - Responsible for enforcing resource quotas on workloads.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NamespaceLifecycle&lt;/code&gt; - Responsible for preventing new objects being created in
a namespace that is currently in a &lt;code&gt;terminating&lt;/code&gt; state.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are a set of admission controllers that are &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#which-plugins-are-enabled-by-default&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;enabled by
default&lt;/a&gt;.
These defaults include two &lt;em&gt;special&lt;/em&gt; admission controllers that allow cluster
administrators to dynamically specify additional admission controllers that will
be called via webhook from the API server (the built-ins are implemented
in-tree). This guide will only focus on designing and writing mutating and
validating admission webhooks.&lt;/p&gt;
&lt;p&gt;Because they are called as a webhook, dynamic admission controllers (both
mutating and validating) can run in-cluster or out-of-cluster (lending
themselves to work well as serverless functions for example). One caveat is that
the API server will call webhooks over TLS, so webhooks must present
certificates trusted by the Kubernetes API. This is often achieved by deploying
Cert Manager into the cluster and automatically generating certificates.&lt;/p&gt;
&lt;h2 id=&#34;mutating-admission-controllers&#34;&gt;Mutating Admission Controllers&lt;/h2&gt;
&lt;p&gt;Mutating admission controllers receive &lt;code&gt;AdmissionReview&lt;/code&gt; requests from the API
server and can optionally alter objects before allowing them to pass on to the
API server (or rejecting them). These types of controllers are useful for things
like injecting sidecar containers (keeping a clean UX for end users) e.g. Istio.&lt;/p&gt;
&lt;p&gt;If a controller chooses to mutate a request, it will allow the request by
sending an &lt;code&gt;AdmissionReview&lt;/code&gt; response object along with a serialized set of
&lt;code&gt;JSONPatch&lt;/code&gt; objects that describe to the API server how the object should be
altered. Depending on the implementation chosen (details below) these patches
may be auto-generated for you.&lt;/p&gt;
&lt;p&gt;One downside of mutating controllers is that visibility is removed from the end
user, with requests / objects being applied to the cluster that are not
consistent with those that the end user originally created, potentially causing
confusion if the user is unaware that mutating controllers are in operation on
the cluster.&lt;/p&gt;
&lt;h2 id=&#34;validating-admission-controllers&#34;&gt;Validating Admission Controllers&lt;/h2&gt;
&lt;p&gt;Validating admission controllers also receive &lt;code&gt;AdmissionReview&lt;/code&gt; requests from
the API server but are not able to modify them. They can only admit or reject
the original object.&lt;/p&gt;
&lt;p&gt;This restriction makes them fairly limited, however they are a good fit when
ensuring that objects applied to the cluster conform to security standards
(specific user IDs, no host mounts, etc&amp;hellip;) or contain all required metadata
(internal team labels, annotations, etc&amp;hellip;).&lt;/p&gt;
&lt;h2 id=&#34;configuring-webhook-admission-controllers&#34;&gt;Configuring Webhook Admission Controllers&lt;/h2&gt;
&lt;p&gt;Cluster administrators can use the &lt;code&gt;MutatingWebhookConfiguration&lt;/code&gt; and
&lt;code&gt;ValidatingWebhookConfiguration&lt;/code&gt; kinds to specify the configuration of dynamic
webhooks. Below is an annotated example describing all of the relevant sections:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;admissionregistration.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;MutatingWebhookConfiguration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;test-mutating-hook&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;webhooks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;test-mutating-hook&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Matching rules. What API / kind / version / operations should this webhook be sent.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;apiGroups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The operation that should trigger a call to the webhook.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;operations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;CREATE&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Which kind to target.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;pods&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Whether Namespace-scoped or cluster-scoped resources should be targeted.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scope&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Namespaced&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Describes how the API server should connect to the webhook. In this case it&amp;#39;s in cluster at `test-service.test-ns.svc`.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clientConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;test-ns&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;test-service&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/test-path&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# A PEM encoded CA bundle which will be used to validate the webhook&amp;#39;s server certificate.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;caBundle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Ci0tLS0tQk...tLS0K&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Declare the admissionReviewVersions that the webhook supports.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;admissionReviewVersions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;v1beta1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Describes whether the webhook has external side effects (calls / dependencies to external systems).&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sideEffects&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# How long to wait until triggering the failurePolicy.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;timeoutSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Whether this webhook can be re-invoked (this may happen after other webhooks have been called).&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;reinvocationPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IfNeeded&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Whether the webhook should fail &amp;#39;open&amp;#39; or &amp;#39;closed. This has security implications.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;failurePolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Fail&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;design-considerations&#34;&gt;Design Considerations&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Failure Modes:&lt;/strong&gt; If a webhook is unreachable or sends an unknown response back
to the API server, it is treated as failing. Administrators must choose whether
to fail &amp;lsquo;open&amp;rsquo; or &amp;lsquo;closed&amp;rsquo; in this situation by setting the &lt;code&gt;failurePolicy&lt;/code&gt;
field to &lt;code&gt;Ignore&lt;/code&gt; (allow the request) or &lt;code&gt;Fail&lt;/code&gt; (reject the request).&lt;/p&gt;
&lt;p&gt;For security-related (or critical functionality) webhooks, &lt;code&gt;Fail&lt;/code&gt; is the safest
option. For non-critical hooks &lt;code&gt;Ignore&lt;/code&gt; may be safe (potentially in conjunction
with a reconciling controller as a backup). Combine these recommendations with
those in the performance section below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ordering:&lt;/strong&gt; The first thing to note with regards to request flow above is that
mutating webhooks will all be called (potentially more than once)&lt;em&gt;before&lt;/em&gt;
validating webhooks are called. This is important because it enables validating
webhooks (which may reject a request based on security requirements) always to
see the &lt;em&gt;final&lt;/em&gt; version of a resource before it is applied.&lt;/p&gt;
&lt;p&gt;Mutating webhooks are not guaranteed to be called in a specific order, and may
be called multiple times if subsequent hooks modify a request. This can be
modified by specifying the &lt;code&gt;reinvocationPolicy&lt;/code&gt; but ideally webhooks should be
designed for idempotency to ensure ordering does not affect their functionality.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance:&lt;/strong&gt; Webhooks are called as part of the critical path of requests
flowing to the API server. If a webhook is critical (security-related) and fails
closed (if a timeout occurs, the request is denied) then it should be designed
with high-availability in mind.&lt;/p&gt;
&lt;p&gt;If a webhook is resource-intensive and / or has external dependencies,
consideration should be taken for how often the hook will be called, and the
performance impact of adding the functionality into the critical path. In these
situations a controller that reconciles objects once in-cluster may be
preferable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Side Effects:&lt;/strong&gt; Some webhooks may be responsible for modifying external
resources (e.g. some resource in a cloud provider) based on a request to the
Kubernetes API. These webhooks should be aware of and respect the &lt;code&gt;dryRun&lt;/code&gt;
option and skip external state modification when it is enabled. Webhooks are
responsible for declaring that they either have no side-effects, or respect this
option by setting the &lt;code&gt;sideEffects&lt;/code&gt; field.&lt;/p&gt;
&lt;h2 id=&#34;implementations&#34;&gt;Implementations&lt;/h2&gt;
&lt;p&gt;There are three main approaches to implementing admission control in Kubernetes.
This section details each approach and calls out the advantages / disadvantages
and most appropriate use cases for each.&lt;/p&gt;
&lt;h3 id=&#34;open-policy-agent-opa-gatekeeper&#34;&gt;Open Policy Agent (OPA) Gatekeeper&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/open-policy-agent/gatekeeper&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Gatekeeper&lt;/a&gt; is an OSS tool
that uses Open Policy Agent to implement a validating admission controller. This
allows users to write constraints in the Rego language to specify rules that
specific resources should conform to.&lt;/p&gt;
&lt;p&gt;Administrators specify &lt;code&gt;ConstraintTemplate&lt;/code&gt; resources which are templates with
variable placeholders that can be re-used by end-users. For example, to specify
a &lt;code&gt;ConstraintTemplate&lt;/code&gt; that allows a user to specify some required labels, the
following could be applied:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;templates.gatekeeper.sh/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConstraintTemplate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8srequiredlabels&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;crd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;K8sRequiredLabels&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;listKind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;K8sRequiredLabelsList&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;plural&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8srequiredlabels&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;singular&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8srequiredlabels&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;validation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Schema for the `parameters` field&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;openAPIV3Schema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;properties&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;items&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;admission.k8s.gatekeeper.sh&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rego&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        package k8srequiredlabels
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        violation[{&amp;#34;msg&amp;#34;: msg, &amp;#34;details&amp;#34;: {&amp;#34;missing_labels&amp;#34;: missing}}] {
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          provided := {label | input.review.object.metadata.labels[label]}
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          required := {label | label := input.parameters.labels[_]}
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          missing := required - provided
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          count(missing) &amp;gt; 0
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          msg := sprintf(&amp;#34;you must provide labels: %v&amp;#34;, [missing])
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;ConstraintTemplate&lt;/code&gt; contains Rego code that can refer to input parameters
defined at a later time. An end-user can then apply the following object to make
use of the template to enforce the constraint:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;constraints.gatekeeper.sh/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;K8sRequiredLabels&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ns-must-have-gk&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;match&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kinds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;apiGroups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kinds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Namespace&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;gatekeeper&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above selects all &lt;code&gt;Namespace&lt;/code&gt; objects and ensures they have the &lt;code&gt;gatekeeper&lt;/code&gt;
label.&lt;/p&gt;
&lt;p&gt;There are also use-cases where it&amp;rsquo;s necessary to make a policy decision based on
data that exists externally to the object that&amp;rsquo;s being applied to the cluster.
An example of this would be ensuring that all ingresses are unique. For that
it&amp;rsquo;s required that we can query the state of the cluster to check all ingress
objects to compare against the one being applied.&lt;/p&gt;
&lt;p&gt;Another even more complex example would be to annotate a namespace with a regex
pattern, and ensure any ingress applied in that namespace conforms to the regex.
A Gatekeeper sync config needs to be applied to make existing cluster information available
to Gatekeeper. This tells Gatekeeper to sync and cache information about the
specified resources:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;config.gatekeeper.sh/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;gatekeeper-system&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;syncOnly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;extensions&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;v1beta1&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Ingress&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;networking.k8s.io&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;v1beta1&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Ingress&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Namespace&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;ConstraintTemplate&lt;/code&gt; uses the &lt;code&gt;data.inventory...&lt;/code&gt; object to look up items
from the sync cache:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;templates.gatekeeper.sh/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConstraintTemplate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;limitnamespaceingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;crd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;LimitNamespaceIngress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;listKind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;LimitNamespaceIngressList&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;plural&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;limitnamespaceingresss&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;singular&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;limitnamespaceingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;validation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Schema for the `parameters` field in the constraint&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;openAPIV3Schema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;properties&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;admission.k8s.gatekeeper.sh&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rego&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        package limitnamespaceingress
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        violation[{&amp;#34;msg&amp;#34;: msg}] {
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          regex :=
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          data.inventory.cluster.v1.Namespace[input.review.object.metadata.namespace].metadata.annotations[input.parameters.annotation]
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          hosts := input.review.object.spec.rules[_].host
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          not re_match(regex, hosts)
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          msg := sprintf(&amp;#34;Only ingresses with host matching %v are allowed in namespace %v&amp;#34;, [regex ,input.review.object.metadata.namespace])
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;annotation&lt;/code&gt; in the custom input parameters allows the user to specify the
specific annotation that Gatekeeper should pull the regex pattern from.&lt;/p&gt;
&lt;p&gt;Rego returns early if any statement returns &lt;code&gt;False&lt;/code&gt;, so the &lt;code&gt;re_match()&lt;/code&gt; is
inverted with &lt;code&gt;not&lt;/code&gt; to ensure that a positive match allows the request.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;LimitNamespaceIngress&lt;/code&gt; object specifies that the rule should apply to
&lt;code&gt;Ingress&lt;/code&gt; objects for both &lt;code&gt;apiGroups&lt;/code&gt; and designates &lt;code&gt;allowed-ingress-pattern&lt;/code&gt;
as the annotation that should be inspected for the regex pattern (this was the
customizable input parameter).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;constraints.gatekeeper.sh/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;LimitNamespaceIngress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;limit-namespace-ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;match&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kinds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;apiGroups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;extensions&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;networking.k8s.io&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kinds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Ingress&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;allowed-ingress-pattern&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally the Namespace object itself is applied with the custom annotation &amp;amp;
pattern:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Namespace&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Note regex special character escaping&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;allowed-ingress-pattern&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;\w\.my-namespace\.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingress-test&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now the setup is complete the ingress objects are applied and rules evaluated
against them:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;c&#34;&gt;# FAILS because the host doesn&amp;#39;t match the pattern above&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;test-1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingress-test&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo.other-namespace.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;service1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# SUCCEEDS as the pattern matches&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;test-2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingress-test&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo.my-namespace.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;service2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The second ingress above will succeed as the &lt;code&gt;spec.rules.host&lt;/code&gt; matches the regex
pattern specified in the &lt;code&gt;allowed-ingress-pattern&lt;/code&gt; annotation on the
&lt;code&gt;ingress-test&lt;/code&gt; namespace. However the first ingress above does not match and
results in an error:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;Error from server ([denied by limit-namespace-ingress] Only ingresses with host matching \w\.my-namespace\.com are allowed in namespace ingress-test): error when creating &amp;#34;ingress.yaml&amp;#34;: admission webhook &amp;#34;validation.gatekeeper.sh&amp;#34; denied the request: [denied by limit-namespace-ingress] Only ingresses with host matching \w\.my-namespace\.com are allowed in namespace ingress-test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extensible &lt;code&gt;ConstraintTemplate&lt;/code&gt; model allows admins to define common policies
and share / re-use them as libraries.&lt;/li&gt;
&lt;li&gt;Doesn&amp;rsquo;t require any custom coding (outside of Rego policies).&lt;/li&gt;
&lt;li&gt;Fairly mature, community-supported project.&lt;/li&gt;
&lt;li&gt;Easy to install.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Only supports validating (not mutating) admission control.&lt;/li&gt;
&lt;li&gt;Rego can get unwieldy when writing non-trivial evaluation logic.&lt;/li&gt;
&lt;li&gt;Care needs to be taken with the defaults (e.g. &lt;code&gt;failurePolicy&lt;/code&gt; is set to
&lt;code&gt;Ignore&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Alternate deprecated approach: &lt;code&gt;OPA with kube-mgmt&lt;/code&gt;&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Before Gatekeeper was released, there was an alternative approach to use OPA with
Kubernetes. This involved deploying a &lt;code&gt;kube-mgmt&lt;/code&gt; component to the cluster which
would watch for &lt;code&gt;ConfigMap&lt;/code&gt; objects containing rego policies and load them into
OPA. This is in contrast to the more Kubernetes-native approach of using CRDs
for policies and templates.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;controller-runtime&#34;&gt;Controller-Runtime&lt;/h3&gt;
&lt;p&gt;The upstream tool
(&lt;a href=&#34;https://github.com/kubernetes-sigs/controller-runtime&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;controller-runtime&lt;/a&gt;)
provides abstractions to ease the creation of mutating and validating admission
webhooks.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/controller-runtime/tree/master/examples/builtins&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;An
example&lt;/a&gt;
of how to implement these hooks for built-in types (e.g. Pod, Deployment,
etc&amp;hellip;) is provided by the project to help users get started.&lt;/p&gt;
&lt;p&gt;This approach is useful when complex logic or side-effects are required in an
admission controller. While it does require coding knowledge (Go), it offers
great flexibility while still taking advantage of the abstractions offered by
controller-runtime.&lt;/p&gt;
&lt;p&gt;Webhooks must implement a &lt;code&gt;Handle&lt;/code&gt; method whose signature is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;w&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Webhook&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;Handle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;req&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;admission&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Request&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;admission&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Response&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;admission.Request&lt;/code&gt; object is an abstraction over the raw JSON that webhooks
receive, and provides easy access to the raw applied object, the operation being
executed (e.g. &lt;code&gt;CREATE&lt;/code&gt;) etc&amp;hellip;&lt;/p&gt;
&lt;p&gt;Within the handler create a new instance of the object being captured and decode
the raw object into the Go structure. In the case below a new Pod struct is
created:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;decoder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;DecodeRaw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;req&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;p&lt;/code&gt; object can be modified or validated in any way before the response is
returned. In the example below an annotation is added to the Pod before
marshaling the object back to JSON and sending the patched response back to the
API server:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;new-annotation&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;new-annotation-value&amp;#34;&lt;/span&gt;\
&lt;span class=&#34;nx&#34;&gt;marshaledPod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Marshal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;admission&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;PatchResponseFromRaw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;req&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Raw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;marshaledPod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Controller-runtime&amp;rsquo;s &lt;code&gt;PatchResponseFromRaw&lt;/code&gt; method will automatically calculate
the JSONPatch diffs required between the original raw object and the modified
one before sending the correctly serialized response.&lt;/p&gt;
&lt;p&gt;In the case of a simple validating hook, controller-runtime provides convenience
functions &lt;code&gt;admission.Allowed()&lt;/code&gt; and &lt;code&gt;admission.Denied()&lt;/code&gt; that can be used after
processing the required logic.&lt;/p&gt;
&lt;p&gt;One of the biggest additional advantages of using Kubebuilder is the use of
markers to auto-generate manifests for deployment &amp;amp; RBAC.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;l&#34;&gt;// +kubebuilder:webhook:path=/validate-v1-pod,mutating=false,failurePolicy=fail,groups=&amp;#34;&amp;#34;,resources=pods,verbs=create;update,versions=v1,name=vpod.kb.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The example above generates the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;admissionregistration.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ValidatingWebhookConfiguration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;vpod.kb.io&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;webhooks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;vpod.kb.io&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;apiGroups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;operations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;CREATE&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;UPDATE&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;pods&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scope&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Namespaced&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clientConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vpod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/validate-v1-pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;caBundle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Ci0tLS0tQk...tLS0K&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;failurePolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Fail&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Supports both mutating and validating admission control.&lt;/li&gt;
&lt;li&gt;Use of high-level programming language allows huge flexibility / &amp;amp; extensibility.&lt;/li&gt;
&lt;li&gt;Abstracts underlying request handling and message parsing with convenience
interfaces and methods.&lt;/li&gt;
&lt;li&gt;Can have more tightly-scoped RBAC privileges.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires Go programming knowledge.&lt;/li&gt;
&lt;li&gt;Requires knowledge of some Kubernetes API server behaviors.&lt;/li&gt;
&lt;li&gt;Admission logic is contained in code rather than being readable in CRDs or
ConfigMaps.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;agnostic-http-handler&#34;&gt;Agnostic HTTP Handler&lt;/h3&gt;
&lt;p&gt;An alternate way to build admission controllers (mutating &amp;amp; validating) is by
implementing an HTTP webhook endpoint from scratch in any language. Examples
below use Go but any language capable of TLS-enabled HTTP handling and JSON
parsing is acceptable.&lt;/p&gt;
&lt;p&gt;Using this approach provides the most flexibility to integrate with the current
stacks in use, but comes at the cost of many high-level abstractions (although
languages with mature Kubernetes client libraries can alleviate this).&lt;/p&gt;
&lt;p&gt;As described above admission control webhooks receive and return HTTPS requests
from and to the API server. The schema of these messages is well known so it&amp;rsquo;s
possible to receive the request and modify the object (via Patches) manually.&lt;/p&gt;
&lt;p&gt;The example below is shown in Go. Whereas &lt;code&gt;controller-runtime&lt;/code&gt; provides a patch
generation helper, it is necessary in plain Go to generate the JSONPatch and
serialize it (to JSON) manually:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;nx&#34;&gt;patch&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;patchOperation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;nx&#34;&gt;Op&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;    &lt;span class=&#34;s&#34;&gt;&amp;#34;add&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
   &lt;span class=&#34;nx&#34;&gt;Path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;s&#34;&gt;&amp;#34;/spec/volumes/0&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
   &lt;span class=&#34;nx&#34;&gt;Value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;volume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
 &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;patchBytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Marshal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;patch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally there is no convenience wrapper around the response, so this also has to
be manually created with the relevant patches and status before being returned:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v1beta1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;AdmissionResponse&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;Allowed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;Patch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;   &lt;span class=&#34;nx&#34;&gt;patchBytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;PatchType&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v1beta1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;PatchType&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;nx&#34;&gt;pt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;v1beta1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;PatchTypeJSONPatch&lt;/span&gt;
   &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;pt&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;}(),&lt;/span&gt;
 &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In addition to the extra work in the logic of the webhook, there is a larger
amount of supporting code required to handle errors, graceful shutdown, HTTP
headers, etc&amp;hellip;&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Maximum flexibility for different languages / stacks.&lt;/li&gt;
&lt;li&gt;Supports both mutating and validating hooks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Almost all functionality must be written from scratch.&lt;/li&gt;
&lt;li&gt;More complex to maintain.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: What Is Helm?</title>
      
      <link>/guides/kubernetes/helm-what-is/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/helm-what-is/</guid>
      <description>

        
        &lt;p&gt;&lt;a href=&#34;https://helm.sh&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm&lt;/a&gt; is a tool to help you define, install, and upgrade applications running on Kubernetes. At its most basic, Helm is a templating engine that creates Kubernetes manifests. What makes Helm more than that is it can upgrade and scale applications as well.&lt;/p&gt;
&lt;h2 id=&#34;why-is-it-important&#34;&gt;Why Is It Important?&lt;/h2&gt;
&lt;p&gt;Helm reduces the amount of work you need to do to deploy, upgrade, and manage an application to Kubernetes. This helps limit human error and also creates a more declarative configuration to enable workflows like &lt;a href=&#34;https://www.weave.works/blog/what-is-gitops-really&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;GitOps&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This capability really stands out when you have a large, complex application; your app may contain dozens of Kubernetes objects that need to be configured and changed during upgrades.
It also applies if you&amp;rsquo;re deploying the same app multiple times. Using find-and-replace in multiple manifests is a recipe for disaster. Helm can make the process easy and repeatable.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s why an instance of a chart running on a Kubernetes cluster is called a &lt;em&gt;release&lt;/em&gt;. If you need three different installs of a web server, each one is its own release. The Helm docs includes releases as one of &lt;a href=&#34;https://helm.sh/docs/intro/using_helm/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;em&gt;three important concepts&lt;/em&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Helm installs &lt;em&gt;charts&lt;/em&gt; into Kubernetes, creating a new &lt;em&gt;release&lt;/em&gt; for each installation. And to find new charts, you can search Helm chart &lt;em&gt;repositories&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can read more about the &lt;a href=&#34;https://helm.sh/docs/topics/architecture/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm architecture here.&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-does-helm-work&#34;&gt;How Does Helm Work?&lt;/h2&gt;
&lt;p&gt;Helm combines the templates and default values in a chart with values you&amp;rsquo;ve supplied, along with information from your cluster to deploy and update applications. You can use charts directly from repos, charts you&amp;rsquo;ve downloaded, or charts you&amp;rsquo;ve created yourself. Helm uses the &lt;a href=&#34;https://golang.org/pkg/text/template/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Go templating engine&lt;/a&gt;, so if you&amp;rsquo;re familiar with that, you&amp;rsquo;ll understand how the charts work.&lt;/p&gt;
&lt;p&gt;As of Helm 3, all of the necessary data is stored locally in your Helm client config or in the cluster where the releases are installed. In previous versions of Helm, it required a component called &lt;code&gt;tiller&lt;/code&gt; installed on the cluster. That component is no longer needed so Helm is now easier to install and use.&lt;/p&gt;
&lt;h2 id=&#34;how-can-i-use-it&#34;&gt;How Can I Use It?&lt;/h2&gt;
&lt;p&gt;If you&amp;rsquo;re ready to start using Helm, check out our guide on &lt;a href=&#34;../helm-gs&#34;&gt;Getting Started With Helm&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Getting Started with Contour - To Ingress and Beyond</title>
      
      <link>/guides/kubernetes/service-routing-contour-to-ingress-and-beyond/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/service-routing-contour-to-ingress-and-beyond/</guid>
      <description>

        
        &lt;h3 id=&#34;introduction-to-contour&#34;&gt;Introduction to Contour&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://projectcontour.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Contour&lt;/a&gt; is an open source Kubernetes
&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Ingress controller&lt;/a&gt;
that acts as a control plane for the Envoy edge and service proxy (see below).​
Contour supports dynamic configuration updates and multi-team ingress delegation
while maintaining a lightweight profile.&lt;/p&gt;
&lt;p&gt;Contour is built for Kubernetes to empower you to quickly deploy cloud native
applications by using the flexible HTTPProxy API which is a lightweight system
that provides many of the advanced routing features of a Service Mesh.&lt;/p&gt;
&lt;p&gt;Contour deploys the
&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/what_is_envoy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Envoy&lt;/a&gt; proxy
as a reverse proxy and load balancer. Envoy is a Layer 7 (application layer) bus
for proxy and communication in modern service-oriented architectures, such as
Kubernetes clusters. Envoy strives to make the network transparent to
applications while maximizing observability to ease troubleshooting.&lt;/p&gt;

&lt;div class=&#34;youtube-video-shortcode&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Kz671dXioS0&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;div align=&#34;center&#34;&gt;&lt;i&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Kz671dXioS0&amp;feature=youtu.be&#34;&gt;Watch Paul livestream trying Contour 1.12.0 for the first time.&lt;/a&gt;&lt;/i&gt;&lt;/div&gt;
&lt;h3 id=&#34;before-you-begin&#34;&gt;Before You Begin&lt;/h3&gt;
&lt;p&gt;You&amp;rsquo;ll need a Kubernetes cluster. This guide uses a
&lt;a href=&#34;https://tanzu.vmware.com/kubernetes-grid&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Tanzu Kubernetes Grid&lt;/a&gt; cluster, but
any Kubernetes Cluster whether they&amp;rsquo;re running on a Public Cloud, in your
[Home] Lab, or on your desktop such as &lt;a href=&#34;https://kind.sigs.k8s.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;KIND&lt;/a&gt; or
&lt;a href=&#34;https://minikube.sigs.k8s.io/docs/start/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;minikube&lt;/a&gt;. You&amp;rsquo;ll also need the
Kubernetes CLI
&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubectl&lt;/a&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Verify access to your Kubernetes cluster&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl version --short
Client Version: v1.20.2
Server Version: v1.19.3+vmware.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a scratch directory to work from&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir ~/scratch/contour-demo
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ~/scratch/contour-demo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;installing-contour-1120&#34;&gt;Installing Contour 1.12.0&lt;/h3&gt;
&lt;p&gt;Since version 1.11.0 we&amp;rsquo;ve got two primary options for installing Contour, A
singleton install from manifests, or by using the
&lt;a href=&#34;https://projectcontour.io/resources/deprecation-policy/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Operator&lt;/a&gt; (which is
currently in Alpha). Since we only plan to install Contour once on the cluster,
we can stick to the safer method of using the Contour provided manifests.&lt;/p&gt;
&lt;p&gt;You can install Contour directly from the manifests provided by the project,
however best practice would have you download them locally first for validation
and repeatability.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download contour installation manifests&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;wget https://projectcontour.io/quickstart/v1.12.0/contour.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;View the manifests in your favorite local text editor&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;less contour.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Validate even further by doing a dry run install&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f contour.yaml --dry-run&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;client
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If that all looks good (and it should!), perform the actual install&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f contour.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After a few moments you can confirm that its ready.&lt;/p&gt;
&lt;p&gt;You&amp;rsquo;re looking for both the &lt;strong&gt;deployment&lt;/strong&gt; and &lt;strong&gt;DaemonSet&lt;/strong&gt; to show as fully
Available, and a valid IP (or hostname) in the &lt;code&gt;EXTERNAL-IP&lt;/code&gt; field of your
envoy &lt;strong&gt;service&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n projectcontour get deployment,daemonset,service

  NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
  deployment.apps/contour   2/2     &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;            &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;           2m18s

  NAME                   DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
  daemonset.apps/envoy   &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;         &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;         &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;       &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;            &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;           &amp;lt;none&amp;gt;          2m17s

  NAME              TYPE           CLUSTER-IP       EXTERNAL-IP
  PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;                      AGE
  service/contour   ClusterIP      100.71.191.199   &amp;lt;none&amp;gt;
  8001/TCP                     2m18s
  service/envoy     LoadBalancer   100.66.114.136   a36c85343e9284c1cb4236d844c31aab-1691151764.us-east-2.elb.amazonaws.com   80:30825/TCP,443:30515/TCP   2m18s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Save the Ingress &lt;code&gt;EXTERNAL-IP&lt;/code&gt; for later use as a &lt;a href=&#34;http://xip.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;xip.io&lt;/a&gt; dynamic DNS host.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Note for AWS Users&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Since this is deployed in Amazon Web Services I had to resolve the hostname
using the &lt;code&gt;host&lt;/code&gt; command, but in other clouds you will probably get an IP
address.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nv&#34;&gt;INGRESS_HOST&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;lt;external ip address from above&amp;gt;.xip.io
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;creating-an-ingress-using-contour-1120&#34;&gt;Creating an Ingress using Contour 1.12.0&lt;/h3&gt;
&lt;p&gt;Now that Contour is installed we can validate it is functioning correctly by
deploying an application, exposing it as a service, then creating an Ingress
resource. As well as creating the resources we&amp;rsquo;ll output the manifests to a file
for later re-use.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a namespace&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create namespace my-ingress-app -o yaml &amp;gt; my-ingress-app-namespace.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a deployment containing a basic nginx pod&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n my-ingress-app create deployment --image&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;nginx &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  nginx -o yaml &amp;gt; my-ingress-app-deployment.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a service for the deployment&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n my-ingress-app expose deployment nginx --port &lt;span class=&#34;m&#34;&gt;80&lt;/span&gt; -o yaml &amp;gt; my-ingress-app-service.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally create an Ingress for the service&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n my-ingress-app create ingress nginx --class&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;default &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --rule&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;nginx.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$INGRESS_HOST&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/*=nginx:80&amp;#34;&lt;/span&gt; -o yaml &amp;gt; my-ingress-app-ingress.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Validate that your resources are deployed and ready&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n my-ingress-app get all,ingress

Warning: extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; use networking.k8s.io/v1 Ingress
NAME                         READY   STATUS    RESTARTS   AGE
pod/nginx-6799fc88d8-dphdt   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          13m

NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;   AGE
service/nginx   ClusterIP   100.69.247.38   &amp;lt;none&amp;gt;        80/TCP    12m

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx   1/1     &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;            &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;           13m

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-6799fc88d8   &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;         &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;         &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;       13m

NAME                       CLASS     HOSTS                                                                     ADDRESS                                                                   PORTS   AGE
ingress.extensions/nginx   default   a36c85343e9284c1cb4236d844c31acb-1691151764.us-east-2.elb.amazonaws.com   a36c85343e9284c1cb4236d844c31acb-1691151764.us-east-2.elb.amazonaws.com   &lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;      51s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Validate that you can access the application&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ curl -s nginx.3.13.150.109.xip.io  &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep h1

&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Congratulations! If you see the &lt;strong&gt;Welcome to nginx!&lt;/strong&gt; message, that means you&amp;rsquo;ve
successfully installed and tested Contour as an Ingress Controller. However its
so much more than that, so lets explore further.&lt;/p&gt;
&lt;p&gt;However let&amp;rsquo;s clean up our resources before we move on. Since all of our
resources are in a single namespace we could use
&lt;code&gt;kubectl delete namespace my-ingress-app&lt;/code&gt;, However we also saved the manifests
so we can use those like so:&lt;/p&gt;


&lt;div class=&#34;aside aside-warning&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Caution&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;We created these manifests in the same directory as our contour manifests, so
we will move them into a subdirectory to ensure we only delete the app itself.
This is a lesson learned that we should have created them in a subdirectory
in the first place for organizational purposes.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir my-ingress-app
mv my-ingress-app-* my-ingress-app/
kubectl delete -f my-ingress-app
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;beyond-ingress-with-contour-1120&#34;&gt;Beyond Ingress with Contour 1.12.0&lt;/h3&gt;
&lt;p&gt;As well as &lt;strong&gt;Ingress&lt;/strong&gt; Contour supports a resource type &lt;strong&gt;HTTPProxy&lt;/strong&gt; which
extends the concept of &lt;strong&gt;Ingress&lt;/strong&gt; to add many features that you would normally
have to reach for &lt;strong&gt;Istio&lt;/strong&gt; or a similar service mesh to get. We can explore
some of those features here.&lt;/p&gt;
&lt;p&gt;Having learned our lesson about sub directories above, lets create a directory
for our exploration of HTTPProxy.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir http-proxy
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; http-proxy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As we did earlier we&amp;rsquo;ll start by deploying a nginx &lt;strong&gt;Pod&lt;/strong&gt; and a &lt;strong&gt;Service&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a namespace&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create namespace http-proxy -o yaml &amp;gt; http-proxy-namespace.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a Deployment containing a basic nginx pod&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n http-proxy create deployment --image&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;nginx &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  nginx -o yaml &amp;gt; http-proxy-nginx-deployment.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a service for the deployment&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n http-proxy expose deployment nginx --port &lt;span class=&#34;m&#34;&gt;80&lt;/span&gt; -o yaml &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  &amp;gt; http-proxy-nginx-service.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now that we have the Deployment and Service created we can create the HTTPProxy
resource. Unfortunately we can&amp;rsquo;t just sling a &lt;code&gt;kubectl create httpproxy&lt;/code&gt; like we
could with the other resources so we&amp;rsquo;ll need to get creative.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a HTTPProxy manifest&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt; EOF &amp;gt; http-proxy.yaml
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;apiVersion: projectcontour.io/v1
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;kind: HTTPProxy
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;metadata:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  name: www
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  namespace: http-proxy
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;spec:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  virtualhost:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    fqdn: www.$INGRESS_HOST
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  routes:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    - conditions:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;      - prefix: /
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;      services:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;        - name: nginx
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;          port: 80
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply the HTTPProxy manifest&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -n http-proxy -f http-proxy.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wait a few moments and then attempt to access the nginx service&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -s www.3.13.150.109.xip.io &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep h1
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;rate-limiting&#34;&gt;Rate Limiting&lt;/h4&gt;
&lt;p&gt;Now that your nginx is working via &lt;strong&gt;HTTPProxy&lt;/strong&gt; we can look at some of the more
advanced features. Let&amp;rsquo;s start with Rate limiting. Contour 1.12.0 supports doing
&lt;em&gt;local&lt;/em&gt; rate limiting, which means that each Envoy &lt;strong&gt;Pod&lt;/strong&gt; will have its own
limits, vs a &lt;em&gt;global&lt;/em&gt; rate limit which would need further coordination between
the Envoy &lt;strong&gt;Pods&lt;/strong&gt;. You can also set the Rate limit for the virtualhost, or for
a specific route.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s create a fairly aggressive rate limit so we can see the affects of it
fairly quickly. The example cluster I am using has three worker nodes, which
means three Envoy &lt;strong&gt;Pods&lt;/strong&gt; so if I set a rate limit of 2 per minute we should be
able to hit the limit after 6 requests.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a new &lt;strong&gt;HTTPProxy&lt;/strong&gt; resource with rate limiting enabled&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt; EOF &amp;gt; rate-limit.yaml
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;apiVersion: projectcontour.io/v1
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;kind: HTTPProxy
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;metadata:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  name: rate
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  namespace: http-proxy
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;spec:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  virtualhost:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    fqdn: rate.$INGRESS_HOST
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    rateLimitPolicy:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;      local:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;        requests: 2
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;        unit: minute
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  routes:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    - conditions:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;      - prefix: /
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;      services:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;        - name: nginx
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;          port: 80
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply the new rate limited manifest:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n http-proxy apply -f rate-limit.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wait a few moments and then fire up a while loop to connecting to the service
and watch it hit the limit after a few hits.&lt;/p&gt;
&lt;p&gt;Note: You&amp;rsquo;ll need to hit CTRL-C to break the while loop.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ &lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; true&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; curl -s rate.&lt;span class=&#34;nv&#34;&gt;$INGRESS_HOST&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep -E &lt;span class=&#34;s1&#34;&gt;&amp;#39;h1|rate&amp;#39;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;

&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
local_rate_limited
local_rate_limited
local_rate_limited
^C
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That&amp;rsquo;s it, rate limiting is enabled. This is incredibly useful if you have a
service with known limitations or you want to restrict any one user from
overwhelming the service.&lt;/p&gt;
&lt;h4 id=&#34;weighted-routing&#34;&gt;Weighted routing&lt;/h4&gt;
&lt;p&gt;The &lt;strong&gt;HTTPProxy&lt;/strong&gt; resource can also route a Virtual Host to multiple services,
this is a great feature if you want to perform Blue/Green deployments, or you
want to send a small percentage of requests to a special debug endpoint. Let&amp;rsquo;s
explore Weighted routing by adding an Apache service to receive 10% of the
requests.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a Deployment containing a basic httpd pod&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n http-proxy create deployment --image&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;httpd &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  httpd -o yaml &amp;gt; http-proxy-httpd-deployment.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a service for the deployment&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n http-proxy expose deployment httpd --port &lt;span class=&#34;m&#34;&gt;80&lt;/span&gt; -o yaml &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  &amp;gt; http-proxy-httpd-service.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ensure the new &lt;strong&gt;Pod&lt;/strong&gt; is available beside the existing nginx one.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pods -n http-proxy
NAME                     READY   STATUS    RESTARTS   AGE
httpd-757fb56c8d-kz476   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          23s
nginx-6799fc88d8-jxvj7   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          163m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;strong&gt;HTTPProxy&lt;/strong&gt; resource to perform weighted routing across the two services&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt; EOF &amp;gt; weighted.yaml
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;apiVersion: projectcontour.io/v1
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;kind: HTTPProxy
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;metadata:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  name: weight
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  namespace: http-proxy
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;spec:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  virtualhost:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    fqdn: weight.$INGRESS_HOST
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  routes:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    - conditions:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;      - prefix: /
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;      services:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;        - name: httpd
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;          port: 80
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;          weight: 10
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;        - name: nginx
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;          port: 80
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;          weight: 90
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply the new resource&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n http-proxy apply -f weighted.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Test the weighting&lt;/p&gt;
&lt;p&gt;Note: It&amp;rsquo;s not clear in the documentation, but it appears that the weighting
is applied per Envoy &lt;strong&gt;Pod&lt;/strong&gt;, so it might not be exactly 10% for small test
runs, but would statistically work out over time.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ &lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; true&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; curl -s weight.&lt;span class=&#34;nv&#34;&gt;$INGRESS_HOST&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep h1 &lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;html&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;It works!&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;
^C
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That&amp;rsquo;s it! we&amp;rsquo;ve successfully done a walk through of some of the new features of
Contour 1.12.0 and tested out both Rate Limiting and Weighted Routing. Let&amp;rsquo;s
clean up.&lt;/p&gt;
&lt;h4 id=&#34;cleanup&#34;&gt;Cleanup&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Delete your http-proxy namespace and resources&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n http-proxy delete -f .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Uninstall Contour&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ..
kubectl delete -f contour.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;As you can see Contour 1.12.0 is more than just an Ingress Controller as it
brings some of the more advanced features of a service mesh but without all the
extra resources required. Next time you find yourself looking to run Istio,
remember to check in with Contour and see if it will do what you need.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Gathering Metrics from Kubernetes with Prometheus and Grafana</title>
      
      <link>/guides/kubernetes/observability-prometheus-grafana-p1/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/observability-prometheus-grafana-p1/</guid>
      <description>

        
        &lt;p&gt;You have your Kubernetes cluster up, it’s running your applications, and
everything seems to be running great. Your work is done, right?&lt;/p&gt;
&lt;p&gt;If only it was that simple. Running in production means keeping a close eye on
how things are performing, so having data that provides such insight is
important. After all, being able to recognize potentially problematic patterns
in how your applications are performing or how Kubernetes is handling specific
workloads can mean the difference between making a quick fix and getting a call
at 3 a.m. because your website is down.&lt;/p&gt;
&lt;p&gt;Two open source tools that can help with this are Prometheus and Grafana.
Prometheus excels at gathering metrics from a wide array of sources, while
Grafana is the go-to tool for visualizing complex time-series data. These two
tools working in tandem are very powerful, and are very easy to install and use!&lt;/p&gt;
&lt;p&gt;In this guide, you’ll be setting up Prometheus and Grafana on an existing Kubernetes cluster, as well as setting up a dashboard in Grafana to visualize the data gathered from that cluster. You can use any Kubernetes installation of your choosing, whether it’s hosted on a cloud provider or even something like &lt;a href=&#34;https://minikube.sigs.k8s.io/docs/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Minikube&lt;/a&gt; running on your local machine.&lt;/p&gt;
&lt;h2 id=&#34;installing-prometheus&#34;&gt;Installing Prometheus&lt;/h2&gt;
&lt;p&gt;Luckily, there’s a comprehensive
&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/kube-prometheus&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm chart for Prometheus&lt;/a&gt;
with an extensive list of configuration options. If you’re not familiar with
Helm, make sure to check out
&lt;a href=&#34;/guides/kubernetes/helm-what-is/&#34;&gt;Helm: What Is it?&lt;/a&gt; and
&lt;a href=&#34;/guides/kubernetes/helm-gs/&#34;&gt;Getting Started With Helm&lt;/a&gt;. For this walkthrough,
you’ll be keeping things fairly straightforward, so if you’ve used Helm before,
or are just starting to learn, you will have seen most of what’s in this guide.&lt;/p&gt;
&lt;p&gt;To install Prometheus, you first need to add the Bitnami Helm repository by
using the &lt;code&gt;helm repo add&lt;/code&gt; command followed by the &lt;code&gt;helm repo update&lt;/code&gt; command to
pull in the latest metadata:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo update
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Before you install Prometheus, check out the
&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/kube-prometheus#parameters&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;configuration options&lt;/a&gt;
you have, because there are a lot of them. In this example, it’s assumed that
you’ll be installing with the default configuration into a Kubernetes cluster
with no specific requirements. As you can see, there are options for everything
from how each component is exposed (i.e., the type of ingress used, if it’s
behind a load balancer, etc.) to how data is stored and more. If this was a
production installation, you’d want to thoroughly sort out these options, but
for the purposes of this demo, you can install Prometheus with the default
configuration using the &lt;code&gt;helm install&lt;/code&gt; command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install prometheus bitnami/kube-prometheus
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After a few moments, you’ll see a few new pods created:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;alertmanager-prometheus-prometheus-oper-alertmanager-0   2/2     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          25m
prometheus-kube-state-metrics-68cb46fdd4-gk4jh           1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          25m
prometheus-node-exporter-rkg84                           1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          25m
prometheus-prometheus-oper-operator-745f4b599c-xjjsn     1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          25m
prometheus-prometheus-prometheus-oper-prometheus-0       3/3     Running   &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          25m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There are a few ways you can access Prometheus, but it largely depends on how
your Kubernetes cluster is configured. As the Prometheus documentation points
out, traditionally you would expose the server through a reverse proxy, such as
nginx. But since the default configuration of the Prometheus Helm chart only
exposes it to other pods in the Kubernetes cluster, you can instead take
advantage of the &lt;code&gt;kubectl port-forward&lt;/code&gt; command. Open a new terminal and keep it
open after running the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl port-forward --namespace default svc/prometheus-kube-prometheus-prometheus 9090:9090
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Great! The above command forwards all traffic to port 9090 on your machine to
the &lt;code&gt;prometheus-server&lt;/code&gt; pod, which you can see by visiting
&lt;a href=&#34;http://localhost:9090&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;http://localhost:9090&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-grafana/prometheus-001.png&#34; alt=&#34;Prometheus Dashboard&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;installing-grafana&#34;&gt;Installing Grafana&lt;/h2&gt;
&lt;p&gt;Much like Prometheus, Grafana has a great
&lt;a href=&#34;https://hub.helm.sh/charts/bitnami/grafana&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm chart&lt;/a&gt; for installing it.
Again, you’ll see a plethora of configuration options to tweak the installation
to your needs, but for this demo, you can just install it with the default
configuration to see it in action. You can install the &lt;code&gt;bitnami/grafana&lt;/code&gt; Helm
chart with the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install grafana bitnami/grafana
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After a few moments, you’ll see a new pod created:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;grafana-66c98bcb86-xpd5t                         1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          2d23h
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There’s one additional step you’ll need to take. The Grafana Helm chart
generates a random password for you and stores it as a secret in Kubernetes. You
can retrieve this password by running the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get secret grafana-admin --namespace default -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{.data.GF_SECURITY_ADMIN_PASSWORD}&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; base64 --decode&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note the password, as you’ll be needing it shortly. Like the Prometheus install,
you may have different requirements or capabilities for exposing services
outside of your Kubernetes cluster, but you can again use the
&lt;code&gt;kubectl port-forward&lt;/code&gt; command. Open a new terminal and run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;POD_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get pods --namespace default -l &lt;span class=&#34;s2&#34;&gt;&amp;#34;app.kubernetes.io/name=grafana,app.kubernetes.io/instance=grafana&amp;#34;&lt;/span&gt; -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{.items[0].metadata.name}&amp;#34;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
kubectl --namespace default port-forward &lt;span class=&#34;nv&#34;&gt;$POD_NAME&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With this command running, you can now access Grafana at
&lt;a href=&#34;http://localhost:3000&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;http://localhost:3000&lt;/a&gt;! You’ll be prompted for a
username, which by default is &lt;code&gt;admin&lt;/code&gt;, along with the password you just
retrieved. Though when you log in, you may notice that things are a bit bare.
That’s because, while Prometheus is automatically gathering metrics from your
Kubernetes cluster, Grafana doesn’t know anything about your Prometheus install.
It does, however, know how to speak to a Prometheus server, and makes it very
easy to configure it as a data source.&lt;/p&gt;
&lt;h2 id=&#34;visualizing-prometheus-data-in-grafana&#34;&gt;Visualizing Prometheus Data in Grafana&lt;/h2&gt;
&lt;p&gt;If you mouse over the cogwheel on the left-hand side of the Grafana screen,
you’ll be prompted with several configuration options. Choose “Data Sources,”
followed by “Add data source.” Here, you’ll see a long list of data sources that
Grafana knows how to talk to automatically, and luckily Prometheus is on that
list. Choose “Prometheus” and you’ll be brought to the configuration screen for
your new data source.&lt;/p&gt;
&lt;p&gt;If you didn’t change the default configuration when installing Prometheus,
you’ll only need to give it a name of your choosing, as well as the URL where
Prometheus is running. Since both are running in the same cluster, you can
connect Grafana to Prometheus using the internal DNS to Kubernetes by providing
it the service name that Prometheus is connected to:
&lt;code&gt;http://prometheus-kube-prometheus-prometheus.default.svc.cluster.local:9090&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-grafana/prometheus-002.png&#34; alt=&#34;Adding a new Grafana data source&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;If you’re already familiar with creating dashboards and
&lt;a href=&#34;https://grafana.com/docs/grafana/latest/panels/panels-overview/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;panels&lt;/a&gt; in
Grafana, you’re all set! However, if you’re new to Grafana, don’t worry; this is
where you can once again look to the great community for information about these
tools. The Grafana website has a huge repository of dashboards that can be
easily shared and imported into your own Grafana installation. And all you need
in order to import one of these dashboards from the Grafana site is a single ID
number. Take &lt;a href=&#34;https://grafana.com/grafana/dashboards/10000&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;this dashboard&lt;/a&gt;, for
example. You can see that it has an ID of “10000.”&lt;/p&gt;
&lt;p&gt;To import this dashboard, mouse over the “Dashboards” section on the left-hand
side of the Grafana screen (the icon is four squares) and choose “Manage.” On
the top right of the dashboard management screen, click “Import” and you’ll be
prompted for the URL, ID, or JSON for the dashboard that you wish to import.
Under “Import via grafana.com,” enter “10000,” matching the ID of the dashboard
that you wish to import. Feel free to change the name or the unique identifier,
but the one thing you must provide is the data source, which is asked for on the
bottom of the configuration screen. Choose your Prometheus data source, click
“Import,” and you will be greeted by your newly created, but fully populated,
dashboard!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-grafana/prometheus-003.png&#34; alt=&#34;Grafana dashboard showing Kubernetes metrics&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What’s Next?&lt;/h2&gt;
&lt;p&gt;The great news is that any data gathered from Prometheus can be used in Grafana.
That means any pod with the
&lt;a href=&#34;https://github.com/helm/charts/tree/master/stable/prometheus#scraping-pod-metrics-via-annotations&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;proper annotations&lt;/a&gt;
will automatically get scraped by Prometheus. Many languages and frameworks have
&lt;a href=&#34;https://prometheus.io/docs/instrumenting/clientlibs/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;libraries that support exposing metrics&lt;/a&gt;
that Prometheus can gather, including
&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-features.html#production-ready-metrics-export-prometheus&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Spring&lt;/a&gt;.
Make sure to check out the libraries available for your language of choice!
Additionally, if you&amp;rsquo;re looking to learn more about observability and how to get
better insight into your applications, make sure to check out our
&lt;a href=&#34;/patterns/observability/&#34;&gt;growing collection of guides&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: What are Kubernetes Secrets and Service Accounts?</title>
      
      <link>/guides/kubernetes/platform-security-secrets-sa-what-is/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/platform-security-secrets-sa-what-is/</guid>
      <description>

        
        &lt;p&gt;In software, there’s often data that you want to keep separate from your build
process. These could be simple configuration properties, such as URLs or IP
addresses, or more sensitive data, such as usernames and passwords, OAuth tokens
or TLS certificates. In Kubernetes, these are referred to as
&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/secret/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Secrets&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;secrets&#34;&gt;Secrets&lt;/h2&gt;
&lt;p&gt;It’s worth noting that while the name “secret” may imply “secure”, there are
some qualifiers. By default, all secrets are stored unencrypted in &lt;code&gt;etcd&lt;/code&gt;. As of
Kubernetes 1.13 though, operators are given the option of
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;encrypting data at rest in etcd&lt;/a&gt;.
Additionally, you can
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kms-provider/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;integrate with an external Key Management Service&lt;/a&gt;,
such as &lt;a href=&#34;https://cloud.google.com/kms/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Google Cloud KMS&lt;/a&gt; or
&lt;a href=&#34;https://www.vaultproject.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;HashiCorp Vault&lt;/a&gt;. This guide doesn’t cover these
topics, but the above links are a great start to learn more.&lt;/p&gt;
&lt;p&gt;All examples used in this guide can be
&lt;a href=&#34;https://github.com/BrianMMcClain/k8s-secrets-and-sa&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;found on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Before you can get started using secrets, you first need to create a secret. As
you may expect, this can be done by defining an object of kind &lt;code&gt;Secret&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Secret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysecret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Opaque&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bXl1c2VybmFtZQo=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#Base64 encoded value of &amp;#34;myusername&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bXlwYXNzd29yZAo=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#Base64 encoded value of &amp;#34;mypassword&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Secrets in Kubernetes are, at their most basic form, a collection of keys and
values. The above example creates a secret named &lt;code&gt;mysecret&lt;/code&gt; with two keys:
&lt;code&gt;username&lt;/code&gt; and &lt;code&gt;password&lt;/code&gt;. There’s one very important thing to note though,
which is that the values of these key/value pairs are encoded as base64.
Remember that base64 is an encoding algorithm, not an encryption algorithm. This
is done to help facilitate data that may not be entirely alpha-numeric, and
instead could include binary data, non-ASCII data, etc. You apply can this YAML
as you would if you were creating any other Kubernetes object:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f https://raw.githubusercontent.com/BrianMMcClain/k8s-secrets-and-sa/main/secret-base64.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once applied, you can see that while you can get the secret with &lt;code&gt;kubectl&lt;/code&gt;, it
avoids printing the values of each key by default:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl describe secret mysecret

Name:         mysecret
Namespace:    default
Labels:       &amp;lt;none&amp;gt;
Annotations:  
Type:         Opaque

&lt;span class=&#34;nv&#34;&gt;Data&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;====&lt;/span&gt;
password:  &lt;span class=&#34;m&#34;&gt;11&lt;/span&gt; bytes
username:  &lt;span class=&#34;m&#34;&gt;11&lt;/span&gt; bytes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Of course, if you want to see the base64-encoded contents of the secret, you can
still fetch them with a slightly different command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get secret mysecret -o yaml

apiVersion: v1
data:
  password: &lt;span class=&#34;nv&#34;&gt;bXlwYXNzd29yZAo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;
  username: &lt;span class=&#34;nv&#34;&gt;bXl1c2VybmFtZQo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;
kind: Secret
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Great! With your secret created, it’s time to start creating pods to use it!
You’re faced with another decision, however, since Kubernetes provides a couple
of methods for presenting secrets to a pod. The first example you’ll look at is
mounting them as files in a volume:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;secret-as-file&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;secret-as-file&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumeMounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysecretvol&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/etc/mysecret&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readOnly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysecretvol&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secret&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysecret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here, a new pod named &lt;code&gt;secret-as-file&lt;/code&gt; is created from the
&lt;a href=&#34;https://hub.docker.com/_/nginx&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;NGINX Docker image&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;NOTE: The nginx container image is used here simply because it&amp;rsquo;s an easily
accessible long-running process, this would look the same for your own container
image.&lt;/p&gt;
&lt;p&gt;There are two sections to point out, the first being the &lt;code&gt;volumes&lt;/code&gt; section,
which defines a new volume. Kubernetes has
&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;many different types of volumes to choose from&lt;/a&gt;,
but for this case you’re specifically interested in creating a
&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volumes/#secret&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;volume of type &lt;code&gt;secret&lt;/code&gt;&lt;/a&gt;.
These volumes are backed by &lt;code&gt;tmpfs&lt;/code&gt;, a RAM-based file system, rather than
written to a persistent disk. Secret volumes require you to define the secret to
mount (in the &lt;code&gt;secretName&lt;/code&gt; field), and for each key in your secret, it creates a
file that contains the key’s value. You can see this in action by applying this
YAML and then listing the files at the &lt;code&gt;mountPath&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f https://raw.githubusercontent.com/BrianMMcClain/k8s-secrets-and-sa/main/pod-secret-as-file.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; secret-as-file -- ls /etc/mysecret

password
username

$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; secret-as-file -- cat /etc/mysecret/username

myusername
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As you can see, there are two files in the volume that was created: &lt;code&gt;password&lt;/code&gt;
and &lt;code&gt;username&lt;/code&gt;. If you print out the contents of the &lt;code&gt;username&lt;/code&gt; file, you can
see the secret’s value of &lt;code&gt;myusername&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; secret-as-file -- cat /etc/mysecret/username

myusername
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Alternatively, secrets can also be presented to your container as environment
variables. Consider the following YAML:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;secret-as-env&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;secret-as-env&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;SECRET_USERNAME&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;valueFrom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretKeyRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysecret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;SECRET_PASSWORD&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;valueFrom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretKeyRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysecret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here, instead of defining volumes that reference your secret, two environment
variables are defined and reference the secret name and key name. Applying this
YAML allows you to retrieve these environment variables from a shell in the pod:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f https://raw.githubusercontent.com/BrianMMcClain/k8s-secrets-and-sa/main/pod-secret-as-env.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; secret-as-env -- sh -c &lt;span class=&#34;s2&#34;&gt;&amp;#34;echo \$SECRET_USERNAME&amp;#34;&lt;/span&gt;

myusername
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As you can see, the value of your secret is stored in the &lt;code&gt;$SECRET_USERNAME&lt;/code&gt;
environment variable as defined!&lt;/p&gt;
&lt;h2 id=&#34;service-accounts&#34;&gt;Service Accounts&lt;/h2&gt;
&lt;p&gt;When you interact directly with Kubernetes, using &lt;code&gt;kubectl&lt;/code&gt; for example, you’re
using a user account. When processes in pods need to interact with Kubernetes
though, they use a
&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;service account&lt;/a&gt;,
which describes the set of permissions they have within Kubernetes. The good
news is that out of the box, all pods are given the &lt;code&gt;default&lt;/code&gt; service account.
Unless your Kubernetes administrator has changed the &lt;code&gt;default&lt;/code&gt; service account
though, the permissions are limited. If you run &lt;code&gt;kubectl&lt;/code&gt; in a container on
Kubernetes, it will automatically know where to find the cluster that it&amp;rsquo;s
running on. You can verify this by standing up a pod and running
&lt;code&gt;kubectl version&lt;/code&gt;, which will show information about the server it&amp;rsquo;s connected
to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl run -it kubectl --restart&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;Never --rm --image&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;brianmmcclain/kubectl-alpine -- /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl version

Client Version: version.Info&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;Major:&lt;span class=&#34;s2&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;, Minor:&lt;span class=&#34;s2&#34;&gt;&amp;#34;18&amp;#34;&lt;/span&gt;, GitVersion:&lt;span class=&#34;s2&#34;&gt;&amp;#34;v1.18.4&amp;#34;&lt;/span&gt;, GitCommit:&lt;span class=&#34;s2&#34;&gt;&amp;#34;c96aede7b5205121079932896c4ad89bb93260af&amp;#34;&lt;/span&gt;, GitTreeState:&lt;span class=&#34;s2&#34;&gt;&amp;#34;clean&amp;#34;&lt;/span&gt;, BuildDate:&lt;span class=&#34;s2&#34;&gt;&amp;#34;2020-06-17T11:41:22Z&amp;#34;&lt;/span&gt;, GoVersion:&lt;span class=&#34;s2&#34;&gt;&amp;#34;go1.13.9&amp;#34;&lt;/span&gt;, Compiler:&lt;span class=&#34;s2&#34;&gt;&amp;#34;gc&amp;#34;&lt;/span&gt;, Platform:&lt;span class=&#34;s2&#34;&gt;&amp;#34;linux/amd64&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
Server Version: version.Info&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;Major:&lt;span class=&#34;s2&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;, Minor:&lt;span class=&#34;s2&#34;&gt;&amp;#34;18&amp;#34;&lt;/span&gt;, GitVersion:&lt;span class=&#34;s2&#34;&gt;&amp;#34;v1.18.2&amp;#34;&lt;/span&gt;, GitCommit:&lt;span class=&#34;s2&#34;&gt;&amp;#34;52c56ce7a8272c798dbc29846288d7cd9fbae032&amp;#34;&lt;/span&gt;, GitTreeState:&lt;span class=&#34;s2&#34;&gt;&amp;#34;clean&amp;#34;&lt;/span&gt;, BuildDate:&lt;span class=&#34;s2&#34;&gt;&amp;#34;2020-04-30T20:19:45Z&amp;#34;&lt;/span&gt;, GoVersion:&lt;span class=&#34;s2&#34;&gt;&amp;#34;go1.13.9&amp;#34;&lt;/span&gt;, Compiler:&lt;span class=&#34;s2&#34;&gt;&amp;#34;gc&amp;#34;&lt;/span&gt;, Platform:&lt;span class=&#34;s2&#34;&gt;&amp;#34;linux/amd64&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Notice that you haven’t provided any credentials or configuration file. This
information is provided by Kubernetes and the &lt;code&gt;default&lt;/code&gt; service account.
However, almost any attempt at interacting with the Kubernetes API will be
greeted with denial:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pods

Error from server &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;Forbidden&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;: pods is forbidden: User
&lt;span class=&#34;s2&#34;&gt;&amp;#34;system:serviceaccount:default:default&amp;#34;&lt;/span&gt; cannot list resource &lt;span class=&#34;s2&#34;&gt;&amp;#34;pods&amp;#34;&lt;/span&gt; in API group
&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt; in the namespace &lt;span class=&#34;s2&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;

$ &lt;span class=&#34;nb&#34;&gt;exit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note: If you need to check if you have permission to run a command before
actually running it, you can use the &lt;code&gt;kubectl auth can-i&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl auth can-i get pods
no
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To address this, you can
&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;create a new service account&lt;/a&gt;
with a wider set of permissions. This is demonstrated in the following YAML:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Role&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pod-read-role&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;apiGroups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# &amp;#34;&amp;#34; indicates the core API group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;pods&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;verbs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;get&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;watch&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;list&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ServiceAccount&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pod-read-sa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;RoleBinding&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pod-read-rolebinding&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subjects&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ServiceAccount&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pod-read-sa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;roleRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Role&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pod-read-role&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here, three things are created: a &lt;code&gt;Role&lt;/code&gt; named “pod-read-role”, a
&lt;code&gt;ServiceAccount&lt;/code&gt;, and a &lt;code&gt;RoleBinding&lt;/code&gt; to tie them together. Specifically, the
&lt;code&gt;Role&lt;/code&gt; gives access to the “get”, “watch” and “list” actions on the resource
“pods”. Described more simply, this role allows you to read information about
pods, but not write or delete information about pods. This will allow you to do
things like &lt;code&gt;kubectl get pods&lt;/code&gt;, but not &lt;code&gt;kubectl delete pod&lt;/code&gt;. You can see this
in action by applying this YAML, creating a pod with this service account and
running the commands yourself:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f https://raw.githubusercontent.com/BrianMMcClain/k8s-secrets-and-sa/main/role-sa-pod-read.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl run -it --restart&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;Never --rm kubectl-with-sa --image&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;brianmmcclain/kubectl-alpine --serviceaccount&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;pod-read-sa -- /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pods

NAME              READY   STATUS    RESTARTS   AGE
kubectl           1/1     Running   &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          22s
kubectl-with-sa   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          6s
secret-as-env     1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          3h40m
secret-as-file    1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          4h10m

$ kubectl delete pod secret-as-file

Error from server &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;Forbidden&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;: pods &lt;span class=&#34;s2&#34;&gt;&amp;#34;secrets-as-file&amp;#34;&lt;/span&gt; is forbidden: User
&lt;span class=&#34;s2&#34;&gt;&amp;#34;system:serviceaccount:default:pod-read-sa&amp;#34;&lt;/span&gt; cannot delete resource &lt;span class=&#34;s2&#34;&gt;&amp;#34;pods&amp;#34;&lt;/span&gt; in API
group &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt; in the namespace &lt;span class=&#34;s2&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;

$ &lt;span class=&#34;nb&#34;&gt;exit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, the combination of secrets and service accounts can be leveraged to
pull container images from private registries by
&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;using the &lt;code&gt;imagePullSecrets&lt;/code&gt; configuration property&lt;/a&gt;.
You can create a secret from the command line with the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create secret docker-registry myregistrykey --docker-server&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;DUMMY_SERVER &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;        --docker-username&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;DUMMY_USERNAME --docker-password&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;DUMMY_DOCKER_PASSWORD &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;        --docker-email&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;DUMMY_DOCKER_EMAIL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note: The secret used here isn&amp;rsquo;t exposed to the pod in the same way that you&amp;rsquo;ve
seen earlier. The processes inside the containers of the pod don&amp;rsquo;t have access
to this information. Instead, Kubernetes knows that it needs to use these
credentials to pull the container images.&lt;/p&gt;
&lt;p&gt;Once you create the secret by filling in your registry’s server, username,
password, and email, you can create a service account, or edit an existing one,
to use this secret when pulling container images. For example, you can add this
to the &lt;code&gt;default&lt;/code&gt; service account. Make note, however, that this will overwrite
any &lt;code&gt;imagePullSecret&lt;/code&gt; previously set:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl patch serviceaccount default -p &lt;span class=&#34;s1&#34;&gt;&amp;#39;{&amp;#34;imagePullSecrets&amp;#34;: [{&amp;#34;name&amp;#34;: &amp;#34;myregistrykey&amp;#34;}]}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Since this adds the &lt;code&gt;imagePullSecrets&lt;/code&gt; property to the default service account,
any pod that you create without specifying a different service account will have
these permissions. However, it&amp;rsquo;s worth noting that you can also
&lt;a href=&#34;https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;specify &lt;code&gt;imagePullSecrets&lt;/code&gt; on an individual pod&lt;/a&gt;
if it fits your deployment model better.&lt;/p&gt;
&lt;h2 id=&#34;cleanup&#34;&gt;Cleanup&lt;/h2&gt;
&lt;p&gt;To remove the resources that you&amp;rsquo;ve created, you can use &lt;code&gt;kubectl delete -f&lt;/code&gt;
command and provide the file names used when applying them:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl delete -f &amp;lt;insert file&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;
&lt;p&gt;As with all things Kubernetes, the best place to go to keep learning is the
&lt;a href=&#34;https://kubernetes.io/docs/home/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;official documentation&lt;/a&gt;, which covers
&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/secret/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;secrets&lt;/a&gt; and
&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;service accounts&lt;/a&gt;
in even greater detail. You can also see where these are used in other guides,
such as &lt;a href=&#34;/guides/containers/cnb-gs-kpack/&#34;&gt;Getting Started with kpack&lt;/a&gt; and
&lt;a href=&#34;/guides/ci-cd/tekton-gs-p1/&#34;&gt;Getting Started with Tekton&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: How to use Harbor Registry to Eliminate Docker Hub Rate Limits</title>
      
      <link>/guides/kubernetes/harbor-as-docker-proxy/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/harbor-as-docker-proxy/</guid>
      <description>

        
        
&lt;div class=&#34;youtube-video-shortcode&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/KSH2Hzk-E7U&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;div align=&#34;center&#34;&gt;&lt;i&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=KSH2Hzk-E7U&amp;feature=youtu.be&#34;&gt;Watch Paul Walk through this guide on Tanzu.TV Shortcuts.&lt;/a&gt;&lt;/i&gt;&lt;/div&gt;
&lt;p&gt;On August 24 2020 &lt;a href=&#34;https://docker.com&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Docker&lt;/a&gt; announced they would be
implementing
&lt;a href=&#34;https://www.docker.com/blog/scaling-docker-to-serve-millions-more-developers-network-egress/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Rate Limits on the Docker Hub&lt;/a&gt;
and they were
&lt;a href=&#34;https://www.docker.com/blog/what-you-need-to-know-about-upcoming-docker-hub-rate-limiting/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;implemented on November 2 2020&lt;/a&gt;
thus ending our free ride of unlimited Docker Image pulls.&lt;/p&gt;
&lt;p&gt;Unless you&amp;rsquo;re a paid customer of Docker or very lucky you&amp;rsquo;ve probably started to
see errors like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ERROR: toomanyrequests: Too Many Requests.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;You have reached your pull rate limit. You may increase
the limit by authenticating and upgrading:
https://www.docker.com/increase-rate-limits.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This can be very frustrating, especially in Kubernetes where it might not be
apparent why your new Pod is just sitting there in a &lt;code&gt;Pending&lt;/code&gt; state. Imagine
this happening right as you need to scale your Deployments to serve a sudden
increase in traffic.&lt;/p&gt;
&lt;p&gt;This would be where a troll on Reddit (You know the sort, the kind that will
&amp;ldquo;&lt;a href=&#34;https://news.ycombinator.com/item?id=6277943&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;What you guys are referring to as Linux, is in fact, GNU/Linux&amp;rdquo;&lt;/a&gt;
at you would proclaim
&amp;ldquo;&lt;a href=&#34;https://www.whoownsmyavailability.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;You own your availability&lt;/a&gt;&amp;rdquo;. He&amp;rsquo;s not
wrong &amp;hellip; but also not helpful.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/harbor-as-docker-proxy/tweet-who-owns-your-availability.png&#34; alt=&#34;that twitter troll&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Thankfully the team developing the &lt;a href=&#34;https://goharbor.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Harbor Registry&lt;/a&gt; have
been hard at work to ensure that you can access the images you need without
downloading the whole internet to your server.&lt;/p&gt;
&lt;p&gt;There are actually two features in Harbor that will let us work around the rate
limits, Registry Replication, and Registry Proxy.&lt;/p&gt;
&lt;p&gt;Registry Replication allows you to replicate images between registries, whereas
Proxy lets you keep a local copy of images on an as-requested basis.&lt;/p&gt;
&lt;p&gt;In a production scenario you would probably look to Replication so that you can
be very specific about what Images to allow, however in a Development scenario
you might use Proxy-ing as you don&amp;rsquo;t necessarily know ahead of time what Images
you might need access to. Further using Proxy-ing can be really useful for a
home lab to cut down on internet traffic as you pull images.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll explore both options below.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;Before you get started, you&amp;rsquo;ll need Harbor (ideally version 2.1.3 or newer)
installed somewhere. If you don&amp;rsquo;t already have it installed, we&amp;rsquo;ve made it
incredibly easy for your with our &lt;a href=&#34;../harbor-gs/&#34;&gt;Getting Started with Harbor&lt;/a&gt;
Guide.&lt;/p&gt;
&lt;p&gt;Once you have a Harbor registry installed, log into it&amp;rsquo;s Web UI as an Admin user.&lt;/p&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Confirm Versions&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Note: Docker has been rapidly changing both the Docker Hub and the Docker CLI,
this makes it difficult for Integrations such as Harbor&amp;rsquo;s replication / proxy
features to keep pace. To ensure the best chance of functionality, ensure you&amp;rsquo;re
using the versions stated in this document.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;set-up-a-registry-endpoint&#34;&gt;Set up a Registry Endpoint&lt;/h2&gt;
&lt;p&gt;Whether doing replication or proxy, you need to configure Dockerhub as a
replication endpoint.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Go to &lt;strong&gt;Administration&lt;/strong&gt; -&amp;gt; &lt;strong&gt;Registries&lt;/strong&gt; and click the &lt;strong&gt;+ New Endpoint&lt;/strong&gt; button.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set the &lt;strong&gt;Provider&lt;/strong&gt; and &lt;strong&gt;Name&lt;/strong&gt; both to &lt;code&gt;Docker Hub&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can leave the rest of the settings as default, unless you want access to
private images, in which case add in your &lt;strong&gt;Access ID&lt;/strong&gt; and &lt;strong&gt;Access
Secret&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/harbor-as-docker-proxy/create-endpoint.png&#34; alt=&#34;Create Endpoint&#34;  /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Press the &lt;strong&gt;Test Connection&lt;/strong&gt; button and an a successful test hit &lt;strong&gt;OK&lt;/strong&gt; to save.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-a-dockerhub-proxy&#34;&gt;Create a Dockerhub Proxy&lt;/h2&gt;
&lt;p&gt;For more information about how Proxy Projects work, see the
&lt;a href=&#34;https://goharbor.io/docs/2.1.0/administration/configure-proxy-cache/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Go to &lt;strong&gt;Projects&lt;/strong&gt; and click the &lt;strong&gt;+ New Project&lt;/strong&gt; button.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set &lt;strong&gt;Project Name&lt;/strong&gt; to &lt;code&gt;dockerhub-proxy&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set &lt;strong&gt;Access Level&lt;/strong&gt; to &lt;code&gt;Public&lt;/code&gt; (unless you intend to make it private and require login).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Leave &lt;strong&gt;Storage Quota&lt;/strong&gt; at the default &lt;code&gt;-1 GB&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set &lt;strong&gt;Proxy Cache&lt;/strong&gt; to &lt;code&gt;Docker Hub&lt;/code&gt; (the Endpoint we created earlier).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/harbor-as-docker-proxy/create-proxy-project.png&#34; alt=&#34;Create Proxy Project&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Test the proxy is working with &lt;code&gt;docker pull&lt;/code&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ docker pull &amp;lt;url-of-registry&amp;gt;/dockerhub-proxy/library/ubuntu:20.04
20.04: Pulling from dockerhub-proxy/library/ubuntu
83ee3a23efb7: Pull &lt;span class=&#34;nb&#34;&gt;complete&lt;/span&gt;
db98fc6f11f0: Pull &lt;span class=&#34;nb&#34;&gt;complete&lt;/span&gt;
f611acd52c6c: Pull &lt;span class=&#34;nb&#34;&gt;complete&lt;/span&gt;
Digest: sha256:703218c0465075f4425e58fac086e09e1de5c340b12976ab9eb8ad26615c3715
Status: Downloaded newer image &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; harbor.aws.paulczar.wtf/dockerhub-proxy/library/ubuntu:20.04
harbor.aws.paulczar.wtf/dockerhub-proxy/library/ubuntu:20.04
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;aside aside-warning&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Content-Type Error&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;If you receive error
&lt;code&gt;Error response from daemon: missing or empty Content-Type header&lt;/code&gt;, you&amp;rsquo;ll need
to upgrade Harbor to version 2.1.3 as some changes in Docker have had downstream
ripple effects. Older versions of Docker will still work.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;configure-docker-hub-replication&#34;&gt;Configure Docker Hub Replication&lt;/h2&gt;
&lt;h3 id=&#34;create-a-project-to-replicate-to&#34;&gt;Create a Project to replicate to&lt;/h3&gt;
&lt;p&gt;With Proxy-ing enabled, let&amp;rsquo;s now turn our eyes to Replication. This is where we
can surgically select which images we want to make available.&lt;/p&gt;
&lt;p&gt;For more information about how Replication works, see the
&lt;a href=&#34;https://goharbor.io/docs/2.1.0/administration/configuring-replication/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Go to &lt;strong&gt;Projects&lt;/strong&gt; and click the &lt;strong&gt;+ New Project&lt;/strong&gt; button.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set &lt;strong&gt;Project Name&lt;/strong&gt; to &lt;code&gt;dockerhub-replica&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Leave all other settings as their defaults.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/harbor-as-docker-proxy/create-replica-project.png&#34; alt=&#34;Create Replica Project&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;create-a-replication-rule&#34;&gt;Create a Replication Rule&lt;/h3&gt;
&lt;p&gt;Next we create a Replication Rule to determine the specific Images we want to
replicate. In this case we want only the &lt;code&gt;library/python:3.8.2-slim&lt;/code&gt; image. We
restrict this as Replication can quickly hit the Docker Hub rate limits.&lt;/p&gt;
&lt;p&gt;The resource filters support basic pattern recognition, so you could use
&lt;code&gt;library/**&lt;/code&gt; if you wanted to replicate all of the official images, however this
would quickly hit the rate limits.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Go to &lt;strong&gt;Administration&lt;/strong&gt; -&amp;gt; &lt;strong&gt;Replication&lt;/strong&gt; and click the &lt;strong&gt;+ New Replication Rule&lt;/strong&gt; button.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set &lt;strong&gt;Name&lt;/strong&gt; to &lt;code&gt;dockerhub-python-slim&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set &lt;strong&gt;Replication mode&lt;/strong&gt; to &lt;code&gt;Pull-based&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set &lt;strong&gt;Source registry&lt;/strong&gt; to &lt;code&gt;Docker Hub&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set &lt;strong&gt;Source resource filter&lt;/strong&gt; -&amp;gt; &lt;strong&gt;Name&lt;/strong&gt; to &lt;code&gt;library/python&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set &lt;strong&gt;Source resource filter&lt;/strong&gt; -&amp;gt; &lt;strong&gt;Tag&lt;/strong&gt; to &lt;code&gt;3.8.2-slim&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set &lt;strong&gt;Destination namespace&lt;/strong&gt; to &lt;code&gt;dockerhub-replica/python&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Leave the rest as their defaults.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/harbor-as-docker-proxy/create-replica-python.png&#34; alt=&#34;Create Replica for Python&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;test-replication&#34;&gt;Test Replication&lt;/h3&gt;
&lt;p&gt;We chose manual replication (so that we don&amp;rsquo;t overwhelm the rate limits) so we
need to actually perform the replication step, and then validate that it worked.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Administration&lt;/strong&gt; -&amp;gt; &lt;strong&gt;Replication&lt;/strong&gt; and click the
&lt;strong&gt;dockerhub-python-slim&lt;/strong&gt; item then click the &lt;strong&gt;Replicate&lt;/strong&gt; Button.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Harbor will kick off the replication and will show the attempt below in the
&lt;strong&gt;Executions&lt;/strong&gt; section. You can click on it for more details or logs, but for
now we&amp;rsquo;re just waiting for it to &lt;strong&gt;finish&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Projects&lt;/strong&gt; and select &lt;strong&gt;dockerhub-replica&lt;/strong&gt; then click
&lt;strong&gt;Repositories&lt;/strong&gt;. You should see &lt;code&gt;dockerhub-replica/python/python&lt;/code&gt; with at
least one Artifact. *To avoid this accidental redundancy in the name we
should have set &lt;strong&gt;Destination namespace&lt;/strong&gt; to &lt;code&gt;dockerhub-replica&lt;/code&gt; rather than
&lt;code&gt;dockerhub-replica/python&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/harbor-as-docker-proxy/replica-success.png&#34; alt=&#34;Successful replication&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;That&amp;rsquo;s it! We&amp;rsquo;ve learned how to replicate Docker images from Docker Hub using
both Proxy-ing and Replication. This can be applied for Harbor to Harbor
replication as well. It&amp;rsquo;s not uncommon to have one main Harbor registry as the
source of truth and then Replication to remote sites, and Proxy-ing to edge
sites.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Getting Started with Using Helm to Deploy Apps on Kubernetes</title>
      
      <link>/guides/kubernetes/helm-gs/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/helm-gs/</guid>
      <description>

        
        &lt;p&gt;&lt;a href=&#34;https://helm.sh&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm&lt;/a&gt; is a tool to help you define, install, and upgrade applications running on Kubernetes. For more information, be sure to check out &lt;a href=&#34;../helm-what-is/&#34;&gt;Helm: What Is It?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this guide you&amp;rsquo;ll deploy a simple application using Helm to a Kubernetes cluster.&lt;/p&gt;
&lt;h2 id=&#34;before-you-begin&#34;&gt;Before You Begin&lt;/h2&gt;
&lt;p&gt;There are a few things you need to do before getting started with Helm:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Have access to a Kubernetes cluster. If you don&amp;rsquo;t, you can use local options like &lt;a href=&#34;https://hub.docker.com/search?type=edition&amp;amp;offering=community&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Docker Desktop&lt;/a&gt; or &lt;a href=&#34;https://github.com/kubernetes/minikube&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Minikube&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check out &lt;a href=&#34;https://kube.academy/courses/getting-started&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Getting Started with Kubernetes&lt;/a&gt; on KubeAcademy, particularly if you&amp;rsquo;ve never worked with Kubernetes before.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the documentation for &lt;a href=&#34;https://helm.sh/docs/intro/install/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;installing Helm&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Helm leverages your local Kubernetes context to operate, so it will have whatever permissions the account you&amp;rsquo;re using for &lt;code&gt;kubectl&lt;/code&gt; does.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you read about Helm and come across references to &lt;code&gt;tiller&lt;/code&gt;, previous versions (before version 3) required an extra component installed on the Kubernetes cluster.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;initial-helm-setup&#34;&gt;Initial Helm Setup&lt;/h2&gt;
&lt;p&gt;You&amp;rsquo;re going to need a chart to deploy with Helm, so the easiest thing is to connect to a chart repository with the &lt;code&gt;helm repo&lt;/code&gt; command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ helm repo add bitnami https://charts.bitnami.com/bitnami
&amp;quot;bitnami&amp;quot; has been added to your repositories
$ helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the &amp;quot;bitnami&amp;quot; chart repository
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now that you have a repo connected, you need to see which charts you have available to deploy.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ helm search repo bitnami
NAME                            	CHART VERSION	APP VERSION            	DESCRIPTION
bitnami/bitnami-common          	0.0.8        	0.0.8                  	Chart with custom templates used in Bitnami cha...
bitnami/airflow                 	5.0.3        	1.10.9                 	Apache Airflow is a platform to programmaticall...
bitnami/apache                  	7.3.9        	2.4.41                 	Chart for Apache HTTP Server
---- Truncated ----
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can see a whole list of charts, but the output above shows the first three. It shows the name of the chart, the versions, and the descriptions. As you&amp;rsquo;ll see, there&amp;rsquo;s both a chart version and an app version. That&amp;rsquo;s because a chart may be updated and changed separately from the underlying application it is deploying.&lt;/p&gt;
&lt;h2 id=&#34;time-to-deploy-a-chart-create-a-release&#34;&gt;Time to Deploy a Chart (Create a Release)&lt;/h2&gt;
&lt;p&gt;Now that you have Helm configured with a repo, you can deploy a chart. In Helm lingo that&amp;rsquo;s called &lt;em&gt;creating a release&lt;/em&gt;. In this example, you&amp;rsquo;ll deploy a pretty simple one, like nginx. You can supply a name for your app like you&amp;rsquo;re going to do here (my app) or you can use the &lt;code&gt;--generate-name&lt;/code&gt; CLI option to have Helm generate one for you.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;l&#34;&gt;$ helm install my-app bitnami/nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;NAME&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;LAST DEPLOYED&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Mon Mar 9 07:37:28 2020&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;NAMESPACE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;STATUS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;deployed&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;REVISION&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;TEST SUITE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;NOTES&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Get the NGINX URL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;NOTE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;It may take a few minutes for the LoadBalancer IP to be available.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Watch the status with&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;kubectl get svc --namespace default -w my-app-nginx&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;export SERVICE_IP=$(kubectl get svc --namespace default my-app-nginx --template &amp;#34;{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}&amp;#34;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;echo &amp;#34;NGINX URL: http://$SERVICE_IP/&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After your release is successfully created, you&amp;rsquo;ll see an output like this with the name, namespace, status, etc. The &lt;code&gt;NOTES&lt;/code&gt; section has specific information about your install; that&amp;rsquo;s because it&amp;rsquo;s generated by Helm using a template, too.&lt;/p&gt;
&lt;p&gt;You can see what was deployed by using &lt;code&gt;kubectl&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl get all
NAME                                READY   STATUS    RESTARTS   AGE
pod/my-app-nginx-655b5cfc8c-mfhcb   1/1     Running   0          2m38s

NAME                   TYPE           CLUSTER-IP   EXTERNAL-IP     PORT(S)                      AGE
service/my-app-nginx   LoadBalancer   10.0.2.51    104.197.x.x   80:30291/TCP,443:31827/TCP   2m38s

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/my-app-nginx   1/1     1            1           2m38s

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/my-app-nginx-655b5cfc8c   1         1         1       2m38s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can see the external IP of your application listed, but if you follow the instructions in the notes, you should see the same as well.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ export SERVICE_IP=$(kubectl get svc --namespace default my-app-nginx --template &amp;quot;{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}&amp;quot;)

$ echo &amp;quot;NGINX URL: http://$SERVICE_IP/&amp;quot;
NGINX URL: http://104.197.x.x/

$ curl $SERVICE_IP
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&amp;lt;style&amp;gt;
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
&amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can see which releases are deployed using &lt;code&gt;helm list&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NAME  	NAMESPACE	REVISION	UPDATED                            	STATUS  	CHART      	APP VERSION
my-app	default     	1       	2020-03-09 08:07:53.54657 -0400 EDT	deployed	nginx-5.1.9	1.16.1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It shows all the relevant information. Anytime you update a release, the revision number will increment.&lt;/p&gt;
&lt;p&gt;You can clean up by removing the app with uninstall.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ helm uninstall my-app
release &amp;quot;my-app&amp;quot; uninstalled
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;changing-the-values&#34;&gt;Changing the Values&lt;/h2&gt;
&lt;p&gt;Now you have a working nginx app, but maybe you don&amp;rsquo;t want it exposed externally via a load balancer. You can delete this app and redeploy it with &lt;code&gt;ClusterIP&lt;/code&gt; instead of &lt;code&gt;LoadBalancer&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Helm charts have a set of default values; the ones for this chart can be seen in &lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/nginx&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;its GitHub repository&lt;/a&gt;. If you look there, you&amp;rsquo;ll see the value you want to change is &lt;code&gt;service.type&lt;/code&gt;. You can now install that same chart using the &lt;code&gt;--set&lt;/code&gt; flag to configure it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ helm install my-app bitnami/nginx --set service.type=ClusterIP
NAME: my-app
LAST DEPLOYED: Mon Mar 9 08:07:53 2020
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
Get the NGINX URL:

  echo &amp;quot;NGINX URL: http://127.0.0.1:8080/&amp;quot;
  kubectl port-forward --namespace blog svc/my-app-nginx 8080:80
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Notice how the &lt;code&gt;NOTES&lt;/code&gt; section changed? It&amp;rsquo;s a template, too. You can see &lt;a href=&#34;https://github.com/bitnami/charts/blob/master/bitnami/nginx/templates/NOTES.txt#L25&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt; that changing the service type changed the output.&lt;/p&gt;
&lt;p&gt;In this instance you supplied the value via the CLI, but you could have also put it into a &lt;code&gt;values.yaml&lt;/code&gt; file and used the &lt;code&gt;--values&lt;/code&gt; CLI option. This is a common practice for when you want to supply numerous values to the chart, and/or you want to keep track of what you&amp;rsquo;re deploying by checking the file into a version control system. The easiest way to get started with your values file is to download the default one from the chart repository, &lt;a href=&#34;https://github.com/bitnami/charts/blob/master/bitnami/nginx/values.yaml&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;like this one&lt;/a&gt; for the nginx chart you deployed. Any value you aren&amp;rsquo;t changing can be deleted from the file as it will be supplied by the default values.
If you wanted to do that to get the same results as above you&amp;rsquo;d create a &lt;code&gt;my-app-values.yaml&lt;/code&gt; file with these contents:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;c&#34;&gt;## NGINX Service properties&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;##&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;## Service type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;##&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The command to create the release would then be:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ helm install my-app bitnami/nginx --values my-app-values.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;upgrading-a-release&#34;&gt;Upgrading a Release&lt;/h2&gt;
&lt;p&gt;Anytime you want to change anything about a release—be it a configuration value for the chart, an upgrade to the chart itself, or the application version—you&amp;rsquo;ll run &lt;code&gt;helm upgrade&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For your nginx chart, you can try this by changing a configuration value. Currently the default image &lt;code&gt;pullPolicy&lt;/code&gt; for this chart is &lt;code&gt;IfNotPresent&lt;/code&gt;. You can change that to &lt;code&gt;Always&lt;/code&gt; via an upgrade.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;l&#34;&gt;$ helm upgrade my-app bitnami/nginx --set service.type=ClusterIP,image.pullPolicy=Always&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Release &amp;#34;my-app&amp;#34; has been upgraded. Happy Helming!&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;NAME&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;LAST DEPLOYED&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Wed Mar 11 13:50:05 2020&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;NAMESPACE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;blog&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;STATUS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;deployed&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;REVISION&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;TEST SUITE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;NOTES&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Get the NGINX URL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;echo &amp;#34;NGINX URL: http://127.0.0.1:8080/&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kubectl port-forward --namespace blog svc/my-app-nginx 8080:80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can see the revision has been incremented. If you get the nginx pod you can see the change of configuration:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;l&#34;&gt;$ kubectl get pod my-app-nginx-5bd7878597-pc8jp -o yaml&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/bitnami/nginx:1.16.1-debian-10-r46&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Always&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Why did you have to supply both &lt;code&gt;service.type&lt;/code&gt; and &lt;code&gt;image.pullPolicy&lt;/code&gt;? Because if you hadn&amp;rsquo;t supplied both, the service type would have tried to revert to the default.&lt;/p&gt;
&lt;h2 id=&#34;rollback&#34;&gt;Rollback&lt;/h2&gt;
&lt;p&gt;What happens if you didn&amp;rsquo;t want that change or it didn&amp;rsquo;t work the way you expected? Remember the revision of the releases? You can rollback to a previous revision with &lt;code&gt;helm rollback&lt;/code&gt;. If you want, you can do a &lt;code&gt;--dry-run&lt;/code&gt; first to see if the rollback would even work.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ helm rollback my-app 1 --dry-run
Rollback was a success! Happy Helming!
$ helm rollback my-app 1
Rollback was a success! Happy Helming!
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you check the pod again, you&amp;rsquo;ll see &lt;code&gt;pullPolicy&lt;/code&gt; is set back to &lt;code&gt;IfNotPreset&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;get-helming&#34;&gt;Get Helming&lt;/h2&gt;
&lt;p&gt;If you&amp;rsquo;re ready to start trying to deploy more charts, there are a whole bunch of charts available in a number of different repositories. A current list of repositories in a Helm install might look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NAME    	URL
stable  	https://kubernetes-charts.storage.googleapis.com
jetstack	https://charts.jetstack.io
elastic 	https://helm.elastic.co
bitnami 	https://charts.bitnami.com/bitnami
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Happy Helming!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Monitoring Containers at Scale with Wavefront</title>
      
      <link>/guides/kubernetes/monitoring-at-scale-wavefront/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/monitoring-at-scale-wavefront/</guid>
      <description>

        
        &lt;p&gt;&lt;a href=&#34;https://tanzu.vmware.com/observability&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Tanzu Observability by Wavefront&lt;/a&gt; efficiently monitors cloud native operations at scale. It is a high-performance streaming analytics platform that supports 3D observability (metrics, histograms, traces/spans) and can scale to very high data ingestion rates and query loads. You can collect data from many services and sources across your entire application stack, and can look at details for earlier data collected by Wavefront.&lt;/p&gt;
&lt;p&gt;The Wavefront platform includes dashboards that give DevOps teams real-time visibility into the operation and performance of containerized applications and Kubernetes clusters. The dashboard displays data on the performance of microservices and resource utilization to help you identify issues, troubleshoot problems, and optimize applications. The data can, for example, help you make decisions about how and when to scale a container environment. In short, Wavefront is an observability platform with automated service discovery and full-stack analytics.&lt;/p&gt;
&lt;h2 id=&#34;monitoring-kubernetes&#34;&gt;Monitoring Kubernetes&lt;/h2&gt;
&lt;p&gt;The Wavefront service can measure, correlate, and analyze data across containers and Kubernetes clusters and can display various information, including metrics, histograms, span logs, traces and distributed tracing analysis.
Because Wavefront can correlate Kubernetes performance with the performance of applications, it can help you scale faster while maintaining high quality. With Wavefront you can:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;See a real-time, full-stack picture of your Kubernetes environment&lt;/li&gt;
&lt;li&gt;Find out about incidents earlier and solve them faster by drilling down into the data&lt;/li&gt;
&lt;li&gt;Understand and assess long-term trends&lt;/li&gt;
&lt;li&gt;Improve collaboration and visibility across teams&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wavefront can also help you evaluate and tune the performance of microservices running on Kubernetes. For example, Wavefront can help you isolate and resolve microservices rate, error, and duration problems.&lt;/p&gt;
&lt;h2 id=&#34;keep-learning&#34;&gt;Keep Learning&lt;/h2&gt;
&lt;p&gt;Wavefront helps monitor and manage container deployments. It offers so much functionality that it’s often best to begin by investigating specific areas you are interested in. The video &lt;a href=&#34;https://tanzu.vmware.com/content/vmware-tanzu-observability-by-wavefront-videos/introduction-to-wavefront&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Introduction to Wavefront&lt;/a&gt; explains more about where and how Wavefront is being used. Watch &lt;a href=&#34;https://tanzu.vmware.com/content/vmware-tanzu-observability-by-wavefront-videos/wavefront-and-kubernetes&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Wavefront and Kubernetes&lt;/a&gt; to understand Kubernetes specifics. You can check out the &lt;a href=&#34;https://tanzu.vmware.com/content/vmware-tanzu-observability-by-wavefront-videos&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;complete library of Wavefront videos&lt;/a&gt; to find topics of interest. &lt;a href=&#34;https://docs.wavefront.com/index.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;The Wavefront docs&lt;/a&gt; also provide an exceptionally thorough introduction to the solution, with in-depth sections on Kubernetes, dashboards, alerts, tracing and more, including lots of video content for visual learners.&lt;/p&gt;
&lt;p&gt;If you are a Spring Boot developer &lt;a href=&#34;/guides/spring/spring-wavefront-gs/&#34;&gt;Wavefront for Spring Boot: Getting Started&lt;/a&gt; is a great starting point and explains how to take advantage of our free tier offer.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Secret Management</title>
      
      <link>/guides/kubernetes/platform-security-secret-management/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/platform-security-secret-management/</guid>
      <description>

        
        &lt;p&gt;This document details secret management and distribution for Kubernetes
clusters, such as those provided by Tanzu Kubernetes Grid (TKG). It covers
architectural considerations, secret provider integration approaches, and best
practices. This document represents how the VMware field team approaches secrets
in large enterprise Kubernetes environments.&lt;/p&gt;
&lt;p&gt;Each section covers architectural recommendations and, at times, configuration
for each concern. At a high-level, the key recommendations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To support secrets, encryption should be active at the application, transport,
and filesystem levels.&lt;/li&gt;
&lt;li&gt;Prefer external secret management solutions, such as
&lt;a href=&#34;https://www.vaultproject.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Vault&lt;/a&gt; over using Kubernetes as a secret store.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;While Vault is the most mature, weigh it against what you&amp;rsquo;re most familiar
with.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If using Kubernetes as a secret store, prefer using a Key Management Service
(KMS)-plugin to achieve envelope encryption.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;KMS-plugins are largely immature, unless using a managed offering.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If using Kubernetes as a secret store and a KMS-plugin is a non-option,
configure encryption at rest using a static key.&lt;/li&gt;
&lt;li&gt;If storing secrets declaratively is desired (e.g. in git) use sealed-secrets.&lt;/li&gt;
&lt;li&gt;Expose secrets in volumes; not environment variables.&lt;/li&gt;
&lt;li&gt;Keep applications unaware of secret providers (Vault, Kubernetes, or
otherwise).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;encryption-layers&#34;&gt;Encryption Layers&lt;/h2&gt;
&lt;p&gt;There are many layers to ensuring secrets are safe. The focus of this reference
architecture is cover application-level encryption. However, this document must
first address all layers. Ignoring encryption on a layer, such as transport,
could cause secrets to be leaked (e.g. plain-text over HTTP) regardless of how
secure a secret management solution is. The layers that should be encrypted
include the Filesystem (or Disk), Transport, and Application.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/encryption-layers.png&#34; alt=&#34;Encryption Layers&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;filesystem&#34;&gt;Filesystem&lt;/h3&gt;
&lt;p&gt;Master nodes should always use encrypted disks. If etcd does not run on the same
nodes as the Kubernetes control plane, its disk should also be fully encrypted.
Encrypting the filesystem ensures volume backups, snapshots, and physical drives
are protected against unauthorized access. Kubernetes master nodes typically
contain secret data from certificate keys to application secrets (in etcd). On
the lowest level, there is also disk encryption, which typically covers the
entire disk and will include all metadata. See
&lt;a href=&#34;https://en.wikipedia.org/wiki/Disk_encryption#Disk_encryption_vs._filesystem-level_encryption&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;disk encryption vs filesystem&lt;/a&gt;
for more details.&lt;/p&gt;
&lt;h3 id=&#34;transport&#34;&gt;Transport&lt;/h3&gt;
&lt;p&gt;Transport Layer Security (TLS) should be used for communication to and from all
control plane components. This is the default mode for most Kubernetes
distributions and provisioning methods. Validation of TLS should be done against
the &lt;code&gt;kube-apisever&lt;/code&gt; and etcd.&lt;/p&gt;
&lt;p&gt;Proper transport encryption between kube-apiserver, its clients, and etcd can be
verified with the following flags.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;kube-apiserver&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;client-ca-file=/etc/kubernetes/pki/ca.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;etcd-servers=https://127.0.0.1:2379&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;insecure-port=0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# disabled and set to 0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;secure-port=6443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;service-account-key-file=/etc/kubernetes/pki/sa.pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;tls-cert-file=/etc/kubernetes/pki/apiserver.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;tls-private-key-file=/etc/kubernetes/pki/apiserver.key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;##### Additional flags removed for brevity #####&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s.gcr.io/kube-apiserver:v1.17.3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Proper transport encryption between etcd members can be verified with the
following flags.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;etcd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# should use https:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;advertise-client-urls=https://192.168.201.0:2379&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# should be set for tls cert&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;cert-file=/etc/kubernetes/pki/etcd/server.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;client-cert-auth=true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;initial-advertise-peer-urls=https://192.168.201.0:2380&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;initial-cluster=master-0=https://192.168.201.0:2380&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;key-file=/etc/kubernetes/pki/etcd/server.key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;listen-client-urls=https://127.0.0.1:2379,https://192.168.201.0:2379&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;listen-metrics-urls=http://127.0.0.1:2381&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;listen-peer-urls=https://192.168.201.0:2380&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;peer-client-cert-auth=true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;peer-key-file=/etc/kubernetes/pki/etcd/peer.key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;##### Additional flags removed for brevity #####&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s.gcr.io/etcd:3.4.3-0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;application&#34;&gt;Application&lt;/h3&gt;
&lt;p&gt;The application layer refers to encrypting a secret &lt;strong&gt;before&lt;/strong&gt; persisting it to
a filesystem. There are many points in time where this encryption could occur.
For example, an application could retrieve a key for an external location,
encrypt or decrypt a secret, and then act on the secret. More commonly, the
application relies on a system capable of secret management, such as Kubernetes
or HashiCorp&amp;rsquo;s Vault. This reference architecture covers the variety of
approaches, architectures, and recommendations to achieve the latter. The goal
is to provide applications an enterprise-grade way to store and retrieve secret
objects.&lt;/p&gt;
&lt;h2 id=&#34;secret-api-overview&#34;&gt;Secret API Overview&lt;/h2&gt;
&lt;p&gt;Kubernetes provides a &lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/secret&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Secret
API&lt;/a&gt;. These objects
are similar to
&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;ConfigMaps&lt;/a&gt;
in that they can be added through the API server and injected into applications.
Secrets are typically injected via environment variables or volumes, which
Kubernetes can do automatically. Alternatively, some applications consume
Secrets by calling the Kubernetes API server directly. The key difference is
that Secrets are managed via their own RBAC, which has different implications
than ConfigMaps. Additionally, secret data is base64 encoded. While this is not
a security measure, it is a minor detail to note.&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-secret-defaults&#34;&gt;Kubernetes Secret Defaults&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/secret&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Secret&lt;/a&gt; object is
present in every Kubernetes cluster under the &lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#secret-v1-core&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;v1 core
APIs&lt;/a&gt;.
The two primary fields supported by this API are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;data&lt;/code&gt;: data that is base64 encoded and unencrypted.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stringData&lt;/code&gt;: data unencoded and unencrypted. It is stored and retrieved
encoded (base64).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In summary, the following manifests produce equivalent objects once processed by
the &lt;code&gt;kube-apiserver&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Secret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysecret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Opaque&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dbuser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;aGVwdGlvCg==&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dbkey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;YmVhcmNhbm9lCg==&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Secret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysecret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Opaque&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stringData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dbuser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;heptio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dbkey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bearcanoe&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Technically, the annotation &lt;code&gt;kubectl.kubernetes.io/last-applied-configuration&lt;/code&gt;
will show the originally sent data from &lt;code&gt;kubectl&lt;/code&gt;, meaning the dbuser and dbkey
will be readable without decoding in the latter example. However, since
&lt;code&gt;encoding&lt;/code&gt; is not a security measure, we consider these equal.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/diagrams/secret-default-behavior.png&#34; alt=&#34;Secret Default Behavior&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;encryption-at-rest-static-key&#34;&gt;Encryption at Rest (Static Key)&lt;/h3&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Avoid this approach when possible&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Ideally, you should not rely solely on encryption at rest using a static key.
While better than storing secrets in an encoded format, the encryption key lives
in plain text on each kubernetes-master. Additionally, key rotation must be
handled by you. You should prefer using an external secret store or leveraging a
KMS-plugin. Both of these alternative approaches are covered in subsequent
sections.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The Kubernetes API server supports encrypting secrets at rest. This is achieved
by providing the Kubernetes API server with an encryption key, which it will use
to encrypt all secret objects before sending them to etcd.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/diagrams/secret-encryption-at-rest.png&#34; alt=&#34;Encryption at rest&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The supported encryption providers are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;secretbox&lt;/code&gt;: XSalsa20 and Poly1305; &lt;strong&gt;Recommended&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aescbc&lt;/code&gt;: Uses &lt;a href=&#34;https://en.wikipedia.org/wiki/Advanced_Encryption_Standard&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Advanced Encryption
Standard&lt;/a&gt;
(AES) &lt;a href=&#34;https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_Block_Chaining_.28CBC.29&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cipher Block
Chaining&lt;/a&gt;
(CBC)
&lt;ul&gt;
&lt;li&gt;Assumes &lt;a href=&#34;https://tools.ietf.org/html/rfc5652#section-1&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;PKCS#7&lt;/a&gt; or PKCS#5 padding; &lt;a href=&#34;https://en.wikipedia.org/wiki/Padding_%28cryptography%29#PKCS#5_and_PKCS#7&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;they are interchangeable&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aesgcm&lt;/code&gt;: AES-GCM with random nonce&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As of Kubernetes &lt;code&gt;1.17&lt;/code&gt;, the documentation recommends using &lt;code&gt;aescbc&lt;/code&gt;. However,
this should be considered carefully. This provider is vulnerable to
&lt;a href=&#34;https://en.wikipedia.org/wiki/Padding_oracle_attack&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Padding oracle attacks&lt;/a&gt;.
Additionally, it is less secure and performant than &lt;code&gt;secretbox&lt;/code&gt;. Issue
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/81127&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubernetes/kubernetes#81127&lt;/a&gt;
is tracking the task to align documentation with best practices. If using static
key encryption at rest, you may wish to consider an alternative such
as&lt;code&gt;secretbox&lt;/code&gt;. There are some critics for &lt;code&gt;secretbox&lt;/code&gt;, stating its immaturity in
the crypto ecosystem may make it a non-option for some organizations.
Partnering with your security team to explain the available options and their
trade-offs is recommended. The following will demonstrate the static key
approach using &lt;code&gt;secretbox&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If static key encryption is used, a 32 byte key must be generated to encrypt and
decrypt secretbox (it is symmetric). Organizations should ensure they&amp;rsquo;re
following security policies and using appropriate tools to generate keys. The
following example demonstrates how to generate a key on a Linux host.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;head -c &lt;span class=&#34;m&#34;&gt;32&lt;/span&gt; /dev/urandom &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; base64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;/dev/urandom&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;On Linux hosts, &lt;code&gt;/dev/urandom&lt;/code&gt; is similar to &lt;code&gt;/dev/random&lt;/code&gt;, but it does not
block to ensure entropy. Typically &lt;code&gt;/dev/urandom&lt;/code&gt; is adequate for crypto
operations, but organizations should consult their security teams before using
this method.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Using the key data above, an &lt;code&gt;EncryptionConfiguration&lt;/code&gt; should be added to all
nodes running a &lt;code&gt;kube-apiserver&lt;/code&gt;. This static file should be added using
configuration management such as &lt;a href=&#34;https://www.ansible.com&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Ansible&lt;/a&gt; or
&lt;a href=&#34;https://godoc.org/github.com/kubernetes-sigs/cluster-api-bootstrap-provider-kubeadm/api/v1alpha2#KubeadmConfigSpec&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;KubeadmConfigSpec&lt;/a&gt;.
if using Cluster API. This ensures keys can be added, deleted, and rotated. The
following example assumes the configuration is stored at
&lt;code&gt;/etc/kubernetes/pki/secrets/encryption-config.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apiserver.config.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EncryptionConfiguration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;secrets&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;providers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;secretbox&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;keys&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;secret-key-1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secret&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;u7mcOcHKbFh9eVluB18hbFIsVfwpvgbXv650QacDYXA=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# identity is a required (default) provider&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;identity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Placed inside of a
&lt;a href=&#34;https://godoc.org/github.com/kubernetes-sigs/cluster-api-bootstrap-provider-kubeadm/api/v1alpha2#KubeadmConfigSpec&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;KubeadmConfigSpec&lt;/a&gt;,
this would look as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;KubeadmControlPlane&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;controlplane.cluster.x-k8s.io/v1alpha3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s-capa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;infrastructureTemplate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;infrastructure.cluster.x-k8s.io/v1alpha3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;AWSMachineTemplate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s-capa-controlplane&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubeadmConfigSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          apiVersion: apiserver.config.k8s.io/v1
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          kind: EncryptionConfiguration
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          resources:
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;            - resources:
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;              - secrets
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;              providers:
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;              - secretbox:
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;                  keys:
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;                  - name: secret-key-1
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;                    secret: u7mcOcHKbFh9eVluB18hbFIsVfwpvgbXv650QacDYXA= 
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;              # identity is a required (default) provider
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;              - identity: {}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;owner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;root:root&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/etc/kubernetes/etcd-encryption/encryption.yaml&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;permissions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;0644&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The list of providers above are ordered. Meaning encryption will always occur
using the first key and decryption will be attempted in order of keys listed
above. Identity is the default, plain-text provider and should be last. If it&amp;rsquo;s
first, secrets will not be encrypted.&lt;/p&gt;
&lt;p&gt;To respect the above configuration, every instance of the &lt;code&gt;kube-apiserver&lt;/code&gt; must
be updated to load the &lt;code&gt;EncryptionConfiguration&lt;/code&gt; locally. In
&lt;code&gt;/etc/kubernetes/manifests/kube-apiserver.yaml&lt;/code&gt; an argument can be added as
follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;--encryption-provider-config&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/etc/kubernetes/pki/secrets/encryption-config.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the &lt;code&gt;kube-apiserver&lt;/code&gt;(s) restart, this change will take effect and secrets
will be encrypted before being sent to etcd.&lt;/p&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Access to encrypted data&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;While data is encrypted in etcd, anyone with proper RBAC permissions to access
the secret will be able to retrieve the unencrypted, base64 encoded, value.
Improper RBAC configuration or inappropriate access to a service account can
leak secrets. Additionally, if anyone gains read access to the
&lt;code&gt;/etc/kubernetes/pki/secrets&lt;/code&gt; directory from above, they will have access to
decrypt secrets from etcd (assuming access to etcd).&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Validation from within etcd should &lt;strong&gt;always&lt;/strong&gt; be performed when enabling
encryption. All existing secrets will &lt;strong&gt;not&lt;/strong&gt; be encrypted unless they are
updated via the &lt;code&gt;kube-apiserver&lt;/code&gt;. The following helper script can be run from a
master node to interact with etcd. This assumes
&lt;a href=&#34;https://github.com/etcd-io/etcd/tree/master/etcdctl&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;etcdctl&lt;/a&gt; is available on
the master node.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# This script assumes you&amp;#39;re running from a master node&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# hosting the kube-apiserver.&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# Change this based on location of etcd nodes&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;ENDPOINTS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;127.0.0.1:2379&amp;#39;&lt;/span&gt;

&lt;span class=&#34;nv&#34;&gt;ETCDCTL_API&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt; etcdctl &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --endpoints&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;ENDPOINTS&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --cacert&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/etc/kubernetes/pki/etcd/ca.crt&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --cert&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/etc/kubernetes/pki/apiserver-etcd-client.crt&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --key&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/etc/kubernetes/pki/apiserver-etcd-client.key&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To validate encryption, one must retrieve an existing secret (pre-encryption
configuration) and a new secret (post-encryption configuration). Kubernetes
stores secrets in &lt;code&gt;etcd&lt;/code&gt; using the format of
&lt;code&gt;/registry/secrets/${NAMESPACE}/${SECRET_NAME}&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Assuming a pre-existing secret named &lt;code&gt;login1&lt;/code&gt; in the &lt;code&gt;default&lt;/code&gt; namespace, using
the above script reveals the plaintext data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;./etcctl-script get /registry/secrets/default/login1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;/registry/secrets/default/login1
k8s


v1Secret

        login1default&amp;quot;*$6c991b48-036c-48f8-8be3-58175913915c2bB
0kubectl.kubernetes.io/last-applied-configuration{&amp;quot;apiVersion&amp;quot;:&amp;quot;v1&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;dbkey&amp;quot;:&amp;quot;YmVhcmNhbm9lCg==&amp;quot;,&amp;quot;dbuser&amp;quot;:&amp;quot;aGVwdGlvCg==&amp;quot;},&amp;quot;kind&amp;quot;:&amp;quot;Secret&amp;quot;,&amp;quot;metadata&amp;quot;:{&amp;quot;annotations&amp;quot;:{},&amp;quot;name&amp;quot;:&amp;quot;login1&amp;quot;,&amp;quot;namespace&amp;quot;:&amp;quot;default&amp;quot;},&amp;quot;type&amp;quot;:&amp;quot;Opaque&amp;quot;}
z
dbkey
bearcanoe

dbuserheptio
Opaque&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Applying a new secret, e.g. &lt;code&gt;login2&lt;/code&gt;, should produce results that are clearly
encrypted, such as the following.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;./etcctl-script get /registry/secrets/default/login2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;/registry/secrets/default/login2
k8s:enc:secretbox:v1:secret-key-1:^Dʜ
                                     HN,lU/:L kdR&amp;lt;_h (fO$V
y.
  r/m
MٜjVĄGP&amp;lt;%B0kZHY}-&amp;gt;q|&amp;amp;c?a\i#xoZsVXd+8_rCצgcj[Mv&amp;lt;X5N):MQ&#39;7݋t
&#39;pLBxqݡ)b݉/+r49ޓ`f
                 6(iciQⰪſ$&#39;.ejbprλ=Cp+R-D%q!r/pbv1_.izyPlQ)1!7@X\0
                                                                  EiĿr(dwlS
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With encryption set up, policies for key retention and rotation must be defined.
Based on a schedule, the key should be rotated. To rotate keys, one must add a
new key to the top of the list inside the provider. Since this key is first, it
will be used for all new encryption. When secret objects are updated, they will
be re-encrypted using this new key over time. Until then, the original key can
remain in the list as a fall back decryption option.&lt;/p&gt;
&lt;h3 id=&#34;envelope-encryption-with-key-management-service-kms&#34;&gt;Envelope Encryption with Key Management Service (KMS)&lt;/h3&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Providers for this approach are limited&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;The following section details a viable design approach for secret management
with etcd (Kubernetes) as the secret store. However, it relies on plugin
implementations that are only available to cloud-providers and are largely
immature. Be sure to understand the available plugins and their maturity before
continuing with this approach.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Kubernetes &lt;code&gt;1.10&lt;/code&gt; and later supports integrating with a KMS to achieve envelope
encryption. Envelope encryption involves two keys; the Key Encryption Key (KEK)
and the data encryption key (DEK). KEKs are stored externally in a KMS and
aren&amp;rsquo;t at risk unless the KMS provider is compromised. KEKs are used to encrypt
DEKs, which are responsible for encrypting Secret objects. Each Secret object
gets its own unique DEK to encrypt and decrypt the data. Since DEKs are
encrypted by a KEK, they can be stored with the data itself, preventing the
&lt;code&gt;kube-apiserver&lt;/code&gt; from needing to be aware of many keys. Architecturally, the
flow of envelope encryption would look as follows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/diagrams/secret-encryption-at-rest-kms.png&#34; alt=&#34;Secret Encryption with KMS&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;There can be some variance in how the above works, based on a KMS provider, but
generally this demonstrates how envelope encryption functions. There are
multiple benefits to the above model.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KMS is external to Kubernetes; increasing security via isolation.&lt;/li&gt;
&lt;li&gt;Centralization of KEKs enables easy rotation of keys.&lt;/li&gt;
&lt;li&gt;Separation of DEK and KEK means secret data is never sent to or known by the KMS
&lt;ul&gt;
&lt;li&gt;KMS is only concerned with decrypting DEKs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Encryption of DEKs means they are easy to store alongside their secret,
making management of keys in relation to their secrets easy.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The provider plugins work by running a privileged container &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/kms-provider/#implementing-a-kms-plugin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;implementing a gRPC
server that can communicate with a remote
KMS&lt;/a&gt;.
This container runs exclusively on master nodes where a &lt;code&gt;kube-apiserver&lt;/code&gt; is
present. Then, similar to setting up encryption in the previous section, an
&lt;code&gt;EncryptionConfiguration&lt;/code&gt; must be added to master nodes with settings to
communicate with the KMS plugin.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apiserver.config.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EncryptionConfiguration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;secrets&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;providers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;kms&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;myKmsPlugin&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;endpoint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;unix:///tmp/socketfile.sock&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cachesize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;timeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;3s&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# required, but not used for encryption&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;identity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Assuming the above is saved on each master node at
&lt;code&gt;/etc/kubernetes/pki/secrets/encryption-config.yaml&lt;/code&gt;, the &lt;code&gt;kube-apiserver&lt;/code&gt;
arguments must be updated to include the following.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;--encryption-provider-config&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/etc/kubernetes/pki/secrets/encryption-config.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Changing the value should restart the &lt;code&gt;kube-apiserver&lt;/code&gt;. If it doesn&amp;rsquo;t, a restart
is required for the change to take effect.&lt;/p&gt;
&lt;p&gt;From a design perspective, this is a viable model. However, kms-plugin
implementations are scarce and the ones that do exist are immature. As of March
2020, the following data points are true. There are no tagged releases for the
&lt;a href=&#34;https://github.com/kubernetes-sigs/aws-encryption-provider&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;aws-encryption-provider
(AWS)&lt;/a&gt; or the
&lt;a href=&#34;https://github.com/GoogleCloudPlatform/k8s-cloudkms-plugin&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;k8s-cloudkms-plugin
(Google)&lt;/a&gt;. Azure&amp;rsquo;s
plugin &lt;a href=&#34;https://github.com/Azure/kubernetes-kms&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubernetes-kms&lt;/a&gt; has notable
limitations such as no support for key rotation. So with the exception of
running in a managed service, such as GKE where the KMS-plugin is automatically
available and supported by Google, usage may prove unstable. Lastly, the only
cloud-provider agnostic KMS plugin available was kubernetes-vault-kms-plugin,
which was only partially implemented and has been archived (abandoned).&lt;/p&gt;
&lt;h2 id=&#34;external-secret-management&#34;&gt;External Secret Management&lt;/h2&gt;
&lt;p&gt;Our preference is to use an external secret store instead of Kubernetes.
Regardless of whether Kubernetes secrets are encrypted at rest. Instead, we
recommend using an external secret store such as &lt;a href=&#34;https://www.vaultproject.io/docs&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;HashiCorp&amp;rsquo;s
Vault&lt;/a&gt;. Over time, if KMS-plugins mature and
see larger adoption, they could be a viable alternative to external stores. Most
external secret stores feature advanced management capabilities, permission
configuration, &lt;a href=&#34;https://en.wikipedia.org/wiki/Hardware_security_module&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;HSM&lt;/a&gt;
support, and key rotation settings. The primary downside to using an external
secret store is you must gain familiarity with it and, most importantly, you may
need to operate the store. As secrets are often critical to the overall
platform, operating this in a performant and resilient manner adds to an
organization&amp;rsquo;s operational overhead.&lt;/p&gt;
&lt;p&gt;VMware does not prefer any specific store. Vault is used as the example for many
of the following secret integration patterns. Vault is not a VMware project or
supported by VMware. It is &lt;a href=&#34;https://landscape.cncf.io/selected=vault&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;a CNCF
project&lt;/a&gt;, widely adopted inside and
outside of Kubernetes, has been used in many customer deployments, and has many
integration capabilities with Kubernetes. It is crucial an organization
understands how to operate Vault before adopting it as their secret manager.&lt;/p&gt;
&lt;p&gt;For testing purposes, Vault can be deployed inside Kubernetes using the Helm
chart at &lt;a href=&#34;https://www.vaultproject.io/docs/platform/k8s/helm/run&#34;&gt;https://www.vaultproject.io/docs/platform/k8s/helm/run&lt;/a&gt;. This is not a
production-ready deployment of Vault. Individuals with Vault expertise and/or
HashiCorp should be consulted if running Vault in production.&lt;/p&gt;
&lt;p&gt;Once an external secret store is available to workloads in Kubernetes, there are
several options for retrieval. The following covers these approaches, our
recommendations, and trade-offs. In the following, we&amp;rsquo;ll cover each design
approach to consuming secrets and describe Vault&amp;rsquo;s implementation.&lt;/p&gt;
&lt;h3 id=&#34;workload-sidecar-retrieval&#34;&gt;Workload Sidecar Retrieval&lt;/h3&gt;
&lt;p&gt;This approach runs an
&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/init-containers&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;initContainer&lt;/a&gt;
and/or sidecar container to communicate with an external secret store.
Typically, secrets are injected into the pod&amp;rsquo;s filesystem, making them available
to all containers running in a pod. We &lt;strong&gt;highly recommend&lt;/strong&gt; this approach when
possible. The major benefit is it decouples the secret store entirely from the
application. However, this does make the platform more complex, as facilitating
secret injection is now an offering of the Kubernetes-based platform.&lt;/p&gt;
&lt;p&gt;Vault&amp;rsquo;s implementation of this model uses a
&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;MutatingWebhook&lt;/a&gt;
pointed at a &lt;code&gt;vault-agent-injector&lt;/code&gt;. As pods are created, based on annotations,
the vault-agent-injector adds an &lt;code&gt;initContainer&lt;/code&gt; (used for retrieval of the
initial secret) and a sidecar container to keep secrets updated, if needed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/diagrams/vault-agent-injection.png&#34; alt=&#34;Vault Agent Injection&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;To facilitate mutation via the &lt;code&gt;vault-agent-injector&lt;/code&gt;, a
&lt;code&gt;MutatingWebhookConfiguration&lt;/code&gt; is added, as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;admissionregistration.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;MutatingWebhookConfiguration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app.kubernetes.io/instance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app.kubernetes.io/managed-by&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Helm&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app.kubernetes.io/name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-agent-injector&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-agent-injector-cfg&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;webhooks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;admissionReviewVersions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clientConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;caBundle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;REDACTED&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-agent-injector-svc&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/mutate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;failurePolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Ignore&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Exact&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault.hashicorp.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespaceSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;objectSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;reinvocationPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Never&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;apiGroups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;operations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;CREATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;UPDATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;pods&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scope&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sideEffects&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Unknown&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;timeoutSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The mutating webhook is invoked on &lt;strong&gt;every&lt;/strong&gt; pod &lt;code&gt;CREATE&lt;/code&gt; or &lt;code&gt;UPDATE&lt;/code&gt; event.
While evaluation will occur on every pod, not every pod will be mutated, or
injected with a &lt;code&gt;vault-agent&lt;/code&gt;. The &lt;code&gt;vault-agent-injector&lt;/code&gt; is looking for 2
annotations in every pod spec.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;vault.hashicorp.com/agent-inject: &amp;quot;true&amp;quot;&lt;/code&gt;: Instructs the injector to include
a &lt;code&gt;vault-agent&lt;/code&gt; &lt;code&gt;initContainer&lt;/code&gt;, which retrieves secrets and writes them to
the pod&amp;rsquo;s filesystem, prior to other containers starting.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vault.hashicorp.com/agent-inject-status: &amp;quot;update&amp;quot;&lt;/code&gt;: Instructs the injector to
include a &lt;code&gt;vault-agent&lt;/code&gt; sidecar, which runs alongside the workload. It will
update the secret, should it change in Vault. The &lt;code&gt;initContainer&lt;/code&gt; still runs
in this mode. This parameter is optional and when it is not included, the
sidecar is not added.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When the &lt;code&gt;vault-agent-injector&lt;/code&gt; does a mutation based on
&lt;code&gt;vault.hashicorp.com/agent-inject: &amp;quot;true&amp;quot;&lt;/code&gt;, the following is added.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;initContainers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;echo ${VAULT_CONFIG?} | base64 -d &amp;gt; /tmp/config.json &amp;amp;&amp;amp; vault agent -config=/tmp/config.json&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;/bin/sh&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- -&lt;span class=&#34;l&#34;&gt;ec&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;VAULT_CONFIG&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;eyJhd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault:1.3.2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IfNotPresent&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-agent-init&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;securityContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsNonRoot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsUser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumeMounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/vault/secrets&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-secrets&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note: Some configuration was removed for brevity.&lt;/p&gt;
&lt;p&gt;When the &lt;code&gt;vault-agent-injector&lt;/code&gt; sees the annotation
&lt;code&gt;vault.hashicorp.com/agent-inject-status: &amp;quot;update&amp;quot;&lt;/code&gt;, the following is added.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ORIGINAL WORKLOAD CONTAINER REMOVED FOR BREVITY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-agent&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;echo ${VAULT_CONFIG?} | base64 -d &amp;gt; /tmp/config.json &amp;amp;&amp;amp; vault agent -config=/tmp/config.json&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;/bin/sh&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- -&lt;span class=&#34;l&#34;&gt;ec&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;VAULT_CONFIG&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;asdfasdfasd&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault:1.3.2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IfNotPresent&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;securityContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsNonRoot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsUser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumeMounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/vault/secrets&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-secrets&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note: Some configuration was removed for brevity.&lt;/p&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Vault image&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;An unfortunate detail (as of March 2020) of the vault-sidecar implementation is
the use of the &lt;strong&gt;entire&lt;/strong&gt; &lt;a href=&#34;https://hub.docker.com/_/vault&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;vault image&lt;/a&gt;. This is
the entire image (~50MB) used to run a Vault server, not just a client. Thus
there is unneeded bloat from packages, code, and more.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;With the agents present, they will retrieve and download secrets based on the
pod annotations, such as the following annotation that requests a database
secret from Vault.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vault.hashicorp.com/agent-inject-secret-db-creds: &amp;quot;serets/db/creds&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;By default, secret value will be persisted as if a &lt;a href=&#34;https://tour.golang.org/moretypes/19&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Go
map&lt;/a&gt; was printed out. Syntactically, it
appears as follows. All secrets are put into &lt;code&gt;/vault/secrets&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;key: map[k:v],
key: map[k:v]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Where &lt;code&gt;k&lt;/code&gt; would be the key and &lt;code&gt;v&lt;/code&gt; would be the value.&lt;/p&gt;
&lt;p&gt;To ensure formatting of a secret is optimal for consumption, Vault supports
adding templates into the annotation of pods. This uses standard &lt;a href=&#34;https://golang.org/pkg/text/template/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Go
templating&lt;/a&gt;. For example, to create a
JDBC connection string, the following template can be applied to a secret named
&lt;code&gt;creds&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;template&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vault.hashicorp.com/agent-inject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vault.hashicorp.com/agent-inject-status&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;update&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vault.hashicorp.com/agent-inject-secret-db-creds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;secrets/db/creds&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vault.hashicorp.com/agent-inject-template-db-creds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          {{- with secret &amp;#34;secrets/db/creds&amp;#34; -}}
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          jdbc:oracle:thin:{{ .Data.data.username }}/{{ .Data.data.password }}@//192.168.34.212:4464/app
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          {{- end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If using Vault&amp;rsquo;s sidecar injector, be sure to review &lt;a href=&#34;https://www.vaultproject.io/docs/platform/k8s/injector/annotations&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;the available
annotations&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;application-secret-retrieval&#34;&gt;Application Secret Retrieval&lt;/h3&gt;
&lt;p&gt;In this approach, the application hosts logic to communicate with the external
secret store. Ideally, depending on the technology, using pre-existing client
libraries. The major benefit to this approach is taking secret consumption
concerns out of the realm of the platform. This is especially important when
there is no centralized secret management facilities and application teams use a
wide array of technologies. However, this comes with two major downsides. One is
applications must be &amp;ldquo;aware&amp;rdquo; of the secret store provider. They cannot just rely
on an environment variable or a volume existing, making them less portable.
Second, there is more code required from application teams. This increases
application concerns and introduces opportunity for security mistakes to be
made, such as accidentally leaving a &lt;code&gt;logger&lt;/code&gt; present that prints out what is
retrieved from Vault.&lt;/p&gt;
&lt;p&gt;The Vault project features several client-libraries that enable applications to
talk directly to Vault. The Vault project&amp;rsquo;s API docs has a &lt;a href=&#34;https://www.vaultproject.io/api-docs/libraries&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;master
reference&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;An example of this approach can be seen in &lt;a href=&#34;https://spring.io/projects/spring-vault#overview&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;The Spring
Framework&lt;/a&gt;. A developer can
utilize the Vault integration by importing
&lt;code&gt;org.springframework.vault.spring-vault-dependencies&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;dependencyManagement&amp;gt;&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependencies&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
      &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.vault&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
      &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-vault-dependencies&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
      &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;2.2.1.RELEASE&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
      &lt;span class=&#34;nt&#34;&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;import&lt;span class=&#34;nt&#34;&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
      &lt;span class=&#34;nt&#34;&gt;&amp;lt;type&amp;gt;&lt;/span&gt;pom&lt;span class=&#34;nt&#34;&gt;&amp;lt;/type&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependencies&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependencyManagement&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A bean can then be created describing where and how to reach Vault.
&lt;code&gt;ClientAuthentication&lt;/code&gt; is shown below, but realistically developers will use a
system such as &lt;code&gt;AWS-IAM&lt;/code&gt;, &lt;code&gt;GCP-IAM&lt;/code&gt;, or &lt;code&gt;TLS-Cert&lt;/code&gt;. Examples of every
authentication method can be found in the &lt;a href=&#34;https://docs.spring.io/spring-vault/docs/2.2.1.RELEASE/reference/html/#vault.core.authentication&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;reference
documentation&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Configuration&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;VaultConfig&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;extends&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AbstractVaultConfiguration&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;

    &lt;span class=&#34;cm&#34;&gt;/**
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * Endpoint for vault load balancer.
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     */&lt;/span&gt;
    &lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VaultEndpoint&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;vaultEndpoint&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VaultEndpoint&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;cm&#34;&gt;/**
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * Credentials for client
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * You SHOULD replace this
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     */&lt;/span&gt;
    &lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ClientAuthentication&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;clientAuthentication&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TokenAuthentication&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;…&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Spring developers may then utilize &lt;code&gt;@VaultPropertySource&lt;/code&gt; to inject secrets
throughout their application.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Configuration&lt;/span&gt;
&lt;span class=&#34;nd&#34;&gt;@VaultPropertySource&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;secret/db-creds&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;AppConfig&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;

       &lt;span class=&#34;nd&#34;&gt;@Autowired&lt;/span&gt;
       &lt;span class=&#34;n&#34;&gt;Environment&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;

       &lt;span class=&#34;nd&#34;&gt;@Bean&lt;/span&gt;
       &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TestBean&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;testBean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
               &lt;span class=&#34;n&#34;&gt;TestBean&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;testBean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;TestBean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
               &lt;span class=&#34;n&#34;&gt;testBean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;setPassword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getProperty&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;database.password&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;));&lt;/span&gt;
               &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;testBean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
       &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These examples provide Java developers ultimate flexibility in their consumption
and usage of Vault-managed secrets.&lt;/p&gt;
&lt;h3 id=&#34;csi-secret-store-driver-retrieval&#34;&gt;CSI Secret Store Driver Retrieval&lt;/h3&gt;
&lt;p&gt;The
&lt;a href=&#34;https://github.com/kubernetes-sigs/secrets-store-csi-driver/blob/master/README.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes-Secrets-Store-CSI-Driver&lt;/a&gt;
offers a common way to expose secrets, hosted in enterprise-grade
secret-management systems. They are exposed through Kubernetes volumes. This
model achieves the same as the injector-sidecar described in the previous
section. With the added benefit of a consistent driver experience where
providers can be plugged in. It offers creation of StorageClasses, which
developers can then consume with details about the specific secret they need.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;secrets-store.csi.x-k8s.io/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;SecretProviderClass&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;db-creds&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;provider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;roleName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;my-role&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vaultAddress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;http://192.32.122.111:8000&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vaultSkipTLSVerify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;objects&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      array:
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        - |
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          objectPath: &amp;#34;/secret/db&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          objectName: &amp;#34;creds&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          objectVersion: &amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Workloads can then consume the secret as a &lt;code&gt;volume&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumeMounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;secrets-store-inline&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/vault/secrets&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readOnly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;secrets-store-inline&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;csi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;driver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;secrets-store.csi.k8s.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readOnly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumeAttributes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretProviderClass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;db-creds&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ideally, this approach will be the future of external secret store integration.
However, we &lt;strong&gt;do not&lt;/strong&gt; recommend this approach today. As of Kubernetes 1.18, the
providers
(&lt;a href=&#34;https://github.com/Azure/secrets-store-csi-driver-provider-azure&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Azure&lt;/a&gt; and
&lt;a href=&#34;https://github.com/hashicorp/secrets-store-csi-driver-provider-vault&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Vault&lt;/a&gt;)
are only partially implemented. Tracking this project or creating your own
provider is advised as a future replacement for the Workload Sidecar Injector
approach.&lt;/p&gt;
&lt;h2 id=&#34;sealed-secrets&#34;&gt;Sealed Secrets&lt;/h2&gt;


&lt;div class=&#34;aside aside-warning&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Know the scope&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Sealed secrets are not a replacement for proper secret management; Their primary
benefit is to enable developers to encrypt secrets and store them safely in
locations such as git repositories. From a Kubernetes perspective, the private
key used by the controller is stored in plain text in etcd. Additionally, the
unsealed version of secrets are stored and managed as plain-text Kubernetes
secrets. Thus, application-level encryption of secrets in etcd remains a
critical concern.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Sealed secrets offer a mechanism to enable developers to encrypt secrets
locally. These encrypted secrets can only be decrypted by the controller running
in the Kubernetes cluster. This makes secrets safe, even when stored in public
locations. This encrypting happens through a command-line utility run by
developers, called
&lt;a href=&#34;https://github.com/bitnami-labs/sealed-secrets#installation&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubeseal&lt;/a&gt;. Along
with &lt;code&gt;kubeseal&lt;/code&gt;, a &lt;code&gt;sealed-secret-controller&lt;/code&gt; runs in the cluster facilitating
decryption of requested secrets. In essence, sealed secrets leverage &lt;a href=&#34;https://en.wikipedia.org/wiki/Public-key_cryptography&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;asymmetric
cryptography&lt;/a&gt; where
clients can use the public key to encrypt but only the
&lt;code&gt;sealed-secret-controller&lt;/code&gt; holds the private key to decrypt. The
&lt;code&gt;sealed-secret-controller&lt;/code&gt; is deployed first in the cluster.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;l&#34;&gt;kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.12.6/controller.yaml&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Releases of sealed secrets can be found at the
&lt;a href=&#34;https://github.com/bitnami-labs/sealed-secrets/releases&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;GitHub releases page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Upon deployment, the controller generates the public and private key pair. After
a developer downloads
&lt;a href=&#34;https://github.com/bitnami-labs/sealed-secrets/releases&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubeseal&lt;/a&gt;, it can
fetch the &lt;strong&gt;public key&lt;/strong&gt;, which is used for encryption. The public (cert) and
private (key) are stored in a Kubernetes Secret under
&lt;code&gt;kube-system/sealed-secret-key&lt;/code&gt;. Fetching the public cert will be done
automatically by creating a proxy to the &lt;code&gt;sealed-secret-controller&lt;/code&gt; via the
&lt;code&gt;kube-apiserver&lt;/code&gt;. You can force retrieval with the following command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubeseal --fetch-cert
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/diagrams/sealed-secret-overview.png&#34; alt=&#34;Sealed Secret Overview&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;This cert can be stored locally or in alternative external locations if this
flow is not realistic for all developer workstations.&lt;/p&gt;
&lt;p&gt;Interaction to download the public key is achieved via the controller. Users
should &lt;strong&gt;not&lt;/strong&gt; be given access to &lt;code&gt;kube-system/sealed-secret-key&lt;/code&gt;. This object
contains the private key.&lt;/p&gt;
&lt;p&gt;Once the public key is loaded in &lt;code&gt;kubeseal&lt;/code&gt;, developers can generate
&lt;code&gt;SealedSecret&lt;/code&gt; CRDs that contain (encrypted) secret data. These CRDs are stored
in etcd. The &lt;code&gt;sealed-secret-controller&lt;/code&gt; makes the secrets available using
standard Kubernetes Secrets. To ensure &lt;code&gt;SealedSecret&lt;/code&gt; data is converted to a
Secret correctly, developers specify templates in the &lt;code&gt;SealedSecret&lt;/code&gt; object.&lt;/p&gt;
&lt;p&gt;Developers can start with a Kubernetes secret, like any other.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Secret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysecret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Opaque&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dbuser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;aGVwdGlvCg==&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dbkey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;YmVhcmNhbm9lCg==&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To &amp;ldquo;seal&amp;rdquo; the secret, a developer may run &lt;code&gt;kubeseal&lt;/code&gt; against the above secret
and it will generate an encrypted output in JSON.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubeseal mysecret.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;kind&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;SealedSecret&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;apiVersion&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;bitnami.com/v1alpha1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;metadata&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;: &amp;#34;mysecret&amp;#34;, &amp;#34;namespace&amp;#34;: &amp;#34;default&amp;#34;, &amp;#34;creationTimestamp&amp;#34;: &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;}&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;spec&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;template&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;metadata&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;mysecret&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;namespace&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;creationTimestamp&amp;#34;: &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;}&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;type&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Opaque&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;}&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;encryptedData&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;dbkey&amp;#34;: &amp;#34;gCHJL+3bTRLw6vL4Gf......&amp;#34;, &amp;#34;dbuser&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;AgCHJL+3bT......&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;}&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;}&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;status&amp;#34;: &lt;/span&gt;{}&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above &lt;code&gt;SealedSecret&lt;/code&gt; object can be placed anywhere. As long as the sealing
key, held by the &lt;code&gt;sealed-secret-controller&lt;/code&gt; is not compromised, the data will be
safe. Rotation is &lt;strong&gt;especially important&lt;/strong&gt; in this model. It&amp;rsquo;s covered in a
subsequent section.&lt;/p&gt;
&lt;p&gt;Once applied, the flow and storage looks as follows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/diagrams/sealed-secret-flow.png&#34; alt=&#34;Sealed Secret Flow&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The Secret object, made by the &lt;code&gt;sealed-secret-controller&lt;/code&gt; is owned by its
corresponding &lt;code&gt;SealedSecret&lt;/code&gt; CRD.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;ownerReferences&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bitnami.com/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;controller&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;SealedSecret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysecret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;uid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;49ce4ab0-3b48-4c8c-8450-d3c90aceb9ee&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This means if the SealedSecret is deleted, its corresponding &lt;code&gt;Secret&lt;/code&gt; object
will be garbage collected.&lt;/p&gt;
&lt;h3 id=&#34;key-renewal&#34;&gt;Key Renewal&lt;/h3&gt;
&lt;p&gt;If the sealed-secret private key is leaked (perhaps due to RBAC
misconfiguration), every secret should be considered compromised. It&amp;rsquo;s
especially important that the sealing key is renewed on an interval and that you
understand the scope of &amp;ldquo;renewal&amp;rdquo;. The default behavior is for this key to be
renewed every 30 days. It does not &lt;strong&gt;replace&lt;/strong&gt; the existing keys; instead it is
appended to the existing list of keys that can unseal. However, the new key is
used for all &lt;strong&gt;new&lt;/strong&gt; encryption activity. Most importantly, &lt;strong&gt;existing sealed
secrets are not re-encrypted&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the event of a leaked key, you should:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Immediately renew your secret.&lt;/li&gt;
&lt;li&gt;Rotate all existing secrets.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Remember that just re-encrypting isn&amp;rsquo;t good enough. For example, someone could
easily go into git history, find the old encrypted asset, and use the
compromised key on it. Generally speaking, you should have rotation and renewal
strategies for passwords and keys respectively.&lt;/p&gt;
&lt;p&gt;Sealed-secrets does not support integration with HSM modules or KMS providers.&lt;/p&gt;
&lt;h3 id=&#34;access-policy&#34;&gt;Access Policy&lt;/h3&gt;
&lt;p&gt;Sealed Secrets use a trick where the namespace is used during encryption. This
provides an isolation mechanic where a &lt;code&gt;SealedSecret&lt;/code&gt; truly belong to the
namespace it was created in and cannot just be moved between them. Generally,
this default behavior is the most secure and should just be left as is. However
there are additional access policies for those that need more flexibility. The
following scopes can be set on the controller.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;strict&lt;/code&gt; (default): the secret must be sealed with exactly the same name and
namespace. These attributes become part of the encrypted data and thus
changing name and/or namespace would lead to &amp;ldquo;decryption error&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;namespace-wide&lt;/code&gt;: you can freely rename the sealed secret within a given
namespace.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;cluster-wide&lt;/code&gt;: the secret can be unsealed in any namespace and can be given
any name.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;application-considerations&#34;&gt;Application Considerations&lt;/h2&gt;
&lt;p&gt;Application consumption of secrets is highly dependent on the language and
frameworks at play. While variance is high, there are general best practices we
recommend encouraging application developers consider.&lt;/p&gt;
&lt;h3 id=&#34;always-audit-secret-interaction&#34;&gt;Always Audit Secret Interaction&lt;/h3&gt;
&lt;p&gt;Kubernetes cluster should be configured with auditing enabled. Auditing allows
you to specify the events that occur around specific resources. This will tell
you when and by whom a resource was interacted with. For mutations, it will also
detail what changed. Auditing secret events is critical in reacting to access
issues. For details about auditing, see the
&lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/audit/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;cluster audit documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;dont-leak-secrets&#34;&gt;Don&amp;rsquo;t leak secrets&lt;/h3&gt;
&lt;p&gt;While leaking secrets is never desirable, in multi-tenant Kubernetes
environments it&amp;rsquo;s important to consider how secrets can be leaked. A common
occurrence is to accidentally log a secret. Logs go to stdout/stderr and are, in
many Kubernetes-based platforms, forwarded to a log analysis platform. This
means the secret may pass in plain text through many environments and systems.&lt;/p&gt;
&lt;p&gt;Kubernetes is primarily a declarative system. Developers write manifests that
can easily contain secret data, especially when testing. Developers should work
with caution to ensure secrets used while testing don&amp;rsquo;t get committed into
source control repositories. If storing secret data declaratively alongside the
application is desirable, see the sealed-secret section of this reference
architecture.&lt;/p&gt;
&lt;h3 id=&#34;prefer-volumes-over-environment-variables&#34;&gt;Prefer volumes over environment variables&lt;/h3&gt;
&lt;p&gt;The most common ways to access secrets provided by Kubernetes is to propagate
the value into an environment variable or volumes. For most applications,
volumes should be preferred. Environment variables have a higher chance of being
leaked through various means. For example, an echo command performed while
testing. Most importantly, when secrets change, volumes are automatically
updated; this will enable hot-reloading of secrets such as tokens. For a secret
change to take place with environment variables, pods must be restarted.&lt;/p&gt;
&lt;h3 id=&#34;make-secret-store-providers-unknown-to-your-application&#34;&gt;Make secret store providers unknown to your application&lt;/h3&gt;
&lt;p&gt;There are several approaches an application can take to retrieve and consume its
required secrets. These can range from calling a secret store within business
logic to expecting an environment variable to be set on start-up. Following the
philosophy of separation of concerns, we recommend implementing secret
consumption in a way that whether Kubernetes, Vault, or other providers are
managing the secret does not matter to the application. Achieving this makes
your application portable, platform agnostic, and reduces complexity of your
apps interaction. Complexity is considered reduced because for an application to
retrieve secrets from a provider it needs to both understand how to talk to the
provider and be able to authenticate for communication with the provider.&lt;/p&gt;
&lt;p&gt;To achieve this provider-agnostic implementation, applications should prefer
loading secrets from Environment variables or volumes. Considering the coverage
in previous sections, volumes are the most ideal. In this model, an application
will assume the presence of secrets in one or many volumes. Since volumes can be
updated dynamically (without pod restart) the application can watch the
filesystem if a hot-reload of secrets is desired. By consuming from the
container&amp;rsquo;s local filesystem, it does not matter whether the backing store is
Kubernetes or otherwise. See the Vault section of this reference architecture to
understand how injection sidecar containers can be used to achieve this model.&lt;/p&gt;
&lt;p&gt;Some application frameworks, such as Spring, include libraries to communicate
directly to the API server and auto inject secrets and configuration. While
these utilities are convenient, consider the points above to determine what
approaches hold most value to your application.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Creating Your First Helm Chart</title>
      
      <link>/guides/kubernetes/create-helm-chart/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/create-helm-chart/</guid>
      <description>

        
        &lt;p&gt;So, you&amp;rsquo;ve got your &lt;a href=&#34;https://docs.bitnami.com/kubernetes/get-started-kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes cluster up and running&lt;/a&gt; and &lt;a href=&#34;https://docs.bitnami.com/kubernetes/get-started-kubernetes/#step-4-install-helm&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;set up Helm v3.x&lt;/a&gt;, but how do you run your applications on it? This guide walks you through the process of creating your first ever chart, explaining what goes inside these packages and the tools you use to develop them. By the end of it you should have an understanding of the advantages of using Helm to deliver your own applications to your cluster.&lt;/p&gt;
&lt;p&gt;For a typical cloud-native application with a 3-tier architecture, the diagram below illustrates how it might be described in terms of &lt;a href=&#34;http://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes objects&lt;/a&gt;. In this example, each tier consists of a &lt;a href=&#34;http://kubernetes.io/docs/user-guide/deployments/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Deployment&lt;/a&gt; and &lt;a href=&#34;http://kubernetes.io/docs/user-guide/services/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Service&lt;/a&gt; object, and may additionally define &lt;a href=&#34;http://kubernetes.io/docs/user-guide/configmap/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;ConfigMap&lt;/a&gt; or &lt;a href=&#34;http://kubernetes.io/docs/user-guide/secrets/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Secret&lt;/a&gt; objects. Each of these objects are typically defined in separate YAML files, and are fed into the &lt;em&gt;kubectl&lt;/em&gt; command line tool.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/create-helm-chart/diagrams/three-tier-kubernetes-architecture.png&#34; alt=&#34;3-tier application architecture on Kubernetes&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;A Helm chart encapsulates each of these YAML definitions, provides a mechanism for configuration at deploy-time and allows you to define metadata and documentation that might be useful when sharing the package. Helm can be useful in different scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Find and use popular software packaged as Kubernetes charts&lt;/li&gt;
&lt;li&gt;Share your own applications as Kubernetes charts&lt;/li&gt;
&lt;li&gt;Create reproducible builds of your Kubernetes applications&lt;/li&gt;
&lt;li&gt;Intelligently manage your Kubernetes object definitions&lt;/li&gt;
&lt;li&gt;Manage releases of Helm packages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s explore the second and third scenarios by creating our first chart.&lt;/p&gt;
&lt;h2 id=&#34;step-1-generate-your-first-chart&#34;&gt;Step 1: Generate your first chart&lt;/h2&gt;
&lt;p&gt;The best way to get started with a new chart is to use the &lt;em&gt;helm create&lt;/em&gt; command to scaffold out an example we can build on. Use this command to create a new chart named &lt;em&gt;mychart&lt;/em&gt; in a new directory:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm create mychart
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Helm will create a new directory in your project called &lt;em&gt;mychart&lt;/em&gt; with the structure shown below. Let&amp;rsquo;s navigate our new chart (pun intended) to find out how it works.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mychart
|-- Chart.yaml
|-- charts
|-- templates
|   |-- NOTES.txt
|   |-- _helpers.tpl
|   |-- deployment.yaml
|   |-- ingress.yaml
|   `-- service.yaml
`-- values.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;templates&#34;&gt;Templates&lt;/h3&gt;
&lt;p&gt;The most important piece of the puzzle is the &lt;em&gt;templates/&lt;/em&gt; directory. This is where Helm finds the YAML definitions for your Services, Deployments and other Kubernetes objects. If you already have definitions for your application, all you need to do is replace the generated YAML files for your own. What you end up with is a working chart that can be deployed using the &lt;em&gt;helm install&lt;/em&gt; command.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s worth noting however, that the directory is named &lt;em&gt;templates&lt;/em&gt;, and Helm runs each file in this directory through a &lt;a href=&#34;https://golang.org/pkg/text/template/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Go template&lt;/a&gt; rendering engine. Helm extends the template language, adding a number of utility functions for writing charts. Open the &lt;em&gt;service.yaml&lt;/em&gt; file to see what this looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
name: {{ template &amp;quot;fullname&amp;quot; . }}
labels:
    chart: &amp;quot;{{ .Chart.Name }}-{{ .Chart.Version | replace &amp;quot;+&amp;quot; &amp;quot;_&amp;quot; }}&amp;quot;
spec:
type: {{ .Values.service.type }}
ports:
- port: {{ .Values.service.externalPort }}
    targetPort: {{ .Values.service.internalPort }}
    protocol: TCP
    name: {{ .Values.service.name }}
selector:
    app: {{ template &amp;quot;fullname&amp;quot; . }}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is a basic Service definition using templating. When deploying the chart, Helm will generate a definition that will look a lot more like a valid Service. We can do a dry-run of a &lt;em&gt;helm install&lt;/em&gt; and enable debug to inspect the generated definitions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;helm install --dry-run --debug ./mychart
...
# Source: mychart/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
name: pouring-puma-mychart
labels:
    chart: &amp;quot;mychart-0.1.0&amp;quot;
spec:
type: ClusterIP
ports:
- port: 80
    targetPort: 80
    protocol: TCP
    name: nginx
selector:
    app: pouring-puma-mychart
...
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;values&#34;&gt;Values&lt;/h4&gt;
&lt;p&gt;The template in &lt;em&gt;service.yaml&lt;/em&gt; makes use of the Helm-specific objects &lt;em&gt;.Chart&lt;/em&gt; and &lt;em&gt;.Values.&lt;/em&gt;. The former provides metadata about the chart to your definitions such as the name, or version. The latter &lt;em&gt;.Values&lt;/em&gt; object is a key element of Helm charts, used to expose configuration that can be set at the time of deployment. The defaults for this object are defined in the &lt;em&gt;values.yaml&lt;/em&gt; file. Try changing the default value for &lt;em&gt;service.internalPort&lt;/em&gt; and execute another dry-run, you should find that the &lt;em&gt;targetPort&lt;/em&gt; in the Service and the &lt;em&gt;containerPort&lt;/em&gt; in the Deployment changes. The &lt;em&gt;service.internalPort&lt;/em&gt; value is used here to ensure that the Service and Deployment objects work together correctly. The use of templating can greatly reduce boilerplate and simplify your definitions.&lt;/p&gt;
&lt;p&gt;If a user of your chart wanted to change the default configuration, they could provide overrides directly on the command-line:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install --dry-run --debug ./mychart --set service.internalPort&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For more advanced configuration, a user can specify a YAML file containing overrides with the &lt;em&gt;--values&lt;/em&gt; option.&lt;/p&gt;
&lt;h4 id=&#34;helpers-and-other-functions&#34;&gt;Helpers and other functions&lt;/h4&gt;
&lt;p&gt;The &lt;em&gt;service.yaml&lt;/em&gt; template also makes use of partials defined in &lt;em&gt;_helpers.tpl&lt;/em&gt;, as well as functions like &lt;em&gt;replace&lt;/em&gt;. The &lt;a href=&#34;https://helm.sh/docs/chart_template_guide/getting_started/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm documentation&lt;/a&gt; has a deeper walkthrough of the templating language, explaining how functions, partials and flow control can be used when developing your chart.&lt;/p&gt;
&lt;h3 id=&#34;documentation&#34;&gt;Documentation&lt;/h3&gt;
&lt;p&gt;Another useful file in the &lt;em&gt;templates/&lt;/em&gt; directory is the &lt;em&gt;NOTES.txt&lt;/em&gt; file. This is a templated, plaintext file that gets printed out after the chart is successfully deployed. As we&amp;rsquo;ll see when we deploy our first chart, this is a useful place to briefly describe the next steps for using a chart. Since &lt;em&gt;NOTES.txt&lt;/em&gt; is run through the template engine, you can use templating to print out working commands for obtaining an IP address, or getting a password from a Secret object.&lt;/p&gt;
&lt;h3 id=&#34;metadata&#34;&gt;Metadata&lt;/h3&gt;
&lt;p&gt;As mentioned earlier, a Helm chart consists of metadata that is used to help describe what the application is, define constraints on the minimum required Kubernetes and/or Helm version and manage the version of your chart. All of this metadata lives in the &lt;em&gt;Chart.yaml&lt;/em&gt; file. The &lt;a href=&#34;https://helm.sh/docs/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm documentation&lt;/a&gt; describes the different fields for this file.&lt;/p&gt;
&lt;h2 id=&#34;step-2-deploy-your-first-chart&#34;&gt;Step 2: Deploy your first chart&lt;/h2&gt;
&lt;p&gt;The chart you generated in the previous step is set up to run an NGINX server exposed via a Kubernetes Service. By default, the chart will create a &lt;em&gt;ClusterIP&lt;/em&gt; type Service, so NGINX will only be exposed internally in the cluster. To access it externally, we&amp;rsquo;ll use the &lt;em&gt;NodePort&lt;/em&gt; type instead. We can also set the name of the Helm release so we can easily refer back to it. Let&amp;rsquo;s go ahead and deploy our NGINX chart using the &lt;em&gt;helm install&lt;/em&gt; command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install example ./mychart --set service.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;NodePort
NAME:   example
LAST DEPLOYED: Tue May  &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; 20:03:27 &lt;span class=&#34;m&#34;&gt;2017&lt;/span&gt;
NAMESPACE: default
STATUS: DEPLOYED

RESOURCES:
&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; v1/Service
NAME             CLUSTER-IP  EXTERNAL-IP  PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;       AGE
example-mychart  10.0.0.24   &amp;lt;nodes&amp;gt;      80:30630/TCP  &lt;span class=&#34;nv&#34;&gt;0s&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; v1beta1/Deployment
NAME             DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
example-mychart  &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;        &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;        &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;           &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          0s

NOTES:
1. Get the application URL by running these commands:
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;NODE_PORT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get --namespace default -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{.spec.ports[0].nodePort}&amp;#34;&lt;/span&gt; services example-mychart&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;NODE_IP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get nodes --namespace default -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{.items[0].status.addresses[0].address}&amp;#34;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; http://&lt;span class=&#34;nv&#34;&gt;$NODE_IP&lt;/span&gt;:&lt;span class=&#34;nv&#34;&gt;$NODE_PORT&lt;/span&gt;/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output of &lt;em&gt;helm install&lt;/em&gt; displays a handy summary of the state of the release, what objects were created, and the rendered &lt;em&gt;NOTES.txt&lt;/em&gt; file to explain what to do next. Run the commands in the output to get a URL to access the NGINX service and pull it up in your browser.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/create-helm-chart/nginx-server.png&#34; alt=&#34;nginx server default page&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;If all went well, you should see the NGINX welcome page as shown above. Congratulations! You&amp;rsquo;ve just deployed your very first service packaged as a Helm chart!&lt;/p&gt;
&lt;h2 id=&#34;step-3-modify-chart-to-deploy-a-custom-service&#34;&gt;Step 3: Modify chart to deploy a custom service&lt;/h2&gt;
&lt;p&gt;The generated chart creates a Deployment object designed to run an image provided by the default values. This means all we need to do to run a different service is to change the referenced image in &lt;em&gt;values.yaml&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We are going to update the chart to run a &lt;a href=&#34;https://github.com/prydonius/todomvc/tree/master/examples/react&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;todo list application&lt;/a&gt; available on &lt;a href=&#34;https://hub.docker.com/r/prydonius/todo/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Docker Hub&lt;/a&gt;. In &lt;em&gt;values.yaml&lt;/em&gt;, update the image keys to reference the todo list image:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;image:
repository: prydonius/todo
tag: 1.0.0
pullPolicy: IfNotPresent
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As you develop your chart, it&amp;rsquo;s a good idea to run it through the linter to ensure you&amp;rsquo;re following best practices and that your templates are well-formed. Run the &lt;em&gt;helm lint&lt;/em&gt; command to see the linter in action:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm lint ./mychart
&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; Linting ./mychart
&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;INFO&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; Chart.yaml: icon is recommended

&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; chart&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;s&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; linted, no failures
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The linter didn&amp;rsquo;t complain about any major issues with the chart, so we&amp;rsquo;re good to go. However, as an example, here is what the linter might output if you managed to get something wrong:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;malformed&amp;#34;&lt;/span&gt; &amp;gt; mychart/values.yaml
helm lint ./mychart
&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; Linting mychart
&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;INFO&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; Chart.yaml: icon is recommended
&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;ERROR&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; values.yaml: unable to parse YAML
    error converting YAML to JSON: yaml: line 34: could not find expected &lt;span class=&#34;s1&#34;&gt;&amp;#39;:&amp;#39;&lt;/span&gt;

Error: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; chart&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;s&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; linted, &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; chart&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;s&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; failed
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This time, the linter tells us that it was unable to parse my &lt;em&gt;values.yaml&lt;/em&gt; file correctly. With the line number hint, we can easily find the fix the bug we introduced.&lt;/p&gt;
&lt;p&gt;Now that the chart is once again valid, run &lt;em&gt;helm install&lt;/em&gt; again to deploy the todo list application:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install example2 ./mychart --set service.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;NodePort
NAME:   example2
LAST DEPLOYED: Wed May  &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt; 12:10:03 &lt;span class=&#34;m&#34;&gt;2017&lt;/span&gt;
NAMESPACE: default
STATUS: DEPLOYED

RESOURCES:
&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; v1/Service
NAME              CLUSTER-IP  EXTERNAL-IP  PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;       AGE
example2-mychart  10.0.0.78   &amp;lt;nodes&amp;gt;      80:31381/TCP  &lt;span class=&#34;nv&#34;&gt;0s&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; apps/v1/Deployment
NAME              DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
example2-mychart  &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;        &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;        &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;           &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          0s


NOTES:
1. Get the application URL by running these commands:
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;NODE_PORT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get --namespace default -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{.spec.ports[0].nodePort}&amp;#34;&lt;/span&gt; services example2-mychart&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;NODE_IP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get nodes --namespace default -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{.items[0].status.addresses[0].address}&amp;#34;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; http://&lt;span class=&#34;nv&#34;&gt;$NODE_IP&lt;/span&gt;:&lt;span class=&#34;nv&#34;&gt;$NODE_PORT&lt;/span&gt;/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once again, we can run the commands in the NOTES to get a URL to access our application.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/create-helm-chart/todo-list-app.png&#34; alt=&#34;Todo List Application&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;If you have already built containers for your applications, you can run them with your chart by updating the default values or the &lt;em&gt;Deployment&lt;/em&gt; template. Check out the Bitnami Docs for an &lt;a href=&#34;https://docs.bitnami.com/tutorials/deploy-custom-nodejs-app-bitnami-containers/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;introduction to containerizing your applications&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;step-4-package-it-all-up-to-share&#34;&gt;Step 4: Package it all up to share&lt;/h2&gt;
&lt;p&gt;So far in this tutorial, we&amp;rsquo;ve been using the &lt;em&gt;helm install&lt;/em&gt; command to install a local, unpacked chart. However, if you are looking to share your charts with your team or the community, your consumers will typically install the charts from a tar package. We can use &lt;em&gt;helm package&lt;/em&gt; to create the tar package:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm package ./mychart
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Helm will create a &lt;em&gt;mychart-0.1.0.tgz&lt;/em&gt; package in our working directory, using the name and version from the metadata defined in the &lt;em&gt;Chart.yaml&lt;/em&gt; file. A user can install from this package instead of a local directory by passing the package as the parameter to &lt;em&gt;helm install&lt;/em&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install example3 mychart-0.1.0.tgz --set service.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;NodePort
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;repositories&#34;&gt;Repositories&lt;/h3&gt;
&lt;p&gt;In order to make it much easier to share packages, Helm has built-in support for installing packages from an HTTP server. Helm reads a repository index hosted on the server which describes what chart packages are available and where they are located.&lt;/p&gt;
&lt;p&gt;We can use the &lt;em&gt;helm serve&lt;/em&gt; command to run a local repository to serve our chart.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm serve
Regenerating index. This may take a moment.
Now serving you on 127.0.0.1:8879
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now, in a separate terminal window, you should be able to see your chart in the local repository and install it from there:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm search &lt;span class=&#34;nb&#34;&gt;local&lt;/span&gt;
NAME         	VERSION	DESCRIPTION
local/mychart	0.1.0  	A Helm chart &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; Kubernetes

helm install example4 local/mychart --set service.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;NodePort
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To set up a remote repository you can follow the guide in the &lt;a href=&#34;https://github.com/kubernetes/helm/blob/master/docs/chart_repository.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;dependencies&#34;&gt;Dependencies&lt;/h2&gt;
&lt;p&gt;As the applications your packaging as charts increase in complexity, you might find you need to pull in a dependency such as a database. Helm allows you to specify sub-charts that will be created as part of the same release. To define a dependency, create a &lt;em&gt;requirements.yaml&lt;/em&gt; file in the chart root directory:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &amp;gt; ./mychart/requirements.yaml &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt;EOF
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;dependencies:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;- name: mariadb
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;version: 0.6.0
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;repository: https://charts.helm.sh/stable
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Much like a runtime language dependency file (such as Python&amp;rsquo;s &lt;em&gt;requirements.txt&lt;/em&gt;), the &lt;em&gt;requirements.yaml&lt;/em&gt; file allows you to manage your chart&amp;rsquo;s dependencies and their versions. When updating dependencies, a lockfile is generated so that subsequent fetching of dependencies use a known, working version. Run the following command to pull in the MariaDB dependency we defined:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm dep update ./mychart
Hang tight &lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; we grab the latest from your chart repositories...
...Unable to get an update from the &lt;span class=&#34;s2&#34;&gt;&amp;#34;local&amp;#34;&lt;/span&gt; chart repository &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;http://127.0.0.1:8879/charts&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;:
    Get http://127.0.0.1:8879/charts/index.yaml: dial tcp 127.0.0.1:8879: getsockopt: connection refused
...Successfully got an update from the &lt;span class=&#34;s2&#34;&gt;&amp;#34;bitnami&amp;#34;&lt;/span&gt; chart repository
...Successfully got an update from the &lt;span class=&#34;s2&#34;&gt;&amp;#34;incubator&amp;#34;&lt;/span&gt; chart repository
Update Complete. *Happy Helming!*
Saving &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; charts
Downloading mariadb from repo
$ ls ./mychart/charts
mariadb-0.6.0.tgz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Helm has found a matching version in the &lt;em&gt;bitnami&lt;/em&gt; repository and has fetched it into my chart&amp;rsquo;s sub-chart directory. Now when we go and install the chart, we&amp;rsquo;ll see that MariaDB&amp;rsquo;s objects are created too:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install example5 ./mychart --set service.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;NodePort
NAME:   example5
LAST DEPLOYED: Wed May  &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt; 16:28:18 &lt;span class=&#34;m&#34;&gt;2017&lt;/span&gt;
NAMESPACE: default
STATUS: DEPLOYED

RESOURCES:
&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; v1/Secret
NAME              TYPE    DATA  AGE
example5-mariadb  Opaque  &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;     &lt;span class=&#34;nv&#34;&gt;1s&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; v1/ConfigMap
NAME              DATA  AGE
example5-mariadb  &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;     &lt;span class=&#34;nv&#34;&gt;1s&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; v1/PersistentVolumeClaim
NAME              STATUS  VOLUME                                    CAPACITY  ACCESSMODES  AGE
example5-mariadb  Bound   pvc-229f9ed6-3015-11e7-945a-66fc987ccf32  8Gi       RWO          &lt;span class=&#34;nv&#34;&gt;1s&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; v1/Service
NAME              CLUSTER-IP  EXTERNAL-IP  PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;       AGE
example5-mychart  10.0.0.144  &amp;lt;nodes&amp;gt;      80:30896/TCP  1s
example5-mariadb  10.0.0.108  &amp;lt;none&amp;gt;       3306/TCP      &lt;span class=&#34;nv&#34;&gt;1s&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&amp;gt; apps/v1/Deployment
NAME              DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
example5-mariadb  &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;        &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;        &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;           &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          1s
example5-mychart  &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;        &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;        &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;           &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          1s


NOTES:
1. Get the application URL by running these commands:
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;NODE_PORT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get --namespace default -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{.spec.ports[0].nodePort}&amp;#34;&lt;/span&gt; services example5-mychart&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;NODE_IP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get nodes --namespace default -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{.items[0].status.addresses[0].address}&amp;#34;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; http://&lt;span class=&#34;nv&#34;&gt;$NODE_IP&lt;/span&gt;:&lt;span class=&#34;nv&#34;&gt;$NODE_PORT&lt;/span&gt;/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;contribute-to-the-bitnami-repository&#34;&gt;Contribute to the Bitnami repository!&lt;/h2&gt;
&lt;p&gt;As a chart author, you can help to build out Bitnami&amp;rsquo;s chart repository by improving existing charts or submitting new ones. Checkout &lt;a href=&#34;https://kubeapps.com&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;https://kubeapps.com&lt;/a&gt; to see what&amp;rsquo;s currently available and head to &lt;a href=&#34;https://github.com/bitnami/charts&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;https://github.com/bitnami/charts&lt;/a&gt; to get involved.&lt;/p&gt;
&lt;h2 id=&#34;useful-links&#34;&gt;Useful links&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ve walked through some of the ways Helm supercharges the delivery of applications on Kubernetes. From an empty directory, you were able to get a working Helm chart out of a single command, deploy it to your cluster and access an NGINX server. Then, by simply changing a few lines and re-deploying, you had a much more useful todo list application running on your cluster! Beyond templating, linting, sharing and managing dependencies, here are some other useful tools available to chart authors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/helm/blob/master/docs/charts_hooks.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Define hooks to run &lt;em&gt;Jobs&lt;/em&gt; before or after installing and upgrading releases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/helm/blob/master/docs/provenance.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Sign chart packages to help users verify its integrity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/helm/blob/master/docs/chart_tests.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Write integration/validation tests for your charts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/helm/blob/master/docs/charts_tips_and_tricks.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Employ a handful of tricks in your chart templates&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: What is Helmfile?</title>
      
      <link>/guides/kubernetes/helmfile-what-is/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/helmfile-what-is/</guid>
      <description>

        
        &lt;p&gt;&lt;a href=&#34;https://github.com/roboll/helmfile&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helmfile&lt;/a&gt; adds additional functionality to &lt;a href=&#34;https://helm.sh&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm&lt;/a&gt; by wrapping it in a declarative spec that allows you to compose several charts together to create a comprehensive deployment artifact for anything from a single application to your entire infrastructure stack.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: If you&amp;rsquo;re not familiar with Helm, start with our &lt;a href=&#34;../helm-what-is&#34;&gt;Getting Started with Helm&lt;/a&gt; guide.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In addition to the Templating and Packaging Helm gives you for your Kubernetes manifests, Helmfile provides a way to apply GitOps style CI/CD methodologies over your Helm charts by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Separating out your Environment specific information from your Chart&lt;/li&gt;
&lt;li&gt;Performing a diff of your existing deployment and only applying the changes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Helmfile uses the same templating system as Helm and in a way lets you template your templates (&lt;em&gt;&lt;insert yo dawg meme here&gt;&lt;/em&gt;). This can be a bit difficult to wrap your mind around at first, but adds a ton of powerful features as it allows you to put basic programming logic like &lt;em&gt;if/then/else&lt;/em&gt; into just about any component including your actual Helm Chart Values.&lt;/p&gt;
&lt;h2 id=&#34;why-is-it-important&#34;&gt;Why Is It Important?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://helm.sh&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm&lt;/a&gt; is a great tool for templating and sharing Kubernetes manifests for your applications. However it can become quite cumbersome to install larger multi-tier applications or groups of applications across multiple Kubernetes clusters.&lt;/p&gt;
&lt;p&gt;Helmfile addresses this issue and more by providing a fairly simple but very powerful declarative specification for deploying Helm charts across many environments.&lt;/p&gt;
&lt;p&gt;First and foremost Helm is a &lt;strong&gt;declarative&lt;/strong&gt; specification. Like Kubernetes manifests you can store them in version control, and perform declarative style actions. Much like Kubernetes has &lt;code&gt;kubectl apply&lt;/code&gt; for Kubernetes manifests, Helmfile has &lt;code&gt;helmfile apply&lt;/code&gt; for Helm charts.&lt;/p&gt;
&lt;p&gt;Helmfile is very &lt;strong&gt;modular&lt;/strong&gt;, you can have one large &lt;code&gt;helmfile.yaml&lt;/code&gt; that does everything or you can break it down to suit your way of working. This modularity allows you to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Give each Helm chart its own &lt;code&gt;helmfile.yaml&lt;/code&gt; and include them recursively in a centralized &lt;code&gt;helmfile.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Separate out &lt;a href=&#34;https://github.com/roboll/helmfile/blob/master/docs/writing-helmfile.md#layering-state-files&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;environment specific&lt;/a&gt; values from general values. Often you&amp;rsquo;ll find while a Helm chart can take 50 different values, only a few actually differ between your environments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As well as providing a set of values, either Environment specific or otherwise, you can also read Environment Variables, Execute scripts and read their output.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Store &lt;a href=&#34;https://github.com/roboll/helmfile/pull/648&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;remote state&lt;/a&gt; in git/s3/fileshare/etc in much the same way as Terraform does.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Helmfile is &lt;strong&gt;versatile&lt;/strong&gt; enough to allow you to also include raw Kubernetes manifests, &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kustomizations&lt;/a&gt;, or even execute scripts via hooks, turning all of these into &lt;a href=&#34;https://github.com/roboll/helmfile/pull/673&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm releases&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Need to modify the resources generated by a specific Helm chart? Helmfile allows you to &lt;a href=&#34;https://github.com/roboll/helmfile/pull/673&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;JSON/Strategic-Merge&lt;/a&gt; &lt;strong&gt;patch&lt;/strong&gt; resources before actually installing them.&lt;/p&gt;
&lt;h2 id=&#34;how-does-it-work&#34;&gt;How Does It Work?&lt;/h2&gt;
&lt;p&gt;Helmfile works by reading in your Helmfile manifest (usually &lt;code&gt;helmfile.yaml&lt;/code&gt;) which declares the Helm Charts you want to install and the values you wish to install them with, these are compared against the actual state of what is running in your cluster and any differences are then acted upon by calling out to Helm itself.&lt;/p&gt;
&lt;p&gt;A basic &lt;code&gt;helmfile.yaml&lt;/code&gt; to install nginx would look something like this:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;./apps/nginx/helmfile.yaml&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;repositories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;stable&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://kubernetes-charts.storage.googleapis.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;releases&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-nginx-server&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;chart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;stable/nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;~1.24.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;./nginx/vault.yaml.gotmpl&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my.registry.com/nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Values are a list that can be passed in as a file or a list of key/values. These are the helm style values that will be rendered into your chart. Helmfile will treat any file with the &lt;code&gt;.gotmpl&lt;/code&gt; extension as a template and will render it &lt;strong&gt;before&lt;/strong&gt; passing it onto Helm.&lt;/p&gt;
&lt;p&gt;If you wanted to load the above into a parent &lt;code&gt;helmfile.yaml&lt;/code&gt; you could do the following:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;./helmfile.yaml&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;helmfiles&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;apps/*/helmfile.yaml&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can even make all of your included &lt;code&gt;helmfile.yaml&lt;/code&gt; files templates and render stuff right into the helmfiles. It really is templates all the way down.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;./helmfile.yaml&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;helmfiles:
  - apps/*/helmfile.yaml.gotmpl
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thankfully the Helmfile GitHub repository has some really good &lt;a href=&#34;https://github.com/roboll/helmfile#configuration&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;documentation&lt;/a&gt; and &lt;a href=&#34;https://github.com/roboll/helmfile/blob/master/docs/writing-helmfile.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;best practices&lt;/a&gt; showing different ways to construct your &lt;code&gt;helmfile.yaml&lt;/code&gt; files.&lt;/p&gt;
&lt;h2 id=&#34;how-can-i-use-it&#34;&gt;How Can I Use It?&lt;/h2&gt;
&lt;p&gt;It&amp;rsquo;s pretty easy to get started with Helmfile. The documentation in the repository is quite good.&lt;/p&gt;
&lt;p&gt;For an interesting perspective showing how to completely decouple your Code and Environment data have a look at Paul Czarkowski&amp;rsquo;s &lt;a href=&#34;https://github.com/paulczar/helmfile-starter-kit&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helmfile Starter Kit&lt;/a&gt; and the &lt;a href=&#34;https://github.com/paulczar/platform-operations-on-kubernetes&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Platform Operations on Kubernetes&lt;/a&gt; project built on top of it. The latter of which is used to deploy a whole kitchen sink worth of platform tooling across dozens of Kubernetes clusters.&lt;/p&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/css/faq.css&#34;&gt;
&lt;div class=&#34;faqs&#34; id=&#34;faqs&#34;&gt;
    &lt;div class=&#34;flex-container jc-between&#34;&gt;&lt;/div&gt;
        &lt;h2 class=&#34;h2 mb-md&#34;&gt;Frequently Asked Questions&lt;/h2&gt;
        &lt;div class=&#34;faq&#34;&gt;
            
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;What is a Helmfile?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Helmfile is a declarative specification wrapping for deploying distributions of Helm charts. They add additional functionality to Helm by allowing you to compose several charts together to create a comprehensive deployment artifact.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;What is a Helm chart?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Helm charts are Kubernetes manifests or a collection of files that correspond to a directly related set of Kubernetes resources.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;How do Helmfiles work?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Helmfiles work by reading your Helmfile manifests and comparing them against the actual state of what is running in your cluster. Any differences are then acted upon by calling out to Helm itself.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;What is the difference between Helm and Helmfile?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Helm is a tool for templating and sharing Kubernetes manifests for your applications, while a Helmfile is a declarative specification for deploying Helm charts that adds functionality to Helm.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;How do you modify the resources generated by a specific Helm chart?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Resources generated by a specific Helm chart can be modified before installation by allowing you to JSON/Strategic-Merge patch resources.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;What are the benefits of Helmfiles?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Helmfiles are beneficial because they provide powerful declarative specification for deploying Helm charts across many environments.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

        &lt;/div&gt;
    &lt;/div&gt;
    
&lt;/div&gt;

&lt;script type=&#34;text/javascript&#34;&gt;
    $(&#34;.faq-item&#34;).each( function() {
        $(this).click(function () {
            $(this).find(&#34;#arrow&#34;).toggleClass(&#34;flip&#34;); 
            $(this).find(&#34;.faq-answer&#34;).slideToggle(200); 
        });
    });
&lt;/script&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Getting Started with Cloud Foundry for Kubernetes</title>
      
      <link>/guides/kubernetes/cf4k8s-gs/</link>
      <pubDate>Wed, 29 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/cf4k8s-gs/</guid>
      <description>

        
        &lt;blockquote&gt;
&lt;p&gt;Updated October 2020: CF CLI version 7+ and 6 CPU availability now required, removed metrics server install, new values added to the install yaml eliminate steps from before, and new Kubernetes rendering file. Overall this simplifies installation from previous iterations.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudfoundry/cf-for-k8s.git&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;CF-for-k8s&lt;/a&gt; brings Cloud Foundry to Kubernetes.&lt;/p&gt;
&lt;p&gt;Cloud Foundry is an open-source, multi-cloud application platform as a service governed by the Cloud Foundry Foundation, a 501 organization.&lt;/p&gt;
&lt;p&gt;Using Cloud Foundry developers only have to focus on writing and delivering code as CF takes care of the rest. Developers enter &lt;code&gt;cf push&lt;/code&gt; into the command line and their app will be deployed immediately receiving an endpoint. The CF platform will take care of containerizing the source code into a working app with the required dependencies, can be configured to bind to a database, connect to a market place and much more.&lt;/p&gt;
&lt;p&gt;The cf-for-k8s platform adds a higher level of abstraction to Kubernetes by removing the sharp learning curve required for teams, developers don&amp;rsquo;t have to know Kubernetes they only have to &lt;code&gt;cf push&lt;/code&gt;. Kubernetes adds new possibilities to Cloud Foundry opening up the massive Kubernetes ecosystem.&lt;/p&gt;
&lt;p&gt;In this guide you&amp;rsquo;ll deploy Cloud Foundry on Kubernetes locally.&lt;/p&gt;
&lt;h2 id=&#34;before-you-begin&#34;&gt;Before you begin&lt;/h2&gt;
&lt;h3 id=&#34;machine-requirements&#34;&gt;Machine Requirements&lt;/h3&gt;
&lt;p&gt;Currently cf-for-k8s supports Kubernetes 1.15.x or 1.16.x, the config yaml file we are using to make our kind cluster will make a cluster with the following requirements, see that your computer can handle them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;have a minimum of 1 node&lt;/li&gt;
&lt;li&gt;have a minimum of 6 CPU, 8GB memory per node&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tools-required&#34;&gt;Tools required&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;You will need a few tools before beginning and once set up installation usually takes 10 minutes or less.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;CF CLI version requirement changed to version 7+&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.cloudfoundry.org/cf-cli/install-go-cli.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cloud Foundry CLI&lt;/a&gt; (version 7+) to talk to Cloud Foundry&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;on mac
&lt;pre&gt;&lt;code&gt;brew install cloudfoundry/tap/cf-cli
# verify install 
cf version
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You will need &lt;code&gt;kubectl&lt;/code&gt; to interact with your cluster &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubectl install instructions&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;on mac
&lt;pre&gt;&lt;code&gt;brew install kubectl
# verify install 
kubectl version --client
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;KinD (Kubernetes in Docker) to instantiate your local cluster &lt;a href=&#34;https://kind.sigs.k8s.io/docs/user/quick-start/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kind install instructions&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;on mac
&lt;pre&gt;&lt;code&gt;brew install kind
# verify install 
kind version
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://bosh.io/docs/cli-v2-install/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bosh CLI&lt;/a&gt; the &lt;code&gt;./hack/generate-values.sh&lt;/code&gt; script will use the Bosh CLI to generate certificates, keys, and passwords in the file &lt;code&gt;./cf-install-values.yml&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;on mac
&lt;pre&gt;&lt;code&gt;brew install cloudfoundry/tap/bosh-cli
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://k14s.io/#install&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kapp&lt;/a&gt; (v0.21.0+) will aid you to deploy cf-for-k8s to your cluster&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;on mac
&lt;pre&gt;&lt;code&gt;brew tap k14s/tap
brew install ytt kapp
kapp --version
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://k14s.io/#install&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;ytt&lt;/a&gt; (v0.26.0+) will help create templates to deploy cf-for-k8s&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;on mac you should have this installed from the above command, to verify:
&lt;pre&gt;&lt;code&gt;ytt version
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;DockerHub&lt;/a&gt; is the image registry used in this guide please make an account if you don&amp;rsquo;t have one they are free and quickly made.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;clone-the-cf-for-k8s-repo&#34;&gt;Clone the CF for K8s repo&lt;/h2&gt;
&lt;p&gt;Clone the repo to preferred location and cd into it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/cloudfoundry/cf-for-k8s.git &amp;amp;&amp;amp; cd cf-for-k8s
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;setup-your-local-k8s-cluster-with-kind&#34;&gt;Setup your local k8s cluster with KinD&lt;/h2&gt;
&lt;p&gt;Create your cluster using the config yaml from the cf-for-k8s repo obtained above.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kind create cluster --config=./deploy/kind/cluster.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Point your kubeconfig to your new cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl cluster-info --context kind-kind
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;generate-the-yaml-used-to-deploy-cf-for-k8s&#34;&gt;Generate the yaml used to deploy CF for k8s&lt;/h2&gt;
&lt;p&gt;In this script you use &lt;code&gt;vcap.me&lt;/code&gt; as your CF domain with the flag &lt;code&gt;-d&lt;/code&gt;, this way you can avoid configuring DNS for a domain.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;./hack/generate-values.sh&lt;/code&gt; script will generate certificates, keys, passwords, and configuration needed to deploy into `./cf-install-values.yml&#39;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./hack/generate-values.sh -d vcap.me &amp;gt; ./cf-install-values.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Append the app_registry credentials to your DockerHub registry to the bottom of the &lt;code&gt;./cf-install-values.yml&lt;/code&gt; replacing with your information. You can copy/paste  or use the following command.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The repeated username is a requirement for DockerHub, this setting changes with some container registries. Also, don&amp;rsquo;t forget to add the quotes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;To use another container registry follow the &lt;a href=&#34;https://github.com/cloudfoundry/cf-for-k8s/blob/master/docs/deploy.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;instructions under step 3&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt;&amp;gt; cf-install-values.yml &amp;lt;&amp;lt; EOL
app_registry:
  hostname: https://index.docker.io/v1/
  repository_prefix: &amp;quot;&amp;lt;DockerHub-username&amp;gt;&amp;quot;
  username: &amp;quot;&amp;lt;DockerHub-username&amp;gt;&amp;quot;
  password: &amp;quot;&amp;lt;DockerHub-password&amp;gt;&amp;quot;
EOL
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are a few more lines to add to your cf-install-values.yml, like adding a metrics server because KinD doesn&amp;rsquo;t come with one.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt;&amp;gt; cf-install-values.yml &amp;lt;&amp;lt; EOL
add_metrics_server_components: true
enable_automount_service_account_token: true
metrics_server_prefer_internal_kubelet_address: true
remove_resource_requirements: true
use_first_party_jwt_tokens: true

load_balancer:
  enable: false
EOL
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, use cf-install-values.yml to render the final Kubernetes template to raw Kubernetes configuration.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ytt -f config -f ./cf-install-values.yml &amp;gt; ./cf-for-k8s-rendered.yml
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;deploy-cf-for-k8s&#34;&gt;Deploy CF for k8s&lt;/h2&gt;
&lt;p&gt;You are ready to deploy cf-for-k8s using the &lt;code&gt;./cf-for-k8s-rendered.yml&lt;/code&gt; file created above. Once you deploy it should take around 10 minutes to finish.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The deployment has a timer and will exit with a timeout error if it takes too long. Assuming all previous steps were followed correctly enter the deployment command again to finish if it exits early.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;kapp deploy -a cf -f ./cf-for-k8s-rendered.yml -y
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;validate-the-deployment&#34;&gt;Validate the deployment&lt;/h2&gt;
&lt;p&gt;Target your CF CLI to point to the new CF instance.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cf api --skip-ssl-validation https://api.vcap.me
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Set the CF_ADMIN_PASSWORD environment variable to the CF administrative password, stored in the cf_admin_password key in the configuration-values/deployment-values.yml file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CF_ADMIN_PASSWORD=&amp;quot;$(bosh interpolate ./cf-install-values.yml --path /cf_admin_password)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Log into the installation as the admin user.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cf auth admin &amp;quot;$CF_ADMIN_PASSWORD&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Enable Docker&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cf enable-feature-flag diego_docker
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A powerful feature provided by CF is multi-tenancy, where you can create a space for a team, an app or whatever your workflow requires.&lt;/p&gt;
&lt;p&gt;Create and target an organization and space.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cf create-org test-org
cf create-space -o test-org test-space
cf target -o test-org -s test-space
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;deploy-an-application-with-cf-push&#34;&gt;Deploy an application with &lt;code&gt;cf push&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;At last you can push the included sample &lt;code&gt;test-node-app&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cf push test-node-app -p ./tests/smoke/assets/test-node-app
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt;Or you can push any app you wish just cd into the directory and push the app with the following command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cf push APP-NAME
&lt;/code&gt;&lt;/pre&gt;&lt;/blockquote&gt;
&lt;p&gt;Once your app stages you can find it in Cloud Foundry with this command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cf apps
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The output in the terminal should look something as follows.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Getting apps in org test-org / space test-space as admin...
OK

name            requested state   instances   memory   disk   urls
test-node-app   started           1/1         1G       1G     test-node-app.vcap.me
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To see the pods that have applications on your Cloud Foundry instance look in the &lt;code&gt;cf-workloads&lt;/code&gt; namespace.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get pods -n cf-workloads
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can now play with cf for k8s and deploy other apps and observe how it affects the Kubernetes infrastructure. Try other cf commands like &lt;code&gt;cf delete test-node-app&lt;/code&gt; and see what changes, enjoy you new cf for k8s instance.&lt;/p&gt;
&lt;h2 id=&#34;delete-the-cf-for-k8s-deployment&#34;&gt;Delete the cf-for-k8s deployment&lt;/h2&gt;
&lt;p&gt;You can delete the cf-for-k8s deployment from your cluster by running the following command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kapp delete -a cf
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;delete-your-kind-cluster&#34;&gt;Delete your Kind cluster&lt;/h2&gt;
&lt;p&gt;To delete your KinD cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kind delete cluster
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;Learn more about Cloud Foundry with the links below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudfoundry/cf-for-k8s.git&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;cf-for-k8s GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cloudfoundry.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;cloudfoundry.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://katacoda.com/cloudfoundry-tutorials/scenarios/trycf&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Online CF Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Workload Identity</title>
      
      <link>/guides/kubernetes/platform-security-workload-identity/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/platform-security-workload-identity/</guid>
      <description>

        
        &lt;p&gt;This document details the philosophy and methods for providing workload identity
in a Kubernetes cluster. It covers architectural considerations, tooling
integrations, and best practices. This document represents how the VMware field
team approaches workload identity in enterprise Kubernetes environments.&lt;/p&gt;
&lt;p&gt;Each section covers architectural recommendations and, at times, configuration
for each concern. At a high-level, the key recommendations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Selectors that determine the identity of a workload (image ID, service
account, node name etc&amp;hellip;) should be scoped as tightly as possible to ensure a
strong guarantee of unique identity.&lt;/li&gt;
&lt;li&gt;Identity-providing systems should be able to easily rotate and revoke granted
identities in the case of compromise.&lt;/li&gt;
&lt;li&gt;Prefer integrating identity solutions into a service mesh or sidecar to avoid
tightly-coupling identity into your applications.&lt;/li&gt;
&lt;li&gt;Ensure you understand the security model (including the blast radius of a
compromise at any level) of your identity provider. Develop and test a
contingency strategy should credentials be compromised at different points.&lt;/li&gt;
&lt;li&gt;Avoid using network primitives (IP addresses, etc&amp;hellip;) as identities.&lt;/li&gt;
&lt;li&gt;Understand the domains throughout which identity has to be proved (single /
multi-cluster, single / multi-cloud, Kubernetes / non-Kubernetes, etc&amp;hellip;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;identity-and-authentication&#34;&gt;Identity and Authentication&lt;/h2&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Authentication vs Authorization&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Authentication is the process of establishing the identity of an application or
user. This is primarily the focus of this guide.&lt;/p&gt;
&lt;p&gt;Authorization is the process of determining what actions an application or user
are able to do, after they have been authenticated.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Establishing identity (usually for the purposes of authentication) is a key
requirement of almost every distributed system. In this context &amp;lsquo;identity&amp;rsquo; means
a verifiable, unique (within the desired scope), set of information that can be
used to identify an actor (this guide focuses on use cases where the actor is an
application, rather than a user). Examples are username / password combinations,
certificates, tokens, and more.&lt;/p&gt;
&lt;p&gt;Establishing the identity of an actor is important so that you can make
decisions about whether the actor is allowed access to a system, what actions
they can take and what data they have access to (broadly, authorization).&lt;/p&gt;
&lt;h2 id=&#34;authentication-methods&#34;&gt;Authentication Methods&lt;/h2&gt;
&lt;p&gt;There are a number of different authentication methods in wide use. All have
different properties, advantages and disadvantages. Some are cross-platform (or
platform-agnostic), some are integrated with specific platforms. In addition to
providing identity, some of the methods described may also provide encryption.
For example, the
&lt;a href=&#34;https://en.wikipedia.org/wiki/Certificate_signing_request&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;CSR&lt;/a&gt; flow used by
Kubernetes provides certificates that could be used in a Mutual TLS (mTLS) flow.
However, encryption is not the focus of this guide and that is an incidental
benefit of those methods of identity grants.&lt;/p&gt;
&lt;h3 id=&#34;shared-secrets&#34;&gt;Shared Secrets&lt;/h3&gt;
&lt;p&gt;A shared secret is a unique piece (or set) of information that is held by the
calling application and the server. For example, when an application needs to
connect to a MySQL database, it can use a username and password combination to
authenticate. This method necessitates that both parties have access to that
combination in some form. You must create an entry in MySQL with that
information, and then distribute the secret to any calling application that may
need it.&lt;/p&gt;
&lt;p&gt;You also need a way to easily rotate secret credentials in the case of a
compromise. Again you need to ensure that secrets are distributed to all calling
applications and kept in sync. There are many secret stores (&lt;a href=&#34;https://www.hashicorp.com/products/vault/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;HashiCorp
Vault&lt;/a&gt; is a prominent and mature
example) that offer integrations that get close to this goal however these still
suffer from the initial &lt;em&gt;secure introduction problem&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://learn.hashicorp.com/vault/identity-access-management/iam-secure-intro&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;secure introduction
problem&lt;/a&gt;
is the issue that is faced when initially bootstrapping application access to a
secret store. Once the authenticated communication is established, you have no
problems refreshing / rotating and so on. However, how does the application
authenticate to the secret store &lt;em&gt;&lt;em&gt;initially&lt;/em&gt;&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;In the example below, the backend application holds a database of authorized
credentials. However, you need to distribute a set of credentials to the
frontend application in order for a connection to be established.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-shared-secrets.png&#34; alt=&#34;Shared Secrets&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Well-understood and supported pattern by almost all applications &amp;amp; platforms.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Suffers from the secure introduction problem.&lt;/li&gt;
&lt;li&gt;Keeping track of, rotating and revoking credentials is challenging, especially
in large environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Shared secrets should only be used in conjunction with a robust secret store /
platform, and additional tooling / approaches are required to bootstrap the
initial connection between applications requesting identity / credentials and
the secrets store.&lt;/p&gt;
&lt;h3 id=&#34;traditional-network-primitives&#34;&gt;&amp;lsquo;Traditional&amp;rsquo; Network Primitives&lt;/h3&gt;
&lt;p&gt;Network primitives like IP addresses, VPNs, firewalls, etc&amp;hellip; have historically
been used as a form of identity for restricting which applications have access
to what services. However in a cloud-native ecosystem these methods are breaking
down.&lt;/p&gt;
&lt;p&gt;Multiple workloads are now sharing networking stacks and underlying machines.
Workloads are increasingly ephemeral and move between nodes often. This results
in a constant churn of IP addresses and network changes.&lt;/p&gt;
&lt;p&gt;In a multi-cloud and API-driven world, the network is no longer a primary
boundary in many systems, with calls to external services across multiple
providers, each of which may need a way to prove identity of our calling
applications (and vice versa).&lt;/p&gt;
&lt;p&gt;Existing traditional (platform level) network primitives (host IP addresses,
firewalls, etc&amp;hellip;) are no longer suitable for establishing workload identity and
if used at all should be only as an additional layer of defense in depth. This
is not to say that network primitives &lt;em&gt;in general&lt;/em&gt; are bad, but that they must
have additional workload context to be effective. This guide covers these
scenarios in more detail in the CNI section below.&lt;/p&gt;
&lt;h3 id=&#34;platform-mediated-node-identity&#34;&gt;Platform Mediated Node Identity&lt;/h3&gt;
&lt;p&gt;In cases where all workloads are running on a homogenous platform (for example,
AWS), it is possible for the platform itself to determine and assign identities
to workloads because of the contextual metadata they possess about the workload.&lt;/p&gt;
&lt;p&gt;Identity is not asserted by the workload itself but determined based on its
properties by an out-of-band provider. The provider returns the workload a
credential to prove identity that may be used to communicate with other services
on the platform. It then becomes trivial for the other services to verify that
credential as they too are on the same underlying platform.&lt;/p&gt;
&lt;p&gt;On AWS, an EC2 instance may request credentials to connect to a different
service like an S3 bucket. The AWS platform inspects the metadata of the
instance, and can provide role-specific credentials back to the instance with
which to make the connection.&lt;/p&gt;
&lt;p&gt;Note that the platform still has to perform &lt;em&gt;Authorization&lt;/em&gt; on the request to
ensure that the identity being used has the appropriate permissions. This method
is only being used to &lt;em&gt;Authenticate&lt;/em&gt; the request.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-platform-mediated.png&#34; alt=&#34;Platform Mediated Identity&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transparent to end users.&lt;/li&gt;
&lt;li&gt;Tight integration with the platform (AWS, GCP, etc&amp;hellip;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires all workloads to be running on the same platform.&lt;/li&gt;
&lt;li&gt;Granularity of identifying metadata may not match granularity of workloads
(&lt;em&gt;see AWS section below&lt;/em&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-identity-primitives--methods&#34;&gt;Kubernetes Identity Primitives / Methods&lt;/h2&gt;
&lt;p&gt;Kubernetes has several primitives built into the platform to provide identity,
all with varying degrees of guarantees, complexity and versatility.&lt;/p&gt;
&lt;h3 id=&#34;certificate-signing-requests-csr&#34;&gt;Certificate Signing Requests (CSR)&lt;/h3&gt;
&lt;p&gt;Any entity with appropriate RBAC permissions can submit a certificate signing
request (containing metadata to be encoded into a x509 certificate) to a
Kubernetes cluster. A user (or automated tooling) then approves or denies the
request. If the request is approved, a certificate signed by the Kubernetes CA
is created and made available for retrieval. This certificate can then be used
in a TLS flow.&lt;/p&gt;
&lt;p&gt;Note that in order for the CSR flow to function correctly the controller-manager
needs to be configured with the &lt;code&gt;--cluster-signing-cert-file&lt;/code&gt; and
&lt;code&gt;--cluster-signing-key-file&lt;/code&gt; parameters as shown below. The CA does &lt;em&gt;not&lt;/em&gt; have
to be the Kubernetes CA, however if you choose to use a different one then it is
your responsibility to make the CA available to applications, for example by
publishing it in a config map.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;kube-controller-manager&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;cluster-signing-key-file=/etc/kubernetes/pki/ca.key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Additional flags removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s.gcr.io/kube-controller-manager:v1.17.3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Firstly the application needs to create (or utilize an existing) private key and
create a CSR. The example shows using &lt;code&gt;openssl&lt;/code&gt; to create this, but libraries
exist for programmatic creation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;openssl req -new -key my-app.key -out my-app.csr -subj &lt;span class=&#34;s2&#34;&gt;&amp;#34;/CN=my-application&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next you need to apply a CSR object into the cluster that utilizes the created
&lt;code&gt;my-app.csr&lt;/code&gt; file above. Below is an example of the request as a YAML object,
but this could (and probably would, in an automated flow) be applied
programmatically via the Kubernetes API.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;l&#34;&gt;cat &amp;lt;&amp;lt;EOF | kubectl apply -f -&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;certificates.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CertificateSigningRequest&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;request&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;$(cat my-app.csr | base64 | tr -d &amp;#39;\n&amp;#39;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;client auth&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EOF&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This creates a CSR object in Kubernetes in a &lt;code&gt;pending&lt;/code&gt; state, awaiting approval.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;⎈ kubernetes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; $ kubectl get csr
NAME     AGE   REQUESTOR                               CONDITION
my-app   17h   system:serviceaccount:default:default   Pending
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This CSR object contains the (base64-encoded) signing request and the username
of the requestor. If using a service account token to authenticate to the
Kubernetes API (as a Pod would in an automated flow) then the username will be
the service account name.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;certificates.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CertificateSigningRequest&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;groups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;system:serviceaccounts&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;system:serviceaccounts:default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;system:authenticated&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;request&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlJQ1hqQ0NBVVlDQVFBd0dURVhNQlVHQTFVRUF3d09iWGt0WVhCd2JHbGpZWFJwYjI0d2dnRWlNQTBHQ1NxRwpTSWIzRFFFQkFRVUFBNElCRHdBd2dnRUtBb0lCQVFEb1hiV2FhUXVGTG9wckx6cjNNZVZnQWVwTThOUnRUQ2diClNiczk2bHVmY0tjMjFkamNFN0JHNkNmYS91NE1zTktyQnRWN2g1SEZxekM5TTArVGJwN1lmcHJLcHFYTEZhdmIKVUdSbExHZk5hUDdtS0xOMFVQTmV6d3d4d1NRdUJTNXcxMTJONElpWnV1eFhXQlNqeFVRNmtEYkx4U1pSQkxzUgp6YTBldVJkRm0wSnJuRzFzVmp4ZUFUZUx5WU90YmV0VXhTOThnOUtIZXJoSFVuNzBOM0hqeXRwRXdOT3lPV2QwCnlVVVlEYWp4bFcwSFl0VndwYkx6VnYvVk92cjFibmR1NUh0MFBwbmY5cUVsSCtxZ1hqOTIxNWFUaG1WY0RXVmQKMUhTMFdwNEVNRnpnRmMzSlRSUGtMYk9wY0haRGxuSS9ESFpkZm81TVZUblFQTzM3YzJBSkFnTUJBQUdnQURBTgpCZ2txaGtpRzl3MEJBUXNGQUFPQ0FRRUFUalV4Y25tOTZKT1VWSVNibWxjaW1wSndGSDhmZG4ydXlBSmJyaFpmCkNiOEYvdE5KWXhtUlRRWVpvQ0Z5aGEzb1hRSGh4T0FGeUZsREUrZ0tDem9CL2JPenFqZjdQZFlQVG1uTldHc0kKcndnZmZ1U2NXUkJsMGZrNGlUNU0vK0x0aUIvNnkzQTJIODE0dTF5dTQ5SmNBYXB2NE5XbUNra08vZE01cDlXcQorbmFubmVWS0FjZzlTQVpFK0JUQ2N6dVhQUm4zV2RxTzRoMUM5djgzQXRzRWt4Q0xBU1g4TU1QM1hJUnhPaHdUCkhkQWZ6bitMa0lQNTNndDNWeFFaK3RsOUVxNXN4OWZBM1JxcWEzZktsREpXN2MvSWZPcjN1Rnd2OGlid0ZuY3cKRUJnLzA3ZXdPNmR0ZjJRdUhzeHNuNW1KL2FicUdJWEppYW5CdTF4Mjl6Z0xsQT09Ci0tLS0tRU5EIENFUlRJRklDQVRFIFJFUVVFU1QtLS0tLQo=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;client auth&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;system:serviceaccount:default:default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;status&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this flow, a Kubernetes platform operator is responsible for ensuring that
the certificate should be granted, based on the metadata contained within the
request and the username / service account of the requestor. Once approved, the
requestor can retrieve the certificate (in the &lt;code&gt;status&lt;/code&gt; field of the CSR) and
use it (in conjunction with their private key) in TLS communications.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;certificates.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CertificateSigningRequest&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Additional fields removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;status&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;certificate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURBRENDQWVpZ0F3SUJBZ0lVWm9JL3pCQS9xckhmVzhWQ3o4dGJST0ZGU1g4d0RRWUpLb1pJaHZjTkFRRUwKQlFBd0ZURVRNQkVHQTFVRUF4TUthM1ZpWlhKdVpYUmxjekFlRncweU1EQXpNRFF4TlRReE1EQmFGdzB5TVRBegpNRFF4TlRReE1EQmFNQmt4RnpBVkJnTlZCQU1URG0xNUxXRndjR3hwWTJGMGFXOXVNSUlCSWpBTkJna3Foa2lHCjl3MEJBUUVGQUFPQ0FROEFNSUlCQ2dLQ0FRRUE2RjIxbW1rTGhTNktheTg2OXpIbFlBSHFUUERVYlV3b0cwbTcKUGVwYm4zQ25OdFhZM0JPd1J1Z24ydjd1RExEU3F3YlZlNGVSeGFzd3ZUTlBrMjZlMkg2YXlxYWx5eFdyMjFCawpaU3hueldqKzVpaXpkRkR6WHM4TU1jRWtMZ1V1Y05kZGplQ0ltYnJzVjFnVW84VkVPcEEyeThVbVVRUzdFYzJ0Ckhya1hSWnRDYTV4dGJGWThYZ0UzaThtRHJXM3JWTVV2ZklQU2gzcTRSMUorOURkeDQ4cmFSTURUc2psbmRNbEYKR0EybzhaVnRCMkxWY0tXeTgxYi8xVHI2OVc1M2J1UjdkRDZaMy9haEpSL3FvRjQvZHRlV2s0WmxYQTFsWGRSMAp0RnFlQkRCYzRCWE55VTBUNUMyenFYQjJRNVp5UHd4MlhYNk9URlU1MER6dCszTmdDUUlEQVFBQm8wUXdRakFUCkJnTlZIU1VFRERBS0JnZ3JCZ0VGQlFjREFqQU1CZ05WSFJNQkFmOEVBakFBTUIwR0ExVWREZ1FXQkJUdWp1WE0KbUVGNFNxNHlkVkljM04zUW01WGdnVEFOQmdrcWhraUc5dzBCQVFzRkFBT0NBUUVBaUIzOS9aWFpRTjQwYmhJRQoxQXc3UmZwaGhqVkZVTEMvT1M3QldPRUxLMjdyVVNYR1U5UWdtejNDbXdwUlo2MktFZ0RLNldGMkdqRXo0K3lvCnpiQitRMU9wd1VaLysvalJiaS91ZE1VUnZEbGdENDNXV2RObnZiYUlTZTI0aGNYSnhjQ2hlWDdmSDNsTUVXVGsKTnJaM3Y4L2dGZEErQVdSV0lJamhHY1UxTi9WZmpNSXhDWVFIK3E1a2NYSFVVTXN1OEtzcFd4elc0encvNnpTbQpISVVyTWMwb2xwQU1lUGQ0cTJvTDZ1VHJZK0lJWWcxUGFSdWhHVjg2cTJ3dVFraFBCTks4Tm5ybTNNY2s4TUczCmJPM0Ntcm9SZnJZQ0VtNnk4dmpmTnZzbzhCd25qR1R0QUY0RlQybEtIQjZqVnVDaHF2Y01vYWpranViUXlmZmsKQWJ5bjVnPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;lastUpdateTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;2020-03-04T15:45:30Z&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;This CSR was approved by kubectl certificate approve.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;reason&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;KubectlApprove&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Approved&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this example, other applications within the cluster can use the Kubernetes CA
that is mounted into each Pod to verify a presented certificate to establish the
identity of the calling application. As noted above, if you are not using the
Kubernetes CA as a root for CSRs, the CA must be made available to all
applications that require the ability to verify provided certificates.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-csr.png&#34; alt=&#34;Kubernetes CSR&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tight integration with the platform (Kubernetes).&lt;/li&gt;
&lt;li&gt;Flexible, supports a wide range of &lt;a href=&#34;https://godoc.org/k8s.io/api/certificates/v1beta1#KeyUsage&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;key
usages&lt;/a&gt; (signing,
client, server, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;Provides identity in a well-understood and consumable format (x509).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires manual intervention or development of additional tooling to verify
and approve certificate requests.&lt;/li&gt;
&lt;li&gt;Impossible to revoke certificates in the case of compromise. This could be
mitigated by using certificates with short TTLs but would require additional
logic to keep requesting new certs.&lt;/li&gt;
&lt;li&gt;Only works with services running on a single Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;service-account-tokens-sat&#34;&gt;Service Account Tokens (SAT)&lt;/h3&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Service Accounts &amp;amp; Tokens&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Service Accounts are primitives in Kubernetes that provide identity for groups
of pods. Every pod runs under a service account. If a service account is not
pre-created by an administrator and assigned to a pod, they are assigned a
default service account for the namespace they reside in.&lt;/p&gt;
&lt;p&gt;Service account tokens are JSON Web Tokens (JWT) that are created as Kubernetes
secrets when a service account is created (including the default service
account). Unless otherwise specified, these tokens are mounted into each pod
running under that service account and can be used to make requests to the
Kubernetes API (and as this section shows, other services).&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Kubernetes Service Accounts provide a way of assigning identity to a set of
workloads. Role-Based Access Control (RBAC) rules then can be applied within the
cluster to limit the scope of access for a specific service account. Service
accounts are the way that Kubernetes itself usually authenticates in-cluster
access to the API.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ServiceAccount&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secrets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-token-mf9v2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When a service account is created, an associated Secret is also created
containing a unique JWT identifying the account.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ca.crt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5ekNDQWJPZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01ETXdNVEl4TVRZeU5sb1hEVE13TURJeU56SXhNakV5Tmxvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTmVECnFsSVREbzh5QXNHb3RNbUFENDdKS3pKNXNtbTVPMWkwVFphN3QwOSttT3YrS01zYmdiQ0JQUG1Hc0FCdlU4SEQKbmw3djc0a1YvMXJHRjNUalJ1dzFQN3VWZWN2WisvTThYa1Y2ZFlnRmllTjBEUFdYWGppS1U1RXAwS21Gc28zeAplOFVUdWtFWm1TRWx4QzBtTGxtMW9SRldVUzMrRmE0MWtVakRjRWxENHNVZnVMK1JMSTh3eEZ4NkcvWHR4VzdmCnI4d0pjVFVOTnZuK3B0YjFwYzBVMXdsYU56TDl6eEI4aytIMkFNSDIyY0FyWmNTNlZybS9JZW5ZVEd4QnczSnkKOE8rMk1hOExaRHljQjRYNkNSdThkK3JISDVDdy80K0VMc2pNWnBTTDIwRDBmS2EzOEFGZFl3M0ZuZUcraUgwdQpFazhYdUxhV0NmWjBha1VPZkRNQ0F3RUFBYU1tTUNRd0RnWURWUjBQQVFIL0JBUURBZ0trTUJJR0ExVWRFd0VCCi93UUlNQVlCQWY4Q0FRQXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBRWZPdjFBVnZCL2d6bTJjdS9zYzhkWGYKNjhOaWV2aW1DMTVaL0k0cUMrdHkzZFJIWTErMndVZlpKT0M4YWwxMEIraVF3ZlRUOUcybitDM0V0NktvcDlmTApNUmVQbFBMK0RDQ1VtUHhjVy9DcENXTE5GQzJNSWZ2OERrS3cvL0RaN0xVZ1dmckIvY3pKUytyMldKLzRZemNZClRKSHZrUTNnV3d0RmlLaGE0SzZ4SjFrSXZyam9yNGFyM0w1TCtqbXlmbzhKRUo5Um1XZUk0S1MzMFFPaTNKYXEKc21wY3dHdG5RSFZNNWZWNFdxcnNRd2lXRDI5eTdCZVJsRWxCYkNvOUYxd0RYa1MvbGNvQUlVNFMzL1IvWmh4aApERHFSUG1tOTVkMnFsaWVjZGZUODFGT1F2aUFndGIxZW9Fa0pqRUpVc3QrcGQ3Qk1wQno2Z2ZDQnRVN0hZWjQ9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ZGVmYXVsdA==&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;token&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNklqRlBXUzFGTkVSRVVtSmFSRlJKWTNWSE5GcGZZV3B6T1hBNUxUTmZUR2RTTXpCV09VTlBkemxQVVUwaWZRLmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUprWldaaGRXeDBJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5OXpaWEoyYVdObFlXTmpiM1Z1ZEM5elpXTnlaWFF1Ym1GdFpTSTZJbVJsWm1GMWJIUXRkRzlyWlc0dGJXWTVkaklpTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxjblpwWTJVdFlXTmpiM1Z1ZEM1dVlXMWxJam9pWkdWbVlYVnNkQ0lzSW10MVltVnlibVYwWlhNdWFXOHZjMlZ5ZG1salpXRmpZMjkxYm5RdmMyVnlkbWxqWlMxaFkyTnZkVzUwTG5WcFpDSTZJalU1WVdWbE5EUTJMV0l6Tm1VdE5ESXdaaTA1T1dWaUxXRTJPRGc1TlRBNE5HTTVPQ0lzSW5OMVlpSTZJbk41YzNSbGJUcHpaWEoyYVdObFlXTmpiM1Z1ZERwa1pXWmhkV3gwT21SbFptRjFiSFFpZlEuUlVqSHNHV3J5djI4Z3hTQ3I3RTczMUlJeUpDcVE1Z1Vfclc4Z1pGdDg4YzdNQVVicmRNYlZBaWN5LW5WTXdWd1JnYVZ1OWMzQTJyRGgxTHVBZkZ3SWlGNklRNzE5QzhNRlY0ZjFIbFI0U1d2Mll6SExJM1RnUmZCWlNxQ3FwZEJMMXg1bmQyc0drSHBvNTYtcGZFdVVJZllfX09KN0lMS09jQkFSVW1hSGlnSWlDRWQ4NURVR3d6eGRjV3BnWUdBOGp5U0hhNkhzLXNwbG9uNjgyS3pVS2hNNTlaaTVxRzlpcHlBN0hMTkpXVEZUSG1SN3NPX0ptWmpfUlV6cVBwZ0FLQ3UtNGZGUEp4NkFwZENsLTRJS01TekhfV0hfbVZfdnozOEVibldyWEFLMnpmSVZmNVlBdm96S0t4STJYaFFjOWlhRmMyRUVqcEdMSGp6TU9vc0ln&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Secret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetes.io/service-account.name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetes.io/service-account.uid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;59aee446-b36e-420f-99eb-a68895084c98&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-token-mf9v2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kubernetes.io/service-account-token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By default, Pods will automatically get the &lt;code&gt;default&lt;/code&gt; service account token for
their namespace mounted if they do not specify a specific service account to
use. This can (and should) &lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#use-the-default-service-account-to-access-the-api-server&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;be
disabled&lt;/a&gt;
to ensure that all service account tokens are explicitly mounted to Pods and
their access scopes are well understood and defined (rather than falling back
and assuming a default).&lt;/p&gt;
&lt;p&gt;To specify a service account for a Pod, use the &lt;code&gt;serviceAccountName&lt;/code&gt; field in the Pod spec:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceAccountName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-pod-sa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Additional fields removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will cause the service account&amp;rsquo;s Secret (containing the token) to be
mounted into the Pod at &lt;code&gt;/var/run/secrets/kubernetes.io/serviceaccount/&lt;/code&gt;. The
application can retrieve the token and use it in a request to other applications
/ services in the cluster.&lt;/p&gt;
&lt;p&gt;The destination application can verify the provided token by calling the
Kubernetes &lt;code&gt;TokenReview&lt;/code&gt; API:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;curl -X &lt;span class=&#34;s2&#34;&gt;&amp;#34;POST&amp;#34;&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;https://{kubernetes API IP}:{kubernetes API Port}/apis/authentication.k8s.io/v1/tokenreviews&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;     -H &lt;span class=&#34;s1&#34;&gt;&amp;#39;Authorization: Bearer {application bearer token}&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;     -H &lt;span class=&#34;s1&#34;&gt;&amp;#39;Content-Type: application/json; charset=utf-8&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;     -d &lt;span class=&#34;s1&#34;&gt;$&amp;#39;{
&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;kind&amp;#34;: &amp;#34;TokenReview&amp;#34;,
&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;apiVersion&amp;#34;: &amp;#34;authentication.k8s.io/v1&amp;#34;,
&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;  &amp;#34;spec&amp;#34;: {
&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;    &amp;#34;token&amp;#34;: &amp;#34;{token to verify}&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;  }
&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The Kubernetes API will respond with metadata about the token to be verified, in
addition to whether or not it has been authenticated.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;kind&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;TokenReview&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;apiVersion&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;authentication.k8s.io/v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;metadata&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;creationTimestamp&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;spec&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;token&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;lt;token to verify&amp;gt;&amp;#34;&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;status&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;authenticated&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
      &lt;span class=&#34;nt&#34;&gt;&amp;#34;username&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system:serviceaccount:default:default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
      &lt;span class=&#34;nt&#34;&gt;&amp;#34;uid&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;4afdf4d0-46d2-11e9-8716-005056bf4b40&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
      &lt;span class=&#34;nt&#34;&gt;&amp;#34;groups&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;system:serviceaccounts&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;system:serviceaccounts:default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;system:authenticated&amp;#34;&lt;/span&gt;
      &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-sat.png&#34; alt=&#34;Service Account Token&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tight integration with the platform (Kubernetes).&lt;/li&gt;
&lt;li&gt;Provides identity in a well-understood and consumable format (JWT).&lt;/li&gt;
&lt;li&gt;Invalidated once the service account / Secret is deleted.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tokens do not have a TTL and not expire (unless the service account / Secret
is deleted).&lt;/li&gt;
&lt;li&gt;Tokens are scoped to the service account so are not a good unique way of
identifying either a Pod or a container.&lt;/li&gt;
&lt;li&gt;Additional functionality must be added to applications to be aware of and
verify Kubernetes tokens.&lt;/li&gt;
&lt;li&gt;Tokens are persisted in the Kubernetes Secrets API and must have access to them
restricted.&lt;/li&gt;
&lt;li&gt;Only works with services running on a single Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Service Account Best Practices&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;To ensure that permissions can be granted to applications in an appropriately
granular way, unique service accounts should be created for each workload that
requires access to the Kubernetes API server.&lt;/p&gt;
&lt;p&gt;Additionally, if a workload &lt;em&gt;does not&lt;/em&gt; require access to the Kubernetes API
server, disable the mounting of a service account token by specifying the
&lt;code&gt;automountServiceAccountToken: false&lt;/code&gt; field on either the &lt;code&gt;ServiceAccount&lt;/code&gt; or
&lt;code&gt;Pod&lt;/code&gt; objects. Note that the &lt;code&gt;Pod&lt;/code&gt; field takes precedence if both are set.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;projected-service-account-tokens-psat&#34;&gt;Projected Service Account Tokens (PSAT)&lt;/h3&gt;
&lt;p&gt;Beginning with Kubernetes v1.12 there is an additional method of identity
available that builds on the ideas in Service Account Tokens but seeks to
address some of the weaknesses (such as lack of TTL, wide scoping and
persistence).&lt;/p&gt;
&lt;p&gt;Note that in order for the PSAT flow to function correctly the API server needs
to be configured with the parameter keys shown below (all are configurable
though).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;kube-apiserver&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;service-account-signing-key-file=/etc/kubernetes/pki/sa.key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;service-account-key-file=/etc/kubernetes/pki/sa.pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;service-account-issuer=api&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;service-account-api-audiences=api&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Additional flags removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s.gcr.io/kube-apiserver:v1.17.3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The flow for establishing and verifying identity is similar to the SAT method.
However instead of having our Pod / application read the auto-mounted service
account token, you instead mount a projected service account token as a volume.
This also injects a token into the Pod, but you can specify a TTL and custom
audience for the token.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceAccountName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ubuntu:bionic&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;sh&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;-c&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;echo Hello Kubernetes! &amp;amp;&amp;amp; sleep 3600&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumeMounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/var/run/secrets/tokens&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app-token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app-token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;projected&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;serviceAccountToken&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;audience&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;api&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;expirationSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;600&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app-token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that when using PSAT, a designated service account must be created and
used. PSAT will not work with the namespace default service accounts.&lt;/p&gt;
&lt;p&gt;The calling application can read the projected token and use that in requests
within the cluster. Destination applications can verify the token by calling the
&lt;code&gt;TokenReview&lt;/code&gt; API and passing the received token. With the PSAT method, the
review will also verify that the TTL has not expired, and will return additional
metadata about the presenting application, including specific Pod information.
This provides a tighter scope than regular SATs (which only assert a service
account).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;err&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Additional&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;fields&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;removed&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;brevity&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;extra&amp;#34;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;authentication.kubernetes.io/pod-name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;authentication.kubernetes.io/pod-uid&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;8b9bc1be-c71f-4551-aeb9-2759887cbde0&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As shown below, there is no real difference between the SAT and PSAT flows
themselves (aside from the server verifying the audience field), only in the
validity and granularity of the identity asserted by the token.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-psat.png&#34; alt=&#34;Projected Service Account Tokens&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tight integration with the platform (Kubernetes).&lt;/li&gt;
&lt;li&gt;Provides identity in a well-understood and consumable format (JWT).&lt;/li&gt;
&lt;li&gt;Invalidated once the service account / Secret is deleted.&lt;/li&gt;
&lt;li&gt;Scoped to individual Pods.&lt;/li&gt;
&lt;li&gt;Configurable TTL.&lt;/li&gt;
&lt;li&gt;Configurable audience.&lt;/li&gt;
&lt;li&gt;Not persisted in the Kubernetes Secrets API.&lt;/li&gt;
&lt;li&gt;Tokens are rotated before expiry automatically by the Kubelet (if using projection).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Additional functionality must be added to applications to be aware of and
verify Kubernetes tokens.&lt;/li&gt;
&lt;li&gt;Only works with services running on a single Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;container-network-interface-cni&#34;&gt;Container Network Interface (CNI)&lt;/h3&gt;
&lt;p&gt;Some CNI solutions provide a degree of identity based on a combination of
network primitives and metadata they have access to via the Kubernetes API, in
addition to combining with other tooling. Deep dives into these CNI technologies
are out of scope for this guide and we will only be covering their capabilities
as they relate to identity.&lt;/p&gt;
&lt;h4 id=&#34;calico&#34;&gt;Calico&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://www.projectcalico.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Calico&lt;/a&gt; provides network policy enforcement at
layers 3 &amp;amp; 4, enabling users to restrict communication between Pods based on
their namespace and other metadata (labels for example). This enforcement is all
enabled by modifying the network configuration &lt;code&gt;iptables&lt;/code&gt; / &lt;code&gt;ipvs&lt;/code&gt;) to allow /
disallow IP addresses.&lt;/p&gt;
&lt;p&gt;Calico also supports making policy decisions based on service accounts using a
component called Dikastes when used in combination with &lt;a href=&#34;https://www.envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Envoy
proxy&lt;/a&gt; (either standalone or part of a service mesh
like &lt;a href=&#34;https://istio.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Istio&lt;/a&gt;). This approach enables enforcement at layer 7,
based on attributes of the application protocol (headers etc&amp;hellip;) and relevant
cryptographic identities (certificates, etc&amp;hellip;).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-dikastes.png&#34; alt=&#34;Calico and Dikastes&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;By default, Istio (Envoy) will only perform mTLS and ensure that workloads
present certificates signed by the Istio CA (Citadel). Dikastes runs as a
sidecar alongside Envoy as a plugin. Envoy verifies the CA before consulting
Dikastes for a decision on whether to admit or reject the request. Dikastes
makes this decision based on user-defined Calico &lt;code&gt;NetworkPolicy&lt;/code&gt; or
&lt;code&gt;GlobalNetworkPolicy&lt;/code&gt; objects.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GlobalNetworkPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app == &amp;#39;summary&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ingress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Allow&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceAccounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;customer&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespaceSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app == &amp;#39;bank&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;egress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Allow&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above rule is specifying that the policy be applied to any Pods with the
label &lt;code&gt;app: summary&lt;/code&gt; and restrict access to Pods calling from the &lt;code&gt;customer&lt;/code&gt;
service account (in namespaces with the label &lt;code&gt;app: bank&lt;/code&gt;). This works because
the Calico control-plane (the Felix node agent) computes rules by reconciling
Pods that are running under a specific service account with their IP addresses
and subsequently syncing this information to Dikastes via a Unix socket.&lt;/p&gt;
&lt;p&gt;This out-of-band verification is important as it mitigates a potential attack
vector in an Istio environment. Istio stores each service account&amp;rsquo;s PKI assets
in a Secret in the cluster. Without this additional verification, an attacker
who was able to steal that Secret would be able to masquerade as the asserted
service account (by presenting those PKI assets), even though it may not be
running as that account.&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If platforms are already leveraging Calico (either as CNI or only for network
policy), Dikastes provides an extra layer of defense in depth.&lt;/li&gt;
&lt;li&gt;Easy-to-understand syntax / user experience and format (CRDs).&lt;/li&gt;
&lt;li&gt;Calico and Istio are cross-platform so can be used across Kubernetes and
non-Kubernetes environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires platforms to already be using a mesh or proxy solution, this often
comes with additional complexity overhead.&lt;/li&gt;
&lt;li&gt;Adds additional latency into the data plane (Dikastes is consulted on every request).&lt;/li&gt;
&lt;li&gt;Identity claims are not independently cryptographically verifiable, relying
on the mesh to be present with every connected service.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;cilium&#34;&gt;Cilium&lt;/h4&gt;
&lt;p&gt;Like Calico, &lt;a href=&#34;https://docs.cilium.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cilium&lt;/a&gt; also provides network policy
enforcement at layers 3 &amp;amp; 4, enabling users to restrict communication between
Pods based on their namespace and other metadata (labels for example). Cilium
also supports (without additional tooling) the ability to apply policy at layer
7 and restrict access to services via service accounts.&lt;/p&gt;
&lt;p&gt;Unlike Calico, enforcement in Cilium is not based on IP address (and updating
node networking configurations). Instead, Cilium calculates identities for each
unique Pod / endpoint (based on a number of selectors) and encodes these
identities into each packet. It then enforces whether packets should be allowed
based on these identities using &lt;a href=&#34;https://lwn.net/Articles/747551/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;BPF&lt;/a&gt; kernel
hooks at various points in the datapath.&lt;/p&gt;
&lt;p&gt;The example below shows the output of listing Cilium endpoints (Pods). The
&lt;code&gt;deathstar-657477f57d-zzz65&lt;/code&gt; has one additional label from the other Pods in the
Deployment, and is assigned a different identity. All Pods in the Deployment
share a namespace, service account and several arbitrary Kubernetes labels.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;NAMESPACE     NAME                              ENDPOINT ID   IDENTITY ID   INGRESS ENFORCEMENT
default       deathstar-657477f57d-jpzgb        &lt;span class=&#34;m&#34;&gt;1474&lt;/span&gt;          &lt;span class=&#34;m&#34;&gt;1597&lt;/span&gt;          &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
default       deathstar-657477f57d-knxrl        &lt;span class=&#34;m&#34;&gt;2151&lt;/span&gt;          &lt;span class=&#34;m&#34;&gt;1597&lt;/span&gt;          &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
default       deathstar-657477f57d-xw2tr        &lt;span class=&#34;m&#34;&gt;16&lt;/span&gt;            &lt;span class=&#34;m&#34;&gt;1597&lt;/span&gt;          &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
default       deathstar-657477f57d-xz2kk        &lt;span class=&#34;m&#34;&gt;2237&lt;/span&gt;          &lt;span class=&#34;m&#34;&gt;1597&lt;/span&gt;          &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
default       deathstar-657477f57d-zzz65        &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;             &lt;span class=&#34;m&#34;&gt;57962&lt;/span&gt;         &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After removing the divergent label, the &lt;code&gt;deathstar-657477f57d-zzz65&lt;/code&gt; Pod is
re-assigned the same identity as its peers.&lt;/p&gt;
&lt;p&gt;Cilium implements the Kubernetes-native &lt;code&gt;NetworkPolicy&lt;/code&gt; API, but like Calico
also exposes more fully-featured capabilities in the form of
&lt;code&gt;CiliumNetworkPolicy&lt;/code&gt; and &lt;code&gt;CiliumClusterwideNetworkPolicy&lt;/code&gt; objects.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;cilium.io/v2&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CiliumNetworkPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;k8s-svc-account&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;endpointSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;io.cilium.k8s.policy.serviceaccount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;leia&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ingress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;fromEndpoints&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;io.cilium.k8s.policy.serviceaccount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;luke&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;toPorts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;80&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TCP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;method&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GET&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/public$&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the example above, we are using special &lt;code&gt;io.cilium.k8s.policy.*&lt;/code&gt; label
selectors to target specific service accounts in the cluster. Cilium then uses
its registry of identities to restrict / allow access as necessary.&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cilium is cross-platform so can be used across Kubernetes and
non-Kubernetes environments.&lt;/li&gt;
&lt;li&gt;No additional solutions besides Cilium are required.&lt;/li&gt;
&lt;li&gt;Increases the complexity of the network stack (for troubleshooting /
debugging, etc&amp;hellip;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identity claims are not independently cryptographically verifiable, relying
on Cilium to be present with every connected service.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;aws-platform-identity-methods--tooling&#34;&gt;AWS Platform Identity Methods / Tooling&lt;/h2&gt;
&lt;p&gt;Note that many cloud vendors expose functionality described in this section.
This guide focuses on Amazon Web Services (AWS) because they are most commonly
seen in the field and their offerings are the most mature.&lt;/p&gt;
&lt;p&gt;AWS provides a strong identity solution at the node level via the EC2 metadata
API. This is an example of a platform mediated system, whereby the platform
(AWS) is able to determine the identity of a calling entity based on a number of
intrinsic properties without the entity asserting any credentials / identity
claim itself. The platform can then deliver secure credentials to the instance
(in the form of a role, for example) that allows it to access any services
defined by the relevant policies.&lt;/p&gt;
&lt;p&gt;This model underpins how AWS (and many other vendors) provide secure access to
their own cloud services. However with the rise of containers and other
multi-tenant application models, this per-node identity / authentication system
breaks down and requires additional tooling and alternative approaches.&lt;/p&gt;
&lt;h3 id=&#34;kube2iam&#34;&gt;Kube2IAM&lt;/h3&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Avoid this approach&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Kube2IAM requires that every node in the cluster be able to assume a superset of
all the roles that Pods may require. This security model means that the scope of
access provided should a break out occur is potentially huge. For this reason
it is strongly advised not to use Kube2IAM.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jtblin/kube2iam&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kube2IAM&lt;/a&gt; is an open source (OSS) tool that
acts as a proxy between running workloads and the AWS EC2 metadata API. The
architecture is shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-kube2iam.png&#34; alt=&#34;Kube2IAM&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Kube2IAM Pods run on every node via a DaemonSet. Each Pod injects an iptables
rule to capture outbound traffic to the metadata API and redirect it to the
running instance of Kube2IAM on that node.&lt;/p&gt;
&lt;p&gt;Pods that want to interact with AWS APIs should specify the role they want to
assume as an annotation in the spec:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx-deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;template&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;iam.amazonaws.com/role&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;&amp;lt;role-arn&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx:1.9.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;containerPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;kiam&#34;&gt;KIAM&lt;/h3&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Use Caution with this approach&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;While safer than Kube2IAM, KIAM also introduces a potentially serious security
flaw. This section describes a mitigation of the flaw, however you should still
use caution and understand the attack vector when using KIAM.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Like Kube2IAM, &lt;a href=&#34;https://github.com/uswitch/kiam&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;KIAM&lt;/a&gt; is an open source (OSS)
tool that acts as a proxy to the AWS EC2 metadata API, although it&amp;rsquo;s
architecture (and as a result, security model) are different / slightly
improved.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-kiam.png&#34; alt=&#34;KIAM&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;KIAM has both server and agent components. The agents run as a DaemonSet on
every node in the cluster. The server component can (and should) be restricted
to the either the control-plane nodes or a subset of cluster nodes. Agents
capture EC2 metadata API requests and forward them to the server components to
complete the appropriate authentication with AWS. Only the server nodes require
access to assume AWS IAM (Identity and Access Management) roles (again, a
superset of all roles that Pods may require).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-kiam-flow.png&#34; alt=&#34;KIAM Flow&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;In this model, there should be controls in place to ensure that no workloads are
able to run on the server nodes (and thereby obtain unfettered AWS API access).
Assumption of roles is achieved (like Kube2IAM) by annotating Pods with the
desired role:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx-deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;template&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;iam.amazonaws.com/role&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;&amp;lt;role-arn&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx:1.9.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;containerPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;While the security model is better than Kube2IAM, KIAM still has a potential
attack vector whereby if a user is able to directly schedule a Pod onto a node
(by populating it&amp;rsquo;s &lt;code&gt;nodeName&lt;/code&gt; field, bypassing the Kubernetes scheduler and any
potential guards) they would have unrestricted access to the EC2 metadata API.&lt;/p&gt;
&lt;p&gt;The mitigation for this issue is to run a mutating or validating admission
webhook that ensures the &lt;code&gt;nodeName&lt;/code&gt; field is always populated on Pod create &amp;amp;
update requests to the Kubernetes API.&lt;/p&gt;
&lt;p&gt;KIAM provides a strong story for enabling individual Pods to access AWS APIs,
using a model that existing AWS users will be familiar with (role assumption).
This is a viable solution in many cases, provided the mitigation above is put in
place prior to use.&lt;/p&gt;
&lt;h3 id=&#34;iam-roles-for-service-accounts-irsa&#34;&gt;IAM Roles for Service Accounts (IRSA)&lt;/h3&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Recommended approach&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Although the setup for IRSA is a little clunky, it possesses the best security
model of all approaches to Pod IAM Role assumption.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Since late 2019, AWS has provided a native integration between Kubernetes and
IAM called
&lt;a href=&#34;https://aws.amazon.com/blogs/opensource/introducing-fine-grained-iam-roles-service-accounts/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;IAM Roles for Service Accounts&lt;/a&gt;
(IRSA).&lt;/p&gt;
&lt;p&gt;At a high level, IRSA exposes a similar experience to KIAM and Kube2IAM, in
that users can annotate their Pods with an AWS IAM role they want it to assume.
The implementation is very different though, eliminating the security concerns
of the earlier approaches.&lt;/p&gt;
&lt;p&gt;AWS IAM supports federating identity out to a third-party OIDC provider, in this
case the Kubernetes API server. As you saw already with PSATs, Kubernetes is
capable of creating and signing short-lived tokens on a per-Pod basis.&lt;/p&gt;
&lt;p&gt;AWS IRSA combines these features with an additional credential provider in their
SDKs that calls &lt;code&gt;sts:AssumeRoleWithWebIdentity&lt;/code&gt;, passing the PSAT. The PSAT and
desired role need to be injected as environment variables within the Pod (there
is a webhook that will do this automatically based on the &lt;code&gt;serviceAccountName&lt;/code&gt;
if desired).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;myapp&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceAccountName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-serviceaccount&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;myapp&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;myapp:1.2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;AWS_ROLE_ARN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;arn:aws:iam::123456789012:role/eksctl-irptest-addon-iamsa-default-my-serviceaccount-Role1-UCGG6NDYZ3UE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;AWS_WEB_IDENTITY_TOKEN_FILE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/var/run/secrets/eks.amazonaws.com/serviceaccount/token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumeMounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/var/run/secrets/eks.amazonaws.com/serviceaccount&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;aws-iam-token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readOnly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;aws-iam-token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;projected&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;defaultMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;420&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;serviceAccountToken&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;audience&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sts.amazonaws.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;expirationSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;86400&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Kubernetes does not natively expose a &lt;code&gt;.well-known&lt;/code&gt; OIDC endpoint, so there is
some additional work required to configure this at a public location (static S3
bucket) so that AWS IAM can verify the token using Kubernetes&#39; public service
account signing key.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-irsa.png&#34; alt=&#34;AWS IRSA&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Once verified, AWS IAM responds to the application&amp;rsquo;s request, exchanging the
PSAT for the desired IAM role credentials.&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tight integration with AWS using familiar primitives for those customers
already invested in the platform.&lt;/li&gt;
&lt;li&gt;Easy-to-understand mapping model between service accounts and roles.&lt;/li&gt;
&lt;li&gt;Webhook makes consumption straightforward once everything else is configured.&lt;/li&gt;
&lt;li&gt;Strong security model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complex to configure if not using EKS.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;&lt;em&gt;IRSA is the recommended approach for providing AWS access to applications
running on Kubernetes.&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;spiffe--spire&#34;&gt;SPIFFE / SPIRE&lt;/h2&gt;
&lt;p&gt;Secure Production Identity Framework for Everyone (SPIFFE) is a standard that
specifies a syntax for identity (SPIFFE Verifiable Identity Document, SVID) that
can leverage existing cryptographic formats such as x509 and JWT. It also
specifies a number of APIs for providing and consuming these identities.&lt;/p&gt;
&lt;p&gt;Example SPIFFE ID format: &lt;code&gt;spiffe://trust-domain/hierarchical/workload&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;SPIRE (SPIFFE Runtime Environment) is the reference implementation of SPIFFE and
has a number of SDKs and integrations to allow applications to make use of (both
providing, and consuming) SVIDs.&lt;/p&gt;
&lt;p&gt;This section will assume use of SPIFFE &amp;amp; SPIRE together unless otherwise noted.&lt;/p&gt;
&lt;h3 id=&#34;architecture--concepts&#34;&gt;Architecture &amp;amp; Concepts&lt;/h3&gt;
&lt;p&gt;SPIRE runs a server component that acts a signing authority for identities, and
maintains a registry of all workload identities and the conditions required for
an identity document to be issued.&lt;/p&gt;
&lt;p&gt;SPIRE agents run on every node as a DaemonSet where they expose an API for
workloads to request identity via a Unix socket. The agent is also configured
with read-only access to the Kubelet to determine metadata about Pods on the Node.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-spire.png&#34; alt=&#34;SPIRE&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;When agents come online they verify and register themselves to the server by a
process called &lt;em&gt;node attestation&lt;/em&gt;. This process utilizes environmental context
(for example the AWS EC2 metadata API or Kubernetes PSATs) to identify a node
and assign it a SPIFFE ID. The server then issues the node an identity in the
form of a x509 SVID. Shown below is an example registration for a node:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;/opt/spire/bin/spire-server entry create &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -spiffeID spiffe://cnr-trust-domain/nodes &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -selector k8s_psat:cluster:cnr-cluster &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -selector k8s_psat:agent_ns:spire &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -selector k8s_psat:agent_sa:spire-agent &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -node
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above tells the SPIRE server to assign the SPIFFE ID
&lt;code&gt;spiffe://cnr-trust-domain/nodes&lt;/code&gt; to any node where the agent Pod satisfies the
selectors specified. In this case, that the Pod is running under a specific
cluster, namespace, and service account (verified via the PSAT).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-node-attestation.png&#34; alt=&#34;Note attestation&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;When workloads come online they call the node-local workload API to request an
SVID. The SPIRE agent uses information available to it on the platform (from the
kernel, Kubelet, etc&amp;hellip;) to determine the properties of the calling workload.
This process is referred to as &lt;em&gt;workload attestation&lt;/em&gt;. The SPIRE server then
matches the properties against known workload identities based on their
selectors and returns an SVID to the workload (via the agent) that can be used
for authentication against other systems.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;/opt/spire/bin/spire-server entry create &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -spiffeID spiffe://cnr-trust-domain/service-a &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -parentID spiffe://cnr-trust-domain/nodes &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -selector k8s:ns:default &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -selector k8s:sa:service-a &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -selector k8s:pod-label:app:frontend &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -selector k8s:container-image:docker.io/johnharris85/service-a:v0.0.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above tells the SPIRE server to assign the SPIFFE ID
&lt;code&gt;spiffe://cnr-trust-domain/service-a&lt;/code&gt; to any workload that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is running on a node with ID &lt;code&gt;spiffe://cnr-trust-domain/nodes&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Is running in the &lt;code&gt;default&lt;/code&gt; namespace.&lt;/li&gt;
&lt;li&gt;Is running under the &lt;code&gt;service-a&lt;/code&gt; service account.&lt;/li&gt;
&lt;li&gt;Has the Pod label &lt;code&gt;app: frontend&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Was built using the &lt;code&gt;docker.io/johnharris85/service-a:v0.0.1&lt;/code&gt; image.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-workload-attestation.png&#34; alt=&#34;Workload Attestation&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Note that the kubelet uses the &lt;code&gt;TokenReview&lt;/code&gt; API to validate bearer tokens. This
requires reachability to the Kubernetes API server. Therefore API server
downtime can interrupt workload attestation. The
&lt;code&gt;--authentication-token-webhook-cache-ttl&lt;/code&gt; kubelet flag controls how long the
kubelet caches TokenReview responses and may help to mitigate this issue. A
large cache TTL value is not recommended however, as that can impact permission
revocation.&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Leverages well understood and widely supported cryptographic standards (x509 &amp;amp;
JWT).&lt;/li&gt;
&lt;li&gt;Cross-platform supporting both Kubernetes and non-Kubernetes workloads.&lt;/li&gt;
&lt;li&gt;Can leverage an upstream CA if required.&lt;/li&gt;
&lt;li&gt;All certificates can be provided in-memory to mitigate compromised disk
access.&lt;/li&gt;
&lt;li&gt;Supports many application integration points (see below).&lt;/li&gt;
&lt;li&gt;Supports more granular property selectors than other identity providers.&lt;/li&gt;
&lt;li&gt;CNCF project.&lt;/li&gt;
&lt;li&gt;Supports federation between clusters.&lt;/li&gt;
&lt;li&gt;Regular rotation of secrets.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Doesn&amp;rsquo;t support separate certificate authorities for client and server.&lt;/li&gt;
&lt;li&gt;Is another component to maintain in an environment.&lt;/li&gt;
&lt;li&gt;Nodes and workloads identities need to be registered. This is manual out of
the box (but could be automated).&lt;/li&gt;
&lt;li&gt;Requires a backing datastore to persist identity data (sqlite by default),
raising the complexity of maintaining the solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;integration-points&#34;&gt;Integration Points&lt;/h3&gt;
&lt;p&gt;SPIFFE / SPIRE have a number of integration points with workload applications.
Which integration point is appropriate will depend on the desired level of
coupling to the platform and the amount of control users have over the environment.&lt;/p&gt;
&lt;h4 id=&#34;direct-application-access&#34;&gt;Direct Application Access&lt;/h4&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Not a recommended approach&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Direct integration is not a recommended approach (unless building intermediate tooling) for
the following reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tightly couples the application with the platform / implementation.&lt;/li&gt;
&lt;li&gt;Requires mounting the SPIRE agent Unix socket into the Pod.&lt;/li&gt;
&lt;li&gt;Not easily extensible.&lt;/li&gt;
&lt;/ul&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;SPIRE provides SDKs for Go, C and Java for applications to directly integrate
with the SPIFFE workload API. These wrap existing HTTP libraries but provide
native support for obtaining and verifying identities. Below is an example in Go
calling a Kubernetes service &lt;code&gt;service-b&lt;/code&gt; and expecting a specific SPIFFE ID to
be presented (through a x509 SVID).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Setenv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;SPIFFE_ENDPOINT_SOCKET&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;unix:///run/spire/sockets/agent.sock&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;conn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;spiffe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;DialTLS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;tcp&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;service-b&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;spiffe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;ExpectPeer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;spiffe://cnr-trust-domain/service-b&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Fatalf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Unable to create TLS connection: %v&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The SPIRE agent also exposes a &lt;a href=&#34;https://grpc.io/about/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;gRPC&lt;/a&gt; API for those
users who want a tighter integration with the platform but are working in a
language without SDK availability.&lt;/p&gt;
&lt;h4 id=&#34;sidecar-proxy&#34;&gt;Sidecar Proxy&lt;/h4&gt;
&lt;p&gt;SPIRE natively supports the Envoy SDS API for publishing certificates to be
consumed by an Envoy proxy. Envoy can then use the SVID x509 certificate to
establish TLS connections with other services, and use the trust bundle to
verify incoming connections.&lt;/p&gt;
&lt;p&gt;Envoy also supports verifying that only specific SPIFFE IDs (encoded into the
SVID) should be able to connect. There are two methods to implement this
verification:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;By specifying a list of &lt;code&gt;verify_subject_alt_name&lt;/code&gt; values in the Envoy configuration.&lt;/li&gt;
&lt;li&gt;By utilizing Envoy&amp;rsquo;s External Authorization API to delegate admission
decisions an external system (for example, OPA). Below is an example of a
Rego policy to achieve this:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-rego&#34; data-lang=&#34;rego&#34;&gt;package envoy.authz

import input.attributes.request.http as http_request
import input.attributes.source.address as source_address

default allow = false

allow {
    http_request.path == &amp;quot;/api&amp;quot;
    http_request.method == &amp;quot;GET&amp;quot;
    svc_spiffe_id == &amp;quot;spiffe://cnr-trust-domain/frontend&amp;quot;
}

svc_spiffe_id = client_id {
    [_, _, uri_type_san] := split(http_request.headers[&amp;quot;x-forwarded-client-cert&amp;quot;], &amp;quot;;&amp;quot;)
    [_, client_id] := split(uri_type_san, &amp;quot;=&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the above example, Envoy verifies the request&amp;rsquo;s TLS certificate against the
SPIRE trust bundle then delegates authorization to OPA. The Rego policy inspects
the SVID and allows the request if the SPIFFE ID matches
&lt;code&gt;spiffe://cnr-trust-domain/frontend&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/workload-identity-spire-envoy.png&#34; alt=&#34;SPIRE and Envoy&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;service-mesh&#34;&gt;Service Mesh&lt;/h4&gt;
&lt;p&gt;Istio&amp;rsquo;s CA creates SVIDs for all service accounts, encoding a SPIFFE ID in the
format &lt;code&gt;spiffe://cluster.local/ns/&amp;lt;namespace&amp;gt;/sa/&amp;lt;service_account&amp;gt;&lt;/code&gt;. Therefore
services in an Istio mesh can leverage SPIFFE aware endpoints.&lt;/p&gt;
&lt;p&gt;Note that while service meshes are out of scope for this guide, many attempt to
address the issue of identity and authentication. Most of these attempts include
or build on the methods and tooling detailed in this guide.&lt;/p&gt;
&lt;h4 id=&#34;other&#34;&gt;Other&lt;/h4&gt;
&lt;p&gt;In addition to the primary methods above, SPIRE also supports the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pulling SVIDs and trust bundles directly to a filesystem, enabling
applications to detect changes and reload. While this enables applications to
be somewhat agnostic to SPIRE, it also opens an attack vector for
certificates to be stolen from the filesystem.&lt;/li&gt;
&lt;li&gt;Nginx module that allows for certificates to be streamed from SPIRE (similar
to the Envoy integration described above). There are custom modules for Nginx
that enable users to specify the SPIFFE IDs that should be allowed to connect
to the server.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;integration-with-secrets-store-vault&#34;&gt;Integration with Secrets Store (Vault)&lt;/h3&gt;
&lt;p&gt;SPIRE can be used to solve the secure introduction problem when an application
needs to obtain some shared secret material from &lt;a href=&#34;https://www.vaultproject.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;HashiCorp
Vault&lt;/a&gt;. Vault can be configured to authenticate
clients using OIDC federation with the SPIRE server as an OIDC provider.&lt;/p&gt;
&lt;p&gt;Roles in Vault can be bound to specific subjects (SPIFFE IDs) so that when a
workload requests a JWT SVID from SPIRE, that is valid to obtain a role and
therefore accessor credentials to Vault.&lt;/p&gt;
&lt;h3 id=&#34;integration-with-aws&#34;&gt;Integration with AWS&lt;/h3&gt;
&lt;p&gt;SPIRE can also be used to establish identity and authenticate to AWS services.
This process utilizes the same OIDC federation idea in the AWS IRSA and Vault
sections above. Workloads request JWT SVIDs that are then verified by AWS by
validating against the federated OIDC provider (SPIRE server). The downside of
this approach is that SPIRE must be publicly accessible for AWS to discover the
JSON Web Key Set (JWKS) material required to validate the JWTs.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Best Practices for Creating Production-Ready Helm Charts</title>
      
      <link>/guides/kubernetes/production-ready-helm/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/production-ready-helm/</guid>
      <description>

        
        &lt;p&gt;Three years have passed since &lt;a href=&#34;https://github.com/helm/helm/releases?after=v1.1&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;the first release of Helm&lt;/a&gt;, and it has indeed made a name for itself. Both avowed fans and fervent haters agree that the Kubernetes &amp;ldquo;apt-get equivalent&amp;rdquo; is the standard way of deploying to production (at least for now, let&amp;rsquo;s see what Operators end up bringing to the table). During this time, Bitnami has contributed to the project in many ways. You can find us in PRs in Helm&amp;rsquo;s code, in solutions like &lt;a href=&#34;https://hub.kubeapps.com/charts/bitnami&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubeapps&lt;/a&gt;, and especially in what we are mostly known for: &lt;a href=&#34;https://bitnami.com/stacks/helm&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;our huge application library&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As maintainers of a collection of more than &lt;a href=&#34;https://github.com/bitnami/charts/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;45 Helm charts&lt;/a&gt;, we know that creating a maintainable, secure and production-ready chart is far from trivial. In this sense, this blog post shows essential features that any chart developer should know.&lt;/p&gt;
&lt;h2 id=&#34;use-non-root-containers&#34;&gt;Use non-root containers&lt;/h2&gt;
&lt;p&gt;Ensuring that a container is able to perform only a very limited set of operations is vital for production deployments. This is possible thanks to the &lt;strong&gt;use of non-root containers, which are executed by a user different from &lt;em&gt;root&lt;/em&gt;.&lt;/strong&gt; Although creating a non-root container is a bit more complex than a root container (especially regarding filesystem permissions), it is absolutely worth it. Also, in environments like OpenShift, &lt;a href=&#34;https://engineering.bitnami.com/articles/running-non-root-containers-on-openshift.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;using non-root containers is mandatory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In order to make your Helm chart work with non-root containers, add the &lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/security-context/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;em&gt;securityContext&lt;/em&gt;&lt;/a&gt; section to your &lt;em&gt;yaml&lt;/em&gt; files.&lt;/p&gt;
&lt;p&gt;This is what we do, for instance, in the Bitnami Elasticsearch Helm chart. This chart deploys several Elasticsearch &lt;em&gt;StatefulSets&lt;/em&gt; and &lt;em&gt;Deployments&lt;/em&gt; (data, ingestion, coordinating and master nodes), all of them with non-root containers. If we check the master node &lt;em&gt;StatefulSet&lt;/em&gt;, we see the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.securityContext.enabled }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;securityContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fsGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.securityContext.fsGroup }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The snippet above changes the permissions of the mounted volumes, so the container user can access them for read/write operations. In addition to this, inside the container definition, we see another &lt;em&gt;securityContext&lt;/em&gt; block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.securityContext.enabled }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;securityContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsUser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.securityContext.runAsUser }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this part we specify the user running the container. In the &lt;em&gt;values.yaml&lt;/em&gt; file, we set the default values for these parameters:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;c&#34;&gt;## Pod Security Context&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;##&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;securityContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fsGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1001&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsUser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1001&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With these changes, the chart will work as non-root in platforms like GKE, Minikube or OpenShift.&lt;/p&gt;
&lt;h2 id=&#34;do-not-persist-the-configuration&#34;&gt;Do not persist the configuration&lt;/h2&gt;
&lt;p&gt;Adding persistence is an essential part of deploying stateful applications. In our experience, deciding what or what not to persist can be tricky. After several iterations in our charts, we found that &lt;strong&gt;persisting the application configuration is not a recommended practice&lt;/strong&gt;. One advantage of Kubernetes is that you can change the deployment parameters very easily by just doing &lt;code&gt;kubectl edit deployment&lt;/code&gt; or &lt;code&gt;helm upgrade&lt;/code&gt;. If the configuration is persisted, none of the changes would be applied. So, when developing a production-ready Helm chart, make sure that the configuration can be easily changed with &lt;code&gt;kubectl&lt;/code&gt; or &lt;code&gt;helm upgrade&lt;/code&gt;. One common practice is to create a &lt;em&gt;ConfigMap&lt;/em&gt; with the configuration and have it mounted in the container. Let&amp;rsquo;s use the &lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/rabbitmq&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami RabbitMQ chart&lt;/a&gt; as an example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConfigMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;rabbitmq.fullname&amp;#34; . }}-config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;rabbitmq.name&amp;#34; . }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;chart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;rabbitmq.chart&amp;#34; .  }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;release&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{{ .Release.Name }}&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;heritage&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{{ .Release.Service }}&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled_plugins&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;|-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;rabbitmq.plugins&amp;#34; . }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rabbitmq.conf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|-&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    ##username and password
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    default_user={{.Values.rabbitmq.username}}
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    default_pass=CHANGEME&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.rabbitmq.configuration | indent 4 }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.rabbitmq.extraConfiguration | indent 4 }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that there is a section in the &lt;em&gt;values.yaml&lt;/em&gt; file that allows you to include any custom configuration:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;## Configuration file content: required cluster configuration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;## Do not override unless you know what you are doing. To add more configuration, use `extraConfiguration` instead&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configuration&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|-&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    ## Clustering
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    cluster_formation.peer_discovery_backend  = rabbit_peer_discovery_k8s
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    cluster_formation.k8s.host = kubernetes.default.svc.cluster.local
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    cluster_formation.node_cleanup.interval = 10
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    cluster_formation.node_cleanup.only_log_warning = true
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    cluster_partition_handling = autoheal
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # queue master locator
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    queue_master_locator=min-masters
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # enable guest user
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    loopback_users.guest = false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;## Configuration file content: extra configuration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;## Use this instead of  `configuration` to add more configuration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;extraConfiguration&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|-&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    #disk_free_limit.absolute = 50MB
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    #management.load_definitions = /app/load_definition.json&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This &lt;em&gt;ConfigMap&lt;/em&gt; then gets mounted in the container filesystem, as shown in this extract of the &lt;em&gt;StatefulSet&lt;/em&gt; spec:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;volumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;config-volume&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configMap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;rabbitmq.fullname&amp;#34; . }}-config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If the application needs to write in the configuration file, then you&amp;rsquo;ll need to create a copy inside the container, as &lt;em&gt;ConfigMaps&lt;/em&gt; are mounted as read-only. This is done in the same spec:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rabbitmq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;rabbitmq.image&amp;#34; . }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.image.pullPolicy | quote }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#copy the mounted configuration to both places&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cp  /opt/bitnami/rabbitmq/conf/* /opt/bitnami/rabbitmq/etc/rabbitmq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will make your chart not only easy to upgrade, but also more adaptable to user needs, as they can provide their custom configuration file.&lt;/p&gt;
&lt;h2 id=&#34;integrate-charts-with-logging-and-monitoring-tools&#34;&gt;Integrate charts with logging and monitoring tools&lt;/h2&gt;
&lt;p&gt;If we are talking about production environments, we are talking about observability. It is essential having our deployments properly monitored so we can early detect potential issues. It also essential to have application usage, cost and resource consumption metrics. In order to gather this information, you would commonly deploy logging stacks like EFK (&lt;a href=&#34;https://www.elastic.co/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;ElasticSearch&lt;/a&gt;, &lt;a href=&#34;https://www.fluentd.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Fluentd&lt;/a&gt;, and &lt;a href=&#34;https://www.elastic.co/products/kibana&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kibana&lt;/a&gt; and monitoring tools like &lt;a href=&#34;https://prometheus.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus&lt;/a&gt;. Bitnami offers the &lt;a href=&#34;https://kubeprod.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami Kubernetes Production Runtime (BKPR)&lt;/a&gt; that easily installs these tools (along with others) so your cluster is ready to handle production workloads.&lt;/p&gt;
&lt;p&gt;When writing your chart, make sure that your deployment is able to work with the above tools seamlessly. To do so, ensure the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All the containers log to stdout/stderr (so the EFK stack can easily ingest all the logging information)&lt;/li&gt;
&lt;li&gt;Prometheus exporters are included (either using sidecar containers or having a separate deployment)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All Bitnami charts work with BKPR (which includes EFK and Prometheus) out of the box. Let&amp;rsquo;s take a look at the &lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/postgresql&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami PostgreSQL chart&lt;/a&gt; and &lt;a href=&#34;https://github.com/bitnami/bitnami-docker-postgresql&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami PostgreSQL container&lt;/a&gt; to see how we did it.&lt;/p&gt;
&lt;p&gt;To begin with, the process inside the container runs at the foreground, so all the logging information is written to stdout/stderr, as shown below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;info &lt;span class=&#34;s2&#34;&gt;&amp;#34;** Starting PostgreSQL **&amp;#34;&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; am_i_root&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; gosu &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$POSTGRESQL_DAEMON_USER&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;cmd&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;flags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[@]&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;cmd&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;flags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[@]&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;fi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With this, we ensured that it works with EFK. Then, in the chart we added a sidecar container for the Prometheus metrics:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.metrics.enabled }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;postgresql.metrics.image&amp;#34; . }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.image.pullPolicy | quote }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.metrics.securityContext.enabled }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;securityContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsUser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.securityContext.runAsUser }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;$database := required &amp;#34;In order to enable metrics you need to specify a database (.Values.postgresqlDatabase or .Values.global.postgresql.postgresqlDatabase)&amp;#34; (include &amp;#34;postgresql.database&amp;#34; .) }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DATA_SOURCE_URI&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;printf &amp;#34;127.0.0.1:%d/%s?sslmode=disable&amp;#34; (int (include &amp;#34;postgresql.port&amp;#34; .)) $database | quote }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.usePasswordFile }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DATA_SOURCE_PASS_FILE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/opt/bitnami/postgresql/secrets/postgresql-password&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;else }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DATA_SOURCE_PASS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;valueFrom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretKeyRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;postgresql.secretName&amp;#34; . }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;postgresql-password&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DATA_SOURCE_USER&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;postgresql.username&amp;#34; . }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.livenessProbe.enabled }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;livenessProbe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;httpGet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http-metrics&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;initialDelaySeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.livenessProbe.initialDelaySeconds }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;periodSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.livenessProbe.periodSeconds }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;timeoutSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.livenessProbe.timeoutSeconds }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;successThreshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.livenessProbe.successThreshold }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;failureThreshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.livenessProbe.failureThreshold }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.readinessProbe.enabled }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readinessProbe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;httpGet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http-metrics&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;initialDelaySeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.readinessProbe.initialDelaySeconds }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;periodSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.readinessProbe.periodSeconds }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;timeoutSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.readinessProbe.timeoutSeconds }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;successThreshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.readinessProbe.successThreshold }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;failureThreshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.readinessProbe.failureThreshold }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumeMounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.usePasswordFile }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;postgresql-password&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/opt/bitnami/postgresql/secrets/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.metrics.customMetrics }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;custom-metrics&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/conf&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readOnly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;--extend.query-path&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/conf/custom-metrics.yaml&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http-metrics&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containerPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9187&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.metrics.resources }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;toYaml .Values.metrics.resources | nindent 12 }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We also made sure that the pods or services contain the proper annotations that Prometheus uses to detect exporters. In this case, we defined them in the chart&amp;rsquo;s &lt;em&gt;values.yaml&lt;/em&gt; file, as shown below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/scrape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;9187&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#...  &lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the case of the PostgreSQL chart, these annotations go to a metrics service, separate from the PostgreSQL service, which is defined as below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;{{- &lt;span class=&#34;l&#34;&gt;if .Values.metrics.enabled }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Service&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;postgresql.fullname&amp;#34; . }}-metrics&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;postgresql.name&amp;#34; . }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;chart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;postgresql.chart&amp;#34; . }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;release&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Release.Name | quote }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;heritage&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Release.Service | quote }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;toYaml .Values.metrics.service.annotations | indent 4 }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.service.type }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;if and (eq .Values.metrics.service.type &amp;#34;LoadBalancer&amp;#34;) .Values.metrics.service.loadBalancerIP }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;loadBalancerIP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Values.metrics.service.loadBalancerIP }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http-metrics&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9187&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http-metrics&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;template &amp;#34;postgresql.name&amp;#34; . }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;release&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;.Release.Name }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;role&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;master&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;{{- &lt;span class=&#34;l&#34;&gt;end }}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With these modifications, your chart will seamlessly integrate with your monitoring platform. All the obtained metrics will be crucial for maintaining the deployment in good shape.&lt;/p&gt;
&lt;h2 id=&#34;production-workloads-in-kubernetes-are-possible&#34;&gt;Production workloads in Kubernetes are possible&lt;/h2&gt;
&lt;p&gt;Now you know some essential guidelines for creating secured (with non-root containers), adaptable (with proper configuration management), and observable (with proper monitoring) charts. With these features, you have covered the basics to ensure that your application can be deployed to production. However, this is just another step in your journey to mastering Helm. You should also take into account other features like upgradability, usability, stability and testing.&lt;/p&gt;
&lt;h2 id=&#34;useful-links&#34;&gt;Useful Links&lt;/h2&gt;
&lt;p&gt;To learn more, check the following links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/docs/chart_best_practices/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Official Helm chart good practice guidelines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://codefresh.io/docs/docs/new-helm/helm-best-practices/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm best practices by CodeFresh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubeprod.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami Kubernetes Production Runtime&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/charts/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami Helm charts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hub.kubeapps.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubeapps Hub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Getting Started with Kubeapps</title>
      
      <link>/guides/kubernetes/kubeapps-gs/</link>
      <pubDate>Thu, 23 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/kubeapps-gs/</guid>
      <description>

        
        &lt;p&gt;This guide will walk you through the process of deploying Kubeapps for your cluster and installing an example application.&lt;/p&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Note&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;This getting started guide is a copy of
&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/docs/user/getting-started.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Get Started with Kubeapps&lt;/a&gt;
in the &lt;a href=&#34;https://github.com/kubeapps/kubeapps&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubeapps/kubeapps repository&lt;/a&gt;
inclusive of commit
&lt;a href=&#34;https://github.com/kubeapps/kubeapps/commit/1e49264088094dfd327d2a24b62cda470cc547d0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;1e49264&lt;/a&gt;
on April 20, 2020.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;This guide is also available in video form:&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/9HsWsoDd1fM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;Kubeapps assumes a working Kubernetes cluster (v1.8+),
&lt;a href=&#34;https://helm.sh/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;Helm&lt;/code&gt;&lt;/a&gt; (2.14.0+) installed in your cluster and
&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;kubectl&lt;/code&gt;&lt;/a&gt; installed
and configured to talk to your Kubernetes cluster. Kubeapps has been tested with
Azure Kubernetes Service (AKS), Google Kubernetes Engine (GKE), &lt;code&gt;minikube&lt;/code&gt; and
Docker for Desktop Kubernetes. Kubeapps works on RBAC-enabled clusters and this
configuration is encouraged for a more secure install.&lt;/p&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;GKE Permissions&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;On GKE, you must either be an &amp;ldquo;Owner&amp;rdquo; or have the &amp;ldquo;Container Engine Admin&amp;rdquo; role
in order to install Kubeapps.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;step-1-install-kubeapps&#34;&gt;Step 1: Install Kubeapps&lt;/h2&gt;
&lt;p&gt;Use the Helm chart to install the latest version of Kubeapps:&lt;/p&gt;
&lt;p&gt;For Helm 2:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
helm install --name kubeapps --namespace kubeapps bitnami/kubeapps
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you are using Helm 3, you need to set an extra flag to enable it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
kubectl create namespace kubeapps
helm install kubeapps --namespace kubeapps bitnami/kubeapps --set &lt;span class=&#34;nv&#34;&gt;useHelm3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For detailed information on installing, configuring and upgrading Kubeapps,
checkout the
&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/chart/kubeapps/README.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;chart README&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The above commands will deploy Kubeapps into the &lt;code&gt;kubeapps&lt;/code&gt; namespace in your
cluster. It may take a few minutes to execute. Once it has been deployed and the
Kubeapps pods are running, continue to step 2.&lt;/p&gt;
&lt;h2 id=&#34;step-2-create-a-kubernetes-api-token&#34;&gt;Step 2: Create a Kubernetes API token&lt;/h2&gt;
&lt;p&gt;Access to the Dashboard requires a Kubernetes API token to authenticate with the
Kubernetes API server.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create serviceaccount kubeapps-operator
kubectl create clusterrolebinding kubeapps-operator --clusterrole&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;cluster-admin --serviceaccount&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;default:kubeapps-operator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; It&amp;rsquo;s not recommended to create &lt;code&gt;cluster-admin&lt;/code&gt; users for Kubeapps
production usage. Please refer to the
&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/docs/user/access-control.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Access Control&lt;/a&gt;
documentation to configure fine-grained access control for users.&lt;/p&gt;
&lt;p&gt;To retrieve the token,&lt;/p&gt;
&lt;h3 id=&#34;on-linuxmacos&#34;&gt;On Linux/macOS:&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get secret &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get serviceaccount kubeapps-operator -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{range .secrets[*]}{.name}{&amp;#34;\n&amp;#34;}{end}&amp;#39;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep kubeapps-operator-token&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{.data.token}&amp;#39;&lt;/span&gt; -o go-template&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{{.data.token | base64decode}}&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;on-windows&#34;&gt;On Windows:&lt;/h3&gt;
&lt;p&gt;Create a file called &lt;code&gt;GetDashToken.cmd&lt;/code&gt; with the following lines in it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bat&#34; data-lang=&#34;bat&#34;&gt;&lt;span class=&#34;p&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ECHO&lt;/span&gt; OFF
&lt;span class=&#34;c1&#34;&gt;REM Get the Service Account&lt;/span&gt;
kubectl get serviceaccount kubeapps-operator -o jsonpath={.secrets[].name} &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; s.txt
&lt;span class=&#34;k&#34;&gt;SET&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;/p&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;ks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&amp;lt;&lt;/span&gt;s.txt
&lt;span class=&#34;k&#34;&gt;DEL&lt;/span&gt; s.txt

&lt;span class=&#34;c1&#34;&gt;REM Get the Base64 encoded token&lt;/span&gt;
kubectl get secret &lt;span class=&#34;nv&#34;&gt;%ks%&lt;/span&gt; -o jsonpath={.data.token} &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; b64.txt

&lt;span class=&#34;c1&#34;&gt;REM Decode The Token&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;DEL&lt;/span&gt; token.txt
certutil -decode b64.txt token.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Open a command prompt and run the &lt;code&gt;GetDashToken.cmd&lt;/code&gt; Your token can be found in
the &lt;code&gt;token.txt&lt;/code&gt; file.&lt;/p&gt;
&lt;h2 id=&#34;step-3-start-the-kubeapps-dashboard&#34;&gt;Step 3: Start the Kubeapps Dashboard&lt;/h2&gt;
&lt;p&gt;Once Kubeapps is installed, securely access the Kubeapps Dashboard from your
system by running:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl port-forward -n kubeapps svc/kubeapps 8080:80
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will start an HTTP proxy for secure access to the Kubeapps Dashboard. Visit
http://127.0.0.1:8080/ in your preferred web browser to open the Dashboard.
Here&amp;rsquo;s what you should see:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps/screenshots/dashboard-login.png&#34; alt=&#34;Dashboard login page&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Paste the token generated in the previous step to authenticate and access the
Kubeapps dashboard for Kubernetes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps/screenshots/dashboard-home.png&#34; alt=&#34;Dashboard main page&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/em&gt; If you are setting up Kubeapps for other people to access, you will
want to use a different service type or setup Ingress rather than using the
above &lt;code&gt;kubectl port-forward&lt;/code&gt;. For detailed information on installing,
configuring and upgrading Kubeapps, checkout the
&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/chart/kubeapps/README.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;chart README&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;step-4-deploy-wordpress&#34;&gt;Step 4: Deploy WordPress&lt;/h2&gt;
&lt;p&gt;Once you have the Kubeapps Dashboard up and running, you can start deploying
applications into your cluster.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use the &amp;ldquo;Deploy App&amp;rdquo; or click on the &amp;ldquo;Catalog&amp;rdquo; page in the Dashboard to select
an application from the list of charts in any of the configured Helm chart
repositories. This example assumes you want to deploy WordPress.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps/screenshots/wordpress-search.png&#34; alt=&#34;WordPress chart&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click the &amp;ldquo;Deploy&amp;rdquo; button.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps/screenshots/wordpress-chart.png&#34; alt=&#34;WordPress chart&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You will be prompted for the release name and values for the application. The
form is populated by the values (YAML), which you can see in the adjacent tab.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps/screenshots/wordpress-installation.png&#34; alt=&#34;WordPress installation&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click the &amp;ldquo;Submit&amp;rdquo; button. The application will be deployed. You will be able
to track the new Helm deployment directly from the browser. The status will be
shown at the top and you can also look at the individual resources lower in
the page. It will also show the number of ready pods. If you run your cursor
over the status, you can see the workloads and number of ready and total pods
within them.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps/screenshots/wordpress-deployment.png&#34; alt=&#34;WordPress deployment&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To access your new WordPress site, you can run the commands in the &amp;ldquo;Notes&amp;rdquo;
section to get the URLs or simply click a URL (HTTP and HTTPS) shown.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/em&gt; Depending on your cloud provider of choice, it may take some time
for an access URL to be available for the application and the Service will stay
in a &amp;ldquo;Pending&amp;rdquo; state until a URL is assigned. If using Minikube, you will need
to run &lt;code&gt;minikube tunnel&lt;/code&gt; in your terminal in order for an IP address to be
assigned to your application.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps/screenshots/wordpress-url.png&#34; alt=&#34;WordPress deployment notes&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;To get the credentials for logging into your WordPress account, refer to the
&amp;ldquo;Notes&amp;rdquo; section. You can also get the WordPress password by scrolling down to
&amp;ldquo;Secrets&amp;rdquo; and clicking the eye next to &lt;code&gt;wordpress-password&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps/screenshots/wordpress-credentials.png&#34; alt=&#34;WordPress deployment notes&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;optional-step-5-uninstalldelete-wordpress&#34;&gt;[Optional] Step 5: Uninstall/Delete WordPress&lt;/h2&gt;
&lt;p&gt;If you want to uninstall/delete your WordPress application, you can do so by
clicking the &amp;ldquo;Delete&amp;rdquo; button. You can choose to click the checkbox for &amp;ldquo;Purge
Release&amp;rdquo; (default action with the Helm 3 CLI). If you do not click it, the Helm
chart history will remain (default action with Helm 2). This is fine, so long as
you don&amp;rsquo;t attempt to install another chart with the same name in the same
namespace.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps/screenshots/wordpress-uninstall.png&#34; alt=&#34;WordPress uninstall&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;Learn more about Kubeapps with the links below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/chart/kubeapps/README.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Detailed installation instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/docs/user/operators.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Deploying Operators&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/docs/user/dashboard.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubeapps Dashboard documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/docs/architecture/overview.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubeapps components&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps/wiki/Roadmap&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Roadmap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Installing Harbor on Kubernetes with Project Contour, Cert Manager, and Let’s Encrypt</title>
      
      <link>/guides/kubernetes/harbor-gs/</link>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/harbor-gs/</guid>
      <description>

        
        &lt;p&gt;Running a private container image registry has been a staple in many enterprise
environments for years. These registries allow full control over access,
updates, and the software platform itself. And while your organization may have
an official image registry, having your own can also be a benefit!&lt;/p&gt;
&lt;p&gt;Maybe it&amp;rsquo;s just for learning. Or maybe you like the idea of self-hosting your
own services. Or maybe, like so many companies that have also made the decision
to self-host, you are concerned about security and access. Whatever the reason,
you have made the decision to deploy your own. But this process includes a lot
more than just an initial install.&lt;/p&gt;
&lt;p&gt;A container image registry needs to be accessible to many online services to be
useful, not the least of which is your desktop. It’s what makes pulling and
pushing images possible. And you probably want it to be accessible from outside
your own network, too, so that you can collaborate and share your projects.
These days, to be secure, this requires TLS encryption to enable HTTPS traffic.&lt;/p&gt;
&lt;p&gt;In this guide, you will deploy Harbor to Kubernetes as the actual image registry
application. You will also use Project Contour to manage ingress to your
Kubernetes cluster.&lt;/p&gt;

&lt;div class=&#34;youtube-video-shortcode&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/SXSqrgYKO4s&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;harbor-and-contour&#34;&gt;Harbor and Contour&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://goharbor.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Harbor&lt;/a&gt; is a powerful registry for containers and Helm
charts. It is fully open source and backed by the
&lt;a href=&#34;https://landscape.cncf.io/selected=harbor&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt;.
But getting it up and running, with automated TLS certificate renewal in
particular, can be a challenge—especially with the multiple services Harbor uses
that require east-west and north-south network communication.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://projectcontour.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Contour&lt;/a&gt;, also a CNCF project, is an ingress
controller built for Kubernetes. It functions as a control plane for Envoy while
also offering advanced routing functionality beyond the default ingress
controller provided by Kubernetes.&lt;/p&gt;
&lt;p&gt;You will deploy Harbor and Contour, and use
&lt;a href=&#34;https://cert-manager.io/docs/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;cert-manager&lt;/a&gt; and
&lt;a href=&#34;https://letsencrypt.org&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Let&amp;rsquo;s Encrypt&lt;/a&gt; to automate TLS certificate generation
and renewal for your Harbor installation. This will allow you to keep your
Harbor installation up and running and utilizing HTTPS without manually
generating and applying new certificates.&lt;/p&gt;
&lt;p&gt;Also, using the patterns in this guide, you should be able to deploy other
services to Kubernetes and secure their ingress as well. And once you understand
the basics of certificate management, ingress, and routing services, you’ll be
able to keep on deploying other services to Kubernetes and enabling secure
access over the internet!&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;Before you get started, you’ll need to do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install Helm 3&lt;/strong&gt;: Helm is used in this guide to install Contour and Harbor.
A guide for installing Helm can be found
&lt;a href=&#34;https://helm.sh/docs/intro/install/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Create a Kubernetes cluster&lt;/strong&gt;: This guide was built using Google Kubernetes
Engine (GKE) with Kubernetes version 1.17. Any Kubernetes cluster with access
to the internet should work fine, but your results may vary depending on the
version you use. Initial testing with 1.16 resulted in errors during the
Harbor install. For a guide on creating a GKE cluster, see
&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/quickstart&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;this page&lt;/a&gt; from
Google. Ensure your
&lt;a href=&#34;https://kubernetes.io/docs/reference/kubectl/cheatsheet/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;kubectl&lt;/code&gt; context&lt;/a&gt;
is using this cluster.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install watch&lt;/strong&gt;: watch is a small command-line utility that continually
shows the output of a command being run. This allows you to monitor
&lt;code&gt;kubectl get pods&lt;/code&gt;, for example, without explicitly re-running the command
multiple times. Instructions for installing on macOS are
&lt;a href=&#34;https://osxdaily.com/2010/08/22/install-watch-command-on-os-x/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;About 30 minutes&lt;/strong&gt;: It could take more time than that; it will depend on how
long the Let’s Encrypt servers take to issue certificates. But in most of my
testing for writing this post, it took about 30 minutes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Optional - buy a domain name&lt;/em&gt;: You can use &lt;code&gt;.xip.io&lt;/code&gt; (a
&lt;a href=&#34;http://xip.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;service&lt;/a&gt; that provides dynamic DNS based on IP address)
addresses to avoid needing to buy a domain. Otherwise you will need a domain
name that you control in order to configure DNS. This guide uses a
Google-managed domain and DNS zone, but instructions can be modified for other
providers. Note: if you do decide to use &lt;code&gt;.xip.io&lt;/code&gt;, you may experience issues
using the &lt;code&gt;letsencrypt-prod&lt;/code&gt; ClusterIssuer later in the demo due to rate
limiting. Often you can just wait a few hours and it&amp;rsquo;ll eventually work. For
best results, we recommend using your own domain.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;prepare-the-environment&#34;&gt;Prepare the Environment&lt;/h2&gt;
&lt;p&gt;Create a Kubernetes cluster.  In GKE this can be as simple as running:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;gcloud container clusters create jan8 --num-nodes &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Being organized is key to any successful project. So before you dig in, create a
new project directory and &lt;code&gt;cd&lt;/code&gt; into it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir harbor-install &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;install-project-contour&#34;&gt;Install Project Contour&lt;/h2&gt;
&lt;p&gt;While you are going to use Helm to install Project Contour, Helm will not create
the namespace for you. So the first step in this installation is to create that
namespace.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl create namespace projectcontour
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you do not have the Bitnami repo referenced in Helm yet (you can check by
running &lt;code&gt;helm repo list&lt;/code&gt;), you will need to install it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You will also need to update your Helm repositories.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;helm repo update
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, run &lt;code&gt;helm install&lt;/code&gt; to finish the installation. Here you will install
Bitnami&amp;rsquo;s image for Contour. This chart includes defaults that will work out of
the box for this guide. And since it comes from Bitnami, you can trust that the
image has been thoroughly tested and scanned.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;helm install ingress bitnami/contour -n projectcontour --version 3.3.1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now simply wait for the Pods to become &lt;code&gt;READY&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;watch kubectl get pods -n projectcontour
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then define some environment variables for your proposed Harbor domain and your
email address. It is recommended that you use a subdomain under the domain
procured in the prerequisites section (e.g., harbor.example.com). This way you
can use other subdomain URLs to access other services you may deploy in the
future. The email address will be used for your Let&amp;rsquo;s Encrypt certificate so the
cert authority can notify you about expirations.&lt;/p&gt;
&lt;p&gt;Defining these variables will make the rest of the commands in this guide more
simple to run. The email address and the domain do not have to use the same
domain (a Gmail address is fine).&lt;/p&gt;
&lt;p&gt;If you do not have a custom domain run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nv&#34;&gt;IP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl describe svc ingress-contour-envoy --namespace projectcontour &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep Ingress &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; awk &lt;span class=&#34;s1&#34;&gt;&amp;#39;{print $3}&amp;#39;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;DOMAIN&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$IP&lt;/span&gt;.xip.io
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Otherwise run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;DOMAIN&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your.domain.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Set your email address for cert-manager:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;EMAIL_ADDRESS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;username@example.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;set-up-dns&#34;&gt;Set Up DNS&lt;/h2&gt;


&lt;div class=&#34;aside aside-warning&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;You may skip this section&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;This section is not applicable for those using &lt;code&gt;xip.io&lt;/code&gt;.
If that&amp;rsquo;s you, please skip this entire section.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;In this section, things can vary a bit. Because this guide was written using
Google Cloud Platform (GCP) tooling, the instructions below will reflect that.
But should you be using another provider, I will try to provide a generalized
description of what is being done so you can look up those specific steps. I
have also numbered these steps for clarity.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In order to set up DNS records, you need the IP address of the Envoy ingress
router installed by Project Contour. Use the following command to describe
the service. If the &lt;code&gt;EXTERNAL-IP&lt;/code&gt; is still in a &lt;code&gt;&amp;lt;pending&amp;gt;&lt;/code&gt; state, just wait
until one is assigned. Record this value for a future step.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;watch kubectl get service ingress-contour-envoy -n projectcontour -o wide
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Now set up a DNS zone within your cloud provider.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For GCP, this can be found in the GCP web UI, under Networking Services,
Cloud DNS. Click &lt;code&gt;Create Zone&lt;/code&gt; and follow the instructions to give the zone
a descriptive name, as well as provide the DNS name. The DNS name will be
whatever domain you have registered (e.g., &lt;code&gt;example.com&lt;/code&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For AWS, this is done via a service called
&lt;a href=&#34;https://aws.amazon.com/route53/faqs/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Route 53&lt;/a&gt;, and for Azure,
&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/dns/dns-getstarted-portal_&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;this is done&lt;/a&gt;
by creating a resource in the Azure Portal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once completed, the important part is that you now have a list of name
servers. For example, one or more of the format
&lt;code&gt;ns-cloud-x1.googledomains.com.&lt;/code&gt; Record these for a future step.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Next, add an A record to your DNS zone for a wildcard (&lt;code&gt;*&lt;/code&gt;) subdomain. An A
record is an &amp;ldquo;Address&amp;rdquo; record, one of the most fundamental types of DNS
records; it maps the more user-friendly URL (harbor.example.com) to an IP
address. Setting this up as a wildcard will allow you to configure any
traffic coming into any subdomain to first be resolved by Project Contour and
Envoy, then be routed to its final destination based on the specific
subdomain requested.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For GCP, click into the DNS zone you just created and select &lt;code&gt;Add Record Set&lt;/code&gt;.
From here, add a &lt;code&gt;*&lt;/code&gt; as the DNS name field so the full DNS name reads
&lt;code&gt;*.example.com&lt;/code&gt;. In the IPv4 address field, enter the &lt;code&gt;EXTERNAL_IP&lt;/code&gt; of the
Envoy service recorded earlier in Step 1. Then click create.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For AWS and Azure, this is done via the respective services listed in the previous step.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once completed, your DNS zone should have an A record set up for any subdomain
(&lt;code&gt;*&lt;/code&gt;) to be mapped to the IP address of the Envoy service running in
Kubernetes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;For the last of the somewhat confusing UI-based steps, you need to add the
list of name servers from Step 2 to your personal domain. This will allow any
HTTP/HTTPS requests for your domain to reference the records you set up
previously in your DNS zone.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For Google-managed domains, in the Google Domains UI, click &lt;code&gt;manage&lt;/code&gt; next to
the domain you want to modify. Then click on &lt;code&gt;DNS&lt;/code&gt;. In the Name Servers
section at the top, click &lt;code&gt;edit&lt;/code&gt;. Now, one at a time, simply paste in the list
of name servers recorded in Step 2. There should be four name server
addresses. Then click &lt;code&gt;Save&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For other domain name registrars, the process is similar. Contact your
registrar if you require further assistance with this process.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That&amp;rsquo;s it for configuring DNS. Now you need to wait for all the new records to
propagate. Run the following command and wait for the output to show that your
domain is now referencing the IP address of the Envoy service. This could take a
few minutes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;watch host &lt;span class=&#34;nv&#34;&gt;$DOMAIN&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;install-cert-manager&#34;&gt;Install cert-manager&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cert-manager.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cert-manager&lt;/a&gt; will automate certificate renewal for
your services behind Project Contour. When a certificate is set to expire,
cert-manager will automatically request a new one from the certificate issuer
(you will set this up in the next section). This is especially important when
using a project like Let&amp;rsquo;s Encrypt, whose certificates are only valid for 90
days.&lt;/p&gt;
&lt;p&gt;To install cert-manager, this guide uses Helm, for uniformity. As with
installing Project Contour, Helm will not create a namespace, so the first step
is to create one.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create namespace cert-manager
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you do not have the Jetstack repo referenced in Helm yet (you can check by
running &lt;code&gt;helm repo list&lt;/code&gt;), you will need to install that reference.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo add jetstack https://charts.jetstack.io
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once again, update your Helm repositories.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo update
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, run &lt;code&gt;helm install&lt;/code&gt; to install cert-manager.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install cert-manager jetstack/cert-manager --namespace cert-manager &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;   --version v1.0.2 --set &lt;span class=&#34;nv&#34;&gt;installCRDs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, wait for the Pods to become &lt;code&gt;READY&lt;/code&gt; before moving on to the next step.
This should only take a minute or so.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;watch kubectl get pods -n cert-manager
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;set-up-lets-encrypt-staging-certificates&#34;&gt;Set up Let&amp;rsquo;s Encrypt Staging Certificates&lt;/h2&gt;
&lt;p&gt;When initially setting up your Harbor service, or any service that will be using
Let&amp;rsquo;s Encrypt, it is important to start by using certificates from their staging
server as opposed to the production server. Staging certificates allow you to
test your service without the risk of running up against any API rate limiting,
which Let’s Encrypt imposes on its production environment. This is not a
requirement, however; production certificates can be used initially. But using
the staging ones is a good habit to get into, and will highlight how these
certificates are applied.&lt;/p&gt;
&lt;p&gt;Create the deployment YAML for the staging certificate by pasting the block
below into a new file. Once applied, this will set up the staging cert
configuration along with your email address, for certificate expirations
notifications. You won&amp;rsquo;t need to worry about these emails, however, as
cert-manager will take care of the renewal for you.&lt;/p&gt;
&lt;p&gt;Notice that this is of &lt;code&gt;kind: ClusterIssuer&lt;/code&gt;. That means this certificate issuer
is scoped to all namespaces in this Kubernetes cluster. For more granular
controls in production, you may decide to simply change this to &lt;code&gt;kind: Issuer&lt;/code&gt;,
which will be scoped to a specific namespace and only allow services in that
namespace to request certificates from that issuer. But be aware that this will
necessitate changing other configuration options throughout this guide. We are
using &lt;code&gt;ClusterIssuer&lt;/code&gt; because it is secure enough for our use case, and
presumably you are not using a multi-tenant Kubernetes cluster when following
this guide.&lt;/p&gt;
&lt;p&gt;Finally, this sets up a “challenge record&amp;quot; in the &lt;code&gt;solvers&lt;/code&gt; section, which
allows Let&amp;rsquo;s Encrypt to verify that the certificate it is issuing is really
controlled by you.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt; EOF &amp;gt; letsencrypt-staging.yaml
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;apiVersion: cert-manager.io/v1alpha2
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;kind: ClusterIssuer
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;metadata:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  name: letsencrypt-staging
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;spec:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  acme:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    email: $EMAIL_ADDRESS
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    privateKeySecretRef:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;      name: letsencrypt-staging
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    server: https://acme-staging-v02.api.letsencrypt.org/directory
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    solvers:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    - http01:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;        ingress:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;          class: contour
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now &lt;code&gt;apply&lt;/code&gt; the file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f letsencrypt-staging.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The process of creating the cluster issuer should be fairly quick, but you can
confirm it completed successfully by running the following and ensuring the
cluster issuer was issued.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get clusterissuers.cert-manager.io
NAME                  READY   AGE
letsencrypt-staging   True    74s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;install-harbor&#34;&gt;Install Harbor&lt;/h2&gt;
&lt;p&gt;Now that you have your staging certificate, you can install Harbor, for which
this guide uses Helm in combination with the Bitnami repo set up earlier. As
with your other install steps, the first thing to do is create the namespace.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create namespace harbor
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, create the values file. The Bitnami Helm chart includes defaults that, for
the most part, will work for your needs. However, there are a few configuration
options that need to be set.&lt;/p&gt;
&lt;p&gt;Here you will notice that you are giving the TLS secret in Kubernetes a name,
&lt;code&gt;harbor-tls-staging&lt;/code&gt;. You can choose any name you like, but it should be
descriptive and reflect that this secret will be distinct from the production
certificate you will apply later.&lt;/p&gt;
&lt;p&gt;You are also setting up references to your domain so Harbor and Contour can set
up routing. The Annotations section is important as it tells Harbor about our
configuration. Notice that for
&lt;code&gt;cert-manager.io/cluster-issuer: letsencrypt-staging&lt;/code&gt; you are telling Harbor to
use the &lt;code&gt;ClusterIssuer&lt;/code&gt; called letsencrypt-staging, the one you set up earlier.
This will come up again later when you move to production certificates. Comments
are provided in the file for further detail.&lt;/p&gt;
&lt;p&gt;Finally, this values file will disable the Harbor Notary service. At the time of
this writing there is a bug in the Bitnami Helm chart (already reported) that
doesn&amp;rsquo;t allow a TLS certificate to be applied for both &lt;code&gt;notary.$DOMAIN&lt;/code&gt; and
&lt;code&gt;registry.$DOMAIN&lt;/code&gt;. I will try to update this post once that bug is fixed.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt; EOF &amp;gt; harbor-values.yaml
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;harborAdminPassword: Password12345
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;service:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  type: ClusterIP
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  tls:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    enabled: true
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    existingSecret: harbor-tls-staging
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    notaryExistingSecret: notary-tls-staging
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;ingress:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  enabled: true
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  hosts:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    core: registry.$DOMAIN
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    notary: notary.$DOMAIN
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  annotations:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    cert-manager.io/cluster-issuer: letsencrypt-staging  # use letsencrypt-staging as the cluster issuer for TLS certs
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    ingress.kubernetes.io/force-ssl-redirect: &amp;#34;true&amp;#34;     # force https, even if http is requested
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    kubernetes.io/ingress.class: contour                 # using Contour for ingress
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    kubernetes.io/tls-acme: &amp;#34;true&amp;#34;                       # using ACME certificates for TLS
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;externalURL: https://registry.$DOMAIN
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;portal:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  tls:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    existingSecret: harbor-tls-staging
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now install Harbor using this values file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install harbor bitnami/harbor -f harbor-values.yaml -n harbor --version 9.4.4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And wait for the Pods to become &lt;code&gt;&amp;lt;READY&amp;gt;&lt;/code&gt;. This may take a minute or two.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;watch kubectl get pods -n harbor
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, ensure that the certificates were requested and returned successfully.
This should happen fairly quickly, but may take up to an hour. It all depends on
the server load at that time.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n harbor get certificate
NAME                 READY   SECRET               AGE
harbor-tls-staging   True    harbor-tls-staging   2m26s
notary-tls-staging   True    notary-tls-staging   2m26s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Print out the URL, username, and password:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt; EOF
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;url: https://registry.$DOMAIN
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;username: admin
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;password: $(kubectl get secret --namespace harbor harbor-core-envvars -o jsonpath=&amp;#34;{.data.HARBOR_ADMIN_PASSWORD}&amp;#34; | base64 --decode)
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now open your browser of choice and go to your URL. You will notice that you
will need to accept the security warning that the site is &amp;ldquo;untrusted.&amp;rdquo; This is
because you are still using the staging certificates, which are not signed by a
trusted certificate authority (CA).&lt;/p&gt;
&lt;p&gt;Once you ensure that you can log in and that Harbor is working as intended, you
can move to production certificates.&lt;/p&gt;
&lt;h2 id=&#34;set-up-lets-encrypt-production-certificates&#34;&gt;Set Up Let&amp;rsquo;s Encrypt Production Certificates&lt;/h2&gt;


&lt;div class=&#34;aside aside-warning&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Rate Limits&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Reminder, if using &lt;code&gt;.xip.io&lt;/code&gt; you may encounter rate limit issues with Lets
Encrypt causing major delays in the certificate issuance.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Similar to how you set up the Let&amp;rsquo;s Encrypt staging certificate, you now need to
create the &lt;code&gt;ClusterIssuer&lt;/code&gt; for production certificates. First, &lt;code&gt;echo&lt;/code&gt; the
following to create the file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt; EOF &amp;gt; letsencrypt-prod.yaml
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;apiVersion: cert-manager.io/v1alpha2
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;kind: ClusterIssuer
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;metadata:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  name: letsencrypt-prod
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;spec:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  acme:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    email: $EMAIL_ADDRESS
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    privateKeySecretRef:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;      name: letsencrypt-prod
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    server: https://acme-v02.api.letsencrypt.org/directory
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    solvers:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    - http01:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;        ingress:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;          class: contour
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then apply it to your Kubernetes cluster.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f letsencrypt-prod.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Again, you can confirm this process completed successfully by running the
following and ensuring the cluster issuer was issued.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get clusterissuers
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Recall how earlier in the annotations of the Harbor &lt;code&gt;values.yml&lt;/code&gt; file you told
Harbor to use the &lt;code&gt;letsencrypt-staging&lt;/code&gt; cluster issuer, as well as the secret
&lt;code&gt;harbor-tls-staging&lt;/code&gt;. You must now tell Harbor to use the production cluster
issuer you just created, and trigger it to create a new secret based on that
certificate. To do this, you are going to update the &lt;code&gt;harbor-values.yaml&lt;/code&gt; file
using &lt;code&gt;sed&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sed -i &#39;s/-staging/-prod/&#39; harbor-values.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Run &lt;code&gt;helm delete&lt;/code&gt; then &lt;code&gt;helm install&lt;/code&gt; to uninstall and reinstall Harbor:&lt;/p&gt;
&lt;p&gt;Note: The persistent volumes are not deleted during the &lt;code&gt;helm delete&lt;/code&gt; so any
changes in Harbor you may have made should persist.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm delete -n harbor harbor
helm install harbor bitnami/harbor -f harbor-values.yaml -n harbor --version 9.4.4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Wait for the new Pods to become &lt;code&gt;&amp;lt;READY&amp;gt;&lt;/code&gt;. This may take a minute or two.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;watch kubectl get pods -n harbor
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This process may take as little as a minute or as long as an hour. It just
depends on the server load at that time. But in most of my testing, it took less
than 10 minutes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;watch kubectl get certificate harbor-tls-prod -n harbor
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the certificates are generated successfully, your Harbor instance should be
up and running with valid and trusted TLS certificates. Try logging into Harbor
again.&lt;/p&gt;
&lt;p&gt;Your browser should no longer present a warning, as the certificate you are now
using is signed by a trusted CA.&lt;/p&gt;
&lt;p&gt;Note: If you still see certificate warnings, you may need to re-open it from a
fresh browser.&lt;/p&gt;
&lt;h2 id=&#34;test-harbor&#34;&gt;Test Harbor&lt;/h2&gt;
&lt;p&gt;Run &lt;code&gt;docker login&lt;/code&gt; to log into your new registry:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker login https://registry.&lt;span class=&#34;nv&#34;&gt;$DOMAIN&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Push an image to the new registry:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker pull nginx:latest
docker tag nginx:latest registry.&lt;span class=&#34;nv&#34;&gt;$DOMAIN&lt;/span&gt;/library/nginx:latest
docker push registry.&lt;span class=&#34;nv&#34;&gt;$DOMAIN&lt;/span&gt;/library/nginx:latest
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Test that Kubernetes can access the new image:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create deployment nginx --image&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;registry.&lt;span class=&#34;nv&#34;&gt;$DOMAIN&lt;/span&gt;/library/nginx:latest
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Wait a few moments and check that the Pod is running:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ NAME                         READY   STATUS    RESTARTS   AGE
pod/nginx-7cdffc88cf-p8v9r   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          5s

NAME                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;   AGE
service/kubernetes   ClusterIP   10.123.240.1   &amp;lt;none&amp;gt;        443/TCP   166m

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx   1/1     &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;            &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;           5s

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-7cdffc88cf   &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;         &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;         &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;       5s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;That&amp;rsquo;s it! You now have a service running in Kubernetes with TLS encryption
enforced and certificate generation automated. And by using these patterns, you
should be able to install and configure other services as well. Specific steps,
especially around the configuration of the service itself, will be different,
but after using this guide you should have a leg up in getting started.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Deploy from a Private Helm Repository Using Kubeapps</title>
      
      <link>/guides/kubernetes/kubeapps-private-repo/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/kubeapps-private-repo/</guid>
      <description>

        
        &lt;p&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubeapps&lt;/a&gt; is a web-based UI for
deploying and managing applications in Kubernetes clusters. Kubeapps includes a
built-in catalog of Helm charts and operators continuously maintained and up to
date. Now Kubeapps also provides support for private Helm repositories with
private Docker images. There is an option of associating Docker credentials to
an application repository so that Kubeapps can ensure they are used to pull any
matching private images within a chart. This option is really useful for
enterprise development team since it allows them to have more granular access
control as well as a known good source of images.&lt;/p&gt;
&lt;p&gt;Kubeapps officially supports the following Helm repositories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/docs/user/private-app-repository.md#chartmuseum&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;ChartMuseum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/docs/user/private-app-repository.md#harbor&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Harbor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/docs/user/private-app-repository.md#artifactory&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Artifactory Pro&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial shows you how to create a private project in Harbor, push a
customized Helm chart to your registry and create an application repository to
have your chart ready from the Kubeapps UI to be deployed.&lt;/p&gt;
&lt;p&gt;Watch the following video or keep reading this tutorial to learn more:&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;360&#34; src=&#34;https://www.youtube.com/embed/LLw1Ib8IQQk&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;assumptions-and-prerequisites&#34;&gt;Assumptions and prerequisites&lt;/h2&gt;
&lt;p&gt;This guide assumes that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You have a Docker environment installed and configured. Learn more about
&lt;a href=&#34;https://docs.docker.com/engine/install/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;installing Docker&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You have a Docker Hub account.
&lt;a href=&#34;https://hub.docker.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Register for a free account&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You have a Kubernetes cluster. Check out our
&lt;a href=&#34;https://docs.bitnami.com/kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Getting Started with Kubernetes guides&lt;/a&gt;
for an easy way to get started with one.&lt;/li&gt;
&lt;li&gt;You have administrator access to a preexisting installation of
&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/harbor&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Harbor&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You have
&lt;a href=&#34;https://docs.bitnami.com/kubernetes/get-started-kubernetes/#step-4-install-helm&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm installed in your cluster&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You have
&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/docs/user/getting-started.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubeapps installed in your cluster&lt;/a&gt;
and are logged into the Kubeapps UI with admin credentials.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-1-create-a-private-project-in-harbor&#34;&gt;Step 1: Create a private project in Harbor&lt;/h2&gt;
&lt;p&gt;The first step is to create a project in Harbor. To do so:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Log in to Harbor.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the &amp;ldquo;Projects&amp;rdquo; section, click &amp;ldquo;+ New Project&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the resulting screen, give a name to your project. This should be private
so don&amp;rsquo;t activate the &amp;ldquo;Public&amp;rdquo; check. To get an unlimited storage quota, set
that value as -1. Click &amp;ldquo;OK&amp;rdquo; to proceed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/harbor-create-new-project.png&#34; alt=&#34;Create a private project in Harbor&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-2-pull-the-docker-image-and-push-it-to-your-private-harbor-registry&#34;&gt;Step 2: Pull the Docker image and push it to your private Harbor Registry&lt;/h2&gt;
&lt;p&gt;Next, pull the Docker image of the chart you want to add to your private
repository. Then, you need to push it to Harbor to make it available in your
project. Follow these steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Execute the following command to obtain the latest Bitnami Ghost image:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker pull bitnami/ghost:3.13.2-debian-10-r0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tag the image by executing the command below. Remember to replace the
&lt;code&gt;HARBOR_DOMAIN_NAME&lt;/code&gt; placeholder with the domain name where Harbor is installed.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker tag docker.io/bitnami/ghost:3.13.2-debian-10-r0 HARBOR_DOMAIN_NAME/project-private/ghost:3.13.2-debian-10-r0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Login in to Harbor.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker login HARBOR_DOMAIN_NAME
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Push the image to your registry by executing this command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker push HARBOR_DOMAIN_NAME/project-private/ghost:3.13.2-debian-10-r0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You should see an output message similar to this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;The push refers to repository &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;harbor.bkpr-kubeapps-gke.nami.run/project-private/ghost&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
325a01bfb407: Preparing
17d308e7f8c1: Preparing
0a621af6678f: Preparing
2e366bd4c478: Preparing
315ad5c0230e: Preparing
1cfb963e6dd2: Waiting
4e78eb629a01: Waiting
f2e5c6cb0141: Waiting
8bce1f8ba802: Waiting
7d1d696c2212: Waiting
9f729ba7c732: Waiting
e048dd4e8543: Waiting
3.13.2-debian-10-r0: digest: sha256:9121f532fbe28f8e6d4cb11bf542374689c4595378ef83adeda5bff46731d972 size: &lt;span class=&#34;m&#34;&gt;2839&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the Harbor UI and in your project, select the tab &amp;ldquo;Repositories&amp;rdquo;.
You should see the repository that contains the image you just pushed. Click
on it to check image details:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/harbor-images-pushed.png&#34; alt=&#34;Harbor repositories&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-3-enable-a-robot-account-in-your-project&#34;&gt;Step 3: Enable a Robot Account in your project&lt;/h2&gt;
&lt;p&gt;Next step is to enable a Robot Account in your project with access to pull both
Helm charts from the private repositories as well as Docker images in the
private project. To do so:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the Harbor UI, navigate to the &amp;ldquo;Robot Account&amp;rdquo; tab in your project and
click &amp;ldquo;+ New Robot Account&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the resulting window, give it a name, a description (optional) and in the
&amp;ldquo;Permissions&amp;rdquo; section, activate the &amp;ldquo;Pull&amp;rdquo; check in the Helm Chart line. Click
&amp;ldquo;Save&amp;rdquo; to proceed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/create-robot-account.png&#34; alt=&#34;Create a Robot Account in your project&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once it is created, remember to copy the token in a safe place or export it to file.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/robot-account-created.png&#34; alt=&#34;Copy or export to file the token&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-4-customize-your-helm-chart-and-push-it-to-your-private-harbor-registry&#34;&gt;Step 4: Customize your Helm chart and push it to your private Harbor Registry&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Get the Bitnami Ghost Helm chart and change to the chart&amp;rsquo;s directory by
executing the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm fetch bitnami/ghost --untar &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ghost
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edit the &lt;em&gt;values.yaml&lt;/em&gt; file of the chart of the chart so that the
image.registry and image.repository value point to your registry and
repository path respectively:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/chart-values-yaml.png&#34; alt=&#34;Modify the chart values.yaml file&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you have edited those values, package you chart by running:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ../ &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; helm package ./ghost
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You will see an output message similar to this: &amp;ldquo;Successfully packaged chart&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;From the Harbor UI, navigate to the &amp;ldquo;Helm Charts&amp;rdquo; tab and click &amp;ldquo;Upload&amp;rdquo;.
Browse the resultant &lt;em&gt;tgz&lt;/em&gt; file of your packaged chart and click &amp;ldquo;Upload&amp;rdquo;. You
will see your Helm Chart uploaded in a few minutes:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/harbor-helm-chart.png&#34; alt=&#34;Harbor Helm chart uploaded&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;You can click on it to check more information about the chart:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/harbor-chart-details.png&#34; alt=&#34;Harbor Helm chart details&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now that you have both the Ghost image and its Helm chart available in your
Harbor private repository, it is time to create an application repository in
Kubeapps to start deploying your charts on Kubernetes from its dashboard.&lt;/p&gt;
&lt;h2 id=&#34;step-5-create-an-application-repository-to-enable-your-harbors-private-repository-in-kubeapps&#34;&gt;Step 5: Create an application repository to enable your Harbor&amp;rsquo;s private repository in Kubeapps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Log in to Kubeapps.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select the namespace where the repository (and the secret) are to be created.
This should be different from the &lt;em&gt;kubeapps&lt;/em&gt; namespace.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;From the menu button in the top right corner, select the &amp;ldquo;App Repositories&amp;rdquo;
option, then click the &amp;ldquo;Add App Repository&amp;rdquo; button.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the resulting screen enter the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Application repository name&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;URL: private repository URL&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repository Authorization: select the &amp;ldquo;Basic Auth&amp;rdquo; option and enter as
&amp;ldquo;Username&amp;rdquo; the name you gave to the Robot Account created in Harbor, and as
&amp;ldquo;Password&amp;rdquo;, the token you obtain at the time of the creation. This way,
Kubeapps will be able to see the charts you have pulled into your Harbor
repository.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Associate Docker Registry Credentials: click &amp;ldquo;Add New Credentials&amp;rdquo; to add
the credentials that will allow Kubernetes to pull images from your private
repository. Add the values below, then click &amp;ldquo;Submit&amp;rdquo;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Secret name&lt;/li&gt;
&lt;li&gt;Server: Harbor&amp;rsquo;s server domain&lt;/li&gt;
&lt;li&gt;Username: in this case, as you created a Robot Account, use its name as username&lt;/li&gt;
&lt;li&gt;Password: use the Robot Account token as password&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/app-repo-pull-secret.png&#34; alt=&#34;Add an application repository with the Harbor credentials&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click the &amp;ldquo;Install Repo&amp;rdquo; button to finish the process. You will see your new
application repository in the list of existing application repositories in
your namespace.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/app-repositories.png&#34; alt=&#34;List of application repositories&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;If you click the repository link, you will be redirected to its catalog. You
should see your Ghost chart there ready to be deployed:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/private-repo-catalog.png&#34; alt=&#34;Private repository application catalog&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-6-deploy-your-custom-ghost-from-the-kubeapps-ui&#34;&gt;Step 6: Deploy your custom Ghost from the Kubeapps UI&lt;/h2&gt;
&lt;p&gt;Finally, you are able to install your custom application from your private
registry on Kubernetes using the Kubeapps UI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In the application repository catalog you just created, click the Ghost entry
to go to the chart page.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the resulting screen, you can learn about the Ghost chart, the repository
where it is located, review older versions, and any related links. Click
&amp;ldquo;Deploy&amp;rdquo; to deploy the chart:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/deploy-ghost.png&#34; alt=&#34;Deploy Ghost from your private repository&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This will take you to a page where you can configure your Ghost deployment.
You can use either the &amp;ldquo;Form&amp;rdquo; or the &amp;ldquo;YAML&amp;rdquo; tab to customize your deployment
as you want: give your chart a name, change the version you want to deploy,
add an admin password (if not, a random 10-character alphanumeric string will
be set), or configure Helm values.&lt;/p&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Important&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;The Ghost chart requires a resolvable host. Specify it in the &amp;ldquo;Hostname&amp;rdquo; section.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/ghost-values-kubeapps.png&#34; alt=&#34;Ghost values&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &amp;ldquo;Submit&amp;rdquo; to start the application deployment. Once submitted, you will
be redirected to a page that describes the state of your deployment. The
status will be &amp;ldquo;Deploying&amp;rdquo; until Ghost is up and running.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/ghost-deployment.png&#34; alt=&#34;Ghost deployment&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the chart is deployed, you can see all the deployment details, including
the URLs to access the application.&lt;/p&gt;
&lt;p&gt;By default, Ghost creates a Service with LoadBalancer type to provide an
externally accessible URL for its web interface. Depending on your cloud
provider of choice, the load balancer can take some time to provision and will
stay in a &amp;ldquo;Pending&amp;rdquo; state until it is available. If using Minikube, you will
need to run minikube tunnel in a new terminal window in order for an IP
address to be assigned.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After some time, the URL should be visible in the Access URL table. Once it is
visible, click one of the URLs shown to access your freshly deployed Ghost
blog.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/kubeapps-private-repo/ghost.png&#34; alt=&#34;Ghost home page&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;useful-links&#34;&gt;Useful links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubeapps Github repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeapps/kubeapps/blob/master/docs/user/private-app-repository.md#harbor&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Using a Private Repository with Kubeapps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://goharbor.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Harbor&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Application Enhancements</title>
      
      <link>/guides/kubernetes/app-enhancements/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/app-enhancements/</guid>
      <description>

        
        &lt;p&gt;Kubernetes does not demand specifics about the applications that run on top of
it. They don&amp;rsquo;t not need to be microservices, 12 factor, or maintain other specific
software philosophies. However, for an application to run well on Kubernetes, there
are aspects of your application you may wish to reconsider.&lt;/p&gt;
&lt;p&gt;Kubernetes is a distributed system that has behaviors different from what many
are used to in a traditional environment. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Workloads must be packaged in a container.&lt;/li&gt;
&lt;li&gt;Workloads may be moved (stopped and recreated) based on the needs of the
system.&lt;/li&gt;
&lt;li&gt;Workload IP addresses are [generally] ephemeral.&lt;/li&gt;
&lt;li&gt;Workloads have no affinity to hosts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Aside from the above constraints, how your application is developed and run is
up to you. There are multiple considerations you can make to comply with more
idiomatic Kubernetes software practices. The following checklist covers the
considerations for running an application in Kubernetes.&lt;/p&gt;
&lt;h2 id=&#34;popular-tooling--approaches&#34;&gt;Popular Tooling &amp;amp; Approaches&lt;/h2&gt;
&lt;h3 id=&#34;application-probes&#34;&gt;Application Probes&lt;/h3&gt;
&lt;p&gt;Kubernetes supports a multitude of probes that indicate state of a running
workload. For details on implementing probes, see &lt;a href=&#34;../app-enhancements-probing-app-state&#34;&gt;the guide on Probing
Application State&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;readiness-probe&#34;&gt;Readiness Probe&lt;/h4&gt;
&lt;p&gt;You should use readiness probes as they gate whether your application is
considered &amp;lsquo;Ready&amp;rsquo; to a cluster. Until applications are &amp;lsquo;Ready&amp;rsquo; they do not
receive traffic. A simple HTTP check that reports ready, post initialization is
often adequate.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/app-enhancements/readiness-probe.png&#34; alt=&#34;Readiness Probe&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;For implementation details, see &lt;a href=&#34;../app-enhancements-probing-app-state&#34;&gt;the guide on Probing Application
State&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;liveness-probe&#34;&gt;Liveness Probe&lt;/h4&gt;
&lt;p&gt;You should consider liveness probes as a &amp;lsquo;safety&amp;rsquo; check for your application to
ensure it hasn&amp;rsquo;t halted operation unexpectedly. These checks should &lt;strong&gt;not&lt;/strong&gt; rely
on external dependencies as you don&amp;rsquo;t want your application to restart due to
external issues.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/app-enhancements/liveness-probe.png&#34; alt=&#34;Liveness Probe&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;For implementation details, see &lt;a href=&#34;../app-enhancements-probing-app-state&#34;&gt;the guide on Probing Application
State&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;startup-probe&#34;&gt;Startup Probe&lt;/h4&gt;
&lt;p&gt;You should consider a startup probe for legacy applications that require a
larger amount of time for their initial startup. This probe only executes on
first start-up and does not continue probing over time (like readiness and
liveness). After a startup probe succeeds, if configured, a liveness probe will
continue. Ideally, modern applications &lt;strong&gt;do not&lt;/strong&gt; require this kind of
protection, but it can be helpful when long start ups cannot be worked around.&lt;/p&gt;
&lt;h3 id=&#34;externalized-configuration&#34;&gt;Externalized Configuration&lt;/h3&gt;
&lt;p&gt;In Kubernetes based-platform, you should keep all application configuration
outside of the application / container when possible. This will enable you to
dynamically change how your application runs by altering ConfigMaps and Secrets.
It&amp;rsquo;s also helpful when deploying the application into different context or
environments.&lt;/p&gt;
&lt;p&gt;For details on how to externalize configuration, see the &lt;a href=&#34;../app-enhancements-externalizing-configuration&#34;&gt;externalizing
configuration guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;graceful-shutdown-mechanics-handlers&#34;&gt;Graceful Shutdown Mechanics Handlers&lt;/h3&gt;
&lt;p&gt;As Kubernetes moves workloads around the cluster, an instance of your
application can be asked to stop so a new instance of it can be started
elsewhere. If your application requires any amount of graceful shutdown, you
should ensure your application can handle this event.&lt;/p&gt;
&lt;p&gt;When a pod is being deleted, moved, or recreated each container&amp;rsquo;s PID 1 receives
a SIGTERM. The process then has a grace-period to do what it needs and exit.
The default grace-period is 30 seconds; check with your cluster administrator to
understand what your cluster is set to. If the grace period expires, a SIGKILL
is sent. For more details, see the &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Termination of Pods
documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If a process, script, or HTTP endpoints must be called to terminate gracefully,
you can also add a &lt;a href=&#34;https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;preStop
hook&lt;/a&gt;
to your Kubernetes manifest.&lt;/p&gt;
&lt;p&gt;For details on how to gracefully shutdown pods, see the &lt;a href=&#34;../app-enhancements-graceful-shutdown&#34;&gt;graceful shutdown guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;structured-logging&#34;&gt;Structured Logging&lt;/h3&gt;
&lt;p&gt;Structured logging allows log aggregation systems to provide a better view of your
applications logs. You should consider this approach for applications running
Kubernetes. Typically it&amp;rsquo;s as simple as creating log-helper functions or
introducing a logging library. For implementation details, see the &lt;a href=&#34;../app-enhancements-logging-practices&#34;&gt;logging
practice guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;export-application-metrics&#34;&gt;Export Application Metrics&lt;/h3&gt;
&lt;p&gt;When exposing metrics about your application, it is a common practice to use
an exporter. This allows you to introduce metrics to your application and a
scraping system, such as &lt;a href=&#34;https://prometheus.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;prometheus&lt;/a&gt;, to gather those
metrics over time.  There are exporter libraries for most languages. See the
&lt;a href=&#34;https://prometheus.io/docs/instrumenting/clientlibs/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Client Library&lt;/a&gt;
documentation for a list of examples.&lt;/p&gt;
&lt;p&gt;Work with your platform team to determine if scrape-based monitoring system such
as prometheus, Datadog, or Elastic is available.&lt;/p&gt;
&lt;p&gt;For more details, see the &lt;a href=&#34;../app-observability-exporting-metrics&#34;&gt;Exporting Application Metrics
guide&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;trace-points&#34;&gt;Trace Points&lt;/h3&gt;
&lt;p&gt;In service based architectures, a request can move through many
applications and thus across network boundaries multiple times. A trade-off to
these architectures is detecting where issues in the stack are occurring. For
example, where is most of the latency in a request coming from?&lt;/p&gt;
&lt;p&gt;If your workload falls into this architecture, implementing tracing in your
application(s) is worth considering. Often you need a system that lets you view
trace results, before running one, you may wish to check with your platform team
to see if something pre-exists.&lt;/p&gt;
&lt;p&gt;For more details on this concern, see the
&lt;a href=&#34;../app-observability&#34;&gt;Observability section&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Application Lifecycle</title>
      
      <link>/guides/kubernetes/app-lifecycle/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/app-lifecycle/</guid>
      <description>

        
        &lt;p&gt;The scripts and systems used in the CI/CD pipelines to deploy and update
applications are limited by the Kubernetes resources they can manage.  In many
cases this may be perfectly sufficient.  An update to the image in a Deployment
spec may be all that is required to perform an update of an application, for
example.&lt;/p&gt;
&lt;p&gt;However, this model is often insufficient
when dealing with workloads that are stateful, distributed and/or complex.
For example, an application that stores data in a relational database may require
a database schema update in coordination with an upgrade to the application itself.
This kind of coordination is awkward for a pipeline to orchestrate and usually
requires a series of manual operations to perform an application update or
upgrade.&lt;/p&gt;
&lt;h2 id=&#34;operators&#34;&gt;Operators&lt;/h2&gt;
&lt;p&gt;A Kubernetes operator is a piece of software that runs in your cluster and
manages the deployment and lifecycle management on your behalf.  In this
example you use a custom resource - an extension to the Kubernetes
API - to define the essential characteristics of your application.  The operator
responds by creating the various Kubernetes resources on your behalf.  When
an app upgrade is needed, the pipeline need only update the custom resource that
represents your application.  The operator contains the logic that allows it to
conduct the upgrade in response.  In the relational database-backed example, it
may put the application into a maintenance mode, initiate a backup of the
database, apply the schema update to the database, upgrade the application
version and restore it to normal functioning mode.&lt;/p&gt;
&lt;p&gt;The advantage of using Kubernetes operators is that you can reduce the human
toil from otherwise labor-intensive operations and perform these operations
reliably.  The drawback is that you have another piece of complex software to
develop and maintain.&lt;/p&gt;
&lt;h2 id=&#34;popular-tooling--approaches&#34;&gt;Popular Tooling &amp;amp; Approaches&lt;/h2&gt;
&lt;h3 id=&#34;kubebuilder&#34;&gt;Kubebuilder&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/kubebuilder&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubebuilder&lt;/a&gt; is an SDK for
building custom Kubernetes controllers and operators.  It is a CLI you can use
to stamp out boilerplate and scaffolded Go code that is common to all such projects.
The code generated by Kubebuilder includes a Dockerfile, deployment manifests and a
Makefile that facilitates local development.  In addition to the base project
codebase, Kubebuilder can be used to add new APIs as CRDs along with their
corresponding controllers.&lt;/p&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;is &lt;a href=&#34;https://book.kubebuilder.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;well documented&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;can include admission webhooks for your CRDs&lt;/li&gt;
&lt;li&gt;has experimental support for
&lt;a href=&#34;https://github.com/kubernetes-sigs/kubebuilder/tree/master/plugins&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;plugins&lt;/a&gt;
to build operators using alternative patterns&lt;/li&gt;
&lt;li&gt;is maintained and controlled by upstream Kubernetes SIG&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;requires the Go programming language&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;metacontroller&#34;&gt;Metacontroller&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/app-lifecycle/metacontroller.png&#34; alt=&#34;metacontroller&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/metacontroller&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Metacontroller&lt;/a&gt; or, the
more actively maintained fork &lt;a href=&#34;https://github.com/AmitKumarDas/metac&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;metac&lt;/a&gt;, is
a cluster add-on that runs in your cluster and takes care of the common
operations all controllers and operators must do.  Whereas Kubebuilder stamps
out boilerplate code for these common operations, metacontroller abstracts
those operations away into a separate workload.  Metacontroller manages all
interactions with the Kubernetes API.  The custom controller&amp;rsquo;s logic is
developed in what metacontroller calls the &amp;ldquo;lambda controller&amp;rdquo;.  The presence
and nature of the lambda controller is defined in a metacontroller custom
resource, for example the &amp;ldquo;Composite Controller&amp;rdquo;.  In the case of a Composite
Controller, the &amp;ldquo;parent resource&amp;rdquo; is the resource that is watched and which
triggers reconciliation.  When a change occurs in the parent resource,
metacontroller calls the lambda controller and passes that parent resource
object as JSON.  The lambda controller responds with the &amp;ldquo;child resource&amp;rdquo; as
JSON and metacontroller makes the change to the actual child resource in the API.&lt;/p&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;lambda controllers can be developed in any language that can expose an HTTP
endpoint to metacontroller and use JSON&lt;/li&gt;
&lt;li&gt;smaller codebase for your controller logic&lt;/li&gt;
&lt;li&gt;fast to get started - great for prototyping&lt;/li&gt;
&lt;li&gt;can run multiple controllers behind a single metacontroller instance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;your controller has the additional dependency and operational overhead of
metacontroller running in the cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;operator-sdk&#34;&gt;Operator SDK&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/operator-framework/operator-sdk&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Operator SDK&lt;/a&gt; is a project
originally started at CoreOS that is similar to Kubebuilder in that it uses a
CLI to generate boilerplate and scaffolded code for a new project.  It is a
component of Red Hat&amp;rsquo;s &lt;a href=&#34;https://github.com/operator-framework&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Operator Framework&lt;/a&gt;
which could make it attractive if you are using other components of that toolkit.
Due to the overlap between Kubebuilder and the Go-based operator support in
Operator SDK, those features will be &lt;a href=&#34;https://github.com/kubernetes-sigs/kubebuilder/blob/master/designs/integrating-kubebuilder-and-osdk.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;merged into
Kubebuilder&lt;/a&gt;
in the future.  Operator SDK should only be considered where value can be
derived from the Ansible or Helm features.&lt;/p&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;allows you to develop operators in Go, Ansible or Helm&lt;/li&gt;
&lt;li&gt;offers integrations with lifecycle manager from the Operator Framework&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;is managed by Red Hat for their ecosystem so may not fit your needs well if
not using OpenShift&lt;/li&gt;
&lt;li&gt;the Go-based operator features will be merged into Kubebuilder&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Application Observability</title>
      
      <link>/guides/kubernetes/app-observability/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/app-observability/</guid>
      <description>

        
        &lt;p&gt;The term &amp;ldquo;observability&amp;rdquo; in control theory states that the system is observable
if the internal states of the system and its behavior can be determined by only
looking at its inputs and outputs.&lt;/p&gt;
&lt;p&gt;In software, observability means we can answer most questions about a system&amp;rsquo;s
status and performance by looking from the outside. The system has been
instrumented to externalize and make available measurements useful to those
responsible for the platform&amp;rsquo;s success and reliability.&lt;/p&gt;
&lt;p&gt;Observability aims to provide highly granular insights into the behavior of
production systems along with rich context, perfect for debugging and
performance analysis.&lt;/p&gt;
&lt;h2 id=&#34;health-checks&#34;&gt;Health checks&lt;/h2&gt;
&lt;p&gt;Health checks (often custom HTTP endpoints) help orchestrators, like Kubernetes,
perform automated actions to maintain overall system health. These can be a
simple HTTP route that returns meaningful values, or a command that can be
executed from within the container.&lt;/p&gt;
&lt;h2 id=&#34;metrics&#34;&gt;Metrics&lt;/h2&gt;
&lt;p&gt;Metrics are a numeric representation of data that is collected at intervals into
a time series. Numerical time series data is easy to store and query, which
helps when looking for historical trends. Over a longer period of time,
this numerical data can be compressed into less granular aggregates like daily
or weekly, for example. This allows for longer retention periods for
historic purposes.&lt;/p&gt;
&lt;h2 id=&#34;logging&#34;&gt;Logging&lt;/h2&gt;
&lt;p&gt;Log entries represent discrete events. Log entries are essential for debugging,
as they often include stack traces and other contextual information that can
help identify the root cause of observed failures.&lt;/p&gt;
&lt;p&gt;Logging is used when the developer wants to explicitly output some message for
someone to see. It is coded directly into executable code, including passing
along values of relevant variables. When problems occur, the logs are useful for
debugging purposes, showing where a failure occurred, such as a stack trace for
an exception that got thrown.&lt;/p&gt;
&lt;h2 id=&#34;distributed-tracing&#34;&gt;Distributed Tracing&lt;/h2&gt;
&lt;p&gt;Distributed, request, or end-to-end tracing captures the end-to-end flow of a
request through the system. Tracing essentially captures both relationships
between services (the services the request touched), and the structure of work
through the system (synchronous or asynchronous processing, child-of or
follows-from relationships). Tracing is something unique to the cloud-native
world, allowing developers and operators to track the exchanges between
different microservices.&lt;/p&gt;
&lt;p&gt;In order to enable distributed tracing, an application needs to be &amp;ldquo;instrumented&amp;rdquo;
by adding and configuring distributed tracing client libraries. For example, you
can configure application to send trace records to an Open Tracing compliant
trace server whenever any JAX-RS annotated method is invoked. This way you have
an audit record of what got called when, by whom, and how long it took. By
adding Open Tracing annotations to traced methods you can also include
information about what private methods have been called in your code for
example.&lt;/p&gt;
&lt;h2 id=&#34;popular-tooling--approaches&#34;&gt;Popular Tooling &amp;amp; Approaches&lt;/h2&gt;
&lt;h3 id=&#34;health-checks-1&#34;&gt;Health checks&lt;/h3&gt;
&lt;p&gt;Kubernetes exposes the following health probes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Readiness -  whether application is considered &amp;lsquo;Ready&amp;rsquo; to a cluster.&lt;/li&gt;
&lt;li&gt;Liveness - safety check to ensure that application hasn&amp;rsquo;t halted operation unexpectedly.&lt;/li&gt;
&lt;li&gt;Startup - for applications that require a larger amount of time for their initial startup.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use above health endpoints based on application&amp;rsquo;s requirements.&lt;/p&gt;
&lt;p&gt;For implementation details, see &lt;a href=&#34;../app-enhancements-probing-app-state&#34;&gt;the guide on Probing Application
State&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;metrics-1&#34;&gt;Metrics&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://prometheus.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus&lt;/a&gt; is an open-source systems monitoring and
alerting toolkit. It works well for recording any purely numeric time series. It
fits both machine-centric monitoring as well as monitoring of highly dynamic
service-oriented architectures. In a world of microservices, its support for
multi-dimensional data collection and querying is a particular strength. We
recommend the &lt;a href=&#34;https://github.com/coreos/prometheus-operator&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus
operator&lt;/a&gt;, which manages the
lifecycle of prometheus and comes with many sensible defaults.&lt;/p&gt;
&lt;p&gt;Managing Prometheus could become challenging overtime:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data retention - ability to efficiently store data for longer periods of time.&lt;/li&gt;
&lt;li&gt;High-Cardinality Metrics - metrics with dimensions that have many different
values can cause performance degradation.&lt;/li&gt;
&lt;li&gt;Dynamic service scraping - could cause performance degradation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We recommend the reader to check with their platform team if any metrics
scraping services are available in the platform.&lt;/p&gt;
&lt;p&gt;For more details on this concern, see &lt;a href=&#34;../app-enhancements#export-application-metrics&#34;&gt;the opinion on Export Application
Metrics&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;logging-1&#34;&gt;Logging&lt;/h3&gt;
&lt;p&gt;In most Kubernetes deployments, all logging should happen to standard out and
standard error. Additionally, most platform teams will offer developers a log
shipping solution, so you should check with your platform team to understand
how this works.&lt;/p&gt;
&lt;p&gt;Typical Logging Stack:&lt;/p&gt;
&lt;h4 id=&#34;log-aggregator&#34;&gt;Log Aggregator&lt;/h4&gt;
&lt;p&gt;This component collects logs from pods running on different nodes and route them
to a central location.
&lt;a href=&#34;https://www.fluentd.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;fluentd&lt;/a&gt; has become a
popular log aggregator for Kubernetes deployments. It is small, efficient and
has a wide plugin ecosystem.&lt;/p&gt;
&lt;h4 id=&#34;log-collectorstoragesearch&#34;&gt;Log Collector/Storage/Search&lt;/h4&gt;
&lt;p&gt;This component stores the logs from log aggregators and provides an interface to
search logs efficiently. It should also provide storage management and archival
of logs. Ideally, this component should be resilient to node failures, so that
logging does not become unavailable in case of infrastructure failures.
&lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Elasticsearch&lt;/a&gt; is one of the
options, as it can ingest logs from fluentd, creates inverted indices on
structured log data making efficient search possible, and has multi-master
architecture with ability to shard data for high availability.&lt;/p&gt;
&lt;h4 id=&#34;ui-and-alerting&#34;&gt;UI and Alerting&lt;/h4&gt;
&lt;p&gt;Visualizations are key for log analysis of distributed applications. A good UI
with query capabilities makes it easier to sift through application logs,
correlate and debug issues. Custom dashboards can provide high level overview of
the health of the distributed application.
&lt;a href=&#34;https://www.elastic.co/products/kibana&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kibana&lt;/a&gt; from Elasticsearch can be used
as the UI for the log storage, and will be explored as an option here. Alerting
is typically an actionable event in the system. It can be set up in conjunction
with logging and monitoring.&lt;/p&gt;
&lt;p&gt;For additional implementation details, see &lt;a href=&#34;../app-enhancements-logging-practices&#34;&gt;the guide on Logging
Practices&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;distributed-tracing-1&#34;&gt;Distributed Tracing&lt;/h3&gt;
&lt;p&gt;Consider using Distributed Tracing in complex multi-service architectures. It
can help with detection of cascading failures in service calls, optimization of
Database requests, latency problems etc.&lt;/p&gt;
&lt;p&gt;We recommend to check with the platform team to see what tracing platform tools
pre-exist / are available.&lt;/p&gt;
&lt;p&gt;Typical Distributed Tracing stack:&lt;/p&gt;
&lt;h4 id=&#34;zop-stack-zipkin-opentracing-prometheus&#34;&gt;ZOP stack (Zipkin, OpenTracing, Prometheus)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zipkin.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Zipkin&lt;/a&gt; - distributed tracing system. Applications need
to be &amp;ldquo;instrumented&amp;rdquo; to report trace data to Zipkin. This usually means
configuration of a &lt;a href=&#34;https://zipkin.io/pages/tracers_instrumentation&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;tracer or instrumentation
library&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://opentracing.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;OpenTracing&lt;/a&gt; - vendor-neutral APIs and
instrumentation for distributed tracing.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://prometheus.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus&lt;/a&gt; - open-source systems monitoring and alerting toolkit. Before
you can monitor your services, you need to add instrumentation to their code
via one of the &lt;a href=&#34;https://prometheus.io/docs/instrumenting/clientlibs/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;client
libraries&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;jop-stack-jaeger-opentracing-prometheus&#34;&gt;JOP stack (Jaeger, OpenTracing, Prometheus)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jaegertracing.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Jaeger&lt;/a&gt; - distributed tracing system. It is
used for monitoring and troubleshooting microservices-based distributed
systems. Applications must be instrumented before they can send tracing data
to Jaeger backend. Check the &lt;a href=&#34;https://www.jaegertracing.io/docs/1.16/client-libraries/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Client
Libraries&lt;/a&gt; section
for information about how to use the OpenTracing API and how to initialize and
configure Jaeger tracers.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://opentracing.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;OpenTracing&lt;/a&gt; - vendor-neutral APIs and
instrumentation for distributed tracing.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://prometheus.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus&lt;/a&gt; - open-source systems monitoring and alerting toolkit. Before
you can monitor your services, you need to add instrumentation to their code
via one of the &lt;a href=&#34;https://prometheus.io/docs/instrumenting/clientlibs/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;client
libraries&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Carvel</title>
      
      <link>/guides/kubernetes/carvel/</link>
      <pubDate>Wed, 14 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/carvel/</guid>
      <description>

        
        &lt;p&gt;&lt;a href=&#34;https://carvel.dev/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Carvel&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; is an open source suite of tools. Carvel provides a set of reliable, single-purpose, composable tools that aid in your application building, configuration, and deployment to Kubernetes.&lt;/p&gt;
&lt;p&gt;It currently&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; contains the following tools:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://carvel.dev/ytt/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;ytt&lt;/a&gt;&lt;/strong&gt;: Template and overlay Kubernetes configuration via YAML structures, not text documents. No more counting spaces, or manual quoting.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://carvel.dev/kbld/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kbld&lt;/a&gt;&lt;/strong&gt;: Build or reference container images in Kubernetes configuration in an immutable way.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://carvel.dev/kapp/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kapp&lt;/a&gt;&lt;/strong&gt;: Install, upgrade, and delete multiple Kubernetes resources as one &amp;ldquo;application&amp;rdquo;. Be confident your application is fully reconciled.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://carvel.dev/imgpkg/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;imgpkg&lt;/a&gt;&lt;/strong&gt;: Bundle and relocate application configuration (with images) via Docker registries. Be assured app contents are immutable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/vmware-tanzu/carvel-kapp-controller&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kapp-controller&lt;/a&gt;&lt;/strong&gt;: Capture application deployment workflow declaratively via App CRD. Reliable GitOps experience powered by kapp.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://carvel.dev/vendir/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;vendir&lt;/a&gt;&lt;/strong&gt;: Declaratively state what files should be in a directory.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;learn-more&#34;&gt;Learn more&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;/%28https:/carvel.dev/%29&#34;&gt;carvel.dev&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Guides&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/guides/kubernetes/kapp-gs/&#34;&gt;Getting Started with kapp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Workshops&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://tanzu.vmware.com/developer/workshops/lab-getting-started-with-carvel/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Getting Started with Carvel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Formerly k14s&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;As of April 13, 2021&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Container Networking</title>
      
      <link>/guides/kubernetes/container-networking/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/container-networking/</guid>
      <description>

        
        &lt;p&gt;Kubernetes uses the &lt;a href=&#34;https://github.com/containernetworking/cni&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Container Network
Interface&lt;/a&gt; (CNI) to provide
networking functionality to containers. Networking is implemented in CNI
plugins. The interface / plugin model enables Kubernetes to support many
networking options implemented via plugins such as Calico, Antrea, and Cilium.&lt;/p&gt;
&lt;p&gt;Anyone may write a CNI-plugin. The expectation is the plugin will support
specific operations defined in the specification (e.g.
&lt;a href=&#34;https://github.com/containernetworking/cni/blob/spec-v0.4.0/SPEC.md#parameters&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;0.4.0&lt;/a&gt;).
These operations include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ADD&lt;/code&gt;: Add a container to the network.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DEL&lt;/code&gt;: Delete a container from the network.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CHECK&lt;/code&gt;: Check whether the container&amp;rsquo;s network is as expected.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CNI Plugins are often only concerned with container to container networking.
Kubernetes constructs such as
&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;services&lt;/a&gt; are
still handled by kube-proxy. This means selecting a target pod for a service may
still happen via IPtables (round-robin) on the host. Once the target pod is
selected, the networking facilitated by the CNI plugin will pick up from there.
Some plugins replace kube-proxy for their own alternative implementation.
&lt;a href=&#34;https://cilium.io/blog/2019/08/20/cilium-16&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cilium&lt;/a&gt;, for example, has replaced
kube-proxy for an implementation using
&lt;a href=&#34;https://en.wikipedia.org/wiki/Berkeley_Packet_Filter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;BPF&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Enforcement of &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;network
policy&lt;/a&gt;
is contingent on your choice of plugin. Some plugins, such as
&lt;a href=&#34;https://github.com/coreos/flannel&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Flannel&lt;/a&gt;, do not enforce policy at all. This
means that adding network policy objects to your cluster will have no impact.
Most plugins, however, do enforce policy. Policy can be set for both ingress
traffic to pods and egress traffic from pods. Kubernetes has a policy API that
plugins may choose to respect. Some plugins, such as
&lt;a href=&#34;https://docs.projectcalico.org/v3.11/reference/resources/networkpolicy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Calico&lt;/a&gt;
and &lt;a href=&#34;https://docs.cilium.io/en/v1.6/kubernetes/policy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cilium&lt;/a&gt; offer extended
APIs through Custom Resource Definitions (CRDs) that provide additional
functionality. Kubernetes network policy is namespace scoped with no ability to
apply cluster-wide policy. The only CNI-plugin that offers cluster-level policy
is Calico&amp;rsquo;s
&lt;a href=&#34;https://docs.projectcalico.org/v3.11/reference/resources/globalnetworkpolicy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;GlobalNetworkPolicy&lt;/a&gt;
CRD.&lt;/p&gt;
&lt;p&gt;Choosing a CNI Plugin comes down to your network topology, desired container
networking features, and understanding of different routing protocols. Plugins
that can be used in Kubernetes have all sorts of routing features such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BGP for route sharing&lt;/li&gt;
&lt;li&gt;Tunneling protocols (VXLAN, GRE, IP-in-IP, and more)&lt;/li&gt;
&lt;li&gt;Native routing (no encapsulation)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;popular-tooling-and-approaches&#34;&gt;Popular Tooling and Approaches&lt;/h2&gt;
&lt;h3 id=&#34;calico&#34;&gt;Calico&lt;/h3&gt;
&lt;p&gt;Calico has been one of the predominant CNI-plugins since Kubernetes became
popular. It supports a variety of routing modes including IP-in-IP, VXLAN, and
Native (non-encapsulated). It even supports versatile routing options such as
only encapsulating when crossing subnet boundaries. With Calico&amp;rsquo;s native-routing
abilities, it does not need to incur encapsulation overhead. This means Calico
can achieve near native network speeds.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Border_Gateway_Protocol&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;BGP&lt;/a&gt; is used to
distribute routes when running in IP-in-IP or native routing modes. BGP is a
well known route sharing protocol that many enterprise networks are capable of
peering with. This enables enterprises to integrate pod networks into their
networking fabric, making pods routable. This capability unlocks a multitude of
network topologies.&lt;/p&gt;
&lt;p&gt;Network Policy support in Calico is arguably the strongest of all CNI plugins.
Historically, the work Calico did with network policy influenced Kubernetes
adoption of those constructs. For example, Calico implemented egress policy
before the Kubernetes project did. Along with full support for Kubernetes
network policy, Calico offers its own
&lt;a href=&#34;https://docs.projectcalico.org/v3.11/reference/resources/networkpolicy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;NetworkPolicy&lt;/a&gt;
and
&lt;a href=&#34;https://docs.projectcalico.org/v3.11/reference/resources/globalnetworkpolicy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;GlobalNetworkPolicy&lt;/a&gt;
CRDs. These network policies offer advanced features. The global policy enables
administrators to apply cluster-wide policies. Calico also supports mixing both
Kubernetes native policies and its own CRDs.&lt;/p&gt;
&lt;p&gt;Calico is the most common CNI-plugin we have seen in deployments. Tigera, the
creators of Calico, offer extended enterprise features and support. Additionally
VMware offers break-fix Calico support for those with the appropriate support
subscription. With the above in mind, Calico is generally our first choice for
CNI-plugin.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Diverse routing mode support.
&lt;ul&gt;
&lt;li&gt;IP-in-IP&lt;/li&gt;
&lt;li&gt;Native&lt;/li&gt;
&lt;li&gt;VXLAN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Integrates with the Kubernetes API server.
&lt;ul&gt;
&lt;li&gt;No direct etcd access required.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Native routing incurs minimal overhead.
&lt;ul&gt;
&lt;li&gt;Supports cross-subnet only encapsulation.&lt;/li&gt;
&lt;li&gt;Uses native routing for all intra-subnet routing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BGP route sharing enables advanced topologies.&lt;/li&gt;
&lt;li&gt;Most capable network policy support.
&lt;ul&gt;
&lt;li&gt;Includes Calico-specific GlobalNetworkPolicy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Break-fix support offered by VMware.&lt;/li&gt;
&lt;li&gt;External data store not required
&lt;ul&gt;
&lt;li&gt;Uses Kubernetes API.&lt;/li&gt;
&lt;li&gt;Scales with &lt;a href=&#34;https://github.com/projectcalico/typha&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;typha&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BGP might not be possible in your environment
&lt;ul&gt;
&lt;li&gt;If so, Calico&amp;rsquo;s VXLAN mode does not use BGP.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;antrea&#34;&gt;Antrea&lt;/h3&gt;
&lt;p&gt;Antrea provides container networking based on Open vSwitch. Using Open vSwitch,
Antrea is capable of offering routing via VXLAN, Geneve, GRE, or STT
encapsulation methods. Unlike Calico, Antrea can enforce networking rules inside
Open vSwitch, which should provide more performant policy enforcement relative
to IPtables.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/antrea.png&#34; alt=&#34;Antrea&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Those familiar with Open vSwitch are likely to find Antrea a very compelling
option. Since Antrea is still in pre-release, we don&amp;rsquo;t recommend it for
production use cases at this time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support many encapsulation protocols.
&lt;ul&gt;
&lt;li&gt;VXLAN&lt;/li&gt;
&lt;li&gt;Geneve&lt;/li&gt;
&lt;li&gt;GRE&lt;/li&gt;
&lt;li&gt;STT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Familiar to users of Open vSwitch.&lt;/li&gt;
&lt;li&gt;Performant network policy enforcement.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/vmware-tanzu/octant&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Octant&lt;/a&gt; UI support.&lt;/li&gt;
&lt;li&gt;Break-fix support from VMware.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Must have Open vSwitch kernel module.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;nsx-t&#34;&gt;NSX-T&lt;/h3&gt;
&lt;p&gt;NSX-T is an extremely capable network virtualization technology. It is used to
facilitate networking in datacenters around the world. As such, it is very
uncommon to see the NSX-T CNI plugin used unless an existing NSX-T deployment
exists. Introducing a net new NSX-T deployment for a Kubernetes platform
introduces a lot of operational overhead. It is also common for teams running
Kubernetes on top of vSphere + NSX-T to run a different CNI-plugin (such as
Calico or Flannel) on top of it.&lt;/p&gt;
&lt;p&gt;With this in mind, we only recommend considering the NSX-T CNI plugin if there
is an existing NSX-T deployment and a strong desire to integrate container
networking with it directly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NSX-T is familiar to many VI Admins.&lt;/li&gt;
&lt;li&gt;NSX-T makes container networking feel more like normal VM networking.
&lt;ul&gt;
&lt;li&gt;e.g. Namespaces are assigned their own subnets.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Architecting, Deploying, and Operating NSX-T is a non-trivial task.
&lt;ul&gt;
&lt;li&gt;It can be overkill for just container networking.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Unlike most plugins, you&amp;rsquo;re not running the pod network on top of another.
&lt;ul&gt;
&lt;li&gt;You&amp;rsquo;re instead using the existing network to run the pod network.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cilium&#34;&gt;Cilium&lt;/h3&gt;
&lt;p&gt;Cilium is a powerful CNI-plugin that uses
&lt;a href=&#34;https://en.wikipedia.org/wiki/Berkeley_Packet_Filter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;BPF&lt;/a&gt; to make routing
decisions in a highly performant manner. Cilium has replaced kube-proxy, which
facilitates services, for it&amp;rsquo;s own eBPF implementation. This makes service
routing decisions O(1) rather than the time complexity it takes to traverse many
IPtables chain rules.&lt;/p&gt;
&lt;p&gt;Cilium&amp;rsquo;s network policy enforcement also uses BPF. Calico leverages IPtables,
which can have its own scalability issues and troubleshooting complexity.
Overall, Cilium appears to be a very promising CNI in the Kubernetes ecosystem.&lt;/p&gt;
&lt;p&gt;Cilium is new to the ecosystem and does not have as many production stories as
we&amp;rsquo;d expect before recommending it. It may be worth considering for lab
environments, depending on your tolerance for risk and comfort with BPF, or
you may want to hold off a little longer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BPF enables extremely fast routing decisions.
&lt;ul&gt;
&lt;li&gt;Services&lt;/li&gt;
&lt;li&gt;Network Policy&lt;/li&gt;
&lt;li&gt;Routing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Community support and enthusiasm is growing.
&lt;ul&gt;
&lt;li&gt;Likely to become a predominant CNI-plugin.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Need to ensure BPF kernel support.
&lt;ul&gt;
&lt;li&gt;Sometimes not possible in highly regulated environments.&lt;/li&gt;
&lt;li&gt;Especially with older versions of RHEL.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;You cannot mix Cilium network policy with Kubernetes network policy.&lt;/li&gt;
&lt;li&gt;Newer player in the ecosystem, still experiencing paper cuts.
&lt;ul&gt;
&lt;li&gt;CRD-based backend not scalable yet.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Developer Workflow</title>
      
      <link>/guides/kubernetes/dev-workflow/</link>
      <pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/dev-workflow/</guid>
      <description>

        
        &lt;p&gt;The developer workflow typically involves writing code, executing automated
tests, building the application, and running the app locally. In most cases,
developers repeat these steps throughout the day, creating a development cycle.
The efficiency of the development cycle has a direct impact on the time it takes
development teams to ship new features and fix bugs. For this reason, minimizing
the time it takes to iterate through the cycle is desirable.&lt;/p&gt;
&lt;p&gt;In the context of the development workflow, Kubernetes only impacts the final
steps of the cycle, which involve running the application. Depending on the
complexity of the application, developers might choose to run it in a
development Kubernetes cluster that mimics a production environment. In doing
so, developers leverage Kubernetes deployment manifests to deploy their
application alongside its dependencies, such as other services, databases, and
message queues.&lt;/p&gt;
&lt;p&gt;The ability to deploy and test applications in a production-like environment is
one of the most significant benefits of including Kubernetes in the development
cycle. Without appropriate processes and tooling, however, Kubernetes could
hinder developers&#39; efficiency, as they would need to add new steps to their
cycle. (Steps such as building container images and running kubectl commands to
deploy new containers).&lt;/p&gt;
&lt;h2 id=&#34;application-development-cycle-on-kubernetes&#34;&gt;Application Development Cycle on Kubernetes&lt;/h2&gt;
&lt;p&gt;For simple projects it is preferable to keep Kubernetes out of a developer&amp;rsquo;s
workflow. As a starting point, a development cycle might involve changing code
and rerunning an executable on one&amp;rsquo;s local machine. Containers usually enter the
development process as a means of easily running dependencies with pinned
versions (for example a SQL database). As the application grows and multiple
containers are needed, it becomes useful to codify the development environment.&lt;/p&gt;
&lt;p&gt;As more services are introduced it becomes increasingly attractive to favor
Kubernetes API manifests as the means of specifying a development environment.
This allows the developer to reuse &lt;code&gt;deployment.yaml&lt;/code&gt; files which are often
already in place in production environments. At this point there is a high level
of parity between development, staging, and production environments. However, a
new challenge arises: how does the developer efficiently update the application
running on their development cluster every time the code is updated?&lt;/p&gt;
&lt;p&gt;The Kubernetes community and the broader Cloud Native ecosystem offers a variety
of tools that improve the development workflow. Each tool attempts to solve one
of these problems: 1) Running Kubernetes in the developer&amp;rsquo;s local environment,
and 2) Continuously building, pushing, and deploying containers as the developer
changes source code.&lt;/p&gt;
&lt;h2 id=&#34;local-vs-remote-cluster&#34;&gt;Local vs Remote Cluster&lt;/h2&gt;
&lt;p&gt;An organization will eventually need to provide a cluster for
sandbox/development workloads for teams of developers. There are an array of
tools and strategies to provide a cluster for development workloads, but the
first question often asked is &amp;ldquo;Where should my developer&amp;rsquo;s develop?&amp;rdquo; As
organizations move towards a cloud native model, the journey often starts with
simple local development machines and matures towards multi-cluster development
environments hosted on-prem or with a cloud provider.&lt;/p&gt;
&lt;p&gt;The following tools provide developers with a local Kubernetes environment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kind.sigs.k8s.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kind&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-minikube/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Minikube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.docker.com/products/docker-desktop&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Docker Desktop&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As the development model matures, on-prem or hosted clusters are used together
with CI/CD tooling to standardize environments and workflows.&lt;/p&gt;
&lt;h2 id=&#34;kubeconfig--multiple-clusters&#34;&gt;Kubeconfig &amp;amp; Multiple Clusters&lt;/h2&gt;
&lt;p&gt;As more clusters are created for teams, projects, or production environments, it
is important to efficiently manage configurations and navigate between clusters.
Your &lt;code&gt;$HOME/.kube/config&lt;/code&gt; file, known as the &lt;code&gt;kubeconfig&lt;/code&gt;, is used to organize
information about clusters, credentials, and namespaces. Below are some common
commands to navigate contexts.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;kubectl config view &lt;span class=&#34;c1&#34;&gt;# Show Merged kubeconfig settings.&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# use multiple kubeconfig files at the same time and view merged config&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;KUBECONFIG&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;~/.kube/config:~/.kube/kubconfig2


kubectl config get-contexts                &lt;span class=&#34;c1&#34;&gt;# display list of contexts&lt;/span&gt;
kubectl config current-context             &lt;span class=&#34;c1&#34;&gt;# display the current-context&lt;/span&gt;
kubectl config use-context my-cluster-name &lt;span class=&#34;c1&#34;&gt;# set the default context to my-cluster-name&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# permanently save the namespace for all subsequent kubectl commands in that context.&lt;/span&gt;
kubectl config set-context --current --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;ggckad-s2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Additionally, useful tooling such as
&lt;a href=&#34;https://github.com/ahmetb/kubectx&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubectx&lt;/a&gt; can help developers navigate
between contexts.&lt;/p&gt;
&lt;h2 id=&#34;popular-tooling--approaches&#34;&gt;Popular Tooling &amp;amp; Approaches&lt;/h2&gt;
&lt;h3 id=&#34;skaffold&#34;&gt;Skaffold&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleContainerTools/skaffold&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Skaffold&lt;/a&gt; is a project from Google that bundles multiple steps (build, tag, test, deploy) into a single command.
The tool can watch for changes and re-run the steps as needed.
Skaffold is configurable with pluggable integrations for each step.
It also assists with debugging by aggregating and tailing logs.
In addition to aiding development workflows, Skaffold can also serve double duty as the basis for executing CI/CD pipelines.&lt;/p&gt;
&lt;h3 id=&#34;tilt&#34;&gt;Tilt&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/windmilleng/tilt&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Tilt&lt;/a&gt; is a CLI+GUI project backed by a startup (Windmill Engineering).
Like Skaffold, Tilt supports pluggable templating solutions (Helm, Kustomize, etc).
However, unlike other tools which only present the developer with aggregated logs, Tilt also shows a summarized view of all their running applications.
This is done by displaying a web view of each application, or showing a high-level status for each service (success/error).
The Tilt team also provides a method of sharing snapshots of one&amp;rsquo;s development environment with teammates via TiltCloud.&lt;/p&gt;
&lt;p&gt;Tilt is able to speed up build processes by avoiding in-container builds during development through copying source files (and injecting restart scripts).
This process is more seamless for interpreted languages than for compiled languages where more workarounds are needed.&lt;/p&gt;
&lt;p&gt;Tilt represents a step forward in development workflow tools because it focuses on optimizing feedback loops within a Developer&amp;rsquo;s own environment as well as across a team.
However, Tilt is still an early stage project and the direction of the startup behind the project is not yet clear.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Identity and Access Control</title>
      
      <link>/guides/kubernetes/identity/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/identity/</guid>
      <description>

        
        &lt;p&gt;In order to deploy Kubernetes securely you need to implement the principle of
least privilege. What this means is that you will allow users to take actions
against the cluster (e.g. create Pods, Services, etc.), but you will ensure that
any privileges that you extend to a user will be constrained to include only
those that are necessary to fulfill the user&amp;rsquo;s needs, and nothing more.&lt;/p&gt;
&lt;p&gt;To ensure that users only have what they need, you will need to know about who
our users are. You will need to both authenticate their credentials, and then
once you have, you will need to ensure that they are allowed to perform the
actions they have requested. Similarly, you will want to be sure that you always
have a consistent view of this user data. This consistent view will ensure that
as users come and go, you always grant them only the access they are entitled
to.&lt;/p&gt;
&lt;p&gt;Many newcomers to Kubernetes are sometimes surprised to learn that Kubernetes
does not have a User resource type. Unlike other platforms in the distributed
computing space, Kubernetes deliberately seeks to offload this functionality
onto other systems.&lt;/p&gt;
&lt;p&gt;While Kubernetes does provide some primitive user management capabilities in the
form of Service Accounts, a production deployment should leverage an
organization-wide user identity store. Often times an organization will have a
common LDAP, Active Directory, or Open ID Connect (OIDC) infrastructure that is
leveraged across its environments. Kubernetes is capable of integrating
(directly or indirectly) with these systems, and doing so will provide that
common user identity integration that you are looking for. When a user leaves
the organization, their access is revoked from this common identity store, and
Kubernetes will in-turn revoke their access to the cluster.&lt;/p&gt;
&lt;h2 id=&#34;open-identity-connect-oidc&#34;&gt;Open Identity Connect (OIDC)&lt;/h2&gt;
&lt;p&gt;If you have examined the Kubernetes documentation, you will notice that there
are quite a few options for integrating user identity systems, but that the only
standard protocol-based configuration involves OIDC.&lt;/p&gt;
&lt;p&gt;With OIDC, a user will authenticate with the identity store, and upon successful
login, will obtain a JSON Web Token (JWT). This token will be presented as a
base64 string, but when decoded, it contains human-readable metadata about the
user. Some of this data may include the username, token issue time, token
expiration time, and most importantly, a field that provides what OIDC calls
&amp;ldquo;claims.&amp;rdquo; These claims are typically an array of strings that indicate which
user groups this user should have access to. These groups will eventually be
mapped to Roles and ClusterRoles for the implementation of Kubernetes RBAC
rules.&lt;/p&gt;
&lt;p&gt;Note that the Kubernetes API server may be configured to specify both a user
claim and a group claim. These fields would correspond to attributes within the
token.&lt;/p&gt;
&lt;p&gt;A sample JWT may look like the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;iss&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;https://auth.example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;sub&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Ch5hdXRoMHwMTYzOTgzZTdjN2EyNWQxMDViNjESBWF1N2Q2&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;aud&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;dDblg7xO7dks1uG6Op976jC7TjUZDCDz&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;exp&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1517266346&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;iat&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1517179946&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;at_hash&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;OjgZQ0vauibNVcXP52CtoQ&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;username&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;marysmith&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;email&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;marysmith@example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;email_verified&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;groups&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;qa&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;infrastructure&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this example, you would configure the API server to use the &amp;ldquo;username&amp;rdquo;
attribute as the username claim field and the &amp;ldquo;groups&amp;rdquo; attribute as the groups
claim. When developing RBAC rules, you will now be able to utilize these claims
as subjects for RoleBinding and ClusterRoleBinding resources:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;RoleBinding&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;web-rw-deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;some-web-app-ns&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;roleRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Role&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;web-rw-deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subjects&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;User&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;marysmith&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;or&amp;hellip;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterRoleBinding&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;web-infra&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;roleRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Role&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;web-infra&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subjects&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;infrastructure&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;What about other protocols?&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;There are no direct LDAP or Active Directory integrations, but it is possible to
integrate these systems with tools that will act as identity brokers.&lt;/p&gt;
&lt;p&gt;One very common tool for brokering various identity backends is
&lt;a href=&#34;https://github.com/dexidp/dex&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Dex&lt;/a&gt;. This service, deployed in-cluster, will
allow us to connect various backends, such as LDAP, SAML, Active Directory, and
similar to an OIDC front-end. Kubernetes may then be configured to utilize Dex
as its identity source.&lt;/p&gt;
&lt;p&gt;This project was developed by CoreOS, and is currently being proposed for
donation to the Cloud Native Computing Foundation.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Once a user has authenticated against their identity store, they will receive a
JWT. The user then adds this token to their kubeconfig, and all subsequent
client requests will include this bearer token in the request&amp;rsquo;s Authorization
header. The Kubernetes API server uses this token to identify and authorize the
user.&lt;/p&gt;
&lt;p&gt;This flow can be complex, however, there are tools that will make this process
straightforward. &lt;a href=&#34;https://github.com/heptiolabs/gangway&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;gangway&lt;/a&gt; is such a
tool, and it will provide an end user with all of the steps necessary to
integrate with an OIDC identity provider in a self-service fashion.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/identity/gangway.png&#34; alt=&#34;Gangway&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;It should be noted that JWT tokens are not able to be revoked, but are also
time-bound. This expiration time is embedded in the token itself, and is
immutable. The identity server may scope this token for as long as it would
like, but remember that the token will be valid until it is expired. So, be sure
to choose a scope that makes sense - an hour is typically sufficient.&lt;/p&gt;
&lt;p&gt;In addition to the access JWT token, the OIDC specification also calls for an
optional refresh token as well. If your identity server supports refresh tokens,
these may be exchanged for a new access token upon expiration. This
functionality makes it possible for a user to continually get new time-scoped
access tokens seamlessly.&lt;/p&gt;
&lt;h2 id=&#34;other-means&#34;&gt;Other Means&lt;/h2&gt;
&lt;p&gt;While OIDC is the preferred integration protocol for identity and access
control, there are scenarios where, despite the availability of OIDC brokering
tools, this is still not possible. Fortunately, Kubernetes affords a number of
alternative means of identity and access control. Each of these, while capable,
may have drawbacks that make it a less favorable approach.&lt;/p&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Why choose one?&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Identity in Kubernetes is not mutually exclusive. It allows for multiple
identity configurations simultaneously. While you are not likely in a scenario
where it will be hard to choose the best integration, you will want to consider
this feature in order to facilitate cluster operations. If you encounter a
scenario where an external user identity system were to become unavailable,
having alternate means of authentication is a great tool to have in order to
effect change during an incident.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Let&amp;rsquo;s take a brief look at some of the other integrations.&lt;/p&gt;
&lt;h3 id=&#34;x509-certificates&#34;&gt;X.509 Certificates&lt;/h3&gt;
&lt;p&gt;Kubernetes, when properly configured, leverages TLS to secure communication
throughout the cluster. All control plane surfaces utilize the encryption
features of TLS to encrypt all over-the-wire communication, but perhaps just as
importantly, they utilize the identity aspects of TLS to ensure that only the
clients that we have authorized will be able to communicate with each other.&lt;/p&gt;
&lt;p&gt;Just as we can utilize these X.509 certificates to secure service-to-service
communication, we can use these certificates to secure and identify users as
well. In order to do so, we will need to generate an X.509 certificate signing
request that will then be signed against a certificate authority common to the
Kubernetes API server. This is a multi-step process that is outside the scope of
this documentation, but instructions may be found in the &lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/certificates/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes
documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With X.509 certificates we may specify the username and groups that a user is a
member of by manipulating the standard fields of the cert.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;openssl req -new -key marysmith.pem -out marysmith-csr.pem -subj &amp;quot;/CN=marysmith/O=group1/O=group2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The Common Name field is used to indicate the username of the identity, and we
add the user to user groups by way of the Organization fields. Just as with the
OIDC case, these fields may be used in RBAC RoleBinding and ClusterRoleBindings.&lt;/p&gt;
&lt;p&gt;X.509 certificates can be very difficult to work with in a practical way. First,
many users are often confused by the steps required to generate a certificate.
And this confusion often leads to reluctance when it comes to proper issuance of
credentials to new users and/or the reissuance in the case of compromise. In
fact, a common pattern that we have encountered in-the-wild has been for
certificates with broad privileges (e.g. cluster-admin) to be shared among many
users. This not only severely compromises security, but also limits your ability
to leverage features like audit logging.&lt;/p&gt;
&lt;p&gt;Secondarily, these certificates must be signed against a common certificate
authority. In the best of scenarios, users will have a certificate authority
that may be used across the organization. But, in most cases, these certificates
are dedicated to the cluster itself. This will require new certificates for each
cluster a user interacts with.&lt;/p&gt;
&lt;p&gt;Finally, and perhaps most problematic, is the fact that x.509 certificates are
note able to be revoked easily. The certificate will be valid until the
certificate expires or the server certificate has been rotated.&lt;/p&gt;
&lt;p&gt;In short, the user experience with certificates is not great. And, poor user
experiences within the realm of security often leads to users circumventing
processes meant to secure all users. So, for general-purpose needs, we do not
recommend this approach.&lt;/p&gt;
&lt;p&gt;With this said, however, X.509 certificates can be a very good option for &amp;ldquo;break
glass&amp;rdquo; access. As these certificates do not require any runtime infrastructure
they may be readily used in the event that other authentication means are
unexpectedly unavailable. Operations teams should ensure that these keys are
only used for remediation.&lt;/p&gt;
&lt;h3 id=&#34;webhooks&#34;&gt;Webhooks&lt;/h3&gt;
&lt;p&gt;Kubernetes also supports a generic mechanism for authentication by way of
webhooks. In this scenario, you may configure the API server to POST webhooks to
a service that will respond with the appropriate HTTP responses. These POSTs
will issue the Kubernetes TokenReview resource type to the authenticating
service. This type includes an attribute for the bearer token associated with
the request that is attempting to authenticate.&lt;/p&gt;
&lt;p&gt;The authenticating webhook service will simply update the TokenReview object
with an &lt;code&gt;authenticated&lt;/code&gt; boolean field, and return it to the calling Kubernetes
API service. In the case of &lt;code&gt;authenticated: true&lt;/code&gt;, the webhook will also provide
detail about the user; username, groups, etc.&lt;/p&gt;
&lt;p&gt;While this mechanism may be used in cases where there are no other viable
methods, we strongly discourage this type of integration. First, any
introduction of a downstream webhook into the regular API request flow will
introduce latencies. Secondly, this is now a (yet another) service that must be
maintained by those who are operating the Kubernetes platform, and this type of
work, while seemingly innocuous, can be non-trivial.&lt;/p&gt;
&lt;p&gt;This should only be used when no other options exist.&lt;/p&gt;
&lt;h3 id=&#34;static-tokens-and-basic-authentication&#34;&gt;Static Tokens and Basic Authentication&lt;/h3&gt;
&lt;p&gt;And, finally, Kubernetes offers some mechanisms to provide the Kubernetes API
server with pointers to files that contain either static tokens and/or basic
authentication credentials. These files must exist on a disk local to the API
server and are neither secure nor scalable. These should be avoided at all cost.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Challenges Managing Multiple Clusters Across Multiple Clouds</title>
      
      <link>/guides/kubernetes/multi-cloud-multi-cluster-management/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/multi-cloud-multi-cluster-management/</guid>
      <description>

        
        &lt;p&gt;While Kubernetes provides a rich and capable environment for modern applications, it introduces a lot of moving parts and day 2 operating issues. How do you create and enforce security policy in a highly fluid environment? How do you make sure that your identity and access control systems are configured? How do you make certain that everything stays properly configured?&lt;/p&gt;
&lt;p&gt;These challenges are hard enough to get right in a single Kubernetes cluster, but we don’t live in a world of single Kubernetes clusters. In the marketplace of ideas, multi-cluster has won. Rather than creating one giant Kubernetes cluster for everyone to share, there’s a clear need to have many small clusters. It makes sense from a security perspective, and can improve resilience and stability, as well. But that brings with it new management challenges.&lt;/p&gt;
&lt;h2 id=&#34;taming-multi-cluster-management&#34;&gt;Taming Multi-Cluster Management&lt;/h2&gt;
&lt;p&gt;While many cloud providers offer managed Kubernetes services, the control planes for these services only work for a particular provider. Several vendors are working to address the issue of multi-cloud cluster management with solutions to unify and simplify cross-cloud management in public clouds and on premises.&lt;/p&gt;
&lt;p&gt;For example, VMware &lt;a href=&#34;https://tanzu.vmware.com/content/tanzu-mission-control/introducing-vmware-tanzu-mission-control-to-bring-order-to-cluster-chaos&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;introduced Tanzu Mission Control&lt;/a&gt; in 2019 to allow operators to apply policy to individual clusters or groups of clusters and establish guardrails, freeing developers to work more freely within defined boundaries. Under the covers, VMware Tanzu Mission Control leverages &lt;a href=&#34;https://github.com/kubernetes-sigs/cluster-api&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cluster API&lt;/a&gt; for lifecycle management.&lt;/p&gt;
&lt;h2 id=&#34;introducing-cluster-api&#34;&gt;Introducing Cluster API&lt;/h2&gt;
&lt;p&gt;The Cluster API is an open-source, cross-vendor effort to simplify cluster lifecycle management. It’s a member of a set of tools and emerging projects that help create/curate/update base virtual machine images, tackling the problem in a Kubernetes-native way, bringing control and consistency across clouds or on-premises, on virtualized or bare metal infrastructure.&lt;/p&gt;
&lt;p&gt;Extensibility is important and a diverse provider universe already exists. You’ll find provider implementations for a host of clouds, including AWS, Microsoft Azure, Baidu Cloud, Digital Ocean, Google Cloud Platform, IBM Cloud, vSphere, Packet, and more.&lt;/p&gt;
&lt;p&gt;VMware is investing heavily in the Cluster API effort, including baking a supervisor cluster into &lt;a href=&#34;https://tanzu.vmware.com/content/blog/vsphere-7-and-tanzu-kubernetes-grid-powerful-platform-for-architecting-modern-apps&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;vSphere 7&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;keep-learning&#34;&gt;Keep Learning&lt;/h2&gt;
&lt;p&gt;If you want to learn more about Cluster API or get started using it, &lt;a href=&#34;https://cluster-api.sigs.k8s.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;The Cluster API Book&lt;/a&gt; provides a deep dive that will help you get started.&lt;/p&gt;
&lt;p&gt;Two recent Tanzu blogs, &lt;a href=&#34;https://tanzu.vmware.com/content/blog/cluster-api-is-a-big-deal-joe-beda-craig-mcluckie-tell-you-why&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cluster API is a Big Deal&lt;/a&gt; and &lt;a href=&#34;https://tanzu.vmware.com/content/blog/cluster-api-provider-for-azure-is-another-giant-leap-for-the-community&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cluster API Provider for Azure&lt;/a&gt; provide more context to help you understand what’s happening in multi-cloud, multi-cluster management.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Packaging</title>
      
      <link>/guides/kubernetes/packaging/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/packaging/</guid>
      <description>

        
        &lt;p&gt;In Kubernetes, the desired state of the system is declared via resources sent to the API Server.
Resources are stored as JSON or YAML files called &lt;em&gt;manifests&lt;/em&gt;.
The management of manifests can be cumbersome but there are many tools which can help.
To inform tooling choices it is helpful to define the nature of the problems commonly encountered and identify the approaches that each tool takes to address them.&lt;/p&gt;
&lt;h2 id=&#34;challenges&#34;&gt;Challenges&lt;/h2&gt;
&lt;h3 id=&#34;value-duplication&#34;&gt;Value Duplication&lt;/h3&gt;
&lt;p&gt;Managing manifests as flat data files (YAML) violates the &lt;a href=&#34;https://en.wikipedia.org/wiki/Don%27t_repeat_yourself&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;DRY principle&lt;/a&gt;.
For example, a service port defined in one resource needs to be defined in multiple other resources.&lt;/p&gt;
&lt;h3 id=&#34;resource-duplication&#34;&gt;Resource Duplication&lt;/h3&gt;
&lt;p&gt;Resource variants must be accounted for.
The number of environments manifests are applied to may be bounded (dev, stage, prod) or unbounded (per developer).
Manifests may be defined inside of an organization (SaaS app) or by a third party (Wordpress).&lt;/p&gt;
&lt;h4 id=&#34;differences-in-application-configuration&#34;&gt;Differences in Application Configuration&lt;/h4&gt;
&lt;p&gt;A. Logging level as defined by env variable &lt;code&gt;LOG_LEVEL&lt;/code&gt; (staging: Debug / production: Info)&lt;/p&gt;
&lt;p&gt;B. Access token for accessing an external API located at &lt;code&gt;/secrets/credentials.json&lt;/code&gt; (staging/prod access separate accounts)&lt;/p&gt;
&lt;p&gt;Kubernetes accounts for these differences via resource references.
Maintaining and applying different ConfigMap and Secret manifests for each environment allows for a common Deployment definition to be used across environments.&lt;/p&gt;
&lt;h4 id=&#34;differences-in-application-operation&#34;&gt;Differences in Application Operation&lt;/h4&gt;
&lt;p&gt;Example: Deployment replica count (staging: 3 / production: 12)&lt;/p&gt;
&lt;p&gt;These types of differences cannot be accounted for by native resource references.&lt;/p&gt;
&lt;h2 id=&#34;techniques&#34;&gt;Techniques&lt;/h2&gt;
&lt;h3 id=&#34;1-configuration-language&#34;&gt;1. Configuration Language&lt;/h3&gt;
&lt;h4 id=&#34;1a-variable-substitution&#34;&gt;1.A. Variable Substitution&lt;/h4&gt;
&lt;p&gt;Value duplication can be solved by elevating the level of abstraction at which resources are specified: using a language in place of data files.
A configuration language can be as simple as an interpolator or it can expose features such as expressions (&lt;code&gt;appName + &amp;quot;:&amp;quot; + appPort&lt;/code&gt;) and conditionals (&lt;code&gt;if appPort != &amp;quot;80&amp;quot;&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Some languages suffer from readability issues through introducing interpolation symbols (for example: &lt;code&gt;foo: {{ .myBarVar }}&lt;/code&gt; vs &lt;code&gt;foo: bar&lt;/code&gt;).
Language features also bring complexity and complexity brings bugs.
Both of these issues are more prominent in languages that lack support for the underlying data structures and formats.
Generic text templating languages fall into this category.
On the opposite end of the spectrum, languages that output structured data can help avoid bugs through data validation.&lt;/p&gt;
&lt;h4 id=&#34;1b-parameterization&#34;&gt;1.B. Parameterization&lt;/h4&gt;
&lt;p&gt;Most configuration languages allow for grouping manifests into modules.
Resource variants are accounted for by exposing module input parameters.
Any value that needs to vary across environments is exposed outside of the module.&lt;/p&gt;
&lt;p&gt;The pitfall of this approach is that encapsulation tends to break down over time.
As the use-cases increase, the number of exposed parameter trends towards the total of the configurable options in the underlying resources.&lt;/p&gt;
&lt;p&gt;You end up with an API contract that is defined by your module.
This is different from (and not as well documented) as the API of the underlying resources that live in your module, yet similar in surface-area after enough time has passed.&lt;/p&gt;
&lt;h3 id=&#34;2-patching&#34;&gt;2. Patching&lt;/h3&gt;
&lt;p&gt;Some tools allow for patches (partial resource definitions) to be applied to resources before they are sent to the API Server.
Patches are defined as YAML manifests that contain enough information to identify the resource they are intended to patch (for instance: &lt;code&gt;kind&lt;/code&gt;, &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;namespace&lt;/code&gt;) as well as target fields they are going to update/insert (for example: &lt;code&gt;replicas&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;While useful, patches introduce a layer of complexity.
Looking at a single file no longer represents the full resource that will be applied.
In addition, ordering must be accounted for: applying patch A before B can result in a different outcome as applying B before A.&lt;/p&gt;
&lt;h3 id=&#34;3-branching&#34;&gt;3. Branching&lt;/h3&gt;
&lt;p&gt;It is best practice to store manifests in version control.
Tools like git can be used to maintain branches for each environment.
This allows for native VCS tools to be used for viewing diffs across environments.
Pull Requests targeting separate branches, as opposed to separate directories can be utilized as a means of promoting changes across environments.&lt;/p&gt;
&lt;h3 id=&#34;4-convention&#34;&gt;4. Convention&lt;/h3&gt;
&lt;p&gt;Favoring convention over configuration can help mitigate repeated values.
Establishing conventions for standard ports (for example: 80 or 443 for REST APIs) can reduce required configuration as most libraries default to these values.
This can be done by taking advantage of the IP-per-pod networking model, where every pod gets a unique IP so port conflict concerns are a non-issue.
In addition, utilizing namespaces in lieu of prefixing/suffixing names (&lt;code&gt;namespace: staging, name: my-app&lt;/code&gt; as opposed to &lt;code&gt;name: my-app-staging&lt;/code&gt;) can help with keeping resource references constant.&lt;/p&gt;
&lt;h2 id=&#34;popular-tooling--approaches&#34;&gt;Popular Tooling &amp;amp; Approaches&lt;/h2&gt;
&lt;h3 id=&#34;helm&#34;&gt;Helm&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://helm.sh/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Helm&lt;/a&gt; is the dominant player in the world of Kubernetes
templating. Helm manifests are organized into modules called &lt;em&gt;charts&lt;/em&gt;. Charts
expose parameters that can be used to customize deployments. Customization of
the underlying resources is accomplished by using Golang text templates as a
DSL. Helm also incorporates the concept of a package registry to facilitate easy
consumption of third-party charts. It&amp;rsquo;s recommended to avoid the use of Helm for
managing internal projects (a business specific API, a website deployment, etc).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Large ecosystem of charts&lt;/li&gt;
&lt;li&gt;Third-party software is usually available via Helm charts
(a message queue, a database, etc)&lt;/li&gt;
&lt;li&gt;Deploying applications and their associated objects is done in one command&lt;/li&gt;
&lt;li&gt;Parameterizing values makes it easier to adjust configurations per environment
(a values file for dev, test, prod)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Charts trend towards becoming a 1:1 mapping of parameters into Kubernetes
resource definition fields&lt;/li&gt;
&lt;li&gt;Instead of configuring a well-documented Kubernetes API resource, users end up
configuring a less well known and under-documented helm chart API (as in the
exposed chart input parameters).&lt;/li&gt;
&lt;li&gt;The Go text templating language is not aware that it is outputting schemas
defined by OpenAPI or even that it is being used to format data at all. Helm
is not able to validate that &lt;code&gt;replicas: &amp;quot;three&amp;quot;&lt;/code&gt; is an invalid Deployment
field.&lt;/li&gt;
&lt;li&gt;YAML&amp;rsquo;s sensitivity to indention along with conditionally defined template
blocks often results in unforeseen issues when input parameters are changed.
Even when indentation is accounted for correctly, the result is often hard to
read.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kustomize&#34;&gt;Kustomize&lt;/h3&gt;
&lt;p&gt;As of &lt;a href=&#34;https://kubernetes.io/blog/2019/03/25/kubernetes-1-14-release-announcement/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes
1.14&lt;/a&gt;,
the &lt;a href=&#34;https://kustomize.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kustomize&lt;/a&gt; tool is a part of the native toolchain
via &lt;code&gt;kubectl apply -k&lt;/code&gt;. Kustomize does not use templates. Instead, it relies on
patching. This attribute allows Kustomize to modify vanilla manifests. Kustomize
also provides &lt;em&gt;Kubernetes aware&lt;/em&gt; functionality such as applying a prefix to all
managed resource names. Behavior is controlled by a &lt;code&gt;kustomization.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;The main negative to using Kustomize is the inability to encapsulate Kubernetes
resource implementation aspects. Because patching operates at the resource
level, updating implementation details (Deployment vs StatefulSet) almost always
results in breaking changes to downstream users. The gravity of this downside
varies greatly based on the use-case. For a team that manages 3 separate
environments, encapsulation is less of a concern. On the other hand an
open-source MySQL implementation might have thousands of consumers, each with
relatively little knowledge of internal implementation details.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Part of the native &lt;code&gt;kubectl&lt;/code&gt; toolchain&lt;/li&gt;
&lt;li&gt;Able to modify vanilla manifests.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Main negative to using Kustomize is the inability to encapsulate Kubernetes
resource implementation aspects&lt;/li&gt;
&lt;li&gt;Because patching operates at the resource level, updating implementation
details (Deployment vs StatefulSet) almost always results in breaking changes
to downstream users.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;operators&#34;&gt;Operators&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/extend-kubernetes/operator/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Operators&lt;/a&gt; are
composed of CustomResourceDefinitions (CRDs) and a control loop that is running
on a cluster. Open source projects such as &lt;a href=&#34;https://github.com/coreos/prometheus-operator&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus now have
operators&lt;/a&gt;. Operators use CRDs to
create a domain-specific API for a specialized application. Similar in concept
to templating tools, this approach uses a programming language (the controller,
usually written in Go) to translate parameters (the CRD) into a set of manifests
(the created resources).&lt;/p&gt;
&lt;p&gt;As the name suggests, operators are responsible for &lt;em&gt;operating&lt;/em&gt; applications.
This means a sufficiently sophisticated operator probably has the ability to
perform application-specific steps required to upgrade to a new app version.
This is done in response to the user (human operator) making a declarative
version update. Because they have an active reconciliation loop running on the
cluster, operators also naturally address config-drift.&lt;/p&gt;
&lt;p&gt;Operators can be seen as tools that move edge-case imperative operations towards
the ideal declarative approach that Kubernetes promises. For internally
developed applications, operators should be considered when there are advanced
lifecycle concerns (for example: stateful or legacy apps).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Naturally address configuration drift&lt;/li&gt;
&lt;li&gt;When running complex third party applications, sufficiently mature operators
should be favored over basic templating tools.&lt;/li&gt;
&lt;li&gt;Mature operators can act like cloud services, making it more simple to install
and update Kubernetes applications&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes API pollution, creating additional cognitive load on cluster users&lt;/li&gt;
&lt;li&gt;Rogue operators can be hard to debug&lt;/li&gt;
&lt;li&gt;Building an operator involves a large amount of effort&lt;/li&gt;
&lt;li&gt;Most cloud native workloads do not warrant the development of an operator&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Platform Observability</title>
      
      <link>/guides/kubernetes/observability/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/observability/</guid>
      <description>

        
        &lt;p&gt;Observability is crucial for successfully operating a complex software system
such as Kubernetes. With this in mind, Kubernetes offers multiple facilities
that enable operators to observe the system at runtime. With that said, the onus
is on the platform operator to consume, evaluate, and act on the information
exposed by Kubernetes.&lt;/p&gt;
&lt;p&gt;Kubernetes has multiple sources of information that operators can use to observe
the platform&amp;rsquo;s behavior. These include component logs, audit logs, events, and
metrics.&lt;/p&gt;
&lt;h2 id=&#34;component-logs&#34;&gt;Component Logs&lt;/h2&gt;
&lt;p&gt;Kubernetes is a distributed system composed of multiple processes that run
across multiple hosts. Each component writes logs to stdout and stderr to
provide visibility into what is happening in the process. These logs are one of
the most important troubleshooting tools available to platform operators when
there is an issue with the system.&lt;/p&gt;
&lt;h2 id=&#34;audit-logs&#34;&gt;Audit Logs&lt;/h2&gt;
&lt;p&gt;The Kubernetes API server records every interaction with an audit log. The audit
logging capability is configurable using a policy file that controls which
events should be recorded and what data they should include. Typically, each log
entry contains what happened, when it happened, and who was involved in the
action. The API server supports multiple audit backends for persisting the audit
log: a file on disk, a statically-configured webhook, and a
dynamically-configured webhook.&lt;/p&gt;
&lt;h2 id=&#34;events&#34;&gt;Events&lt;/h2&gt;
&lt;p&gt;In addition to logs, Kubernetes components emit events that track what is
happening in the system. Examples of events include the Kubelet pulling a
container image, or the Scheduler assigning a pod to a node. Events are
first-class resources in the Kubernetes API, and thus are stored in the
Kubernetes API server. Because they are stored in the API, there is a retention
policy that controls the length of time the events are stored. To persist events
for historical analysis, platform operators should implement a solution that
ships the events to an external system.&lt;/p&gt;
&lt;h2 id=&#34;metrics&#34;&gt;Metrics&lt;/h2&gt;
&lt;p&gt;Each Kubernetes component exposes a set of metrics that track the component&amp;rsquo;s
state. These metrics are available through an HTTP endpoint at &lt;code&gt;/metrics&lt;/code&gt; and
are exposed using the Prometheus data format. The API server, for example,
exposes metrics such as &lt;code&gt;apiserver_current_inflight_requests&lt;/code&gt; and
&lt;code&gt;apiserver_watch_events_total&lt;/code&gt;. To take advantage of these metrics, platform
operators should use a monitoring system that can scrape Prometheus metrics and
generate alerts on those metrics.&lt;/p&gt;
&lt;p&gt;Kubernetes also exposes node and pod-level resource consumption metrics through
the Metrics API. These metrics are accessible directly via the API, or more
easily, through the &lt;code&gt;kubectl top&lt;/code&gt; command. To enable this API, operators must
deploy the &lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/resource-metrics-pipeline/#metrics-server&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes Metrics
server&lt;/a&gt;,
which is not deployed by default.&lt;/p&gt;
&lt;h2 id=&#34;distributed-tracing&#34;&gt;Distributed Tracing&lt;/h2&gt;
&lt;p&gt;Distributed Tracing is another important pillar of observability. As a platform
operator, consider deploying a tracing system to offer it as a platform service.
This will enable developers to perform distributed tracing in their
applications.&lt;/p&gt;
&lt;h2 id=&#34;popular-tooling-and-approaches&#34;&gt;Popular Tooling and Approaches&lt;/h2&gt;
&lt;h3 id=&#34;logging&#34;&gt;Logging&lt;/h3&gt;
&lt;h4 id=&#34;elasticsearch&#34;&gt;Elasticsearch&lt;/h4&gt;
&lt;p&gt;Open source search and analytics database for all types of data that is commonly
utilized in the Kubernetes ecosystem for log storage.&lt;/p&gt;
&lt;p&gt;It is the storage and search engine component of the ELK/EFK stack.&lt;/p&gt;
&lt;p&gt;Its distributed, fast and scalable data ingestion nature make it a natural fit
for container log aggregation, search and analytics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Built for scale&lt;/li&gt;
&lt;li&gt;Automated failover handling&lt;/li&gt;
&lt;li&gt;Distributed by design&lt;/li&gt;
&lt;li&gt;Widely tested&lt;/li&gt;
&lt;li&gt;Commonly used and known as part of the ELK/EFK stack&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Geographic distribution of nodes not recommended&lt;/li&gt;
&lt;li&gt;Relatively large memory footprint&lt;/li&gt;
&lt;li&gt;The difficulty configuring and tuning it is considerable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s worth considering buying and paying support for an alternative hosted
platform such as vRealize Log Insight.&lt;/p&gt;
&lt;h4 id=&#34;logstash&#34;&gt;Logstash&lt;/h4&gt;
&lt;p&gt;The data processing pipeline that aggregates and ships logs to the storage
engine utilized in the cluster. Commonly combined with Elasticsearch as
component of the ELK stack. It can ingest and process multiple sources
simultaneously, making it a good candidate to funnel container logs from a host,
process and forward them to the storage engine.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Commonly used&lt;/li&gt;
&lt;li&gt;Flexible&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Performance and resource consumption can be problematic&lt;/li&gt;
&lt;li&gt;Written in JRuby (java runtime required)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;fluentd&#34;&gt;Fluentd&lt;/h4&gt;
&lt;p&gt;Fluentd is another data collector/processing engine that is commonly combined
with Elasticsearch as a container logging platform. It can parse, analyze and
transform logs before sending them to the storage engine. Written in Ruby and C
for the speed-sensitive components, it has a lot of plugins provided by the Ruby
community.&lt;/p&gt;
&lt;p&gt;Fluentd runs containerized in the cluster as a DaemonSet. Typically all nodes in
the platform will run a Fluentd Pod which is configured to read the standard
output of all containers running in the node and funnel them for storage in a
database. The database can live inside or outside of the cluster.&lt;/p&gt;
&lt;p&gt;Typically, containerized log storage leverages Elasticsearch. Fluentd can ship
logs to external entities such as Splunk as well.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Part of CNCF&lt;/li&gt;
&lt;li&gt;Wide ecosystem of plugins out of the box provided
by the Ruby community&lt;/li&gt;
&lt;li&gt;Excellent support for Elastic&lt;/li&gt;
&lt;li&gt;Written in CRuby (No java runtime required)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Partly written in Ruby make it slower than other options&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;fluent-bit&#34;&gt;Fluent Bit&lt;/h4&gt;
&lt;p&gt;Fluent Bit is Fluentd&amp;rsquo;s smaller counterpart. It&amp;rsquo;s part of the Fluentd ecosystem.
It&amp;rsquo;s more suitable for containerized workloads given its smaller footprint. It&amp;rsquo;s
fully written in C, but significantly fewer plugins are available for it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Created with a highly distributed use case in mind&lt;/li&gt;
&lt;li&gt;Super light memory footprint&lt;/li&gt;
&lt;li&gt;Extensible&lt;/li&gt;
&lt;li&gt;Fully written in C, zero dependencies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Smaller number of plugins available compared to Fluentd&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Fluent Bit should be your first choice for Kubernetes, unless you find a
specific need or missing plugin to consider Fluentd.&lt;/p&gt;
&lt;h4 id=&#34;loki&#34;&gt;Loki&lt;/h4&gt;
&lt;p&gt;Loki is a horizontally-scalable, highly-available, multi-tenant log aggregation
system inspired by Prometheus. It is designed to be very cost effective and easy
to operate. It does not index the contents of the logs, but rather a set of
labels for each log stream.&lt;/p&gt;
&lt;p&gt;Loki supports a number of database options for the indexes and can store logs on
disk or on any of the major object storage options such as S3, Minio, Google
Cloud Object Storage.&lt;/p&gt;
&lt;p&gt;It is usually paired with &lt;a href=&#34;#grafana&#34;&gt;Grafana&lt;/a&gt; for visualization and
&lt;a href=&#34;#promtail&#34;&gt;Promtail&lt;/a&gt; for log ingestion.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Considerably easier to use and operate than Elasticsearch&lt;/li&gt;
&lt;li&gt;Offloads indexing and log storage to reliable external services&lt;/li&gt;
&lt;li&gt;Allows you to use Grafana for both logs and metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Less sophisticated search capabilities than Elasticsearch&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;promtail&#34;&gt;Promtail&lt;/h4&gt;
&lt;p&gt;Promtail is the log shipping component built specifically for shipping logs to
Loki. It would not be used otherwise.&lt;/p&gt;
&lt;h4 id=&#34;vrealize-log-insight&#34;&gt;vRealize Log Insight&lt;/h4&gt;
&lt;p&gt;vRealize Log Insight (vRLI) is VMware&amp;rsquo;s product offering that delivers
heterogeneous and highly scalable log management with intuitive, actionable
dashboards, sophisticated analytics and broad third-party extensibility.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Fluentd plugin exists for vRLI&lt;/li&gt;
&lt;li&gt;Scalability. Supports up to 15,000 events / second by scaling out appliances&lt;/li&gt;
&lt;li&gt;Automatic visualizations based on existing data&lt;/li&gt;
&lt;li&gt;Integration with vRealize Operations Manager&lt;/li&gt;
&lt;li&gt;Accepts rsyslog, syslog-ng, log4j agents or through API ingestion&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires a licenses to be purchased
&lt;ul&gt;
&lt;li&gt;The version that&amp;rsquo;s bundled with NSX-T can only be used for NSX-T or vSphere
logs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Must be deployed in a virtual environment through an appliance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;visualization&#34;&gt;Visualization&lt;/h3&gt;
&lt;h4 id=&#34;kibana&#34;&gt;Kibana&lt;/h4&gt;
&lt;p&gt;Open source data discovery and visualization dashboard for accessing information
stored in Elasticsearch. It&amp;rsquo;s the &amp;lsquo;K&amp;rsquo; in the ELK/EFK stacks. It and provides
insight into the container logs aggregated from the cluster. With the stored
data in Elasticsearch it is possible to create colorful dashboards, charts and
reports, gaining immediate valuable insight into the state of the cluster and
the applications running in it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integrates seamlessly with Elasticsearch&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;grafana&#34;&gt;Grafana&lt;/h4&gt;
&lt;p&gt;Grafana is an interactive visualization tool popularly used as a frontend for
metrics. It has native integration with Prometheus and Elasticsearch, making it
an easy choice to make for visualizing performance data of a running Kubernetes
cluster.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s easy to install and expandable, making it appealing for visualizing
application performance data.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s typically installed as an application in the cluster it will operate on.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integrates seamlessly with Prometheus&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;monitoring&#34;&gt;Monitoring&lt;/h3&gt;
&lt;h4 id=&#34;prometheus&#34;&gt;Prometheus&lt;/h4&gt;
&lt;p&gt;Prometheus is a CNCF project widely used for Kubernetes platform monitoring as
well as metrics collection and aggregation. Prometheus works by scraping data
from configured endpoints, parsing it and storing it in its internal time-series
database. This data can then be easily queried directly with PromQL, or
displayed using a visualization tool such as Grafana.&lt;/p&gt;
&lt;p&gt;Prometheus has push-gateway facility as well, for instrumenting applications
with the available client libraries to push metrics when exposing an endpoint to
scrape is not suitable. Ephemeral jobs such as pipelines are a good example of
tasks in which pushing data to the metrics server make sense.&lt;/p&gt;
&lt;p&gt;A &lt;a href=&#34;https://github.com/coreos/prometheus-operator&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus Operator&lt;/a&gt; exists to
install and manage the operation of your Prometheus cluster. We highly recommend
taking advantage of it when installing Prometheus.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Part of CNCF&lt;/li&gt;
&lt;li&gt;Easy installation&lt;/li&gt;
&lt;li&gt;Well documented&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Long term storage is limited&lt;/li&gt;
&lt;li&gt;Often requires addon solutions&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;datadog&#34;&gt;Datadog&lt;/h4&gt;
&lt;p&gt;System and application monitoring tool that runs as a DaemonSet in the cluster.
Allows you to get metrics and logs from services in real time to visualize
kubernetes states and get notified of failovers and events.&lt;/p&gt;
&lt;p&gt;Additionally, it can be configured outside of the cluster and have it gather
Kubernetes metrics.&lt;/p&gt;
&lt;p&gt;Alerting is also possible based on collected metrics from the platform or
the applications running in it.&lt;/p&gt;
&lt;p&gt;Similarly to ELK, it provides log aggregation, live tail facility, log archiving
and custom visualizations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Platform administrators have less to worry about&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Agent is not open source&lt;/li&gt;
&lt;li&gt;Agent configuration not properly documented&lt;/li&gt;
&lt;li&gt;Cost $$$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If customers aren&amp;rsquo;t price sensitive, this is a good option and offloads from the
platform administrator duties.&lt;/p&gt;
&lt;h4 id=&#34;tanzu-observability-by-wavefront&#34;&gt;Tanzu Observability by Wavefront&lt;/h4&gt;
&lt;p&gt;Tanzu Observability by Wavefront is a Software as a Service solution from VMware
that collects and aggregates Kubernetes and Application metrics.&lt;/p&gt;
&lt;p&gt;The Tanzu Observability by Wavefront service deploys daemon sets on Kubernetes
cluster nodes to collect metrics on clusters, nodes, pods, containers, and
control plane objects. These metrics are then pushed to the SaaS application
through a proxy.&lt;/p&gt;
&lt;p&gt;Wavefront integrates with many different platforms and applications out of the
box and builds initial dashboards to quickly visualize the health of workloads
and clusters.&lt;/p&gt;
&lt;p&gt;Wavefront integrates with many different platforms including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes&lt;/li&gt;
&lt;li&gt;Pivotal Cloud Foundry&lt;/li&gt;
&lt;li&gt;VMware vSphere&lt;/li&gt;
&lt;li&gt;Amazon Web Services&lt;/li&gt;
&lt;li&gt;Microsoft Azure&lt;/li&gt;
&lt;li&gt;Google Cloud Platform&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;VMware Tanzu Kubernetes Grid Integrated has an integration built in to enable
the Wavefront functionality.&lt;/p&gt;
&lt;p&gt;Wavefront also integrates with application services including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apache HTTP&lt;/li&gt;
&lt;li&gt;Envoy&lt;/li&gt;
&lt;li&gt;Istio&lt;/li&gt;
&lt;li&gt;Elasticsearch&lt;/li&gt;
&lt;li&gt;NGINX&lt;/li&gt;
&lt;li&gt;WebSphere&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wavefront can also ingest data from other monitoring tools such as: Fluentd,
Logstash, Splunk, vROps, Jaeger, and Prometheus.&lt;/p&gt;
&lt;p&gt;Alert notifications can be sent to a variety of solutions including: Slack,
PagerDuty, ServiceNow, or a Webhook for custom alerts.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Platform administrators have less to worry about&lt;/li&gt;
&lt;li&gt;Wavefront can scale to manage large numbers of clusters simultaneously&lt;/li&gt;
&lt;li&gt;Built in Integrations for platforms, applications, and alerts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data is stored outside the customer&amp;rsquo;s data center&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Platform Security</title>
      
      <link>/guides/kubernetes/platform-security/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/platform-security/</guid>
      <description>

        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Best practices in Kubernetes security are rapidly evolving. Many security
problems in early versions of Kubernetes are resolved by default in recent
versions. However, like any complex system, there are still risks you should
understand before you trust it with your production data. We’ve tried to
summarize the most important things you should have in mind when you host
sensitive workloads on Kubernetes.&lt;/p&gt;
&lt;p&gt;The topics discussed here help you understand potential risks in your cluster.
The risk in your environment depends on your threat model and the types of
applications you run in your cluster. You’ll have to consider how best to invest
in security controls and hardening based on the sensitivity of your data, the
amount of time and staff you’re able to dedicate to security, and your company’s
particular compliance requirements.&lt;/p&gt;
&lt;p&gt;Kubernetes provides several mechanisms to enforce security within the cluster.
These range from API security controls, down to container isolation, resource
limiting, and network policy control.&lt;/p&gt;
&lt;h2 id=&#34;general-points&#34;&gt;General points&lt;/h2&gt;
&lt;p&gt;Kubernetes core components cooperate to schedule and run your workloads in a
cluster. Kubernetes provides a range of access control mechanisms, however their
default values tend to be overly permissive. You should carefully determine what
access your system components and users need, and configure the most restrictive
controls possible.&lt;/p&gt;
&lt;p&gt;Remember also to secure the infrastructure that your clusters run on - for
example, SSH access, or cloud provider access such as AWS IAM.&lt;/p&gt;
&lt;h2 id=&#34;tls-certificates&#34;&gt;TLS Certificates&lt;/h2&gt;
&lt;p&gt;Kubernetes clusters require
&lt;a href=&#34;https://en.wikipedia.org/wiki/Public_key_infrastructure&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;PKI&lt;/a&gt; certificates for
secure communication between cluster components. Default CAs and certificates
are provided by kubeadm, but you should consider your requirements before
accepting only the defaults.&lt;/p&gt;
&lt;p&gt;Kubernetes requires TLS for the communication between the control plane
components of your cluster. For details about the required PKI certificates, see
the
&lt;a href=&#34;https://kubernetes.io/docs/setup/certificates/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;certificates documentation&lt;/a&gt;.
You can reuse the control plane CA certificate bundle for TLS in your
application/workloads. See the documentation about &lt;a href=&#34;https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;managing TLS
certificates&lt;/a&gt;.
kubeadm automatically generates the certificates required by the cluster; this
topic explains when and why you might want to generate your own certificates. It
also discusses options for managing certificates for your applications.&lt;/p&gt;
&lt;h3 id=&#34;certificate-authorities&#34;&gt;Certificate Authorities&lt;/h3&gt;
&lt;p&gt;The certificates generated with a kubeadm install rely on a single cluster CA
for all certificates. You might want to manage your certificates differently in
the following cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For finer-grained control over authentication, you might set up different
certificate authorities for server certificates and client certificates.&lt;/li&gt;
&lt;li&gt;Your company’s policies might require TLS certificates that are issued by your
own PKI.&lt;/li&gt;
&lt;li&gt;If you integrate with an OpenID Connect (OIDC) provider, you can use the OIDC CA.&lt;/li&gt;
&lt;li&gt;Publicly facing workloads may require a Commercial or
&lt;a href=&#34;https://en.wikipedia.org/wiki/Let%27s_Encrypt&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;non-profit&lt;/a&gt; certificate
bundle.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;if-you-issue-your-own-certificates&#34;&gt;If you issue your own certificates&lt;/h3&gt;
&lt;p&gt;The certificate for the API server control plane component requires a
subjectAltName (&lt;a href=&#34;https://en.wikipedia.org/wiki/Subject_Alternative_Name&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;SAN&lt;/a&gt;):
kubernetes. We recommend you use a corporate CA on a load balancer in front of
the API server instead of replacing the CA. Note that the &lt;code&gt;--root-ca-file&lt;/code&gt; flag
for the controller manager must also include a copy of the CA for the
API-server.&lt;/p&gt;
&lt;h3 id=&#34;certificate-rotation&#34;&gt;Certificate rotation&lt;/h3&gt;
&lt;p&gt;By default, kubeadm generates certificate authorities that expire after 10
years. The server and client certificates expire after one year. It is strongly
recommended to not let certificates expire as your cluster will become
inoperable.&lt;/p&gt;
&lt;p&gt;To help make sure your certificates do not expire, you can use the &lt;a href=&#34;https://github.com/prometheus/blackbox_exporter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus
BlackBox exporter&lt;/a&gt;, which
allows probing and alerting on certificate expiry dates.&lt;/p&gt;
&lt;p&gt;You can also configure automatic certificate rotation. See the documentation for
&lt;a href=&#34;https://kubernetes.io/docs/tasks/tls/certificate-rotation/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubelet certificate
rotation&lt;/a&gt; and
&lt;a href=&#34;https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/#setup-nodes-certificate-rotation-with-auto-approval&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;node certificate rotation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;authentication-and-authorizationhttpskubernetesiodocsreferenceaccess-authn-authzcontrolling-access&#34;&gt;&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/controlling-access/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Authentication and Authorization&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&#34;authentication&#34;&gt;Authentication&lt;/h3&gt;
&lt;p&gt;Kubernetes uses client certificates, bearer tokens, an authenticating proxy, or
HTTP basic auth to authenticate API requests through authentication plugins. As
HTTP requests are made to the API server, plugins attempt to associate the
following attributes with the request: Username, UID, Groups, and Extra fields.&lt;/p&gt;
&lt;p&gt;A critical component of cluster security is making sure that human users,
Kubernetes services accounts, cluster components, and application components
have the right permissions to access only the resources they need to get their
respective jobs done. Authentication and authorization are critical parts of
access control.&lt;/p&gt;
&lt;h3 id=&#34;integrate-an-identity-provider&#34;&gt;Integrate an identity provider&lt;/h3&gt;
&lt;p&gt;Certificates take care of authentication for clients, servers, clusters and
applications. To authenticate human users, we recommend integrating an existing
corporate identity system. Kubernetes lets you provide authentication with any
compliant OpenID Connect provider (for example, GitHub or Google). Kubernetes
authentication and authorization can also be extended with webhook-based plugins
to create a custom identity integration.&lt;/p&gt;
&lt;p&gt;If your organization integrates multiple identity providers,
&lt;a href=&#34;https://github.com/dexidp/dex&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Dex&lt;/a&gt; can be integrated with Gangway to act as
the OIDC endpoint. Dex acts as a broker for identity, providing a standard OIDC
frontend for a variety of backends such as LDAP servers, SAML providers, or
established identity providers like GitHub, Google, and Active Directory.&lt;br&gt;
Multi-factor authentication is not required, but provides additional protection
for end user flows.&lt;/p&gt;
&lt;h3 id=&#34;authorization&#34;&gt;Authorization&lt;/h3&gt;
&lt;p&gt;Human users and service accounts need to be carefully authorized to access only
the resources they need to get their jobs done, and no more. The principle of
least privilege is central to good authorization policies.&lt;/p&gt;
&lt;p&gt;Kubernetes expects attributes that are common to REST API requests. This means
that Kubernetes authorization works with existing organization-wide or
cloud-provider-wide access control systems, which may handle other APIs besides
the Kubernetes API. Every authenticated request to the Kubernetes API server
made by a human user or a service account needs to be authorized.&lt;/p&gt;
&lt;h3 id=&#34;rbac-authorizationhttpskubernetesiodocsreferenceaccess-authn-authzrbac&#34;&gt;&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;RBAC Authorization&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Role-Based Access Control (RBAC) allows the control of actions performed on
resources in the cluster, and defines who is allowed to perform them. Every
resource in Kubernetes is represented as an API object (Pods, Namespaces,
Secrets, ConfigMaps, etc.) These resources can be created, read, updated, and
deleted (verbs). A rule is composed of a verb and a resource, as an operation to
be performed on an API group. These rules are bundled together in Roles. Roles
are scoped to a namespace. Cluster-wide roles are defined in ClusterRole
objects. Roles can then be bound to users, groups and service accounts by
creating a role binding thereby granting them the ability to perform actions
described in the roles.&lt;/p&gt;
&lt;p&gt;At a minimum, we recommend that you enable RBAC. RBAC is enabled by default in
most recent installers and provides a framework for implementing the principle
of least privilege for humans and applications that access the Kubernetes API.&lt;/p&gt;
&lt;p&gt;To get the most benefit from RBAC, an appropriate configuration is required:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run each component with the most restrictive permissions that still allow for
expected functionality. Most applications in a cluster will need little or no
access to the Kubernetes API. System components such as an ingress controller
or monitoring system may need more access, but can often be limited to
read-only access or access within a particular namespace.&lt;/li&gt;
&lt;li&gt;Make sure that trusted components don’t act as pivots that allow less
privileged users to escalate privileges. The Kubernetes Dashboard and Helm
tiller daemon are examples that deserve special attention. Isolate these
components with application-level authentication/ authorization and network
access controls to prevent unauthorized access.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When creating RBAC policies, prefer Roles and RoleBindings over ClusterRoles and
ClusterRoleBindings whenever possible as they are scoped to namespaces by
default. While Kubernetes comes with default RBAC policies in place, we
recommend setting up your baseline policies with the least required privileges
that you need.&lt;/p&gt;
&lt;p&gt;The Kubernetes API audit logs are a useful tool for discovering which APIs a
particular application is using, and for testing locked-down RBAC policies. The
&lt;a href=&#34;https://github.com/liggitt/audit2rbac&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;audit2rbac&lt;/a&gt; tool can act as a reference
as it can generate RBAC roles and bindings to cover the API requests made by a
user. See also
&lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/audit/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Auditing&lt;/a&gt; in
the Kubernetes documentation.&lt;/p&gt;
&lt;h3 id=&#34;admission-controllershttpskubernetesioblog20190321a-guide-to-kubernetes-admission-controllers&#34;&gt;&lt;a href=&#34;https://kubernetes.io/blog/2019/03/21/a-guide-to-kubernetes-admission-controllers/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Admission Controllers&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;An admission controller is a piece of code that intercepts requests to the
Kubernetes API. This happens before the persistence of the object, but after the
request is authenticated and authorized. These are plugins that govern and
enforce the acceptance of requests. There are two individual Admission
Controllers: MutatingAdmissionWebhook and ValidatingAdmissionWebhook, which
execute mutating and validating actions, respectively. Mutating controllers may
modify the objects they admit; validating controllers do not. The admission
control process has two phases: the mutating phase is executed first, followed
by the validating phase. An excellent example of a mutating admission controller
is Istio&amp;rsquo;s
&lt;a href=&#34;https://istio.io/docs/setup/additional-setup/sidecar-injection/#automatic-sidecar-injection&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;automatic sidecar injection&lt;/a&gt;
mechanism. If any of the controllers in either phase reject the request, the
entire request is rejected immediately and an error is returned to the end-user&lt;/p&gt;
&lt;h2 id=&#34;network-and-application-access-control&#34;&gt;Network and Application Access Control&lt;/h2&gt;
&lt;p&gt;Access to the cluster network should be carefully controlled and permissions
granted only to the components or resources that need access. The Kubernetes
NetworkPolicy API allows users to express ingress and egress policies (starting
with Kubernetes 1.8.0) to Kubernetes pods based on labels and ports.&lt;/p&gt;
&lt;p&gt;Many existing applications assume that network-level access implies a level of
authorization. Even if applications include strong application-layer
authentication and authorization, network-level access control provides an
additional layer of defense. For example, it provides crucial protection against
pre-auth vulnerabilities such as the &lt;a href=&#34;https://en.wikipedia.org/wiki/Heartbleed&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Heartbleed
(CVE-2014-0160)&lt;/a&gt; vulnerability in
OpenSSL.&lt;/p&gt;
&lt;h3 id=&#34;network-policyhttpskubernetesiodocsconceptsservices-networkingnetwork-policies&#34;&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Network Policy&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;By default, Kubernetes clusters do not restrict traffic. Pods can communicate
with any other pods. External clients can also communicate with pods, assuming
they are routable from the client&amp;rsquo;s network.&lt;/p&gt;
&lt;p&gt;The NetworkPolicy resource in Kubernetes allows you to control how pods are
allowed to communicate with each other and other network endpoints. The
NetworkPolicy resource is namespace scoped. Rules defined in the policy allow
traffic and are combined additively.&lt;/p&gt;
&lt;p&gt;Kubernetes provides core data types for specifying network access controls
between pods. Network policy in Kubernetes can limit inbound traffic to a pod
based on the source pod’s namespace and labels, plus the IP address for traffic
that originates outside the cluster. Network policy can also limit outbound
traffic using the same set of selectors. A good starting point is to restrict
ingress to only the application namespace by default. For details, see the
&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-deny-all-ingress-traffic&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes Network Policy
documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The enforcement of network policy relies on the cluster’s
&lt;a href=&#34;https://github.com/containernetworking/cni&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;CNI&lt;/a&gt; provider. Without them,
Kubernetes “fails open” — the API happily accepts any network policy, but the
policies are not enforced. We recommend
&lt;a href=&#34;https://www.projectcalico.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Calico&lt;/a&gt; as your CNI provider, because it
enforces controls. Examples of Network policies can be found
&lt;a href=&#34;https://github.com/ahmetb/kubernetes-network-policy-recipes&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;restricting-access-to-control-plane-services&#34;&gt;Restricting access to control plane services&lt;/h3&gt;
&lt;p&gt;Network controls in the infrastructure underlying the cluster must also be
considered. In a cloud provider environment, make sure that pods cannot
communicate with the instance metadata service. We also recommend the use of the
&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/node/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Node Authorizer&lt;/a&gt;
to limit kubelet access to the API. When enabled, this special-purpose
authorization module restricts kubelet access to resources that are referenced
by Pods running on that specific node. The Node Authorizer is enabled by default
in recent releases of kubeadm. For example, instead of being able to access all
Secrets in the cluster, a kubelet can access only Secrets that are referenced by
Pods scheduled to that kubelet.&lt;/p&gt;
&lt;p&gt;Enforcing network controls in the infrastructure underlying your cluster is also
critical. In a cloud provider environment, make sure that your pods cannot talk
to the instance metadata service (for example,
&lt;code&gt;http://169.254.169.254/latest/meta-data&lt;/code&gt; on AWS EC2). Depending on your
requirements, you may also need to restrict access to the kubelet localhost
read-only port (10255 by default). This port exposes metadata about the pods
running on the node, which you may not want access to your applications.&lt;/p&gt;
&lt;h3 id=&#34;application-layer-access-control&#34;&gt;Application-layer access control&lt;/h3&gt;
&lt;p&gt;One solution to the problem of network-level access controls is strong
application-layer authentication such as
&lt;a href=&#34;https://en.wikipedia.org/wiki/Mutual_authentication&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;mutual TLS&lt;/a&gt;. Cryptographic
application identity is powerful because it allows identity to be efficiently
expressed across network boundaries. Securely provisioning certificates for
applications is still a hard problem in Kubernetes.&lt;/p&gt;
&lt;h3 id=&#34;limitations&#34;&gt;Limitations&lt;/h3&gt;
&lt;p&gt;Network access controls have some limitations in dynamic environments like
Kubernetes, which results in the following difficulties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Federating Kubernetes network policy across multiple clusters.&lt;/li&gt;
&lt;li&gt;Integrating Kubernetes network-level controls and granular network-level
controls expressed outside of the pod networking layer (for example, in AWS
EC2 Security Groups).&lt;/li&gt;
&lt;li&gt;When services running in a Kubernetes cluster need to communicate with
services outside the cluster, NetworkPolicy is often unable to filter traffic
as expected due to source and destination IP address translation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you encounter any of these issues, we recommend that you define a more
coarse-grained network policy and rely on the application layer for fine-grained
access control.&lt;/p&gt;
&lt;h2 id=&#34;container-security&#34;&gt;Container Security&lt;/h2&gt;
&lt;h3 id=&#34;security-contextshttpskubernetesiodocstasksconfigure-pod-containersecurity-context&#34;&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/security-context/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Security Contexts&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Security contexts limit what a Pod or Container can do and what privileges the
object has when running in the cluster. Example controls are the UID of the
process running inside the container, the filesystem access group, the process
capabilities, SELinux labels, etc.&lt;/p&gt;
&lt;p&gt;These can be applied to individual Pods and containers, and they define a set of
conditions that it must run with.&lt;/p&gt;
&lt;h3 id=&#34;pod-security-policies-psphttpskubernetesiodocsconceptspolicypod-security-policy&#34;&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/policy/pod-security-policy/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Pod Security Policies PSP&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Pod security policies are cluster-wide resources that provide automation of the
above described security contexts. PSPs can be used to automatically set
security context parameters or to prevent out-of-policy pods from running in the
cluster. For example, if you don&amp;rsquo;t want any containers in your cluster to run as
root, you can enforce this using a PSP with a &lt;code&gt;runAsUser&lt;/code&gt; rule of
&lt;code&gt;MustRunAsNonRoot&lt;/code&gt;. They define a set of conditions that a pod must run with to
be accepted into the system. Pod Security Policies are comprised of settings and
strategies that control the security features a pod has access to, and hence
this must be used to control pod access permissions. Strong pod security
policies make sure that pod access is appropriately controlled.&lt;/p&gt;
&lt;p&gt;Pod Security Policies provide a policy-driven mechanism for requiring
applications in your cluster to use container sandboxing in an approved way. For
example, you can require that all pods in a particular namespace run as
non-root, that they don&amp;rsquo;t mount host file systems and do not use host
networking.&lt;/p&gt;
&lt;p&gt;To use pod security policies, the PodSecurityPolicy admission controller must be
enabled in the API server configuration. Policies must be present before
enabling the controller, or no pods would be allowed to run. For more
information, see to the
&lt;a href=&#34;https://kubernetes.io/docs/concepts/policy/pod-security-policy/#run-another-pod&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;credentials-security-secrets&#34;&gt;Credentials security (Secrets)&lt;/h2&gt;
&lt;p&gt;Secrets are sensitive pieces of data such as passwords, tokens or keys.
Applications use secrets to access internal resources like the Kubernetes API or
external resources such as git repositories, databases, etc. The following
section details concerns related to secrets in the context of Kubernetes.&lt;/p&gt;
&lt;h3 id=&#34;secrets-management&#34;&gt;Secrets Management&lt;/h3&gt;
&lt;p&gt;Kubernetes has a core primitive for managing application secrets, appropriately
called a &lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/secret/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Secret&lt;/a&gt;.
Applications typically need secrets for two reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They need access to a credential that proves their identity to another system
(for example, a database password or third-party API token).&lt;/li&gt;
&lt;li&gt;They need a cryptographic secret for some essential operation (for example, an
HMAC signing key for issuing signed HTTP cookies).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;identity-secrets&#34;&gt;Identity Secrets&lt;/h3&gt;
&lt;p&gt;For the first use case of application identity, follow the efforts of
&lt;a href=&#34;https://spiffe.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;SPIFFE&lt;/a&gt; and the Container Identity working group for a long
term solution to dynamically provisioning unique application identities. In the
near term, there is no well-established best practice in this area. Still, some
users have success integrating with existing certificate provisioning workflows
as part of a CI/CD pipeline. Simple Kubernetes-native solutions like
&lt;a href=&#34;https://github.com/jetstack/cert-manager&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;cert-manager&lt;/a&gt; may also work for your
use case.&lt;/p&gt;
&lt;h3 id=&#34;non-identity-secrets&#34;&gt;Non-identity Secrets&lt;/h3&gt;
&lt;p&gt;For the other use case, systems such as
&lt;a href=&#34;https://github.com/hashicorp/vault&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Vault&lt;/a&gt; perform cryptographic operations in
a centralized service. If you choose this option, make sure you understand the
entire chain of attestations involved in authenticating to the system. Often
these systems depend on Kubernetes secret resources as one step in the chain. In
Vault, the
&lt;a href=&#34;https://www.vaultproject.io/docs/auth/kubernetes.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Vault Kubernetes auth backend&lt;/a&gt;
authenticates pods by consuming a Kubernetes Service Account token. Still, the
token is stored as a secret object before it’s injected into the pod. This
pattern requires that you trust Vault not to replay your token and impersonate
the pod to the Kubernetes API.&lt;/p&gt;
&lt;h3 id=&#34;caveats-for-kubernetes-secrets&#34;&gt;Caveats for Kubernetes Secrets&lt;/h3&gt;
&lt;p&gt;You should be aware of the following limitations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many standard components – for example, ingress controllers – require
permission to read all secrets in your cluster.&lt;/li&gt;
&lt;li&gt;Secrets are not encrypted at rest by default. You can, however, configure,
etcd, to encrypt secret data at rest. For details, see &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Encrypting Secret Data
at Rest&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;auditing-to-support-security&#34;&gt;Auditing to support security&lt;/h2&gt;
&lt;p&gt;Audit logging must be explicitly enabled. It provides valuable insight into
access rules, compliance, and potential access issues. Kubernetes auditing
provides a security-relevant chronological set of records documenting the
sequence of activities that have affected the system by individual users,
administrators, or other components of the system.&lt;/p&gt;
&lt;p&gt;The Kubernetes API server audit log documents the sequence of cluster activities
performed by users, administrators, and system services. Each API request has
multiple stages that can be tracked and logged using an Audit Policy.&lt;/p&gt;
&lt;h3 id=&#34;enabling-audit-logging&#34;&gt;Enabling Audit Logging&lt;/h3&gt;
&lt;p&gt;The Kubernetes API server does not perform audit logging by default. We
recommend that you enable audit logging to a file by setting the following flags
in the API server configuration:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--audit-log-path&lt;/code&gt; specifies the log file path that log backend uses to write
audit events.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--audit-log-maxage&lt;/code&gt; defines the maximum number of days to retain old audit log
files&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--audit-log-maxbackup&lt;/code&gt; defines the maximum number of audit log files to retain&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--audit-log-maxsize&lt;/code&gt; defines the maximum size in megabytes of the audit log
file before it gets rotated&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--audit-policy-file&lt;/code&gt; specifies the Audit policy file to be used&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Audit events can also be sent to a webhook backend, but we recommend logging to
a file that can be aggregated. Audit data should be treated as a high priority,
and care should be taken that the file specified for &amp;ndash;audit-log-path is
aggregated for multiple control plane nodes and handled by systems with high
reliability. In the case of an outage or other issue, administrators need to be
able to rely on the data produced by audit systems.&lt;/p&gt;
&lt;p&gt;When logging to files on the control plane hosts, you should set
&lt;code&gt;--audit-log-maxage&lt;/code&gt;, &lt;code&gt;--audit-log-maxbackup&lt;/code&gt;, and &lt;code&gt;--audit-log-maxsize&lt;/code&gt;
appropriately based on the available disk space before aggregation.&lt;/p&gt;
&lt;h2 id=&#34;node-and-container-runtime-hardening&#34;&gt;Node and container runtime hardening&lt;/h2&gt;
&lt;p&gt;It is of critical importance to consider the security of the container-host
boundary. This is important even in single-tenant environments since a remote
code execution vulnerability like &lt;a href=&#34;https://en.wikipedia.org/wiki/Shellshock_%28software_bug%29&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Shellshock
(CVE-2014-6271)&lt;/a&gt; or the
&lt;a href=&#34;https://groups.google.com/forum/#!topic/rubyonrails-security/61bkgvnSGTQ/discussion&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Ruby YAML parsing vulnerability (CVE-2013-0156)&lt;/a&gt;
can turn your otherwise trusted workload into a malicious agent. Without proper
hardening, that single remote code execution vulnerability can escalate into a
whole-node or whole-cluster takeover.&lt;/p&gt;
&lt;p&gt;Current container runtimes don’t provide the most reliable possible sandboxing,
but there are some steps you can take to help mitigate the risk of container
escape vulnerabilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Segment your Kubernetes clusters by integrity level — a simple but very
effective way to limit your exposure to container escape vulnerabilities. For
example, your dev/test environments might be hosted in a different cluster
than your production environment.&lt;/li&gt;
&lt;li&gt;Invest in streamlined host/kernel patching. Make sure that you have a way to
test new system updates (for example, a staging environment) and that your
applications can tolerate a rolling upgrade of the cluster without affecting
application availability.&lt;/li&gt;
&lt;li&gt;Kubernetes shines at orchestrating these upgrades. Once you build confidence
in letting Kubernetes dynamically rebalance application pods, patch management
at the node level becomes relatively easy. You can automate a rolling upgrade
that gracefully drains each node and either upgrade it in place or (in an IaaS
environment) replaces it with a new node. Investments in this area also
improve your overall resiliency to node-level outages.&lt;/li&gt;
&lt;li&gt;Run your applications as a non-root user. Root (UID 0) in a Linux container is
still the same user as root on the node. A combination of sandboxing
mechanisms restrict what code running in the container can do. Still, future
Linux kernel vulnerabilities are more likely to be exploitable by a root user
than by a non-privileged user.&lt;/li&gt;
&lt;li&gt;Enable and configure extra Linux security modules like SELinux and AppArmor.
These tools let you enforce more restrictive sandboxing on particular
containers. They are valuable in many situations, but building and maintaining
appropriate configurations requires a time investment. They may not be
appropriate for every application or environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;image-security&#34;&gt;Image Security&lt;/h2&gt;
&lt;h3 id=&#34;runtime-security&#34;&gt;Runtime Security&lt;/h3&gt;
&lt;p&gt;Runtime security is concerned with potential changes to a running container
through its lifetime, invalidating an initial security scan. A container image
could have been scanned and approved but become a liability as new
vulnerabilities, bugs, and threats are found. Runtime security tools help to
mitigate this problem by looking at what&amp;rsquo;s happening inside containers:
filesystem, process activity, networking behavior, etc. Examples of runtime
security tools: Falco, Aquasec, Twistlock, Sysdig.&lt;/p&gt;
&lt;h3 id=&#34;attack-surface-minimization&#34;&gt;Attack Surface Minimization&lt;/h3&gt;
&lt;p&gt;Minimize container footprint and attack surface by excluding extraneous
libraries and utilities that are not needed and could be leveraged during an
attack. Consider building images from scratch and include only what is necessary
at runtime. Also leverage multi-stage builds where applicable so that build
tools are not included in the final image used in production.&lt;/p&gt;
&lt;h3 id=&#34;container-image-scanning&#34;&gt;Container Image Scanning&lt;/h3&gt;
&lt;p&gt;Container image scanning is an integral part of building container images,
whether from source or third party base images, to discover any known
vulnerabilities and mitigate them before cluster deployment. One of the last
steps of your CI (Continuous Integration) pipeline involves building the
container images that would be pulled and executed in your environment.
Therefore, whether you are building Docker images from your code or using
unmodified third party images, it’s crucial to identify and find any known
vulnerabilities that may be present in those images. This process is known as
container image scanning. Container image scanning helps make sure that your
images are free from known vulnerabilities before they are deployed.
Appropriately managed scanning keeps your clusters safe by not introducing
malicious or malformed artifacts.&lt;/p&gt;
&lt;p&gt;Services and open source tools that provide image scanning include the
following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/clair&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Clair&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sysdig.com/opensource/falco/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Falco&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.aquasec.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Aqua Security&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.twistlock.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Twistlock&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We recommend integrating a container scan as part of a continuous delivery
pipeline. In addition, we recommend running periodic scans against stored images
so you can identify and mitigate new vulnerabilities.&lt;/p&gt;
&lt;p&gt;We also recommend deploying an ImagePolicyWebhook
&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;admission controller&lt;/a&gt;
with the Kubernetes API server that only allows images that have passed security
scans to run in a cluster.&lt;/p&gt;
&lt;h4 id=&#34;deploying-the-imagepolicywebhook-in-kubernetes&#34;&gt;Deploying the ImagePolicyWebhook in Kubernetes&lt;/h4&gt;
&lt;p&gt;The ImagePolicyWebhook admission controller plugin queries a backend service to
determine whether a workload can be run on a cluster. It does not make any
changes to the submitted workload, but instead accepts or rejects it as-is based
on whether the images associated with the workload comply with the policy set
for the cluster. The webhook service queries the scanner tool to scan an image
and either accept the workload or reject it based on the scan results.&lt;/p&gt;
&lt;p&gt;The webhook service must use TLS.&lt;/p&gt;
&lt;p&gt;See &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers#imagepolicywebhook&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;the documentation on ImagePolicyWebhook&lt;/a&gt;
for a detailed explanation.&lt;/p&gt;
&lt;h2 id=&#34;image-signing&#34;&gt;Image signing&lt;/h2&gt;
&lt;p&gt;Image signing helps make sure that your container images have not been tampered
with. In other words, image signing is used to prove the provenance of your
images. Signed images do not guarantee compliance, however.&lt;/p&gt;
&lt;p&gt;Image signing establishes image trust, ensuring that the image you run in your
cluster is the image you intended to run.&lt;/p&gt;
&lt;p&gt;Private image registries or private accounts on public registries let you
establish some degree of trust. Still, if your registry is compromised, bad
actors could replace your images with malicious versions.&lt;/p&gt;
&lt;p&gt;Image signing adds a layer of protection by cryptographically signing an image.
As long as your private keys are not compromised, you can be guaranteed that the
image you run is trusted.&lt;/p&gt;
&lt;p&gt;Note that you must also deploy a mechanism to verify image trust. An example is
&lt;a href=&#34;https://github.com/IBM/portieris&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;portieris&lt;/a&gt;, which allows you to configure
image security policies and stop the workload from being deployed if it is not
signed.&lt;/p&gt;
&lt;h2 id=&#34;patch-management-and-cicd&#34;&gt;Patch management and CI/CD&lt;/h2&gt;
&lt;h3 id=&#34;deployment-pipelines&#34;&gt;Deployment pipelines&lt;/h3&gt;
&lt;p&gt;A successful cluster access pattern is to have most users interact with the
production cluster only through a deployment pipeline. This pipeline consists of
one or more automated systems that handle building code into a container image,
running unit and integration tests and other validation steps such as pausing
for any manual approval. Depending on your needs, developers could still have
direct read-only access to the Kubernetes API or have a way to “break the glass”
and exec into pods during an incident.&lt;/p&gt;
&lt;p&gt;A robust application deployment pipeline is also the key to remediating
vulnerabilities in container images. You can use tools like
&lt;a href=&#34;https://github.com/coreos/clair&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Clair&lt;/a&gt; to identify known vulnerabilities in
the libraries and packages you use. Still, to release patches on time, you need
a trusted, automated way of rebuilding and testing patched versions of the
container.&lt;/p&gt;
&lt;h3 id=&#34;limiting-churn&#34;&gt;Limiting churn&lt;/h3&gt;
&lt;p&gt;Healthy Kubernetes clusters are dynamic environments. New versions of
applications are deployed, nodes disappear for kernel upgrades, deployments
scale up and down, and (hopefully) the users of your application never notice.
Making all this work in practice requires some diligence, but it’s critical to
reaping all the benefits of Kubernetes.&lt;/p&gt;
&lt;p&gt;One tool that can help put bounds on the amount of chaos introduced into your
cluster is the &lt;a href=&#34;https://kubernetes.io/docs/tasks/run-application/configure-pdb/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Pod Disruption Budget&lt;/a&gt;.
It’s useful when you have multiple automated systems, and you want to make sure
they don’t interact in unwanted ways. For example, an application-level bug might
leave some pods of your application temporarily unavailable. A pod disruption
budget could make sure that an automated rolling node upgrade doesn’t terminate
the remaining healthy copies of your application.&lt;/p&gt;
&lt;h3 id=&#34;overly-privileged-container-builds&#34;&gt;Overly privileged container builds&lt;/h3&gt;
&lt;p&gt;One Docker-specific anti-pattern to avoid in your build pipeline is mounting the
host-level Docker control socket “/var/run/docker.sock” into a container during
a build. Access to this socket is equivalent to root on the host, which means
any running build could compromise the node. This is doubly true if your build
system runs build before a manual code review (a typical pattern).&lt;/p&gt;
&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;
&lt;h3 id=&#34;what-to-do-now&#34;&gt;What to do now&lt;/h3&gt;
&lt;p&gt;We keep saying it: how you secure your Kubernetes cluster depends in part on
your available resources and your application requirements. Consider each
element in the broader security picture and spend some time upfront assessing
how important it is to your needs overall. At a very high level, some of our
recommendations fit nicely into larger best practices in deployment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automated deployment pipeline and scheduler. Lets you simplify host and
application patch management with rolling upgrades that are integrated into
the rest of your overall development cycle.&lt;/li&gt;
&lt;li&gt;Integrated access controls at appropriate levels. (authz/authn with API
integration)&lt;/li&gt;
&lt;li&gt;Integrated logging and monitoring. You log and monitor for performance and
reliability &amp;ndash; adding support for security-specific events and pod metadata is
non-trivial but vital. Precisely what to monitor depends as always on your
specific needs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;planning-for-the-future&#34;&gt;Planning for the future&lt;/h3&gt;
&lt;p&gt;Security is an increasing concern for everyone, and initiatives are well
underway to improve the security landscape. Keep an eye out for developments on
these fronts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More strongly encrypted identity specific to your hardware or cloud provider&lt;/li&gt;
&lt;li&gt;Stronger provenance for cryptographically signed binaries/images&lt;/li&gt;
&lt;li&gt;Automatically updated inventories&lt;/li&gt;
&lt;li&gt;More sophisticated alerts and monitoring&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other-resources&#34;&gt;Other Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Securing a Cluster (Kubernetes documentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1xeagoDn-6kQ6FPdfX9IlD5MjWalW2o8PeCt20DEfFpg/edit&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Hacking and Hardening Kubernetes By Example (slides from Brad Geesaman)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;popular-tooling-and-approaches&#34;&gt;Popular Tooling and Approaches&lt;/h2&gt;
&lt;h3 id=&#34;encryption-configuration&#34;&gt;Encryption Configuration&lt;/h3&gt;
&lt;p&gt;The Kubernetes docs provide
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;instructions to enable encryption at rest&lt;/a&gt;
for specified resources. Most importantly, this allows cluster operators to
ensure the data contained in Secrets has a layer of protection against a
malicious actor gaining access to the storage disk for etcd.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adds a layer of protection for data contained in Secrets&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is compromised if attacker gains access to the encryption keys used by the API Server&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;validating-admission-webhook-controllers&#34;&gt;Validating Admission Webhook Controllers&lt;/h3&gt;
&lt;p&gt;Kubernetes RBAC provides a useful way to manage access to resources. However, it
does not provide ways to restrict access based on external systems or the
attributes of the resource being created. Proper authorization may require a
deeper understanding of the requester, evaluation of business logic, or
understanding of the cluster&amp;rsquo;s current state to determine whether a request
should be authorized. Kubernetes offers preset admission controllers built into
the &lt;code&gt;kube-apiserver&lt;/code&gt;, such as &lt;code&gt;PodSecurityPolicy&lt;/code&gt;. These can be enabled by
altering flags on the &lt;code&gt;kube-apiserver&lt;/code&gt;. To provide custom admission control
without modifying the API server, Kubernetes offers an Admission webhook
functionality. In this model, Kubernetes offers selected inbound request to an
external service that can approve or deny the request.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/diagrams/k8s-admission-flow.png&#34; alt=&#34;Kubernetes Admission Flow&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Writing an admission webhook controller in code enables you to do complex logic
and access Kubernetes objects structurally, through a language&amp;rsquo;s type system.
For example, see &lt;a href=&#34;https://github.com/kubernetes/apimachinery&#34;&gt;https://github.com/kubernetes/apimachinery&lt;/a&gt;. A downside to this
approach is maintaining the controller code base over time, which can involve
keeping logic up to date against changing Kubernetes API versions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flexible option for resource validation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Webhook is on the critical path for resource management in the cluster
&lt;ul&gt;
&lt;li&gt;Development &amp;amp; maintenance overhead for the webhook&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;open-policy-agent-opa&#34;&gt;Open Policy Agent (OPA)&lt;/h3&gt;
&lt;p&gt;Similar to Validating Admission Webhook Controllers,
&lt;a href=&#34;https://www.openpolicyagent.org&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;OPA&lt;/a&gt; performs validation on requests sent to
it. OPA is a general purpose policy agent. It&amp;rsquo;s primary goal is to unify
policies around a centralized model and language. It uses a DSL called
&lt;a href=&#34;https://www.openpolicyagent.org/docs/latest/#rego&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Rego&lt;/a&gt; that analyzes input,
usually JSON, and provides an output. For Kubernetes admission control, the
request is typically the JSON from an
&lt;a href=&#34;https://godoc.org/k8s.io/api/admission/v1beta1#AdmissionReview&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;AdmissionReview&lt;/a&gt;
object and the response is the same object with the
&lt;a href=&#34;https://godoc.org/k8s.io/api/admission/v1beta1#AdmissionResponse&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;AdmissionResponse&lt;/a&gt;
filled in.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/platform-security/diagrams/k8s-admission-flow-opa.png&#34; alt=&#34;Admission Flow with OPA&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;While this unified model is great, it can be harder to do complex logic in rego
over a general purpose language.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Powerful validation framework&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires learning a new policy definition language: Rego&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;network-policy&#34;&gt;Network Policy&lt;/h3&gt;
&lt;p&gt;Kubernetes provides a &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;NetworkPolicy
API&lt;/a&gt;.
Verify that your CNI-Plugin enforces policies. By default, Kubernetes allows
traffic to and from any pod or external source that can reach it. With this in
mind, enforcing Network Policy is critical to protect applications from unwanted
access. How policy is enforced depends on the CNI-plugin. For example, in Calico
it&amp;rsquo;s enforced via IPtables and in Cilium it&amp;rsquo;s BPF. If network policy if a large
part of your Kubernetes design, ensure the solution you&amp;rsquo;re using offers a
scalable approach to enforcement.&lt;/p&gt;
&lt;p&gt;Along with the Kubernetes network policy API, some CNI-Plugins offer their own
CRDs that extend the base functionality. Calico offers a
&lt;a href=&#34;https://docs.projectcalico.org/v3.9/reference/resources/globalnetworkpolicy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;GlobalNetworkPolicy&lt;/a&gt;
and
&lt;a href=&#34;https://docs.projectcalico.org/v3.9/reference/resources/networkpolicy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;NetworkPolicy&lt;/a&gt;
CRD. The primary trade-off to using a CNI-specific CRD is portability. Should
you choose to change plugins in the future, you may need to convert policies
between types. However, some of the plugin-specific policy features are very
compelling for various cluster architectures.&lt;/p&gt;
&lt;p&gt;Historically, organizations have attempted to keep their existing network models
outside of Kubernetes and make Kubernetes fit within it. For example, this can
include making layers of Kubernetes nodes such as running nodes in Kubernetes
dedicated to certain layers such as Web, App, and Data. This moves away from
Kubernetes declarative approach and add a lot of complexity to the system. We
highly recommend considering intra-cluster and workload traffic policies into
the Kubernetes API.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Essential network controls can be enforced&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Differences in implementation between CNI plugins can be a challenge&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Service Routing</title>
      
      <link>/guides/kubernetes/service-routing/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/service-routing/</guid>
      <description>

        
        &lt;p&gt;Fundamental to the deployment of most software is the ability to route traffic
to network services. This is especially true when the software platform adopts a
microservices architecture.&lt;/p&gt;
&lt;p&gt;Traditionally, exposing such services has been an arduous task. Concerns such as
service discovery, port contention, and even load balancing were often left as
an exercise for the operator. These capabilities were, no doubt, available, but
were often configured and operated through manual user intervention.&lt;/p&gt;
&lt;p&gt;Fortunately, Kubernetes provides a number of primitives that allow us to route
service traffic across the cluster as well as from external sources. Just as all
other Kubernetes resources, these are configured in a declarative way.&lt;/p&gt;
&lt;h2 id=&#34;the-kubernetes-service-resource&#34;&gt;The Kubernetes Service Resource&lt;/h2&gt;
&lt;p&gt;The Kubernetes Service resource is a core API type that allows users to define
how service endpoints may be exposed to client applications. This construct
operates between layer 3 and 4 of the OSI networking stack. This resource,
natively, offers three types of services that provide various levels of service
exposure.&lt;/p&gt;
&lt;p&gt;An example Service declaration may take the following form:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Service&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;myapp&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# this is the default value if unspecified&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TCP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3307&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3306&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This Service will provide Layer 3/4 access to mysql Pods that are labeled with
the &lt;code&gt;app: mysql&lt;/code&gt; key-value pair within the &lt;code&gt;myapp&lt;/code&gt; namespace. While the Pod
exposes the service on the standard mysql port (3306), the Service may
selectively expose it on an alternate port (in this case, 3307).&lt;/p&gt;
&lt;p&gt;Each of the Service types build on the previous type, beginning with ClusterIP
as the most basic type.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/service-routing.png&#34; alt=&#34;Service Routing&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;clusterip&#34;&gt;ClusterIP&lt;/h3&gt;
&lt;p&gt;The ClusterIP Service type is used to expose a Pod&amp;rsquo;s layer 4 endpoint to the
rest of the cluster. As stated earlier, this service type serves as the most
basic of all of the types. This construct is namespaced, and has two primary
functions: to provide a cluster-local virtual IP and an associated DNS entry.
This virtual IP is pulled from an IP pool that is dedicated for all services,
and once created it is used as the target for a consistent DNS record.&lt;/p&gt;
&lt;p&gt;These DNS records take the fully-qualified form of:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&amp;lt;service name&amp;gt;.&amp;lt;namespace&amp;gt;.svc.cluster.local&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;From the example above, this record would take the form:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mysql.myapp.svc.cluster.local&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;These records may be used for service discovery from within the cluster. They
may be used to address services across namespaces as well as within the same
namespace. In the case of intra-namespace resolution, they may be addressed with
just the short name of the record.&lt;/p&gt;
&lt;p&gt;When a service type is not specified, ClusterIP is the default.&lt;/p&gt;
&lt;h3 id=&#34;nodeport&#34;&gt;NodePort&lt;/h3&gt;
&lt;p&gt;NodePort services provide a mechanism for exposing services to external
entities. In this case, a high port will be opened on all Nodes in the cluster.
The range from which this port will be allocated may be specified through the
&lt;code&gt;--service-node-port-range&lt;/code&gt; &lt;code&gt;kube-api-server&lt;/code&gt; configuration parameter. The
default port range can be consulted in the
&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#nodeport&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;official documentation.&lt;/a&gt;
While a valid, unused port that falls within the range may be specified in the
declaration, the most common case calls for the port to be selected
automatically by Kubernetes itself.&lt;/p&gt;
&lt;p&gt;When a NodePort service type is specified, this functionality will build upon
the ClusterIP construct. In other words, when specified, NodePort will
instantiate the functionality of both NodePort as well as ClusterIP. An external
user will be able to address an in-cluster service by connecting to any single
node in the cluster at the high port which has been dedicated to the service.
Likewise, clients that originate their connection from within the cluster may
utilize either the virtual IP and/or DNS entries provided by the ClusterIP
functionality.&lt;/p&gt;
&lt;p&gt;This functionality can be a critical component for exposing services to external
clients, but it can be a bit cumbersome. An external client would need to know
the IP address of cluster Nodes as well as the ephemeral high port that has been
delegated to the Service. While custom service discovery mechanisms may be
reliably configured with this ephemeral data, in the next section we will
demonstrate how NodePort may be utilized to front Services with an external load
balancer.&lt;/p&gt;
&lt;p&gt;Node ports are opened on all Nodes within the cluster. Therefore, there is no
guarantee that your destination Pod is also colocated on that Node. Once the
traffic hits the Node port, it will be forwarded through the ClusterIP service
that may direct it to a Pod on another Node, even if a suitable Pod is running
on that Node. This behavior can be controlled by configuring your Service with
an &lt;code&gt;externalTrafficPolicy&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;An &lt;code&gt;externalTrafficPolicy&lt;/code&gt; denotes if the traffic received is desired to be
routed to node-local or cluster-wide endpoints. The default value for this
parameter is &lt;code&gt;Cluster&lt;/code&gt;, which as described above will forward the NodePort
traffic to any Pod running in the cluster, even if it is running on a Node
different than the one receiving the traffic. When choosing &lt;code&gt;Local&lt;/code&gt; for this
setting, the client source IP is preserved and a second hop to another node is
avoided, but this potentially limits the load-spread across the cluster and
risks imbalanced traffic spreading.&lt;/p&gt;
&lt;h3 id=&#34;loadbalancer&#34;&gt;LoadBalancer&lt;/h3&gt;
&lt;p&gt;The LoadBalancer Service type, again, builds on the foundation provided by the
NodePort and ClusterIP functionality. When this type is specified, both
in-cluster and external access is configured as outlined above. Additionally, an
external load balancer will also be configured to front all of the NodePort
services.&lt;/p&gt;
&lt;p&gt;This Service type requires the cluster is built on top of infrastructure that
provides load balancing functionality. Nearly all cloud IaaS providers (i.e. AWS,
GCP, Azure, etc.), provide support for these services through Kubernetes cloud
provider integrations. Additionally, there are third-party integrations (i.e. F5,
NSX, etc.) that may also provide load balancing functionality that implements
the Kubernetes Service resource.&lt;/p&gt;
&lt;h2 id=&#34;ingress&#34;&gt;Ingress&lt;/h2&gt;
&lt;p&gt;As web-based services continue to grow in popularity, whether those are
user-facing interfaces or REST/GraphQL APIs, it is likely that these types of
applications will constitute the majority of what gets deployed on an average
cluster. With these types of applications, there are a number of features that
are necessary for a production deployment. First and foremost, these
applications will require redundancy, and this is typically achieved by
deploying a number of discreet instances of the web-based application and, in
turn, fronting these with a layer 7 proxy. This reverse proxy will register a
number of upstream instances of the application, ensuring that each is reachable
by way of a health check, and forwarding traffic to healthy upstreams according
to the declared configuration.&lt;/p&gt;
&lt;p&gt;These configurations will provide mechanisms for the traffic to be qualified by
a number of rules before it is forwarded on to the upstream instances of the
application. These rules for evaluation may include conditions such as the value
of the &lt;code&gt;Host&lt;/code&gt; header in the HTTP request, as well as the specific paths that are
being requested. Once a rule has evaluated to a known upstream, the traffic may
be passed as-is or forwarded on with specified modifications (i.e. header
changes, path rewrites, etc).&lt;/p&gt;
&lt;p&gt;Kubernetes provides a mechanism for easy configuration of an in-cluster reverse
proxy deployment with its Ingress resource. This resource serves as a generic
configuration for nearly any reverse proxy. As Pods for a Service scale up or
down (again, these are determined by label selectors), the Ingress controller
will, in turn, add or remove the Pod&amp;rsquo;s IP from the pool of upstream Endpoints.
Endpoints for a Service may be queried with the &lt;code&gt;kubectl get endpoints&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/service-routing-ingress.png&#34; alt=&#34;Service Routing Ingress&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Some proxies, however, also provide functionality above and beyond what would be
considered a common feature set. In this case, custom features may be
supplemented with annotations on the resource.&lt;/p&gt;
&lt;p&gt;In addition to specific implementation details, annotations may be utilized for
adjacent and/or complementary functionality. For instance, with the
&lt;a href=&#34;https://github.com/jetstack/cert-manager&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;cert-manager&lt;/a&gt; project, annotations
are placed on an Ingress resource so that the reverse proxy may secure the
deployment with TLS certificates.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;test-ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nginx.ingress.kubernetes.io/rewrite-target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/testpath&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As with any Kubernetes controller, a user may declare a desired state and the
controller is responsible for reconciling that configuration towards that
desired state. The case for Ingress controllers is no different. The controller
will watch for any updates to the full collection of Ingress objects and, in
turn, configure the reverse proxy to reflect the desired state. In the case of
proxies such as nginx, this will amount to the controller writing a collection
of nginx configuration files, and reloading the nginx service. Alternatively,
with more modern proxies (e.g. Envoy managed by the Contour Controller),
upstreams and other configurations may be manipulated with an API, and thus do
not require reloads. This functionality is advantageous as it will not disrupt
any in-flight connections.&lt;/p&gt;
&lt;h2 id=&#34;service-mesh&#34;&gt;Service Mesh&lt;/h2&gt;
&lt;p&gt;As mentioned earlier, natively, Kubernetes service routing is concerned with
providing the layer 3 and 4 plumbing that will connect a client to a network
service that is being served from within the cluster. There is, however, a
desire amongst the industry to provide additional routing capabilities. While
layer 3 and 4 can provide adequate mechanisms for connectivity, it is incapable
of providing any data or features for application-centric concerns. As one
extends into the higher layers, we can start to change the way we deploy and
observe these applications.&lt;/p&gt;
&lt;p&gt;Service mesh deployments make use of the native Kubernetes service constructs,
but layer on features implemented with layers 5 through 7. Some of the features
afforded by service mesh controllers include mutual TLS, tracing, circuit
breaking, dynamic routing, rate limiting, load balancing, and more. This is
typically implemented by placing lightweight proxies at application boundaries
within the Kubernetes cluster. Specifically, in the case of projects like
&lt;a href=&#34;https://istio.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Istio&lt;/a&gt; this is accomplished by automatically attaching an
Envoy proxy container to all Pods. Envoy, when deployed in this way, can provide
the features mentioned above. This does, however, come at the price of
additional resource utilization.&lt;/p&gt;
&lt;p&gt;While service mesh implementations are relatively nascent in the wild, it is
quickly becoming a must-have feature set. And, we fully expect that service mesh
deployments will continue to expand in size and scope. Let&amp;rsquo;s review some of the
common service mesh features.&lt;/p&gt;
&lt;h3 id=&#34;mutual-tls&#34;&gt;Mutual TLS&lt;/h3&gt;
&lt;p&gt;Mutual TLS provides some very attractive features for application developers and
platform operators alike. As with most deployments, there will be requirements
for adhering to security constraints before going to production. One of the most
popular requests is that all network traffic should be encrypted. While this may
be achieved with some CNI implementations, many do not provide this type of
overlay capability. Regardless of what the nature of our network fabric looks
like, we can provide this capability seamlessly with a service mesh operating at
layer 5 and 7 of the OSI model.&lt;/p&gt;
&lt;p&gt;In addition to the requirement that all traffic be encrypted, mutual TLS also
provides service-to-service identity. In other words, we can ensure that only
services that we have been authorized to transact with one another may do so. Of
course we can implement firewall policies that would also provide similar
capabilities, but these are not nearly as advanced as what TLS can provide.
Firewall rules merely indicate which IP and port combinations may initiate and
complete connections. Mutual TLS, however, can ensure cryptographically which
layer 7 connections will be able to be initiated and completed.&lt;/p&gt;
&lt;h3 id=&#34;tracing&#34;&gt;Tracing&lt;/h3&gt;
&lt;p&gt;In dynamic environments like Kubernetes, there is often a desire to understand
how microservices are connected to one another. Not only are we concerned with
what services speak to each other, we are also concerned with understanding to
what degree they do so. How many connections are there, and how frequently? Or,
are there some service-to-service connections that are slower than others?&lt;/p&gt;
&lt;p&gt;Due to service mesh-placed proxies alongside the application, we can now
automatically add Open Tracing headers to help us understand how services
interact. And, this is precisely how tracing works with service mesh
technologies: headers are placed on intra-service traffic, and may then be
analyzed by tools such as &lt;a href=&#34;https://jaegertracing.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Jaeger&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;circuit-breaking&#34;&gt;Circuit Breaking&lt;/h3&gt;
&lt;p&gt;Circuit breaking allows for advanced patterns concerning failure detection. Now,
instead of relying on the, relatively simplistic, health checks offered by layer
3 and layer 4 (i.e. can we connect?), we can now programmatically remove
upstreams based on more qualified data. Because service mesh operates at the
application layer, we can add criteria concerning HTTP status codes, response
times, number of pending requests and the like. Utilizing application data in
this way helps to provide a better end-user experience.&lt;/p&gt;
&lt;h3 id=&#34;advanced-request-routing&#34;&gt;Advanced Request Routing&lt;/h3&gt;
&lt;p&gt;Service mesh implementations also allow for routing traffic based upon policy
that extend above and beyond what is capable with native Kubernetes constructs
alone. Advanced patterns, such as canary, weighted, and/or blue/green
deployments, are available through service mesh-specific resource types.
Likewise, this capability also enables advanced development patterns. Users may
be directed to specific application instances based on designated headers and
even the request&amp;rsquo;s attached user identity.&lt;/p&gt;
&lt;h3 id=&#34;load-balancing&#34;&gt;Load Balancing&lt;/h3&gt;
&lt;p&gt;While Kubernetes Ingress controllers are implemented with load balancing reverse
proxies, service mesh is capable of providing features above what is typically
provided by these third-party controllers. Whereas most Ingress controllers are
a bit limited with regard to how they maybe configured through the Ingress
resource type, service mesh provides additional resource types that allow a user
to be more expressive. Service mesh also typically provides for some advanced
capabilities like locality-based balancing, with failover based upon priority
designations.&lt;/p&gt;
&lt;h2 id=&#34;popular-tooling-and-approaches&#34;&gt;Popular Tooling and Approaches&lt;/h2&gt;
&lt;h3 id=&#34;ingress-1&#34;&gt;Ingress&lt;/h3&gt;
&lt;h4 id=&#34;nginx-ingress-controller&#34;&gt;NGINX Ingress Controller&lt;/h4&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;NGINX Ingress Controller&lt;/a&gt; is
the most commonly deployed Ingress controller within the Kubernetes ecosystem.
It is maintained in the open as a Kubernetes community project. It is built on
the decades-old NGINX reverse proxy and, is therefore, well understood and a
technology that many organizations have already operationalized and/or have
familiarity with.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Broad adoption.&lt;/li&gt;
&lt;li&gt;Well-tested in production scenarios.&lt;/li&gt;
&lt;li&gt;Extends the Ingress resource with dozens of implementation-specific
annotations.&lt;/li&gt;
&lt;li&gt;Functionality may be extended with Lua scripting.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Technology is not well-suited for highly dynamic environments.
&lt;ul&gt;
&lt;li&gt;All Ingress changes require that NGINX reloads the process in order to apply
the changes. This may have a detrimental impacts on in-flight connections.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;contour&#34;&gt;Contour&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://projectcontour.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Contour&lt;/a&gt; is an Ingress controller that is developed
and maintained by VMware. Built on top of the
&lt;a href=&#34;https://www.envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Envoy&lt;/a&gt; proxy from Lyft. It offers a performant,
cloud native solution for Ingress control.&lt;/p&gt;
&lt;p&gt;Because Envoy is configurable via gRPC APIs, this means that new route
configurations may be applied dynamically and without disrupting any in-flight
connections.&lt;/p&gt;
&lt;p&gt;Contour adds a Custom Resource Definition called HTTPProxy, which enables
advanced capabilities that may not be expressed with Ingress normally. Features
such as route delegation, multi-service routes, weighted endpoints, and load
balancing strategies allow end users to craft highly-specific application
rollout patterns, thus further enabling CI/CD.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Built on top of Envoy, a highly performant and scalable reverse proxy.&lt;/li&gt;
&lt;li&gt;Ingress configuration is applied via an API; not static configuration files.&lt;/li&gt;
&lt;li&gt;Extends Ingress control to support multi-team environments.
&lt;ul&gt;
&lt;li&gt;HTTPProxy provides richer configuration than is available with the Ingress
resource alone. Some of these extended features include weighted routes
and specification of load balancing strategies without the use of
annotations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Relatively new within the ecosystem, only reaching GA recently.
&lt;ul&gt;
&lt;li&gt;Features that already exist for other Ingress controllers may not yet be
available for Contour.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;traefik&#34;&gt;Traefik&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://containo.us/traefik/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Traefik&lt;/a&gt; bills itself as the &amp;ldquo;Cloud Native Edge
Router.&amp;rdquo; While we have seen limited numbers of deployments leveraging Traefik,
it has often been utilized in cases where other solutions did not provide
equivalent functionality. Specifically, features like header-based routing have
been implemented with Traefik in the past, but as this functionality becomes
more commonplace, the need for Traefik to fill this gap will likely diminish.&lt;/p&gt;
&lt;p&gt;Traefik is supported by &lt;a href=&#34;https://containo.us&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Containous&lt;/a&gt; and is developed as
open source software.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Has some extended features that may not be available with other Ingress
solutions.&lt;/li&gt;
&lt;li&gt;Seamless integrations with services such as Let&amp;rsquo;s Encrypt&lt;/li&gt;
&lt;li&gt;Full-featured dashboard&lt;/li&gt;
&lt;li&gt;Multi-platform support beyond Kubernetes alone.
&lt;ul&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Rancher&lt;/li&gt;
&lt;li&gt;Marathon&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Has not seen strong traction within the community.&lt;/li&gt;
&lt;li&gt;Deep feature list, but configuration can be a bit complicated.&lt;/li&gt;
&lt;li&gt;Some Enterprise features are not open sourced.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;service-mesh-1&#34;&gt;Service Mesh&lt;/h3&gt;
&lt;h4 id=&#34;linkerd&#34;&gt;Linkerd&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://linkerd.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Linkerd&lt;/a&gt; is an ultra lightweight service mesh for
Kubernetes. It provides end users with the features that they would expect from
a service mesh solution: runtime debugging, observability, reliability, and
security. Linkerd is a fully open source solution falling under the Apache 2
license.&lt;/p&gt;
&lt;p&gt;Features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP, HTTP/2, and gRPC Proxying&lt;/li&gt;
&lt;li&gt;TCP Proxying and Protocol Detection&lt;/li&gt;
&lt;li&gt;Retries and Timeouts&lt;/li&gt;
&lt;li&gt;Automatic mTLS&lt;/li&gt;
&lt;li&gt;Ingress&lt;/li&gt;
&lt;li&gt;Telemetry and Monitoring&lt;/li&gt;
&lt;li&gt;Automatic Proxy Injection&lt;/li&gt;
&lt;li&gt;Dashboard and Grafana&lt;/li&gt;
&lt;li&gt;Distributed Tracing&lt;/li&gt;
&lt;li&gt;Fault Injection&lt;/li&gt;
&lt;li&gt;High Availability&lt;/li&gt;
&lt;li&gt;Service Profiles&lt;/li&gt;
&lt;li&gt;Traffic Split (canaries, blue/green deploys)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lightweight service mesh solution which requires absolutely no changes to
application code.&lt;/li&gt;
&lt;li&gt;Contains all of the features that would be expected from a service mesh
solution.&lt;/li&gt;
&lt;li&gt;Was one of the first service mesh options and is quite mature as a result.&lt;/li&gt;
&lt;li&gt;Recently rewritten in the aim of improving performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linkerd doesn&amp;rsquo;t provide an Ingress Controller. The &lt;a href=&#34;https://linkerd.io/2/tasks/using-ingress/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;project
documentation&lt;/a&gt; has information
about integrating with Nginx, Contour, and others. This means Linkerd requires
managing Ingress as additional operational overhead.&lt;/li&gt;
&lt;li&gt;Traffic splitting syntax can be cumbersome.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;istio&#34;&gt;Istio&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://istio.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Istio&lt;/a&gt; is perhaps the most popular service mesh offering
today. It is an open source project that is being maintained by Google, IBM, and
Red Hat. Just as with Linkerd, it has dozens of features that one would expect
to see in a service mesh solution.&lt;/p&gt;
&lt;p&gt;Istio makes it easy to create a network of deployed services with load
balancing, service-to-service authentication, monitoring, and more, with few or
no code changes in service code. You add Istio support to services by deploying
a special sidecar proxy throughout your environment that intercepts all network
communication between microservices, then configure and manage Istio using its
control plane functionality, which includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatic load balancing for HTTP, gRPC, WebSocket, and TCP traffic.&lt;/li&gt;
&lt;li&gt;Fine-grained control of traffic behavior with rich routing rules, retries,
failovers, and fault injection.&lt;/li&gt;
&lt;li&gt;A pluggable policy layer and configuration API supporting access controls,
rate limits and quotas.&lt;/li&gt;
&lt;li&gt;Automatic metrics, logs, and traces for all traffic within a cluster,
including cluster ingress and egress.&lt;/li&gt;
&lt;li&gt;Secure service-to-service communication in a cluster with strong
identity-based authentication and authorization.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Istio has a huge amount of momentum behind it. It is currently the most
popular service mesh offering on the market.&lt;/li&gt;
&lt;li&gt;It forms the basis of VMware&amp;rsquo;s NSX-SM solution.&lt;/li&gt;
&lt;li&gt;It is extraordinarily full-featured, but this also creates a large degree of
complexity.&lt;/li&gt;
&lt;li&gt;Istio may be used as both an Ingress and a service mesh with the Ingress
Gateway feature.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Istio does not have an open governance model. Its steering committee is run by
IBM, Google, and Red Hat.&lt;/li&gt;
&lt;li&gt;Istio is in rapid development and many features are at various levels of
stability, some of which may not be suitable for production.&lt;/li&gt;
&lt;li&gt;Configuration can be extraordinarily complex.&lt;/li&gt;
&lt;li&gt;You may be required to leverage the Istio ingress controller exclusively in
order to leverage the features you are interested in.&lt;/li&gt;
&lt;li&gt;The complexity that Istio introduces to a Kubernetes deployment often mandates
a team dedicated to its operation and support.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Storage Integration</title>
      
      <link>/guides/kubernetes/storage-integration/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/storage-integration/</guid>
      <description>

        
        &lt;p&gt;Core Kubernetes does not concern itself with storage integration. At most, it
provides a set of APIs, &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Persistent
Volumes&lt;/a&gt;,
&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Persistent Volume
Claims&lt;/a&gt;,
and &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/storage-classes&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Storage
Classes&lt;/a&gt;. By
default, containers can use their own ephemeral storage system and/or leverage
host storage. Both of these solutions are typically inadequate for enterprise
workloads. Ephemeral storage goes away if the container dies. Host storage ties
the container to a specific host and (depending on how you access host storage)
it can be insecure in multi-tenant environments.&lt;/p&gt;
&lt;p&gt;The model used by most enterprise platforms is to introduce a provider that can
enable dynamic provisioning of volumes for workloads requiring some amount of
persistence. Integration to providers is typically accomplished through a
container storage interface (CSI) plugin. The following demonstrates the
relationship.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/storage-integration/diagrams/dynamic-storage-provisioning.png&#34; alt=&#34;Dynamic Storage Provisioning&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;There is high variance in how the above works based on the provider. Some
providers create multiple PVs ahead of time and make them available to workloads.
The above is only meant to give a conceptual overview of how the flow might
work.&lt;/p&gt;
&lt;h3 id=&#34;container-storage-interface-csi&#34;&gt;Container Storage Interface (CSI)&lt;/h3&gt;
&lt;p&gt;Kubernetes uses the &lt;a href=&#34;https://github.com/container-storage-interface/spec&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;container storage
interface&lt;/a&gt; (CSI) to provide
storage functionality to containers. Storage is implemented in CSI plugins. This
interface / plugin model enables Kubernetes to support many storage options
implemented via plugins (or drivers) such as
&lt;a href=&#34;https://github.com/kubernetes-sigs/vsphere-csi-driver&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;vSphere&lt;/a&gt;,
&lt;a href=&#34;https://dell.github.io/storage-plugin-docs/docs/dell-csi-driver/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;DellEMC&lt;/a&gt;,
&lt;a href=&#34;https://github.com/libopenstorage/openstorage/tree/master/csi&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;portworx&lt;/a&gt;, &lt;a href=&#34;https://github.com/kubernetes-sigs/aws-ebs-csi-driver&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;AWS
EFS&lt;/a&gt;, and
&lt;a href=&#34;https://github.com/NetApp/trident&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;NetApp&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A more complete list is available in the &lt;a href=&#34;https://kubernetes-csi.github.io/docs/drivers.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;CSI driver documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Prior to standardization around CSI, the implementation of storage integrations
had high-variance across providers. There are two common models for running
storage drivers in Kubernetes. These are through cloud providers and dedicated
storage providers. Cloud providers (such as AWS and vSphere) package their
storage driver into the provider, so that it can handle all the integration
points such as provisioning load balancers and storage volumes. Dedicated
integrations run as independent processes managing only storage. Below you&amp;rsquo;ll
find explanations on each.&lt;/p&gt;
&lt;h3 id=&#34;in-tree-providers&#34;&gt;In-tree Providers&lt;/h3&gt;
&lt;p&gt;Historically, Kubernetes relied on in-tree &amp;ldquo;cloud&amp;rdquo; provider functionality for
most storage integration. This method of integration predates CSI. These
providers are referred to as in-tree because &lt;a href=&#34;https://github.com/kubernetes/kubernetes/tree/v1.18.0-alpha.2/pkg/cloudprovider&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;their code lives in the core
kubernetes/kubernetes
repo&lt;/a&gt;.
With this model, every Kubernetes cluster has cloud provider logic in it, even
if it wasn&amp;rsquo;t activated. In a cluster integrated with vCenter, the
kube-apiserver, controller-manager, and kubelet will look as follows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/storage-integration/diagrams/in-tree-provider.png&#34; alt=&#34;In-tree provider&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;As you can imagine, shipping these components with cloud-provider logic for
every cut of Kubernetes is not a good model. Additionally, the in-tree model
does not allow you to update the provider without updating your cluster. In-tree
providers have been deprecated and are planned to be removed. You should &lt;strong&gt;not&lt;/strong&gt;
use an in-tree provider for storage integration of your platform.&lt;/p&gt;
&lt;h3 id=&#34;out-of-tree-providers&#34;&gt;Out-of-tree Providers&lt;/h3&gt;
&lt;p&gt;Out-of-tree providers encapsulate cloud-provider logic in a controller. This
controller is commonly referred to as a cloud-controller-manager (CCM). The CCM
is deployed to your cluster and interacts with the cloud-provider&amp;rsquo;s APIs. The
storage driver (CSI-plugin) often runs outside of the CCM, but can require the
CCM to function correctly. In the case of vSphere, you install 3 components.&lt;/p&gt;





&lt;table class=&#34;table&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Cloud Controller Manager&lt;/td&gt;
&lt;td&gt;&lt;code&gt;vsphere-cloud-controller&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deployment&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Storage Controller&lt;/td&gt;
&lt;td&gt;&lt;code&gt;vsphere-csi-controller&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;StatefulSet&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Storage Driver (CSI-plugin)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;vsphere-csi-node&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;DaemonSet&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;With these components installed, a 4 node Kubernetes cluster (assuming 1 master)
would look as follows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/storage-integration/diagrams/out-of-tree-provider-and-csi.png&#34; alt=&#34;Out-of-tree provider&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;dedicated-storage-integrations&#34;&gt;Dedicated Storage Integrations&lt;/h3&gt;
&lt;p&gt;Some storage providers have nothing to do with cloud-provider integration. In
this case they run their integrations / drivers as isolated processes (pods in
Kubernetes). An example of this model is NetApp&amp;rsquo;s
&lt;a href=&#34;https://netapp-trident.readthedocs.io/en/stable-v19.10/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Trident&lt;/a&gt; integration.
Running trident in a cluster will provision volumes against its supported
providers, such as NetApp&amp;rsquo;s SolidFire. It also handles concerns around backup
and recovery. Another common project that follows this model is
&lt;a href=&#34;https://rook.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;rook&lt;/a&gt;, which provides integration with providers like Ceph and
NFS.
Also, Dell EMC &lt;a href=&#34;https://github.com/dell/karavi&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Container Storage Modules&lt;/a&gt; (formerly known as Karavi)
enriches CSI with enterprise storage capabilities such as Authorization, Resiliency and others.&lt;/p&gt;
&lt;h3 id=&#34;option-considerations&#34;&gt;Option Considerations&lt;/h3&gt;
&lt;p&gt;There is no shortage of CSI-plugin options. For your environment, the decision
may be easy because you only have one type of storage available to you, for
example vSAN. However, if you&amp;rsquo;re thinking about integrating a new storage
provider, it&amp;rsquo;s important that you consider the storage offerings and resiliency
guarantees your platform needs to offer. Some key considerations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What I/O speeds are required for platform workloads?&lt;/li&gt;
&lt;li&gt;What disaster scenarios does the persistence layer need to handle?&lt;/li&gt;
&lt;li&gt;How many workloads will need persistent storage?
&lt;ul&gt;
&lt;li&gt;How much storage do you need and what are your expansion requirements?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Do you need to offer dynamic volume resizing if a workload uses up its
storage?&lt;/li&gt;
&lt;li&gt;What backup scenarios (if any) do you plan to offer?
&lt;ul&gt;
&lt;li&gt;Alternatively, do you plan to make the application teams responsible for
their backups?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;What storage system can you realistically operate? Ceph? vSAN?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Having conversations around these points will help you determine the best
storage integration for you.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Backing Up, Restoring, and Migrating Resources with Velero</title>
      
      <link>/guides/kubernetes/what-is-velero/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/what-is-velero/</guid>
      <description>

        
        &lt;p&gt;Velero is an open source tool for safely backing up and restoring resources in a Kubernetes cluster, performing disaster recovery, and migrating resources and persistent volumes to another Kubernetes cluster.&lt;/p&gt;
&lt;p&gt;Velero offers key data protection features, such as scheduled backups, retention schedules, and pre- or post-backup hooks for custom actions. Velero can help protect data stored in persistent volumes and makes your entire Kubernetes cluster more resilient.&lt;/p&gt;
&lt;h1 id=&#34;velero-use-cases&#34;&gt;Velero Use Cases&lt;/h1&gt;
&lt;p&gt;Here are some of the things Velero can do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Back up your cluster and restore it in case of loss.&lt;/li&gt;
&lt;li&gt;Recover from disaster.&lt;/li&gt;
&lt;li&gt;Copy cluster resources to other clusters.&lt;/li&gt;
&lt;li&gt;Replicate your production environment to create development and testing environments.&lt;/li&gt;
&lt;li&gt;Take a snapshot of your application&amp;rsquo;s state before upgrading a cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;velero-components-and-architecture&#34;&gt;Velero Components and Architecture&lt;/h1&gt;
&lt;p&gt;Velero consists of two main components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A server that runs on your cluster&lt;/li&gt;
&lt;li&gt;A command-line utility that runs locally&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Velero supports plug-ins to enable it to work with different storage systems and Kubernetes platforms. You can run Velero in clusters on a cloud provider or on premises.&lt;/p&gt;
&lt;h1 id=&#34;how-velero-works&#34;&gt;How Velero Works&lt;/h1&gt;
&lt;p&gt;Each Velero operation&amp;ndash;on-demand backup, scheduled backup, restoration&amp;ndash;is a custom resource that is defined with a Kubernetes custom resource definition, or CRD, and stored in &lt;code&gt;etcd&lt;/code&gt;. Velero includes controllers that process the CRDs to back up and restore resources. You can back up or restore all objects in your cluster, or you can filter objects by type, namespace, or label.&lt;/p&gt;
&lt;p&gt;Data protection is a chief concern for application owners who want to make sure that they can restore a cluster to a known good state, recover from a crashed cluster, or migrate to a new environment. Velero provides those capabilities.&lt;/p&gt;
&lt;h3 id=&#34;keep-learning&#34;&gt;Keep Learning&lt;/h3&gt;
&lt;p&gt;On the &lt;a href=&#34;https://velero.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Velero home page&lt;/a&gt; you can get information on the latest release and download Velero from Github.&lt;/p&gt;
&lt;p&gt;To get started using Velero read our guide, &lt;a href=&#34;/guides/kubernetes/velero-gs&#34;&gt;Getting Started with Velero&lt;/a&gt;, and watch these videos covering two of Velero’s useful features, &lt;a href=&#34;https://kube.academy/courses/cluster-operations/lessons/backuprestore&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Backup and Restore&lt;/a&gt;, and &lt;a href=&#34;https://www.youtube.com/watch?v=q2FCxheA8VI&amp;amp;list=PL7bmigfV0EqQRysvqvqOtRNk4L5S7uqwM&amp;amp;index=5&amp;amp;t=0s&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Migration&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Workload Tenancy</title>
      
      <link>/guides/kubernetes/workload-tenancy/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/workload-tenancy/</guid>
      <description>

        
        &lt;p&gt;Kubernetes is an inherently multi-tenant system. The term tenant can
have many meanings. For the purpose of this page, we consider a workload (e.g.
Kubernetes pod) to be a tenant. In most Kubernetes environments, pods are
scheduled alongside other pods on the same hosts. Kubernetes has features that
provide the illusion of workload boundaries such as namespaces. However, odds
are pods in different namespaces will run together on the same host.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/k8s-workers-tenancy.png&#34; alt=&#34;Worker Tenancy&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;With multiple tenants running on hosts, there are several concerns to account
for.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resource isolation between pods.&lt;/li&gt;
&lt;li&gt;Workload scheduling decisions based on resource requests.&lt;/li&gt;
&lt;li&gt;Workload scheduling decisions based on host properties.&lt;/li&gt;
&lt;li&gt;Priority of workloads (e.g. removing workloads for more important ones).&lt;/li&gt;
&lt;li&gt;Preventing cross-workload access to memory or data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes provides constructs to ensure workloads run well side-by-side. These
configuration options have significant depth and can be especially challenging
in environments where multiple teams are consumers. Additionally, platform teams
often want to reduce cost by overcommitting resources on nodes. Without these
constructs in place, workloads will run over each other and incur platform
instability.&lt;/p&gt;
&lt;h2 id=&#34;resource-limits-and-requests&#34;&gt;Resource Limits and Requests&lt;/h2&gt;
&lt;p&gt;For resource contention, limits and requests are the most important concepts to
understand. An example snippet of a pod setting a resource limit and request is
as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;frontend&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;64Mi&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;250m&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;128Mi&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;500m&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;limits&#34;&gt;Limits&lt;/h3&gt;
&lt;p&gt;Limits are enforced on the host level. This means that a container can not use
more than its allotted resource limit. For CPU, throttling occurs when a process
exceeds its limit. For memory, a workload is killed when it exceeds its limit.&lt;/p&gt;
&lt;h3 id=&#34;request&#34;&gt;Request&lt;/h3&gt;
&lt;p&gt;Requests are used by the scheduler to make scheduling decisions based on desired
resources and availability. Requests are generally not enforced on the host. For
memory, a pod can use more than its requested amount. If the node comes under
contention, the pod may be killed. For CPU, requests are translated into CPU
shares. This means the pod can use more than its requested CPU, but if the node
comes under contention, CPU may be throttled to only what was requested.&lt;/p&gt;
&lt;h3 id=&#34;quality-of-service&#34;&gt;Quality of Service&lt;/h3&gt;
&lt;p&gt;Based on what is configured above, pods automatically get marked with a specific
quality of service.&lt;/p&gt;





&lt;table class=&#34;table&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;QoS&lt;/th&gt;
&lt;th&gt;Condition&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Best Effort&lt;/td&gt;
&lt;td&gt;No request or limit set&lt;/td&gt;
&lt;td&gt;Pod is scheduled and uses any available resources to the host.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Guaranteed&lt;/td&gt;
&lt;td&gt;Limits == Requests&lt;/td&gt;
&lt;td&gt;The amount of resources a pod is scheduled for equals what its able to consume on the host. If the host comes under contention, the pod could be throttled or killed.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Burstable&lt;/td&gt;
&lt;td&gt;Limits &amp;gt; Requests&lt;/td&gt;
&lt;td&gt;A pod can &amp;ldquo;burst&amp;rdquo; beyond its resource request but not above its limit. If the host comes under contention, the pod could be throttled or killed.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;popular-tooling-and-approaches&#34;&gt;Popular Tooling and Approaches&lt;/h2&gt;
&lt;p&gt;This section covers a multitude of configuration and our recommendations for
each. For an in-depth guide on tuning these parameters, see the &lt;a href=&#34;../workload-tenancy-cluster-tuning&#34;&gt;Cluster Tuning
Guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;guaranteed-pods&#34;&gt;Guaranteed Pods&lt;/h3&gt;
&lt;p&gt;Guaranteed pods are created when only &lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#how-pods-with-resource-limits-are-run&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Resource
limits&lt;/a&gt;
are set. Resource limits are enforced on the host level. CPU limits enforce
throttling when the limit is reached. Memory limits kill the workload when the
limit is exceeded. In the absence of resource requests, the request is
automatically set to that of the limit. This can be a good model as it ensures
the amount of resources the workload is scheduled for is exactly the amount that
will be available on the host (i.e. no overcommitting). This decreases the
complexity of workloads. The downside to only using limits is you cannot
overcommit resources. An example of overcommitting is where you set a limit
higher than a request, which means the container can use more than is requested,
unless the host comes under contention.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/guaranteed-pods.png&#34; alt=&#34;Guaranteed Pods&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improved stability
&lt;ul&gt;
&lt;li&gt;Eliminates resource contention between workloads&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduced infra utilization
&lt;ul&gt;
&lt;li&gt;May result in underutilized compute resources&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can lead to CPU throttling and OOM kills
&lt;ul&gt;
&lt;li&gt;Important to understand resource consumption profile of workloads&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;burstable-pods&#34;&gt;Burstable Pods&lt;/h3&gt;
&lt;p&gt;An advanced use case of cluster resource allocation is to allow pods to burst
beyond their resource requests and provide a high upper bounds. This enables
nodes to be overcommitted, where more workloads are scheduled than could be
handled should they all consume 100% of their CPU and memory resource requests.
This model can be complex to implement correctly, but also can be the most cost
effective.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/burstable-pod.png&#34; alt=&#34;Burstable Pods&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;When a host comes under contention, CPU is throttled back to the CPU shares
allocated via the resource request. Once resources free up, containers are able
to consume the unused resources again.&lt;/p&gt;
&lt;p&gt;We recommend you &lt;strong&gt;do not&lt;/strong&gt; overcommit memory. Overcommitting memory can cause
instability in workloads as they are killed when the host comes under resource
contention.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Possibly improved infra resource utilization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Potential for resource contention&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pod-disruption-budgets&#34;&gt;Pod Disruption Budgets&lt;/h3&gt;
&lt;p&gt;During the life of a Kubernetes cluster, there are many voluntary events, which
can impact workloads. An example would be draining specific nodes to perform
maintenance. &lt;code&gt;PodDisruptionBudget&lt;/code&gt;s (PDB) allow you to set a minimum number of
instances available for your application to ensure Kubernetes blocks before
continuing with an operation that would break that PDB.&lt;/p&gt;
&lt;p&gt;For any workload that requires a minimum number of instances running, this is
recommended.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improved stability through availability guarantees&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Potential to stall upgrades
&lt;ul&gt;
&lt;li&gt;If cluster resources are under contention, an upgrade may stall to respect
the disruption budget&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;limit-ranges&#34;&gt;Limit Ranges&lt;/h3&gt;
&lt;p&gt;A &lt;code&gt;LimitRange&lt;/code&gt; sets the maximum or minimum resource limits and requests a pod
can be declared to use. It also allows for configuring default values, should a
pod be submitted without these setting in place. The &lt;code&gt;LimitRange&lt;/code&gt; is namespace
scoped and recommended for administrators to enforce a sensible default and
limit per-pod.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provides &amp;ldquo;guardrails&amp;rdquo; for development teams&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Possibly confusing for tenants that don&amp;rsquo;t know how resource values are being set&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;resource-quotas&#34;&gt;Resource Quotas&lt;/h3&gt;
&lt;p&gt;A &lt;code&gt;ResourceQuota&lt;/code&gt; enables an administrator to set the aggregate resources
available to a given namespace. It also enables the administrator to limit the
number of objects that can be created within the namespace, which is referred to
as object count quota.&lt;/p&gt;
&lt;p&gt;Below are some of the resources that can be placed under object count quota:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;count/persistentvolumeclaims&lt;/li&gt;
&lt;li&gt;count/services&lt;/li&gt;
&lt;li&gt;count/secrets&lt;/li&gt;
&lt;li&gt;count/configmaps&lt;/li&gt;
&lt;li&gt;count/replicationcontrollers&lt;/li&gt;
&lt;li&gt;count/deployments.apps&lt;/li&gt;
&lt;li&gt;count/replicasets.apps&lt;/li&gt;
&lt;li&gt;count/statefulsets.apps&lt;/li&gt;
&lt;li&gt;count/jobs.batch&lt;/li&gt;
&lt;li&gt;count/cronjobs.batch&lt;/li&gt;
&lt;li&gt;count/deployments.extensions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For multi-team environments, these constraints can be beneficial to enforce.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provides controls over resource consumption&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can be over-restrictive in single-tenant environments&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Platform Readiness Checklist</title>
      
      <link>/guides/kubernetes/workload-tenancy-platform-checklist/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/workload-tenancy-platform-checklist/</guid>
      <description>

        
        &lt;p&gt;This list is a starting place for considerations about the Kubernetes platform
running your applications. It is not exhaustive and should be expanded based on
your requirements.&lt;/p&gt;
&lt;h3 id=&#34;required&#34;&gt;Required&lt;/h3&gt;

&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;etcd is highly available&#34;&gt;
  &lt;label for=&#34;etcd is highly available&#34;&gt;
    &lt;h4&gt;etcd is highly available&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;It is important to configure etcd with high availability to minimize the risk of
data loss. Ensure a minimum of three nodes are running and are placed in
different fault domains.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;etcd cluster is healthy&#34;&gt;
  &lt;label for=&#34;etcd cluster is healthy&#34;&gt;
    &lt;h4&gt;etcd cluster is healthy&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Ensure the members of your etcd cluster are healthy. The below commands give you
a glimpse of the status of your cluster.&lt;/p&gt;
&lt;p&gt;Note the need to substitute the node IP&amp;rsquo;s for x, y and z below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt --key=/etc/kubernetes/pki/etcd/healthcheck-client.key member list

ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt --key=/etc/kubernetes/pki/etcd/healthcheck-client.key --endpoints=https://x:2379,https://y:2379,https://z:2379 endpoint health
https://x:2379 is healthy: successfully committed proposal: took = 9.969618ms
https://y:2379 is healthy: successfully committed proposal: took = 10.675474ms
https://z:2379 is healthy: successfully committed proposal: took = 13.338815ms
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;A Backup/restore strategy is outlined&#34;&gt;
  &lt;label for=&#34;A Backup/restore strategy is outlined&#34;&gt;
    &lt;h4&gt;A Backup/restore strategy is outlined&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Each cluster is different. Think through and understand what elements of your
cluster need to be backed up and restored in the event of single or multi-node
failure, database corruption or other problems. Consider the applications
running in the platform, the roles and role bindings, persistent storage
volumes, ingress configuration, security and network policies, etc.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;A certificate renewal process is in place&#34;&gt;
  &lt;label for=&#34;A certificate renewal process is in place&#34;&gt;
    &lt;h4&gt;A certificate renewal process is in place&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;All certificates in the cluster have an expiration date. Although it is likely
the cluster will be upgraded/replaced before then, it is still recommended to
have a process to refresh/renew them documented.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Failure domain/availability zones have been considered&#34;&gt;
  &lt;label for=&#34;Failure domain/availability zones have been considered&#34;&gt;
    &lt;h4&gt;Failure domain/availability zones have been considered&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;In both cloud and on-premise installations, the importance of using different
availability zones/failure domains for your control plane nodes is fundamental
to cluster resiliency. Unless there is an architectural redundancy in your
topology (mirror clusters per AZ, or globally load balanced clusters) consider
control plane node location.&lt;/p&gt;

  &lt;/div&gt;

&lt;h3 id=&#34;ingress&#34;&gt;Ingress&lt;/h3&gt;

&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Load balancer is redundant&#34;&gt;
  &lt;label for=&#34;Load balancer is redundant&#34;&gt;
    &lt;h4&gt;Load balancer is redundant&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Your ingress should be configured to run on several pre-defined nodes for
high availability. Configure the load balancer to route traffic to these nodes
accordingly. Test to make sure all defined nodes are getting traffic.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Load balancer throughput meets requirements&#34;&gt;
  &lt;label for=&#34;Load balancer throughput meets requirements&#34;&gt;
    &lt;h4&gt;Load balancer throughput meets requirements&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Testing your cluster for network bottlenecks before going live is a must. Test
your load balancer and ingress throughput capacity to set realistic expectations
from the results obtained.&lt;/p&gt;

  &lt;/div&gt;

&lt;h3 id=&#34;network--cni&#34;&gt;Network / CNI&lt;/h3&gt;

&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Pod to Pod communication works&#34;&gt;
  &lt;label for=&#34;Pod to Pod communication works&#34;&gt;
    &lt;h4&gt;Pod to Pod communication works&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Validate that Pods can communicate with other Pods and that the Services
exposing those Pods correctly route traffic.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Egress communication has been tested&#34;&gt;
  &lt;label for=&#34;Egress communication has been tested&#34;&gt;
    &lt;h4&gt;Egress communication has been tested&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Validate that Pods can reach endpoints outside of the cluster.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;DNS functionality validated&#34;&gt;
  &lt;label for=&#34;DNS functionality validated&#34;&gt;
    &lt;h4&gt;DNS functionality validated&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Test that containers in the platform can resolve external and internal domains.
Test internal domains with and without &lt;code&gt;.cluster.local&lt;/code&gt; prefix.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Network Policy configuration validated&#34;&gt;
  &lt;label for=&#34;Network Policy configuration validated&#34;&gt;
    &lt;h4&gt;Network Policy configuration validated&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;When applicable, validate that network policies are being enforced as expected.&lt;/p&gt;
&lt;p&gt;More information on designing a network policy for your cluster can be found in
the
&lt;a href=&#34;../container-networking-network-policy&#34;&gt;Network Policy Implementation&lt;/a&gt;
library document.&lt;/p&gt;

  &lt;/div&gt;

&lt;h3 id=&#34;capacity&#34;&gt;Capacity&lt;/h3&gt;

&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Nodes can be added seamlessly&#34;&gt;
  &lt;label for=&#34;Nodes can be added seamlessly&#34;&gt;
    &lt;h4&gt;Nodes can be added seamlessly&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;The worker node deployment and bootstrap process should be defined and
automated. Ensure new nodes can be seamlessly added to the cluster enabling and
preparing it for growth.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Cluster autoscaling enabled&#34;&gt;
  &lt;label for=&#34;Cluster autoscaling enabled&#34;&gt;
    &lt;h4&gt;Cluster autoscaling enabled&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Cluster autoscaling automatically adjusts the size of the cluster when
insufficient resources are available to run new Pods or nodes have been
underutilized for an extended period of time. When applicable, verify it is
enabled and the expected actions are taken under these conditions.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;ResourceQuotas are defined&#34;&gt;
  &lt;label for=&#34;ResourceQuotas are defined&#34;&gt;
    &lt;h4&gt;ResourceQuotas are defined&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/policy/resource-quotas/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;ResourceQuotas&lt;/a&gt;
provide constraints that limit aggregate consumption of resources per namespace.
They limit the quantity of resources of a given type that can be created. Define
and implement them in the relevant namespaces.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;LimitRanges are defined&#34;&gt;
  &lt;label for=&#34;LimitRanges are defined&#34;&gt;
    &lt;h4&gt;LimitRanges are defined&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/policy/limit-range/#enabling-limit-range&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;LimitRanges&lt;/a&gt;
define default, minimum and maximum memory, CPU and storage utilization per Pod
in a namespace. These should be defined to avoid running unbounded containers.&lt;/p&gt;
&lt;p&gt;You can find more information about this in the
&lt;a href=&#34;../workload-tenancy-cluster-tuning#resource-limits&#34;&gt;resource limits&lt;/a&gt;
section of the cluster tuning library document.&lt;/p&gt;

  &lt;/div&gt;

&lt;h3 id=&#34;monitoring&#34;&gt;Monitoring&lt;/h3&gt;

&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Platform is monitored&#34;&gt;
  &lt;label for=&#34;Platform is monitored&#34;&gt;
    &lt;h4&gt;Platform is monitored&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;The API, controllers, etcd, and worker node health status should be monitored.
Ensure notifications are correctly delivered, and a dead man&amp;rsquo;s switch is
configured and working.&lt;/p&gt;
&lt;p&gt;The Tanzu Labs library contains a
&lt;a href=&#34;../observability-k8s-monitoring-checklist/&#34;&gt;thorough monitoring checklist&lt;/a&gt;
to help you plan your tests accordingly and ensure full coverage.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Containers are monitored&#34;&gt;
  &lt;label for=&#34;Containers are monitored&#34;&gt;
    &lt;h4&gt;Containers are monitored&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;The containers running on the platform should be monitored for performance and
availability. Kubernetes provides liveness and readiness checks, and prometheus
can give you more in-depth information of application performance. Review the
&lt;a href=&#34;../app-enhancements-probing-app-state/&#34;&gt;probing application state&lt;/a&gt;
guide content for details.&lt;/p&gt;

  &lt;/div&gt;

&lt;h3 id=&#34;storage&#34;&gt;Storage&lt;/h3&gt;

&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Test storage classes&#34;&gt;
  &lt;label for=&#34;Test storage classes&#34;&gt;
    &lt;h4&gt;Test storage classes&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Ensure defined storage classes are working as expected. Test them by creating
persistent volume claims to ensure they work as defined. Validate the claims
bind properly and have the expected write permissions.&lt;/p&gt;

  &lt;/div&gt;

&lt;h3 id=&#34;upgrades&#34;&gt;Upgrades&lt;/h3&gt;

&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Define and test the upgrade process&#34;&gt;
  &lt;label for=&#34;Define and test the upgrade process&#34;&gt;
    &lt;h4&gt;Define and test the upgrade process&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Document, automate and test the upgrade process to ensure it is consistent and
repeatable.&lt;/p&gt;
&lt;p&gt;This will help determine the upgrade expected downtime and availability impact
to properly set expectations with application owners.&lt;/p&gt;

  &lt;/div&gt;

&lt;h3 id=&#34;identity&#34;&gt;Identity&lt;/h3&gt;

&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Configure an identity provider&#34;&gt;
  &lt;label for=&#34;Configure an identity provider&#34;&gt;
    &lt;h4&gt;Configure an identity provider&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Verify that the configured identity provider is functional. Test the platform
login process using existing and new users.&lt;/p&gt;
&lt;p&gt;See the &lt;a href=&#34;../identity&#34;&gt;identity and access control&lt;/a&gt; section of the
library for more details.&lt;/p&gt;

  &lt;/div&gt;


&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Define user groups and roles&#34;&gt;
  &lt;label for=&#34;Define user groups and roles&#34;&gt;
    &lt;h4&gt;Define user groups and roles&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Ensure roles and role bindings have been correctly applied to the groups
created.&lt;/p&gt;

  &lt;/div&gt;

&lt;h3 id=&#34;metrics&#34;&gt;Metrics&lt;/h3&gt;

&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Validate metric collection&#34;&gt;
  &lt;label for=&#34;Validate metric collection&#34;&gt;
    &lt;h4&gt;Validate metric collection&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Verify that the metrics aggregation pipeline for the workloads and the platform
is functional. This is a requirement for cluster and pod autoscalers to work.&lt;/p&gt;
&lt;p&gt;The
&lt;a href=&#34;../app-observability-exporting-metrics/&#34;&gt;Platform Monitoring Guide&lt;/a&gt;
goes deep detailing monitoring, alerting and visualizing the metrics collected
by the system.&lt;/p&gt;

  &lt;/div&gt;

&lt;h3 id=&#34;logging&#34;&gt;Logging&lt;/h3&gt;

&lt;div class=&#34;checklist-item&#34;&gt;
  &lt;input type=&#34;checkbox&#34; id=&#34;Validate log aggregation and forwarding&#34;&gt;
  &lt;label for=&#34;Validate log aggregation and forwarding&#34;&gt;
    &lt;h4&gt;Validate log aggregation and forwarding&lt;/h4&gt;
  &lt;/label&gt;
  &lt;p&gt;Verify the container and platform logs are reaching their destination. These can
be stored within the cluster or forwarded to an external system.&lt;/p&gt;

  &lt;/div&gt;


      </description>
    </item>
    
    <item>
      
      <title>Guides: Automated Cluster Acceptance Testing</title>
      
      <link>/guides/kubernetes/workload-tenancy-conformance-test/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/workload-tenancy-conformance-test/</guid>
      <description>

        
        &lt;p&gt;Conformance testing assists in determining whether software is in compliance
with standards or specifications. With such a wide array of Kubernetes
implementations available, conformance testing is an invaluable tool. It’s
important for clusters to be CNCF conformant. It helps to ensure that a
Kubernetes cluster meets a minimum set of requirements and functionality. There
is a subset of community maintained end-to-end (e2e) tests that should pass on
any Kubernetes cluster.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sonobuoy.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Sonobuoy&lt;/a&gt; is a tool for cluster owners to ensure their
cluster conforms to CNCF guidelines via these tests. It does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integrated end-to-end (e2e) conformance testing&lt;/li&gt;
&lt;li&gt;Workload debugging&lt;/li&gt;
&lt;li&gt;Custom data collection via extensible plugins&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The support for custom plugins means that you can write and integrate any logic
into the workflow that you need. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ensuring your cluster meets regulatory and security requirements&lt;/li&gt;
&lt;li&gt;Checking availability and connectivity of private, custom resources&lt;/li&gt;
&lt;li&gt;Performing cluster benchmarking&lt;/li&gt;
&lt;li&gt;Testing custom objects and APIs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;VMware Tanzu Labs recommends Sonobuoy to evaluate cluster conformance. Tests can
be selected based on the &lt;a href=&#34;https://github.com/kubernetes-sigs&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;SIG&lt;/a&gt; or test type
at execution time.&lt;/p&gt;
&lt;p&gt;A conformance-passing cluster provides the following guarantees:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Recommended configuration: The Kubernetes cluster is properly configured
following correct practices. This is useful to have confirmed, whether you are
running a vendor maintained distribution of Kubernetes, or handling your own
custom setup. &lt;em&gt;This does not imply your cluster is fully secured or fostering
best-practices specific to your organization&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Predictability: The tested Kubernetes cluster behavior is consistent and
performs as expected. Available features in the official Kubernetes
documentation can be taken as a given. Unexpected bugs should be rare, because
distribution-specific issues are weeded out during the conformance tests.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interoperability: Workloads from other conforming clusters can be ported into
your cluster, or vice versa. This standardization of Kubernetes is a key
advantage of open source software, and allows you to avoid vendor lock-in. It
is recommended to review the requirements and assumptions for the &lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/conformance-tests.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;e2e
conformance
tests&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;Sonobuoy&lt;/code&gt; also has a plugin architecture that allows implementors to write
additional tests. These plugins include the &lt;code&gt;kube-hunter&lt;/code&gt; project (and it’s
associated plugins from AquaSecurity) and the &lt;code&gt;kube-bench&lt;/code&gt; project which is
based on &lt;a href=&#34;https://www.cisecurity.org/benchmark/kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;CIS benchmarks&lt;/a&gt;.
Users can also write tests specific to your own environments. &lt;code&gt;Sonobuoy&lt;/code&gt;
provides a plugin mechanism to add additional tests. A plugin needs to follow
the documented API that provides a communication mechanism for &lt;code&gt;Sonobuoy&lt;/code&gt; to
inform it of the plugin’s status including whether it is pending, running, or
complete.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Sonobuoy&lt;/code&gt; also documents the configuration of the cluster being tested. It
might be helpful to store these results in a data store or check them into a
version control system. This will allow you to track conformance and
configuration changes over time. configuration changes over time.&lt;/p&gt;
&lt;p&gt;Example customer requirements might be to run automated acceptance tests based
on cluster lifecycle events.&lt;/p&gt;
&lt;p&gt;Examples of these events might be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Whenever there are major changes to cluster software version, policies, or configuration.&lt;/li&gt;
&lt;li&gt;Whenever a new cluster is built and deployed.&lt;/li&gt;
&lt;li&gt;Whenever minor software or configuration changes.&lt;/li&gt;
&lt;li&gt;Whenever there are changes in the control plane.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first phase in this effort would be manually running &lt;code&gt;sonobuoy&lt;/code&gt; against test
clusters in certified-conformance mode. This will establish a baseline of
conformance in your base cluster configuration. From this point you can manually
adopt a strategy that follows the list of events above.&lt;/p&gt;
&lt;p&gt;Some examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Major cluster change - Sonobuoy run in certified-conformance mode&lt;/li&gt;
&lt;li&gt;New cluster build - Sonobuoy run in non-disruptive-conformance mode&lt;/li&gt;
&lt;li&gt;Minor changes to conformant cluster - Sonobuoy run in quick mode&lt;/li&gt;
&lt;li&gt;Change in control plane - Sonobuoy run in non-disruptive-conformance mode on a deployed test cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;options&#34;&gt;Options&lt;/h2&gt;
&lt;p&gt;There are several ways to proceed with automating the conformance tests. First,
they can be after bootstrapping Kubernetes via CI/CD and Helm. This would hard
code the tests into workflows. It isn’t perfect because it relies on the person
provisioning to pick and insert the right test into the provisioning flow. If
possible, you could have the user select the lifecycle event from a dropdown in
an interface, and then have that configure the correct tests.&lt;/p&gt;
&lt;p&gt;Second, as you potentially move toward a GitOps-type workflow, it will be
possible to have the tests run automatically based on changes checked into a
Git repository. The issue would be tagging the change types in the workflow
so that the correct tests would be run, based on the type of event that occurs.
Tests can be selected based on the SIG or test type. This would potentially
allow a further refinement of the test run to the particular areas impacted by
changes (e.g., storage, network, security, etc.)&lt;/p&gt;
&lt;h2 id=&#34;concerns&#34;&gt;Concerns&lt;/h2&gt;
&lt;p&gt;There are a couple of areas that need to be discussed and monitored. The first
is provisioning time. A full conformance test could take an hour or more, while
consuming significant resources during that time. We suggest considering the
possible impact to a running production cluster. This entails selecting the
lowest test level that meets the requirements for any given action.&lt;/p&gt;
&lt;p&gt;Second, is that the tests are generally meant to be non-disruptive to other
resources. There have been instances in the past where disruption occurred.&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/vmware-tanzu/sonobuoy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;required prerequisites&lt;/a&gt; for
Sonobuoy are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Access to a Kubernetes cluster. If you do not have a cluster, we recommend
following the &lt;a href=&#34;https://aws.amazon.com/quickstart/architecture/vmware-kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;AWS Quickstart for Kubernetes
instructions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;An admin &lt;code&gt;kubeconfig&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;For some advanced workflows it may be required to have &lt;code&gt;kubectl&lt;/code&gt; installed.
See &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-with-homebrew-on-macos&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;installing via Homebrew
(MacOS)&lt;/a&gt;
or &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/#tabset-1&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;building the binary
(Linux)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;sonobuoy images&lt;/code&gt; subcommand requires &lt;a href=&#34;https://www.docker.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Docker&lt;/a&gt; to
be installed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;installation-steps&#34;&gt;Installation Steps&lt;/h3&gt;
&lt;p&gt;First, Download the sonobuoy binaries to your local system and ensure it&amp;rsquo;s added
to your &lt;code&gt;PATH&lt;/code&gt;. The link to download &lt;code&gt;sonobuoy&lt;/code&gt; binaries is
&lt;a href=&#34;https://github.com/vmware-tanzu/sonobuoy/tags&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;https://github.com/vmware-tanzu/sonobuoy/tags&lt;/a&gt;.
Ensure that you download the version closest to your version of Kubernetes. For
example, If you are running versions 1.17.3 of Kubernetes, then you should
download the most recent v0.17.x version of &lt;code&gt;Sonobuoy&lt;/code&gt;. You can also execute &lt;code&gt;$ sonobuoy version&lt;/code&gt; and it will return the maximum and minimum versions of
Kubernetes that it will support.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sonobuoy version
Sonobuoy Version: v0.17.2
MinimumKubeVersion: 1.15.0
MaximumKubeVersion: 1.17.99
GitSHA: eb9343dbd96ebc225d076630be5c348a57dfc430
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;executing-sonobuoy&#34;&gt;Executing Sonobuoy&lt;/h4&gt;
&lt;p&gt;To run a quick sanity test and make sure your environment is working correctly
execute:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sonobuoy run --wait --mode quick
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To run the standard conformance tests with &lt;code&gt;Sonobuoy&lt;/code&gt; execute the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sonobuoy run --wait
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can also specify running just one module or plugin:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sonobuoy run --plugin e2e
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;sonobuoy run --plugin systemd-logs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;During the execution you can monitor status with the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sonobuoy status
   PLUGIN     STATUS   RESULT   COUNT
      e2e   complete   passed       1

Sonobuoy has completed. Use `sonobuoy retrieve` to get results.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can also view the raw logs from the running containers via:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sonobuoy logs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note: Using &amp;ndash;mode quick will significantly shorten the runtime of Sonobuoy. It
runs just a single test, helping to quickly validate your Sonobuoy and
Kubernetes configuration.&lt;/p&gt;
&lt;p&gt;Get the results from the plugins (e.g. e2e test results):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;results=$(sonobuoy retrieve)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To inspect results for test failures, the number of tests failed and their names
execute:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# sonobuoy results $results
Plugin: e2e
Status: passed
Total: 4814
Passed: 1
Failed: 0
Skipped: 4813
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Sonobuoy output is a gzipped tarball, named in the following manner:
&lt;code&gt;YYYYmmDDHHMM_sonobuoy_&amp;lt;uuid&amp;gt;.tar.gz&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;202003061908_sonobuoy_2e9ee3d9-8505-46d1-8664-0b3536b49b0f.tar.gz&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;YYYYmmDDHHMM&lt;/code&gt; is a timestamp containing the year, month, day, hour, and minute
of the run. The &amp;lsquo;&lt;uuid&gt;&amp;rsquo; string is an RFC4122 UUID, consisting of lowercase
hexadecimal characters and dashes (e.g.,
&amp;ldquo;dfe30ebc-f635-42f4-9608-8abcd6311916&amp;rdquo;). This UUID should match the UUID from
the snapshot&amp;rsquo;s meta/config.json, stored at the root of the tarball.&lt;/p&gt;
&lt;p&gt;The tar file contains the &lt;a href=&#34;https://sonobuoy.io/docs/master/results/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;output of the
tests&lt;/a&gt;, and a &lt;a href=&#34;https://sonobuoy.io/docs/master/snapshot/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;snapshot of the tested
cluster&amp;rsquo;s running configuration&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Autoscaling Reference Architecture</title>
      
      <link>/guides/kubernetes/workload-tenancy-autoscaling-refarch/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/workload-tenancy-autoscaling-refarch/</guid>
      <description>

        
        &lt;p&gt;This reference provides guidance, trade-off considerations and implementation
details for autoscaling application workloads and the cluster&amp;rsquo;s compute
resources that host them. It includes a variety of approaches to the practice
of using software to monitor usage and manage capacity for application
workloads.&lt;/p&gt;
&lt;h3 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h3&gt;
&lt;p&gt;If the following conditions are present, autoscaling may be advisable:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Workloads can readily scale: The architectural nature of the application
workload lends itself to scaling by:
&lt;ul&gt;
&lt;li&gt;Adding replicated instances&lt;/li&gt;
&lt;li&gt;Taking advantage of added compute resources&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compute can scale: In environments such as the public cloud where new compute
resources can be brought online programmatically, the capacity of the
underlying infrastructure can be dynamically managed.&lt;/li&gt;
&lt;li&gt;Bursting usage: If the load on your application is prone to sharp increases,
such as eCommerce workloads, the ability to respond immediately using
automated systems may be important.&lt;/li&gt;
&lt;li&gt;High utilization needs: If cost management and efficient utilization are
important for a workload with varying load, using automated scaling mechanisms
may provide the most cost-effective solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Where autoscaling may be less effective or inadvisable:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictable: In the situation where you have predictable load, the underlying
purpose for autoscaling is absent.&lt;/li&gt;
&lt;li&gt;Utilization is low priority: If high utilization is not a priority and cost
constraints are not present, you may be better served by sufficiently
over-provisioning software and hardware resources to accommodate increases in
load.&lt;/li&gt;
&lt;li&gt;Resource constrained environment: In an environment where you cannot readily
provision more compute, scaling of workloads may be possible within those
compute constraints but will have hard limits that cannot be dynamically
moved.&lt;/li&gt;
&lt;li&gt;Not failure tolerant: autoscaling workloads involves removing or restarting
application units so if your application does not handle termination signals
or otherwise handle shut-downs well, it will not be well-suited.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;general-trade-offs&#34;&gt;General Trade-Offs&lt;/h3&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;lower operational toil in managing capacity&lt;/li&gt;
&lt;li&gt;ability to better utilize compute&lt;/li&gt;
&lt;li&gt;dynamic responsiveness to changing load and consumption&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;added complexity&lt;/li&gt;
&lt;li&gt;potentially unpredictable behavior&lt;/li&gt;
&lt;li&gt;may overspend if not tuned well or capped appropriately&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;horizontal-scaling&#34;&gt;Horizontal Scaling&lt;/h3&gt;
&lt;p&gt;Horizontal scaling involves changing the replicated number of instances of
something. In application terms this often is simply increasing and decreasing
app instances. This is feasible for stateless operations where adding identical
replicas to a load-balanced pool can increase capacity or for stateful
applications that are designed to achieve similar capabilities. In
infrastructure terms, it involves adding more virtual or physical machines to
adjust the pool of underlying compute. This is feasible in a Kubernetes-based
platform that can dynamically utilize changes to the pool of worker nodes.&lt;/p&gt;
&lt;h3 id=&#34;vertical-scaling&#34;&gt;Vertical Scaling&lt;/h3&gt;
&lt;p&gt;Vertical scaling refers to changes in the allocated resources for a given unit.
For an application, this means giving it more or less CPU, memory or other
resources in response to actual usage by the workload. Vertical infrastructure
scaling is not covered in this reference since mutating infrastructure is far
less manageable than horizontally scaling the underlying machines.&lt;/p&gt;
&lt;h2 id=&#34;workload-autoscaling&#34;&gt;Workload Autoscaling&lt;/h2&gt;
&lt;h3 id=&#34;horizontal-pod-autoscaling&#34;&gt;Horizontal Pod Autoscaling&lt;/h3&gt;
&lt;p&gt;The Horizontal Pod Autoscaler (HPA) manages the number of replicas of a
workload based on the consumption of some measurable resource. A common example
is to declare a target percentage of CPU request. You declare what the target
usage is for your workload, and the HPA controller will add or remove replicas
based on actual usage compared to that target.&lt;/p&gt;
&lt;p&gt;The HPA desired state is defined by the &lt;code&gt;HorizontalPodAutoscaler&lt;/code&gt; API kind in
the &lt;code&gt;autoscaling&lt;/code&gt; group. The latest version of the API is &lt;code&gt;v1&lt;/code&gt; and is the
version addressed in this reference, but versions &lt;code&gt;v2beta1&lt;/code&gt; and &lt;code&gt;v2beta2&lt;/code&gt; also
exist. The state is reconciled by a control loop in the kube-controller-manager.&lt;/p&gt;
&lt;p&gt;Periodically, the HPA control loop will query the metric used to determine
workload scale. By default, this controller will query the metric every 15
seconds but this can be adjusted with the
&lt;code&gt;--horizontal-pod-autoscaler-sync-period&lt;/code&gt; flag on the kube-controller-manager.
Using the metric and the desired state defined in the &lt;code&gt;HorizontalPodAutoscaler&lt;/code&gt;
resource, the desired number of replicas will be calculated and updated on the
target workload as needed. The target may be a ReplicaSet, Deployment or
StatefulSet resource.&lt;/p&gt;
&lt;h4 id=&#34;resource-metrics&#34;&gt;Resource Metrics&lt;/h4&gt;
&lt;p&gt;A simple, common method for autoscaling with HPAs is using pod CPU usage. For
workloads that consume more CPU as their load increases, this may be a good
solution. It is &lt;em&gt;not&lt;/em&gt; a good solution if, for example, CPU remains relatively
constant but memory consumption grows with increased load.&lt;/p&gt;
&lt;p&gt;If using this method, you will need the &lt;a href=&#34;https://github.com/kubernetes-sigs/metrics-server&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Metrics
Server&lt;/a&gt; deployed in your
cluster. The Metrics Server will collect metrics from the various Nodes&#39;
kubelets and create &lt;code&gt;metrics.k8s.io/v1beta1/PodMetrics&lt;/code&gt; resources for each
running pod. The HPA controller will use the HorizontalPodAutoscaler to
determine which PodMetrics to query. According to the metrics observed and the
desired state defined in the HPAs, it will update the replicas in the relevant
resource, e.g. Deployment, which will, in turn, alter the number of pods
running.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;/images/guides/kubernetes/workload-tenancy/autoscaling-hpa-0.png&#34;&gt;Horizontal Pod Autoscaling&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When using HPAs it is important to understand how your workload is going to
scale in response to changes in resource usage. In the following sample
manifest, the Deployment requests 100m CPU for each pod. Note that &lt;code&gt;replicas&lt;/code&gt;
are not set on the Deployment spec. Normally this would result in zero replicas
being created, however the HPA is managing the number of replicas and has
&lt;code&gt;minReplicas&lt;/code&gt; set which will ensure at least one replica is running at all
times. Note also that if CPU resource requests aren&amp;rsquo;t set for the Deployment,
the HPA will have no effect.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;template&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample-image:1.0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;100m&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# must be set&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;autoscaling/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HorizontalPodAutoscaler&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# will not scale below this value&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# will not scale above this value&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetCPUUtilizationPercentage&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# will scale based on this percentage of usage&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The formula used to determine replica count is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;desiredReplicas = ceil( currentReplicas * ( currentMetricValue / desiredMetricValue ) )
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;desiredReplicas&lt;/code&gt; is the value that will be set on the target resource&amp;rsquo;s
&lt;code&gt;replicas&lt;/code&gt; when it has changed.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ceil&lt;/code&gt; is the ceiling function that rounds up to the nearest integer.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;currentReplicas&lt;/code&gt; is the existing replica count on the target resource.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;currentMetricValue&lt;/code&gt; is the aggregate CPU usage for all relevant pods as queried
from the PodMetrics resource for the pods in question.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;desiredMetricValue&lt;/code&gt; is the &lt;code&gt;targetCPUUtilizationPercentage&lt;/code&gt; of the CPU request
(50% of 100m, in this example) multiplied by the &lt;code&gt;currentReplicas&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In order to illustrate how the replicas will scale, consider these examples:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;There is one replica running. The HPA controller queries the PodMetrics for
that pod and finds the currentMetricValue is 120m.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ceil( 1 * (120/50) ) = 3
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this case, it will scale the replicas out to the maximum of 3.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There is one replica running. The HPA controller queries the PodMetrics for
that pod and finds the currentMetricValue is 52m.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ceil( 1 * (52/50) ) = 2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this case, the recommendation from the formula output will &lt;em&gt;not&lt;/em&gt; be used
since the ratio &lt;code&gt;52/50&lt;/code&gt; is less than the default tolerance of 0.1. This
tolerance prevents scaling when the amount of CPU usage change doesn&amp;rsquo;t
warrant it. This default tolerance can be adjusted with the
&lt;code&gt;--horizontal-pod-autoscaler-tolerance&lt;/code&gt; flag on the kube-controller-manager.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are two replicas running. The HPA controller queries the PodMetrics
for them and finds the currentMetricValues are 15m and 25m (40m combined).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ceil( 2 * (40/100) ) = 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this case, it will scale the replicas in to 1 &lt;em&gt;if&lt;/em&gt; a scaledown has been
the calculated outcome for the last 5 minutes. This 5 minute period prevents
scaledowns due to temporary drops in metric values. This default
stabilization period can be adjusted with the
&lt;code&gt;--horizontal-pod-autoscaler-downscale-stabilization&lt;/code&gt; flag on the
kube-controller-manager.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;custom-metrics&#34;&gt;Custom Metrics&lt;/h4&gt;
&lt;p&gt;If the Metrics Server is insufficient in providing metrics there are other
&lt;a href=&#34;https://github.com/kubernetes/metrics/blob/master/IMPLEMENTATIONS.md#custom-metrics-api&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;custom metrics
implementations&lt;/a&gt;
available. Of these, the &lt;a href=&#34;https://github.com/directxman12/k8s-prometheus-adapter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus
Adapter&lt;/a&gt; is the most
generally useful. It is not vendor-specific and leverages a common open-source
metrics solution.&lt;/p&gt;
&lt;h3 id=&#34;vertical-pod-autoscaling&#34;&gt;Vertical Pod Autoscaling&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;vertical pod
autoscaler&lt;/a&gt;
is a community-managed project in the Kubernetes autoscaler repo. Unlike the
HPA, it is not bundled into the kube-controller-manager. It consists of three
distinct components that run in the cluster and uses two custom resources. As
with the HPA, the VPA relies on the Metrics Server to provide CPU and memory
usage metrics.&lt;/p&gt;
&lt;p&gt;Components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Recommender: recommends CPU and/or memory request values based on observed
consumption. Fetches metrics once a minute by default which can be adjusted
with the &lt;code&gt;--recommender-interval&lt;/code&gt; flag. Is the core component that is active
in all modes.&lt;/li&gt;
&lt;li&gt;Admission Plugin: sets resource requests on new pods as determined by the
Recommender. Is active in all modes except the &lt;code&gt;Off&lt;/code&gt; mode.&lt;/li&gt;
&lt;li&gt;Updater: evicts pods that have requested resources that differ significantly
from the values determined by the Recommender. Is active in &lt;code&gt;Recreate&lt;/code&gt; and
&lt;code&gt;Auto&lt;/code&gt; modes; dormant in &lt;code&gt;Off&lt;/code&gt; and &lt;code&gt;Initial&lt;/code&gt; modes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CustomResources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VerticalPodAutoscaler: the resource where you provide the desired state for
your vertical autoscaling.&lt;/li&gt;
&lt;li&gt;VerticalPodAutoscalerCheckpoint: used internally by the Recommender to
checkpoint VPA state. It is used for recovery if the Recommender restarts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/autoscaling-vpa-0.png&#34; alt=&#34;Vertical Pod Autoscaler&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;There are different modes the VPA can run in. Technically there are four modes,
but in effect there are just three since two are functionally equivalent at this
time:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Off&lt;/code&gt;: The dry-run mode. Recommendations are calculated and can be queried
using &lt;code&gt;kubectl describe&lt;/code&gt; for the VPA resource in question, but are never
applied.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Initial&lt;/code&gt;: The safe mode. Recommendations are calculated and can be queried.
They are applied when new pods are created, but running pods are never evicted
in order to update them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Recreate&lt;/code&gt;: The active mode. Recommendations are calculated and are applied
when they differ significantly from the current requested resources. The
recommendations are applied by evicting the running pods so that the new pod
gets the recommendations. Only use this mode if your pods can safely be
evicted and restarted when the VPA determines they should be updated. If
using this mode, and when availability is important, you should also apply a
PodDisruptionBudget to ensure &lt;em&gt;all&lt;/em&gt; of your pods are not evicted at once.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Auto&lt;/code&gt;: Is currently (in v1) equivalent to &lt;code&gt;Recreate&lt;/code&gt;. May take advantage of
restart-free updates in future.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The sample manifests below represent a Deployment that will create 4 pods and a
VerticalPodAutoscaler that will vertically scale the pods if resource usage
increases significantly above the CPU or memory requests. The VPA will not
increase requests beyond the &lt;code&gt;maxAllowed&lt;/code&gt; of 1 CPU and 500Mi memory. If using
the &lt;code&gt;Recreate&lt;/code&gt; mode, the Updater will evict pods in order to scale them but the
PodDisruptionBudget will ensure that only one pod at a time is evicted.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;template&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample-image:1.0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;100m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;50Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;autoscaling.k8s.io/v1beta2&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;VerticalPodAutoscaler&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;apps/v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resourcePolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containerPolicies&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;containerName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minAllowed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;100m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;50Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxAllowed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;500Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;controlledResources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;cpu&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;memory&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;updatePolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;updateMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Recreate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;policy/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;PodDisruptionBudget&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minAvailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;limitrequest-ratio&#34;&gt;Limit:Request Ratio&lt;/h4&gt;
&lt;p&gt;The VPA will maintain the limit:request ratio specified in the original pod
template spec. This is important to keep in mind for capacity planning since
the VPA will increase the limits beyond what you specify in the original
deployment spec. The &lt;code&gt;resourcePolicy&lt;/code&gt; in the VPA below applies to resource
requests. The workload starts with a CPU request of 500m and a limit of 1000m.
The VPA indicates the CPU request may be scaled as high as 1000m. Maintaining
the limit:request ratio in the Deployment template, the VPA Recommender will set
the CPU limit to 2000m if scaled up to the maximum CPU request of 1000m.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/autoscaling-vpa-1.png&#34; alt=&#34;Vertical Pod Autoscaler&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;limit-range-constraint&#34;&gt;Limit Range Constraint&lt;/h4&gt;
&lt;p&gt;The VPA will respect Limit Ranges unless the VPAs resource policy overrides it.
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Limit
Range&lt;/a&gt;
resources allow cluster admins to set minimum and/or maximum values for resource
consumption in a Namespace. In the following example, the Limit Range will be
respected. The &lt;code&gt;minAllowed&lt;/code&gt; value in the VPA &lt;code&gt;resourcePolicy&lt;/code&gt; allows for the
limit:request ratio to be respected without violating the Limit Range. The
&lt;code&gt;maxAllowed&lt;/code&gt; value of 2000m will not be reached since it will hit the Limit
Range at a request of 1500m due to the limit:request ratio which is set in the
pod spec.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/autoscaling-vpa-2.png&#34; alt=&#34;Vertical Pod Autoscaler&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;limit-range-override&#34;&gt;Limit Range Override&lt;/h4&gt;
&lt;p&gt;If, on the other hand, the &lt;code&gt;minAllowed&lt;/code&gt; value in the VPA &lt;code&gt;resourcePolicy&lt;/code&gt; causes
the Limit Range to be violated in order to maintain the limit:request ratio set
in the pod spec, the Limit Range will be overridden.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/autoscaling-vpa-3.png&#34; alt=&#34;Vertical Pod Autoscaler&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Because this could lead to unintended or unauthorized Limit Range violations,
you should use admission control to prevent this. Two possible ways to achieve
this are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Simple: enforce that the &lt;code&gt;minAllowed&lt;/code&gt; in the VerticalPodAutoscaler matches
the resource requests in the pod spec.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Complex: have the admission controller fetch the applicable Limit Range,
calculate the limit:request ratio in the pod spec, calculate the projected
limit based on the VPA&amp;rsquo;s &lt;code&gt;minAllowed&lt;/code&gt; value, and check to see if the
projected limit violates the Limit Range.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;cluster-proportional-autoscaling&#34;&gt;Cluster Proportional Autoscaling&lt;/h3&gt;
&lt;p&gt;If you have a workload that needs to scale in proportion to the size of the
cluster itself, the
&lt;a href=&#34;https://github.com/kubernetes-sigs/cluster-proportional-autoscaler&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;cluster-proportional-autoscaler&lt;/a&gt;
may be appropriate to use. While it has a narrower use-case and is generally
useful only for cluster services like DNS, it has a very simple operating model
and fewer dependencies.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/autoscaling-cpa-0.png&#34; alt=&#34;Cluster Proportional Autoscaling&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;By default, every 10 seconds, the Cluster Proportional Autoscaler (CPA) will
check the number nodes in the cluster and autoscale the target workload as
needed. The default poll period can be changed using the &lt;code&gt;--poll-period-seconds&lt;/code&gt;
on the CPA. If you would like to scale a workload based on a subset of nodes you
may use the &lt;code&gt;--nodelabels&lt;/code&gt; flag on the CPA which will instruct it to count only
those nodes with particular labels. The target workload that will be scaled by
the CPA is defined with the &lt;code&gt;--target&lt;/code&gt; flag. The scaling parameters to use are
defined in a configmap which is specified by the &lt;code&gt;--configmap&lt;/code&gt; flag. Because
only one target and configmap may be provided, if you have multiple workloads
for which you would like to use the CPA, you will need to deploy and configure
an instance of the CPA for each.&lt;/p&gt;
&lt;p&gt;The replicas are set by either a cores:replicas ratio provided by
&lt;code&gt;coresPerReplica&lt;/code&gt; &lt;em&gt;or&lt;/em&gt; nodes:replicas with &lt;code&gt;nodesPerReplica&lt;/code&gt;. You can provide
one method or both. If both are given, the larger of the two values will be
applied to the target.&lt;/p&gt;
&lt;p&gt;There are two modes to provide scaling parameters. The first example below
denotes the &lt;code&gt;linear&lt;/code&gt; mode. In this case there will never be less than one
replica, and never more than 100 replicas. Within that range, the
&lt;code&gt;coresPerReplica&lt;/code&gt; or the &lt;code&gt;nodesPerReplica&lt;/code&gt; will determine the replicas set on
the target workload. The evaluation that returns the highest value will be used.
In this case, given 20 nodes with 16 cores each, &lt;code&gt;16 cores * 20 nodes = 320 cores&lt;/code&gt; the &lt;code&gt;coresPerReplica&lt;/code&gt; will be used which will set 80 replicas on the
target. Alternatively if the nodes have 4 cores each, the &lt;code&gt;nodesPerReplica&lt;/code&gt; will
produce the higher value of 20 replicas at one node per replica so the target
workload will be set to 20 replicas. In this case
&lt;code&gt;&amp;quot;includeUnschedulableNodes&amp;quot;: true&lt;/code&gt; will exclude non-schedulable nodes that have
been cordoned, for example. Also, &lt;code&gt;&amp;quot;preventSinglePointFailure&amp;quot;: true&lt;/code&gt; will
effectively increase the minimum to 2 if there are multiple nodes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data:
  linear: |-
    {
      &amp;quot;coresPerReplica&amp;quot;: 4,
      &amp;quot;nodesPerReplica&amp;quot;: 1,
      &amp;quot;min&amp;quot;: 1,
      &amp;quot;max&amp;quot;: 100,
      &amp;quot;preventSinglePointFailure&amp;quot;: true
      &amp;quot;includeUnschedulableNodes&amp;quot;: true
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The other mode is the &lt;code&gt;ladder&lt;/code&gt; mode which allows for a stepping function that
provides for more granular control. Re-using the example of 20 nodes with 16
cores each, 320 cores would result in 3 replicas due to &lt;code&gt;[ 64, 3 ]&lt;/code&gt;. If the
nodes increase to 40, 640 cores passes the 512 threshold so &lt;code&gt;[ 512, 5 ]&lt;/code&gt; would
cause 5 replicas to be set on the target.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data:
  ladder: |-
    {
      &amp;quot;coresToReplicas&amp;quot;:
      [
        [ 1, 1 ],
        [ 64, 3 ],
        [ 512, 5 ],
        [ 1024, 7 ],
        [ 2048, 10 ],
        [ 4096, 15 ]
      ],
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this &lt;code&gt;ladder&lt;/code&gt; mode example, a 40 node cluster would lead to 5 replicas on the
target. If the node count increases above 64, the replicas will be increased to 6.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data:
  ladder: |-
    {

      &amp;quot;nodesToReplicas&amp;quot;:
      [
        [ 1, 1 ],
        [ 4, 2 ],
        [ 8, 3 ],
        [ 16, 4 ],
        [ 32, 5 ],
        [ 64, 6 ]
      ]
    }
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;cluster-autoscaling&#34;&gt;Cluster Autoscaling&lt;/h2&gt;
&lt;p&gt;When horizontally autoscaling applications, as the workload pod replicas
increase, it may run out of worker nodes to run on. Scaling the cluster around
the workload solves this problem. Using &lt;a href=&#34;https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cluster
Autoscaler&lt;/a&gt;
(CA) you can ensure your worker node pool will increase in response to pods
being unschedulable due to a lack of worker nodes.&lt;/p&gt;
&lt;p&gt;In the following example diagram, the HPA queries metrics and determines the
replica count needs to be scaled from 26 to 36. This exceeds the capacity of the
cluster&amp;rsquo;s worker nodes which is 30. That leaves 6 pods in a Pending state. They
are unschedulable due to a lack of compute available. The CA observes this
condition and determines that one more worker node will satisfy the shortage of
node resources and provisions a new node using the underlying infrastructure
provider. The workload pods will remain Pending until the node joins the cluster
and at that time they will be scheduled to the new node satisfying the
workload&amp;rsquo;s scaling requirements.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/autoscaling-ca-0.png&#34; alt=&#34;Cluster Autoscaling&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;provider-support&#34;&gt;Provider Support&lt;/h4&gt;
&lt;p&gt;At this time, Cluster Autoscaler supports the following cloud providers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/compute/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Google Compute Engine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Google Kubernetes Engine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Amazon Web Services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Microsoft Azure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://us.alibabacloud.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Alibaba Cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.openstack.org/wiki/Magnum&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;OpenStack Magnum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Digital Ocean&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cluster-api.sigs.k8s.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cluster API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: Cluster Autoscaler uses specific resource types in the infrastructure
provider that will need to be in use in order to leverage CA. If your cluster
infra management does not use these resource types, you will not be able to
leverage CA. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Web Services: Autoscaling Groups (ASGs) are used for scaling worker
nodes in AWS. So if you leverage ASGs to manage your worker node pool, CA may
be a viable option. On the other hand, if you are provisioning individual EC2
instances for worker nodes, CA will not work.&lt;/li&gt;
&lt;li&gt;Azure: Virtual Machine Scale Sets (VMSS) are used in Azure. So in order to use
CA in a cluster running in Azure, you&amp;rsquo;ll need to use VMSS to manage your node
pools.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An important consideration when deploying Cluster Autoscaler is ensuring it does
not get evicted or that the node it&amp;rsquo;s running on does not get decommissioned
during a scaling event. Consider:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run on Master Node: When using CA, worker nodes may be decommissioned to scale
in. Running the CA itself on a master node solves this potential problem.&lt;/li&gt;
&lt;li&gt;Run in &lt;code&gt;kube-system&lt;/code&gt;: CA doesn&amp;rsquo;t decommission nodes with non-mirrored
&lt;code&gt;kube-system&lt;/code&gt; pods running on them.&lt;/li&gt;
&lt;li&gt;Use a Priority Class: Set &lt;code&gt;priorityClassName: system-cluster-critical&lt;/code&gt; on the
CA to prevent eviction.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;cluster-api&#34;&gt;Cluster API&lt;/h4&gt;
&lt;p&gt;Cluster API extends the Kubernetes API to manage clusters&#39; underlying
infrastructure using Kubernetes controllers. This has relevance to CA since the
autoscaler needs to implement controls over a subset of cluster infrastructure
as well. A &lt;a href=&#34;https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/cloudprovider/clusterapi&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cluster API
provider&lt;/a&gt;
was recently added to CA. It is different to the other providers in that Cluster
API is an abstraction of the cloud provider rather than an actual provider. Note
that there are currently important limitations that should be understood. For
example, CA only supports using Cluster API when the cluster used serves as the
both management and workload cluster.&lt;/p&gt;
&lt;h4 id=&#34;node-scaling&#34;&gt;Node Scaling&lt;/h4&gt;
&lt;p&gt;The CA will check for unschedulable pods every 10 seconds by default. This value
can be altered with the &lt;code&gt;--scan-interval&lt;/code&gt; flag on the CA. If it finds
unschedulable pods, it will calculate how many nodes of the kind in the relevant
node group will be required to satisfy the Pending pods. Then it will increase
the node group by that amount.&lt;/p&gt;
&lt;p&gt;The node groups are configured with the &lt;code&gt;--nodes&lt;/code&gt; flag. The configuration is
provided in the form of &lt;code&gt;[node minimum count]:[node maximum count]:[node group name]&lt;/code&gt;. The node group name will match the name of the autoscaling resource
(e.g. autoscaling group in AWS or VMSS in Azure). So in the following example,
two node groups will be managed. The &lt;code&gt;worker-asg-1&lt;/code&gt; node group will not be
scaled higher than 10 or lower than 1. The &lt;code&gt;worker-asg-2&lt;/code&gt; will be kept between 1
and 3 nodes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--nodes=1:10:worker-asg-1
--nodes=1:3:worker-asg-2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When using multiple node groups. the expander will determine which of the node
groups is scaled. If using a single node group, the expander is irrelevant.
Supply the &lt;code&gt;--expander&lt;/code&gt; flag to denote the expander you need to use. The
available expanders are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;random&lt;/code&gt; - The node group will be selected at random. This is the default and
is not very useful. If using multiple node groups, use a more useful expander.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;most-pods&lt;/code&gt; - The node group that will allow for the most pods to be
scheduled. For example, if the unschedulable pods use &lt;code&gt;nodeSelector&lt;/code&gt; this
expander will scale the node group that will allow for the pods to be
scheduled.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;least-waste&lt;/code&gt; - Will scale the node group that is the best fit for the
unschedulable pods and will have the least idle resources once provisioned and
the pods scheduled.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;price&lt;/code&gt; - Chooses the most effective option. Currently only compatible with
GCE and GKE providers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;priority&lt;/code&gt; - Uses a priority configuration supplied as a configmap which must
be named &lt;code&gt;cluster-autoscaler-priority-expander&lt;/code&gt; and run in the same namespace
as the CA. The configmap is watched by the CA and can be dynamically updated.
The CA will load configuration changes on the fly. The following example
includes three priority groups. Each group accepts a list of regular
expressions. The group with the highest value with a match is used. In the
following example, if there is a m4.4xlarge node group, it will be used and is
the most preferred. Failing that, the t2.large or t3.large nodes will be used.
If no node group name matches any of these, the lowest priority is &lt;em&gt;any&lt;/em&gt; other
group.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-priority-expander
  namespace: kube-system
data:
  priorities: |-
    1:
      - .*
    10:
      - .*t2\.large.*
      - .*t3\.large.*
    50:
    - .*m4\.4xlarge.*
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When Cluster Autoscaler finds nodes that have been under-utilized for a
significant amount of time, the CA will remove that node. Nodes that are removed
are deleted in the underlying infra. Deleting the Node resource in Kubernetes is
the responsibility of the node controller in the cloud-controller-manager. If
there are high-priority workloads that you do not want the CA to remove nodes
for, use disruption budgets or annotations to protect them. You can use the
annotation &lt;code&gt;&amp;quot;cluster-autoscaler.kubernetes.io/scale-down-disabled&amp;quot;: &amp;quot;true&amp;quot;&lt;/code&gt; on a
Node and then use &lt;code&gt;nodeSelector&lt;/code&gt; to assign workloads to those protected nodes.&lt;/p&gt;
&lt;p&gt;Because the CA performs calculations to determine the number of new nodes to
provision when adding nodes, and because the operation can be time-sensitive,
request a full core of CPU for CA so it has sufficient compute capacity reserved
and can perform calculations quickly. Also note that using pod affinity and
anti-affinity can have a significant performance impact on the CA, especially in
larger clusters, so if using in conjunction with CA, do appropriate testing to
ensure CA will meet your service level objectives.&lt;/p&gt;
&lt;h3 id=&#34;cluster-overprovisioning&#34;&gt;Cluster Overprovisioning&lt;/h3&gt;
&lt;p&gt;One concern that should be considered when using CA is that, since it is
triggered by Pending pods, it will only begin scaling the number of Nodes when
you are out of capacity. This means you will be out of capacity for the amount
of time it takes for the following to happen:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CA recognizes the cluster is out of capacity and calls the infra provider to
provision more worker nodes&lt;/li&gt;
&lt;li&gt;The new machines boot up&lt;/li&gt;
&lt;li&gt;The new machines join the Kubernetes cluster&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If this process is relatively short and you build in sufficient headroom to your
workload autoscaling, i.e. you scale the number pods well before the workload is
at full capacity, this may not be a problem. However, if you do find that
cluster scaling cannot meet the demands of a rapidly scaling application,
cluster overprovisioning may be a useful solution.&lt;/p&gt;
&lt;p&gt;Cluster overprovisioning involves using a placeholder workload with a
PriorityClass lower than that used by the autoscaling workloads. The placeholder
workload does nothing but request enough resources to trigger the CA to add
standby worker nodes. To extend the cluster autoscaling example used above, this
diagram shows a workload with 26 replicas. Additionally, the overprovisioner is
holding an additional node on standby for scaling events.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/autoscaling-overprovisioner-0.png&#34; alt=&#34;Autoscaling Overprovisioner&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Now, when the HPA scales the replicas for the workload to 36, there is a node
ready to accept new pods immediately. Provided the workload pods use a higher
PriorityClass than the overprovisioner, the overprovisioner pod will be evicted
to make way for the 6 pods that couldn&amp;rsquo;t otherwise be scheduled elsewhere in the
cluster. Meanwhile, the overprovisioner will fall into a Pending state which
will trigger the CA to provision a new standby node for the overprovisioner to
live.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/autoscaling-overprovisioner-1.png&#34; alt=&#34;Autoscaling Overprovisioner&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;There is a &lt;a href=&#34;https://github.com/helm/charts/tree/master/stable/cluster-overprovisioner&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;helm
chart&lt;/a&gt;
that can be used to deploy the overprovisioner, but these sample manifests
demonstrate the principle:&lt;/p&gt;
&lt;p&gt;First you need to create a PriorityClass for your autoscaling workloads. If you
are already using PriorityClasses, you need only ensure the overprovisioner&amp;rsquo;s
PriorityClass value is lower. If you&amp;rsquo;re not using PriorityClasses, create a
default that will be used if one is not specified:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;scheduling.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;PriorityClass&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;globalDefault&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;This priority class will be used by all pods that do not specify one.&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next create a PriorityClass for your overprovisioner. This priority class will
work provided you have not altered the CA&amp;rsquo;s default priority cutoff of -10. If
you set the &lt;code&gt;--expendable-pods-priority-cutoff&lt;/code&gt; flag to 0, for example, the CA
will not provision standby nodes for the overprovisioner using a PriorityClass
of -1.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;scheduling.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;PriorityClass&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;overprovisioner&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;globalDefault&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;This priority class will be used the overprovisioner to create standby worker nodes.&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now Create a deployment that acts as the placeholder workload:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;overprovisioner&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Recreate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# helps determine standby nodes&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;overprovisioner&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;template&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;overprovisioner&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;priorityClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;overprovisioner&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# specifies priority class&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;overprovisioner&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s.gcr.io/pause:3.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# workload consumes no resources&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;31&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# helps determine standby nodes&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;An important consideration with this strategy is the relationship between this
deployment&amp;rsquo;s CPU requests, replicas and the standby nodes it creates. In this
example we have asked for 3 replicas that request 31 CPU each. In a cluster that
uses 32 core worker nodes, the objective is for the CA to provision 3 standby
nodes. It is generally not going to work to request &lt;em&gt;all&lt;/em&gt; CPU for the node. If
there are any DaemonSet pods that request resources, the overprovisioner will
not get scheduled at all. So, determine the aggregate CPU request for the pods
that &lt;em&gt;every&lt;/em&gt; node runs such as your CNI provider pod, kube-proxy, and any other
DaemonSets. Then set the CPU requests for your overprovisioner to just below
that. If you set it too low, workloads will be provisioned alongside the
overprovisioner and you will not get new standby nodes added to the cluster when
you otherwise might expect to.&lt;/p&gt;
&lt;p&gt;This system has the benefit that you can scale the number of replicas for the
overprovisioner and get a corresponding number of standby nodes. It has the
disadvantage that if you add DaemonSets without adjusting the overprovisioner
CPU request, or if you adjust the number of cores for your worker nodes, your
overprovisioner may stop working as expected.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Calico Reference Architecture</title>
      
      <link>/guides/kubernetes/container-networking-calico-refarch/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/container-networking-calico-refarch/</guid>
      <description>

        
        &lt;p&gt;This document details a reference architecture for running
&lt;a href=&#34;https://docs.projectcalico.org/introduction&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Calico&lt;/a&gt; as the container
networking plugin (CNI) for a Kubernetes cluster, such as &lt;a href=&#34;https://my.vmware.com/web/vmware/info/slug/infrastructure_operations_management/vmware_tanzu_kubernetes_grid/1_16&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Tanzu Kubernetes Grid
(TKG)&lt;/a&gt;.
It covers architectural considerations, network integration approaches, and best
practices. This document represents how the VMware field team approaches Calico
deployments in large enterprise Kubernetes environments.&lt;/p&gt;
&lt;p&gt;Each section covers architectural recommendations and, at times, configuration
for each concern in a Calico deployment. At a high-level, the key
recommendations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use the Kubernetes datastore.&lt;/li&gt;
&lt;li&gt;Install Typha to ensure datastore scalability.&lt;/li&gt;
&lt;li&gt;Use no encapsulation for single subnet clusters.&lt;/li&gt;
&lt;li&gt;Use IP-in-IP in CrossSubnet mode for multi-subnet clusters.&lt;/li&gt;
&lt;li&gt;Configure Calico MTU based on the network MTU and the chosen routing mode.&lt;/li&gt;
&lt;li&gt;Add global route reflectors for clusters capable of growing above 50 nodes.&lt;/li&gt;
&lt;li&gt;Use GlobalNetworkPolicy for cluster-wide ingress and egress rules. Modify the
policy by adding namespace-scoped &lt;code&gt;NetworkPolicy&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Solution design is complex and requires a multitude of considerations that a
simple list cannot encapsulate. The sections below cover in detail the various
design decisions and examples of their configuration.&lt;/p&gt;
&lt;h2 id=&#34;calico-component-overview&#34;&gt;Calico Component Overview&lt;/h2&gt;
&lt;p&gt;Calico is a CNI plugin offering container networking to a Kubernetes cluster. It
uses Linux-native tools to facilitate traffic routing and enforce network
policy. It also hosts a BGP daemon for distributing routes to other nodes.
Calico&amp;rsquo;s tools run as a DaemonSet atop a Kubernetes cluster. This enables
administrators to install Calico with
&lt;code&gt;kubectl apply -f ${CALICO_MANIFESTS}.yaml&lt;/code&gt; and no need to setup additional
services or infrastructure. In this reference architecture, there are a
multitude of components.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-components.png&#34; alt=&#34;Calico Components&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Here are some details and functionalities of each of the core components:&lt;/p&gt;
&lt;h3 id=&#34;calico-node&#34;&gt;calico-node&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;calico-node&lt;/code&gt; pod runs on every host. It is responsible for 2 pieces of
functionality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Route programming&lt;/strong&gt;: Based on known routes to pods in the Kubernetes
cluster, configure the Linux host to facilitate routing accordingly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Route sharing&lt;/strong&gt;: Based on pods running on this host, provide a mechanism to
share known routes with other hosts. Typically accomplished with &lt;a href=&#34;https://en.wikipedia.org/wiki/Border_Gateway_Protocol&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Border
Gateway Protocol
(BGP)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To accomplish the above mentioned functionalities, the &lt;code&gt;calico-node&lt;/code&gt; container
runs 2 processes, &lt;a href=&#34;https://github.com/projectcalico/felix&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Felix&lt;/a&gt; and
&lt;a href=&#34;https://github.com/projectcalico/bird&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;BIRD&lt;/a&gt;, which are shown in the diagram
below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-node.png&#34; alt=&#34;Calico Node&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/projectcalico/felix&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Felix&lt;/a&gt; is responsible for programming
the host to satisfy pod routes and network policy. To do this, it interacts with
the Linux kernel&amp;rsquo;s route tables and the Linux IPtables (for network policy).
Felix will configure the route tables statically translating what is learned to
static routes in the host&amp;rsquo;s routing table. Calico&amp;rsquo;s use of IPtables can raise
concerns around scalability, however the use of IPtables has a &lt;a href=&#34;https://www.projectcalico.org/comparing-kube-proxy-modes-iptables-or-ipvs&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;time complexity
of
&lt;code&gt;O(1)&lt;/code&gt;&lt;/a&gt;.
Calico relies on
&lt;a href=&#34;https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kube-proxy&lt;/a&gt;
to facilitate services, which (in IPtables mode) can have a complexity closer to
&lt;code&gt;O(n)&lt;/code&gt;. This should be considered for clusters featuring thousands of services.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/projectcalico/bird&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;BIRD&lt;/a&gt; takes routing rules written by
Felix and peers with other BIRD instances that run on all hosts by default.
These BGP peers are constantly sharing routing information about their known
routes. BIRD is a capable daemon that enables a multitude of topologies. This
will be covered in greater depth in the Route Distribution section.&lt;/p&gt;
&lt;h3 id=&#34;calico-kube-controller&#34;&gt;calico-kube-controller&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;calico-kube-controller&lt;/code&gt; is responsible for recognizing changes in
Kubernetes objects that impact routing. The controller contains multiple
controllers inside of it, watching changes in the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Network Policies (used to program IPtables for network access enforcement)&lt;/li&gt;
&lt;li&gt;Pods (e.g. labels)&lt;/li&gt;
&lt;li&gt;Namespaces (used to determine if enforcement is needed for the new namespace)&lt;/li&gt;
&lt;li&gt;Service Accounts (used for setting up Calico
&lt;a href=&#34;https://docs.projectcalico.org/v3.9/reference/resources/profile&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;profiles&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Nodes (used to determine the associated subnet and inform the routing topology)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-kube-controller.png&#34; alt=&#34;Calico kube-controller&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Based on changes seen by the controllers, Calico can update its datastore, which
will eventually be seen and enforced in each calico-node.&lt;/p&gt;
&lt;h3 id=&#34;typha&#34;&gt;Typha&lt;/h3&gt;
&lt;p&gt;Typha is a process that fans out configuration to all calico-node instances in a
cluster. It acts as a cache that can de-duplicate events from the API server,
lessening load significantly. As the Calico datastore changes, these changes
must be propagated to every instance of calico-node, which can be hundreds or
thousands of instances. This creates scaling issues in a cluster with more than
50 nodes as every node will be opening up a watch for API server events. Typha
gets around this by being an intermediary between the API server and all
instances of calico-node.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/typha.png&#34; alt=&#34;Typha&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;For brevity, only 8 hosts are displayed above. However, it&amp;rsquo;s important to
consider this model at scale as connecting each calico-node to the datastore
could impact &lt;code&gt;kube-apiserver&lt;/code&gt; performance.&lt;/p&gt;
&lt;h2 id=&#34;calico-datastore&#34;&gt;Calico Datastore&lt;/h2&gt;
&lt;p&gt;The Calico Datastore is a generic term referring to whatever is used to store
Calico configuration, routing, policy, and other information. Calico supports 2
datastore modes, Kubernetes and etcd. The types of resources you can expect in
this datastore are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/bgpconfig&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;BGPConfiguration&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set global BGP configuration settings. Allows you to set an autonomous
system (AS) number for your network, disable node-to-node mesh (used when
peering with route reflectors or top of rack switches), and settings to
advertise clusterIPs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/bgppeer&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;BGPPeer&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Represents each BGP peer containing the peer&amp;rsquo;s IP and AS it&amp;rsquo;s associated
with.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/felixconfig&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;FelixConfiguration&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Low-level Felix settings that impact these routing daemons. This is where
you alter IPtables settings, MTU sizes, and routing protocols.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/globalnetworkpolicy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;GlobalNetworkPolicy&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Network policy rules that are applied cluster-wide rather than namespace
wide.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/globalnetworkset&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;GlobalNetworkSet&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;List of external network IPs or CIDRs that can be executed on via a Calico
GlobalNetworkPolicy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/hostendpoint&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;HostEndpoint&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Represents the interfaces attached to each host running Calico.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/ippool&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;IPPool&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Represents the pool(s) of IP addresses and their preferences from which
endpoint IPs will be assigned to pods. You can set the pool&amp;rsquo;s encapsulation
protocol such as IP-in-IP, VXLAN, or Native. A cluster can have multiple
IPPools, each with its own configuration.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/networkpolicy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;NetworkPolicy&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Namespace-scoped network policy that extends the functionality of Kubernetes
default network policy API.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/networkset&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;NetworkSet&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;List of external network IPs or CIDRs that can be executed on via a Calico
NetworkPolicy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/node&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Node&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Represents a Kubernetes node and holds details on its IPv4/6 number, AS
association, and tunnel address (IP-in-IP or VXLAN).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/profile&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Profile&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Configuration to group multiple endpoints by auto-applying labels to them.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/reference/resources/workloadendpoint&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;WorkloadEndpoint&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The association of an endpoint to a workload. Includes details such as what
the container ID is, pod name, MAC address, interface association (cali*),
and IP network(s).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of the above resources are editable by administrators while others are
automatically configured and updated by the &lt;code&gt;calico-kube-controllers&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;kubernetes-datastore-mode-recommended&#34;&gt;Kubernetes Datastore Mode (Recommended)&lt;/h3&gt;
&lt;p&gt;In almost all cases, it&amp;rsquo;s preferable to use the Kubernetes datastore instead of
etcd. In this model, all persisted data used by Calico is stored through the
Kubernetes API server as custom resource definitions (CRDs).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-datastore-k8s.png&#34; alt=&#34;Calico Datastore&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Support for a Kubernetes backend was introduced after the etcd backend. For some
time after its release, it did not offer the same features as the etcd backend.
In current Calico (3.9+), feature parity has been achieved. Another issue with
the Kubernetes backend was its inability to scale. With hundreds of Felix
instances trying to interact with the kube-apiserver to get the latest updates
and changes, it had a negative impact on the system. This has been remedied with
the introduction of &lt;a href=&#34;https://github.com/projectcalico/typha&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Typha&lt;/a&gt;. With the
feature parity and scalability solved, the etcd mode incurs an unnecessary cost
of administering a second etcd cluster. It also requires the implementation of
authentication and authorization controls to prevent unauthorized modification
of the Calico datastore. In the Kubernetes backend mode, it uses the
administrator&amp;rsquo;s kubeconfig, which means access to Calico resources can be
controlled by Kubernetes RBAC. Based on the practices in this reference
architecture, verify the following to ensure you&amp;rsquo;re using the Kubernetes
datastore mode and leveraging typha:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Check the &lt;code&gt;kube-system/calico-config&lt;/code&gt; configmap to verify the following is
set.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConfigMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;calico-config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# other config removed for brevity.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;typha_service_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;calico-typha&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cni_network_config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|-&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    {
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      &amp;#34;name&amp;#34;: &amp;#34;k8s-pod-network&amp;#34;,
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      &amp;#34;cniVersion&amp;#34;: &amp;#34;0.3.1&amp;#34;,
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      &amp;#34;plugins&amp;#34;: [
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        {
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          &amp;#34;type&amp;#34;: &amp;#34;calico&amp;#34;,
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          &amp;#34;log_level&amp;#34;: &amp;#34;info&amp;#34;,
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          &amp;#34;datastore_type&amp;#34;: &amp;#34;kubernetes&amp;#34;,
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          &amp;#34;nodename&amp;#34;: &amp;#34;__KUBERNETES_NODE_NAME__&amp;#34;,
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          &amp;#34;mtu&amp;#34;: __CNI_MTU__,
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          &amp;#34;ipam&amp;#34;: {
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;              &amp;#34;type&amp;#34;: &amp;#34;calico-ipam&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          },
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          &amp;#34;policy&amp;#34;: {
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;              &amp;#34;type&amp;#34;: &amp;#34;k8s&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          },
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          &amp;#34;kubernetes&amp;#34;: {
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;              &amp;#34;kubeconfig&amp;#34;: &amp;#34;__KUBECONFIG_FILEPATH__&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          }
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        },
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        # other config removed for brevity
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      ]
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above has some configuration removed. But the attributes left should be
checked to ensure you&amp;rsquo;re running in the Kubernetes datastore mode using
Typha.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the &lt;code&gt;calico/node&lt;/code&gt; container spec to ensure the following environment
variables are being set:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Use Kubernetes API as the backing datastore.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DATASTORE_TYPE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;kubernetes&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Typha support: controlled by the ConfigMap.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;FELIX_TYPHAK8SSERVICENAME&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;valueFrom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configMapKeyRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;calico-config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;typha_service_name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the following Typha resources have been deployed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Typha Service&lt;/li&gt;
&lt;li&gt;Typha Deployment&lt;/li&gt;
&lt;li&gt;Typha PodDisruptionBudget&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;etcd-datastore-mode&#34;&gt;etcd Datastore Mode&lt;/h3&gt;
&lt;p&gt;The etcd datastore mode is still supported and considered a viable approach for
running Calico.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;/images/guides/kubernetes/container-networking/calico-datastore-etcd.png&#34;&gt;Calico Datastore (etcd)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the reasons stated in the previous section, this approach is not recommended
as it introduces unnecessary complexity and security risk. If this model is
used, &lt;strong&gt;do not&lt;/strong&gt; use the Kubernetes etcd cluster as the datastore for Calico. No
process outside of core Kubernetes should have access to the cluster&amp;rsquo;s etcd for
security and performance reasons.&lt;/p&gt;
&lt;h3 id=&#34;datastore-interaction&#34;&gt;Datastore Interaction&lt;/h3&gt;
&lt;p&gt;For all datastore interaction, it&amp;rsquo;s recommended you use
&lt;a href=&#34;https://docs.projectcalico.org/getting-started/clis/calicoctl/install&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;calicoctl&lt;/a&gt;
to interact with the datastore. The Calico documentation also describes how to
run &lt;code&gt;calicoctl&lt;/code&gt; as a container inside your Kubernetes cluster. Since the
Kubernetes datastore exposes the Calico objects as CRDs, it is also possible to
interact through &lt;code&gt;kubectl&lt;/code&gt;. However, &lt;code&gt;calicoctl&lt;/code&gt; is still recommended as it adds
additional validation to your interaction with the Calico datastore objects.
&lt;code&gt;calicoctl&lt;/code&gt; needs to be configured based on your datastore. Below are the steps
for setting up &lt;code&gt;calicoctl&lt;/code&gt; to connect to the Kubernetes datastore:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download and setup the appropriate calicoctl binary from
&lt;a href=&#34;https://github.com/projectcalico/calicoctl/releases&#34;&gt;https://github.com/projectcalico/calicoctl/releases&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Export the &lt;code&gt;DATASTORE_TYPE&lt;/code&gt; variable to &lt;code&gt;kubernetes&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nv&#34;&gt;CALICO_DATASTORE_TYPE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kubernetes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Export the &lt;code&gt;CALICO_KUBECONFIG&lt;/code&gt; variable to the location of your kubeconfig.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nv&#34;&gt;CALICO_KUBECONFIG&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;LOCATION_OF_YOUR_KUBECONFIG&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;CALICO&lt;/code&gt; prefix is optional, but since it can conflict with the
&lt;code&gt;kubectl&lt;/code&gt; CLI, it&amp;rsquo;s best to add it and possibly persist this setting
somewhere such as &lt;code&gt;~/.bashrc&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;routing-configuration&#34;&gt;Routing Configuration&lt;/h2&gt;
&lt;p&gt;Calico supports multiple routing modes each with unique trade-offs. This section
details the differences in those routing modes, our recommendations based on
topology, and an overview of alternative configurations.&lt;/p&gt;
&lt;h3 id=&#34;routing-methods&#34;&gt;Routing Methods&lt;/h3&gt;
&lt;p&gt;Calico supports 3 routing modes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Native: Packets routed as-is, no encapsulation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;IP-in-IP: Minimal encapsulation; outer header includes host
source/destination IPs and inner header includes pod source/destination.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VXLAN: Robust encapsulation using UDP over IP; outer header includes host
source/destination IP addresses and inner header includes pod
source/destination IP addresses as well as Ethernet headers.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;native&#34;&gt;Native&lt;/h4&gt;
&lt;p&gt;Native routing does not encapsulate packets to and from pods. As such, it&amp;rsquo;s a
highly performant routing method as you&amp;rsquo;re not incurring the overhead of
encapsulation, decapsulation, and larger header sizes. It also makes
troubleshooting simpler as analyzing network traffic does not involve looking
inside a packet for another packet. When running in this mode, the packet
structure looks as shown in the diagram below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-native-packet.png&#34; alt=&#34;Calico Native Packet&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The interface data path is simplified in this diagram to keep the focus on the
packet in transit. Additionally, Calico will prefer the NIC of the default
route.&lt;/p&gt;
&lt;p&gt;In order to facilitate this model, Felix programs the route table to use the
default interface and send traffic to the target pod via its host, seen below as the
Gateway:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/calico-route-table-direct.png&#34; alt=&#34;Calico Route Table (Direct&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The above image shows the output of &lt;code&gt;worker-1&lt;/code&gt;&amp;rsquo;s routing table. In this cluster
there are 3 other nodes, &lt;code&gt;worker-2&lt;/code&gt;, &lt;code&gt;worker-3&lt;/code&gt;, and &lt;code&gt;master&lt;/code&gt;. Each of the nodes
have their own pod CIDR specified.&lt;/p&gt;
&lt;p&gt;This routing mode can be problematic in environments that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Cross multiple subnets or feature routers that rely on the destination IP to
determine the host it should route the packet to.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enforce source/destination checks for inbound packets.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some networks such as AWS allow you to disable these checks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/calico-src-dst-check.png&#34; alt=&#34;Calico Inbound Checks&#34;  /&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Environments that block all BGP, which is used in this model for route
distribution.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;ip-in-ip&#34;&gt;IP-in-IP&lt;/h4&gt;
&lt;p&gt;IP-in-IP is a simple form of encapsulation that wraps the packet with an outer
IP header that appears as if the source and destination are hosts rather than
pods. Therefore, when a host receives an IP-in-IP packet, it examines the
internal IP header to determine the target pod. This is Calico&amp;rsquo;s default routing
method. While this routing method incurs more overhead than native routing, it
does work in most environments without modification, especially in environments
that cross multiple subnets. When running in this mode, the packet structure
looks as shown in the diagram below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-ip-in-ip-packet.png&#34; alt=&#34;Calico IP-in-IP&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Note the ethernet frame destination is set to the &lt;code&gt;$GATEWAY&lt;/code&gt;, this could be
targeting a node&amp;rsquo;s mac address or a router depending on whether the request is
crossing a subnet boundary.&lt;/p&gt;
&lt;p&gt;In order to facilitate this model, Felix programs the route table to use
IP-in-IP tunnel interfaces to provide routing across nodes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/calico-route-table-ipinip.png&#34; alt=&#34;Calico IP-in-IP Route Table&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;At the cost of the additional IP-in-IP overhead, this model works in most
network topologies. Environments where this model can be problematic are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Environments that explicitly disallow IP-in-IP, such as Azure.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Environments that block all BGP, which is used in this model for route
distribution.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;vxlan&#34;&gt;VXLAN&lt;/h4&gt;
&lt;p&gt;VXLAN is a feature-rich form of encapsulation that enables the creation of
virtualized layer 2 networks. This is achieved by completely encapsulating the
pod&amp;rsquo;s ethernet frame and adding some header information specific to VXLAN. The
VXLAN mode &lt;strong&gt;does not&lt;/strong&gt; require BGP, which is ideal for environments where BGP
peering is blocked. When running in this mode, the packet structure looks as
shown in the diagram below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-vxlan-packet.png&#34; alt=&#34;Calico VXLAN Packet&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Note the outer ethernet frame destination is set to the &lt;code&gt;$GATEWAY&lt;/code&gt;, this could
be targeting a node&amp;rsquo;s mac address or a router depending on whether the request
is crossing a subnet boundary.&lt;/p&gt;
&lt;p&gt;In order to facilitate this model, Felix programs the route table to use VXLAN
tunnel interfaces to provide routing across nodes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/calico-route-table-vxlan.png&#34; alt=&#34;Calico Route Table (VXLAN)&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;VXLAN is arguably a more complex encapsulation option. However, it&amp;rsquo;s a known and
capable protocol, which a network team may prefer.&lt;/p&gt;
&lt;h3 id=&#34;single-subnet-configuration&#34;&gt;Single Subnet Configuration&lt;/h3&gt;
&lt;p&gt;For clusters deployed in a single subnet, use the Native routing mode. This will
provide the best performance and simplest network model as there will be no
encapsulation. Packets traversing the network will contain the source and
destination IPs of pods in their IP headers. If for any reason, networks or
hosts cannot allow this type of configuration, you&amp;rsquo;ll need to look into a full
IP-in-IP configuration instead.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-single-subnet.png&#34; alt=&#34;Calico Single Subnet&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;To enable this mode, the IPPools in the cluster must have &lt;code&gt;ipipMode&lt;/code&gt; and
&lt;code&gt;vxlanMode&lt;/code&gt; set to &lt;code&gt;Never&lt;/code&gt;. This should be done during deployment of Calico, but
it can be changed after.&lt;/p&gt;
&lt;p&gt;To ensure native routing is setup during the deployment, verify that the
following is set in the &lt;code&gt;calico-node&lt;/code&gt; container manifest:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# other variables removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Enable IPIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CALICO_IPV4POOL_IPIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Never&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using &lt;code&gt;calicoctl&lt;/code&gt;, you can verify (or modify) the &lt;code&gt;IPPool&lt;/code&gt; setting. The default
pool is exposed as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;calicoctl get ippool default-ipv4-ippool
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output should show the current setting for &lt;code&gt;ipipMode&lt;/code&gt; and &lt;code&gt;vxlanMode&lt;/code&gt;. Both
of these must be set to &lt;code&gt;Never&lt;/code&gt; as shown below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IPPool&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-ipv4-ippool&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;blockSize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;26&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cidr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;192.168.0.0&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/16&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ipipMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Never&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;natOutgoing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;all()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vxlanMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Never&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;multi-subnet-configuration&#34;&gt;Multi-Subnet Configuration&lt;/h3&gt;
&lt;p&gt;For clusters that are deployed across subnets, it&amp;rsquo;s likely native routing will
work for intra-subnet traffic. However, when pods are communicating across the
subnet boundary, they are often met with a router that relies on the destination
IP to determine what host to route to. IP-in-IP solves this, however, you&amp;rsquo;re
taking an unnecessary hit to performance and complexity for intra-subnet
traffic.&lt;/p&gt;
&lt;p&gt;For these cases, the recommended option is to run &lt;code&gt;ipipMode&lt;/code&gt; in &lt;code&gt;CrossSubnet&lt;/code&gt;.
With this setting enabled, native routing is used for all intra-subnet
communication and IP-in-IP (encapsulation) is used when crossing the subnet
boundary as illustrated in the diagram below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-multi-subnet.png&#34; alt=&#34;Calico Multi-Subnet&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;In our experience, the majority of clusters span subnets. Thus, this is the most
common recommended topology.&lt;/p&gt;
&lt;p&gt;To ensure native cross-subnet IP-in-IP is setup during the deployment, verify
that the following is set in the &lt;code&gt;calico-node&lt;/code&gt; container manifest.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# other variables removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Enable IPIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CALICO_IPV4POOL_IPIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;CrossSubnet&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using &lt;code&gt;calicoctl&lt;/code&gt;, you can verify (or modify) the &lt;code&gt;IPPool&lt;/code&gt; setting. The default
pool is exposed as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;calicoctl get ippool default-ipv4-ippool
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output should show the current setting for &lt;code&gt;ipipMode&lt;/code&gt; as &lt;code&gt;CrossSubnet&lt;/code&gt; and
&lt;code&gt;vxlanMode&lt;/code&gt; as &lt;code&gt;Never&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IPPool&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-ipv4-ippool&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;blockSize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;26&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cidr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;192.168.0.0&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/16&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ipipMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CrossSubnet&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;natOutgoing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;all()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vxlanMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Never&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;full-ip-in-ip-configuration&#34;&gt;Full IP-in-IP Configuration&lt;/h3&gt;
&lt;p&gt;If native routing for intra-subnet traffic is not possible in your environment,
e.g. the network performs source/destination checks against the IP datagram, you
can use full IP-in-IP configuration. This is the default for most Calico
deployments. To verify that, you can check the following in the &lt;code&gt;calico-node&lt;/code&gt;
manifest:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# other variables removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Enable IPIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CALICO_IPV4POOL_IPIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Always&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using &lt;code&gt;calicoctl&lt;/code&gt;, you can verify (or modify) the &lt;code&gt;IPPool&lt;/code&gt; setting. The default
pool is exposed as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;calicoctl get ippool default-ipv4-ippool
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output should show the current setting for &lt;code&gt;ipipMode&lt;/code&gt; as &lt;code&gt;Always&lt;/code&gt; and
&lt;code&gt;vxlanMode&lt;/code&gt; as &lt;code&gt;Never&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IPPool&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-ipv4-ippool&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;blockSize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;26&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cidr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;192.168.0.0&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/16&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ipipMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Always&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;natOutgoing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;all()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vxlanMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Never&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;IP-in-IP and Native both require BGP to distribute routes amongst nodes. In some
environments, BGP peering might not be possible. In these cases it&amp;rsquo;s best to
consider VXLAN, where BGP is optional.&lt;/p&gt;
&lt;h3 id=&#34;vxlan-configuration&#34;&gt;VXLAN Configuration&lt;/h3&gt;
&lt;p&gt;For environments where VXLAN is preferred or BGP is not possible, Calico can be
configured to operate in this mode. Due to the changes in routing and route
sharing between Native/IP-in-IP and VXLAN, &lt;strong&gt;do not&lt;/strong&gt; change this setting in a
running cluster. Instead, follow the steps below to ensure a cluster has VXLAN
enabled. Unless you plan to peer IPPools with existing network hardware, &lt;strong&gt;you
should disable BGP peering to reduce overhead&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;calico-config&lt;/code&gt; configmap has &lt;code&gt;backend&lt;/code&gt; set to &lt;code&gt;vxlan&lt;/code&gt; as shown below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConfigMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;calico-config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# other settings removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# value changed from bird to vxlan&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;calico_backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;“vxlan”&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;calico-node&lt;/code&gt; manifest has &lt;code&gt;CALICO_IPVPOOL_VXLAN&lt;/code&gt; set to &lt;code&gt;Always&lt;/code&gt; as
shown below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# other variables removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Enable VXLAN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CALICO_IPV4POOL_VXLAN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Always&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;calico-node&lt;/code&gt; manifest is not setting &lt;code&gt;CALICO_IPVPOOL_IPIP&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;calico-node&lt;/code&gt; manifest has all BIRD-related liveness and readiness checks
disabled as shown below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;livenessProbe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;exec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;/bin/calico-node&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- -&lt;span class=&#34;l&#34;&gt;felix-live&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# disable bird liveness test&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# - -bird-live&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;periodSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;initialDelaySeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;failureThreshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readinessProbe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;exec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;/bin/calico-node&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- -&lt;span class=&#34;l&#34;&gt;felix-ready&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# disable bird readiness test&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#- -bird-ready&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;periodSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If the above is true, Calico will operate in VXLAN mode for all traffic.&lt;/p&gt;
&lt;h3 id=&#34;mtu-configuration&#34;&gt;MTU Configuration&lt;/h3&gt;
&lt;p&gt;MTU calculation is done by determining the Network MTU and then subtracting
based on your routing configuration:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Native: Subtract by &lt;code&gt;0&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;IP-in-IP: Subtract by &lt;code&gt;20&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;VXLAN: Subtract by &lt;code&gt;50&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following table shows 2 sets of example calculation:&lt;/p&gt;





&lt;table class=&#34;table&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Network MTU&lt;/th&gt;
&lt;th&gt;Native MTU&lt;/th&gt;
&lt;th&gt;IP-in-IP MTU&lt;/th&gt;
&lt;th&gt;VXLAN MTU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1500&lt;/td&gt;
&lt;td&gt;1500&lt;/td&gt;
&lt;td&gt;1480&lt;/td&gt;
&lt;td&gt;1450&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9001 (&lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/network_mtu.html#jumbo_frame_instances&#34;&gt;AWS Jumbo&lt;/a&gt;)&lt;/td&gt;
&lt;td&gt;9001&lt;/td&gt;
&lt;td&gt;8981&lt;/td&gt;
&lt;td&gt;8951&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To set the MTU, the &lt;code&gt;calico-config&lt;/code&gt; configmap can be set as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConfigMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;calico-config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# other config omitted for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# SET THE MTU based on routing mode and network MTU&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;veth_mtu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;1440&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If this is set after deployment, &lt;strong&gt;only new pods will respect the MTU change&lt;/strong&gt;.
Any existing pods must be restarted or &lt;code&gt;calico-node&lt;/code&gt; (on the host) must be
restarted.&lt;/p&gt;
&lt;h2 id=&#34;route-distribution&#34;&gt;Route Distribution&lt;/h2&gt;
&lt;p&gt;Unless running in VXLAN mode, Calico requires the Border Gateway Protocol (BGP)
to share routes amongst hosts. BGP is a common protocol that many routers are
able to peer with. By default, Calico requires no BGP-capable routers to be
deployed. Instead it runs a routing daemon (BIRD) in each node, creating a BGP
mesh.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-bgp.png&#34; alt=&#34;Calico BGP&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Each colored line represents a peering relationship. This model is referred to
as a node-to-node mesh, as it does not centralize route distribution. Using
&lt;code&gt;calicoctl&lt;/code&gt; on 1 of the 4 hosts reveals the peering relationship.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo calicoctl node status

Calico process is running.

IPv4 BGP status
+--------------+-------------------+-------+----------+--------------------------------+
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; PEER ADDRESS &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;     PEER TYPE     &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; STATE &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;  SINCE   &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;              INFO              &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
+--------------+-------------------+-------+----------+--------------------------------+
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 10.30.0.17   &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; node-to-node mesh &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; up    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 01:17:08 &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; Established                    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 10.30.0.16   &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; node-to-node mesh &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; up    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 01:17:07 &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; Established                    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 10.30.0.14   &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; node-to-node mesh &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; up    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 01:29:06 &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; Established                    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
+--------------+-------------------+-------+----------+--------------------------------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Running the above on 1 out of 4 hosts reveals the host is peered with 3 others.
For small clusters (under 50 nodes), this model is adequate and should not
change. However, when a cluster is running 50 to thousands of nodes, this
peering relationship between every node becomes a bottle neck. For clusters that
plan to scale into hundreds of nodes, route reflectors should be leveraged.&lt;/p&gt;
&lt;p&gt;There are two types of targets Calico may be configured to peer routes with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;calico-node&lt;/code&gt; configured reflector:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In this model, nodes run dedicated &lt;code&gt;calico-node&lt;/code&gt; instances responsible for
acting as reflectors. The configuration of this model is demonstrated in
the Global Route Reflection section below.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Top of rack (ToR) switch or router:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In this model, Calico is configured to peer with existing network gear that
supports BGP. This is a valid approach for making pod &lt;code&gt;IPPools&lt;/code&gt; routable to
the network fabric. The configuration of this model is demonstrated in the
Node-Specific Route Reflection section below.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;global-route-reflection&#34;&gt;Global Route Reflection&lt;/h3&gt;
&lt;p&gt;BGP route reflectors provide centralized, highly-available route sharing hubs
that nodes can peer with. In the default node-to-node mesh topology, the
quantity of node peers are &lt;code&gt;N-1&lt;/code&gt;, where N is the total number of hosts in the
cluster. In the route reflector model, the number of peers become the quantity
of reflectors deployed. For clusters exceeding 50 nodes and potentially growing
far beyond that, this topology is recommended. Once applied, the route sharing
model looks as shown in the diagram below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-route-reflector.png&#34; alt=&#34;Calico Route Reflector&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;This model is referred to as global reflection because nodes peer to all route
reflectors made available to the cluster. This is an ideal model for most
deployments as it is simple and scalable. However, it does assume a single layer
2 network that &lt;code&gt;calico-node&lt;/code&gt; instances can peer to reflectors. For more complex
or massive-scale deployments, nodes may need to peer with specific routers in
their segment. This model is covered in the Node-Specific Route Reflection
section.&lt;/p&gt;
&lt;p&gt;Clusters wishing to achieve the global reflection model without additional
routers can leverage the &lt;code&gt;calico-node&lt;/code&gt; container. To configure this, add two
nodes to the Kubernetes cluster running &lt;code&gt;calico-node&lt;/code&gt; containers. These nodes
are tainted to ensure &lt;strong&gt;only&lt;/strong&gt; the reflector will run on them. For each node,
the Calico &lt;code&gt;Node&lt;/code&gt; CRD is altered to include a label representing the instance of
&lt;code&gt;calico-node&lt;/code&gt; as a reflector as show below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Node&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s-node-z&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Set to represent this node is a reflector&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;route-reflector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;bgp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ipv4Address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10.30.0.13&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/22&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ipv4IPIPTunnelAddr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;192.168.0.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routeReflectorClusterID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.0.0.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With nodes labeled via the &lt;code&gt;Node&lt;/code&gt; CRD, &lt;code&gt;BGPPeer&lt;/code&gt; CRDs are added for peering
configuration. These &lt;code&gt;BGPPeers&lt;/code&gt; instruct the nodes to peer with the reflectors
and the reflectors to peer with each other.&lt;/p&gt;
&lt;p&gt;Worker-to-reflector &lt;code&gt;BGPPeer&lt;/code&gt; configuration:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;BGPPeer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;node-peer-to-rr&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;!&lt;span class=&#34;l&#34;&gt;has(route-reflector)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;peerSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;has(route-reflector)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Reflector-to-reflector &lt;code&gt;BGPPeer&lt;/code&gt; configuration:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;BGPPeer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rr-to-rr-peer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;has(route-reflector)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;peerSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;has(route-reflector)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With peering for the route reflectors setup, the cluster has the node-to-node
BGP mesh disabled by modifying the &lt;code&gt;BGPConfiguration&lt;/code&gt; CRD.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;BGPConfiguration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logSeverityScreen&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Info&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Set to disable node mesh and leverage route reflectors&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeToNodeMeshEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;asNumber&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;63400&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The cluster&amp;rsquo;s new peer table looks as follows from the perspective of any node:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo calicoctl node status

Calico process is running.

IPv4 BGP status
+--------------+-----------+-------+----------+-------------+
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; PEER ADDRESS &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; PEER TYPE &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; STATE &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;  SINCE   &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;    INFO     &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
+--------------+-----------+-------+----------+-------------+
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 10.30.0.45   &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; global    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; up    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 03:52:51 &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; Established &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 10.30.0.46   &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; global    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; up    &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; 03:54:11 &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; Established &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
+--------------+-----------+-------+----------+-------------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Clusters that run in this mode introduce a (highly-available) centralized point
of failure. For this reason, you should ensure that at least 2 route reflectors
are running per cluster. Furthermore, in multi-subnet environments, ensure that
at least 1 route reflector is running per subnet.&lt;/p&gt;
&lt;h3 id=&#34;node-specific-route-reflection&#34;&gt;Node-Specific Route Reflection&lt;/h3&gt;
&lt;p&gt;Peering can be configured for BGP-capable hardware in a datacenter&amp;rsquo;s network.
Most commonly setup with top of rack (ToR) switches. Each grouping of reflected
routes typically represent a separate network AS as illustrated in the diagram
below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-route-reflection-tor.png&#34; alt=&#34;Calico Route Reflection (TOR)&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;To configure the above model, each node should be labeled with an identifier
representing the part of the network it runs in.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Node&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s-node-z&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Add rack label; used for BGPPeer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rack&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;bgp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ipv4Address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10.30.0.13&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/22&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ipv4IPIPTunnelAddr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;192.168.0.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routeReflectorClusterID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.0.0.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With nodes labeled via the &lt;code&gt;Node&lt;/code&gt; CRD, &lt;code&gt;BGPPeer&lt;/code&gt; CRDs are added for each target
switch / router to be peered with. These &lt;code&gt;BGPPeers&lt;/code&gt; instruct the nodes to peer
with the ToR.&lt;/p&gt;
&lt;p&gt;Here is a Worker-to-ToR &lt;code&gt;BGPPeer&lt;/code&gt; configuration:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;BGPPeer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;node-peer-rack-a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# peer all nodes with label rack: a with peerIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rack == &amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;peerIP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;192.168.1.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# remote AS number of the peer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;asNumber&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;64400&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With peering for the switch or router setup, the cluster&amp;rsquo;s node-to-node
BGP mesh is disabled by modifying the &lt;code&gt;BGPConfiguration&lt;/code&gt; CRD as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;BGPConfiguration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logSeverityScreen&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Info&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Set to disable node mesh and leverage route reflectors&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeToNodeMeshEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;asNumber&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;63400&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;routable-pod-and-service-networks&#34;&gt;Routable Pod and Service Networks&lt;/h3&gt;
&lt;p&gt;Calico supports making pod and service networks routable to the entire network.
By default, the pod network and service networks are only routable from the
hosts that &lt;code&gt;calico-node&lt;/code&gt; runs on. The need for routable pod and service networks
should be considered carefully. In many architectures, an external load balancer
paired with an ingress controller can achieve a more idiomatic network topology
for Kubernetes. Making these networks routable can come with some downsides:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reliance on routing directly to Pod IPs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes treats pod IPs ephemerally. Assuming a pod&amp;rsquo;s IP will stay
consistent is generally an anti-pattern.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Service IPs, when routable, are still backed by &lt;code&gt;kube-proxy&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kube-proxy&lt;/code&gt; implements simple round-robin load balancing with IPtables.
The limited routing capabilities and scalability of IPtables may be a
concern.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Routing pod networks can consume a large chunk of an organization&amp;rsquo;s IPv4 space.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If your use case justifies routable pods, the following sections discuss how to
setup various topologies:&lt;/p&gt;
&lt;h4 id=&#34;routable-pod-network&#34;&gt;Routable Pod Network&lt;/h4&gt;
&lt;p&gt;To make the entire pod network routable, &lt;code&gt;BGPPeer&lt;/code&gt;s are to be configured. The
Node-Specific Route Reflection of this reference architecture covers this in
detail. However, for routable pods, global or node-specific peering is
acceptable. The key is to peer with a ToR that propagates routes to the larger
network as illustrated in the diagram below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-routable-pods.png&#34; alt=&#34;Calico Routable Pods&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;An example peering configuration to accomplish the above is as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;BGPPeer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;node-peer-router&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# peer all nodes containing label network-node with ToR&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;has(&amp;#39;network-node&amp;#39;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;peerIP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;192.168.1.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# remote AS number of the peer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;asNumber&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;64400&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Node-to-node meshing should be disabled.&lt;/p&gt;
&lt;p&gt;In this topology, the entire pod CIDR is routable. This can be non-desirable as
a pod CIDR can often be as large as a &lt;code&gt;/16&lt;/code&gt; and consuming that much IP space is
unrealistic. In these cases, additional &lt;code&gt;IPPool&lt;/code&gt;(s) can be introduced to target
a smaller routable space. With another &lt;code&gt;IPPool&lt;/code&gt;, the topology may look as
follows:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/container-networking/diagrams/calico-routable-pods-extra-pool.png&#34; alt=&#34;Calico Routable Pods (Extra Pool)&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;This topology makes deployment, management, and networking more complex than
usual. If routable pods are a use case, it&amp;rsquo;s worth considering running a
dedicated cluster with a smaller pod CIDR to facilitate routable pods as opposed
to running a single cluster fostering multiple routing models.&lt;/p&gt;
&lt;p&gt;The routable pods model relies on labels in the
&lt;a href=&#34;https://docs.projectcalico.org/v3.11/reference/resources/node&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Node&lt;/a&gt; CRD. The
above requires a common label for nodes containing non-routable pods and labels
for nodes containing routable pods. To start, the cluster adds a label qualifier
to only apply the default IPPool to specific nodes (based on label).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IPPool&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-ipv4-ippool&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;blockSize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;26&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cidr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;192.168.0.0&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/16&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ipipMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Never&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;natOutgoing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Use IPs from this pool for all non-routable nodes.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;network-type == &amp;#39;non-routable&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vxlanMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Never&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A second IPPool is added to represent the routable pod pool.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IPPool&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-ipv4-ippool&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;blockSize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;26&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Introduce a smaller routable pod CIDR&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cidr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;192.168.100.0&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/24&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ipipMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Never&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;natOutgoing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Use IPs from this pool for all routable nodes.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;network-type == &amp;#39;routable&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vxlanMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Never&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This would apply to worker-AA and worker-BB in the diagram above.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/v3.11/reference/resources/bgppeer&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;BGPPeer&lt;/a&gt;s are
setup for the non-routable pods, in the same way described in Global Route
Reflection section. The only difference is the &lt;code&gt;nodeSelector&lt;/code&gt; must only select
nodes where &lt;code&gt;nodeSelector: network-type == &#39;routable&#39;&lt;/code&gt;. A &lt;code&gt;BGPPeer&lt;/code&gt; for the
nodes featuring routable pods looks as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;BGPPeer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;node-peer-router&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;network-type == &amp;#39;routable&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;peerIP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;192.168.1.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# remote AS number of the peer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;asNumber&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;64400&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With the above in place, there is now an internally routable (default) &lt;code&gt;IPPool&lt;/code&gt;
and a fully routable &lt;code&gt;IPPool&lt;/code&gt;. Using taints and admission control, the cluster
can be configured to ensure only select workloads land in the routable space.&lt;/p&gt;
&lt;h4 id=&#34;routable-service-network&#34;&gt;Routable Service Network&lt;/h4&gt;
&lt;p&gt;Along with pod IPs, services can be routable. This means propagating
&lt;code&gt;ClusterIP&lt;/code&gt;s to upstream routers over BGP. To enable this feature set, add the
service CIDRs to the &lt;code&gt;BGPConfiguration&lt;/code&gt;. This assumes &lt;code&gt;BGPPeers&lt;/code&gt; are already
configured.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;BGPConfiguration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceClusterIPs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;cidr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;172.34.12.0&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/24&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It is important that ToR components support ECMP load balancing. If they do not,
service traffic will be routed through a single node.&lt;/p&gt;
&lt;h2 id=&#34;network-policy-enforcement&#34;&gt;Network Policy Enforcement&lt;/h2&gt;
&lt;p&gt;While network policy designs are out of scope for this reference architecture,
it is a core feature of Calico and thus is mentioned here to provide initial
guidance.&lt;/p&gt;
&lt;p&gt;Calico enforces 3 types of policies:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NetworkPolicy: Kubernetes API: Namespace scoped&lt;/li&gt;
&lt;li&gt;NetworkPolicy: Calico CRD: Namespace scoped&lt;/li&gt;
&lt;li&gt;GlobalNetworkPolicy: Calico CRD: Cluster scoped&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Calico CRDs are more capable than the Kubernetes API, however the Kubernetes
API policies are portable, should migration to another CNI-plugin happen in the
future. Many organizations want to enforce default policy to every namespace.
Normally, administrators need to ensure default policy rules are deployed to
every namespace. This can be challenging over time as changes to the default
policy rules require changes to every namespace. Calico&amp;rsquo;s &lt;code&gt;GlobalNetworkPolicy&lt;/code&gt;
enables creating cluster-wide policies that impact every workload based on label
selectors. Cluster-wide policy set in &lt;code&gt;GlobalNetworkPolicy&lt;/code&gt; can be overwritten
by &lt;code&gt;NetworkPolicy&lt;/code&gt; (namespace scoped) from both the Kubernetes API and Calico
CRD. The example below enforces a global default deny-all policy:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;c&#34;&gt;# This GlobalNetworkPolicy uses Calico&amp;#39;s CRD&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# (https://docs.projectcalico.org/v3.5/reference/calicoctl/resources/globalnetworkpolicy)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcalico.org/v3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GlobalNetworkPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;global-deny-all&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# order controls the precedence. Calico applies the policy with the lowest value first.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Kubernetes NetworkPolicy does not support order. They are automatically converted to an order&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# value of 1000 by Calico. Setting this value to 2000, provides flexibility for 999 additional&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# GlobalNetworkPolicies to be added and ensures Kubernetes namespace-scoped policies always take&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# precedence.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;types&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;Egress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# egress network rules&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;egress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Allow all egress traffic from kube-system.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Allow&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespaceSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;name == &amp;#39;kube-system&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Allow egress DNS traffic to any destination.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Allow&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;UDP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;m&#34;&gt;0.0.0.0&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;m&#34;&gt;53&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ingress network rules&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ingress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Allow all ingress traffic for the kube-system namespace.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Allow&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespaceSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;name == &amp;#39;kube-system&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The policy above denies all pod network traffic by default, except for workloads
in &lt;code&gt;kube-system&lt;/code&gt; and DNS communications (UDP:53). With this in place, a
namespace could open up ingress traffic to port 80 for any workload in it, by
adding the following &lt;code&gt;NetworkPolicy&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;NetworkPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;team-netpol&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;org-1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;policyTypes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;Egress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ingress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# allow all inbound traffic on port 80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TCP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With appropriate admission control, the above model can provide powerful policy
constructs impacting egress and ingress traffic for a cluster.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Configuring the Dex Identity Provider</title>
      
      <link>/guides/kubernetes/identity-dex/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/identity-dex/</guid>
      <description>

        
        &lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Most organizations have an IT department that handle new staff on boarding and
provide them a new set of credentials. These credentials are stored in
centralized directory service, most commonly Active Directory. Some cases expose
these services through an Identity Provider using OIDC or SAML.&lt;/p&gt;
&lt;p&gt;Authentication and Authorization is a common topic on how you can provide
Kubernetes cluster access and the resources to the intended user; e.g.:
Developers, Kubernetes Admin, Backup Admin, etc. Rather than create and manage a
new user repository, you can leverage Dex and Gangway to enable kubernetes
cluster authentication using an existing Identity Provider.&lt;/p&gt;
&lt;p&gt;Gangway is a web application that enables the OIDC authentication flow which
results in the minting of the ID Token.Dex acts as a portal to other identity
providers through &amp;ldquo;connectors.&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;configuration&#34;&gt;Configuration&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/identity/diagrams/dex-setup-01.png&#34; alt=&#34;Dex Gangway Setup&#34;  /&gt;
&lt;strong&gt;Figure 1: Dex - Gangway Identity Federation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Assuming you have either Active Directory or IDP server that provide centralized
user management and you wish all your Kubernetes user is authenticated before
they are able to access the resource. This scenario is the typical usage for
Dex and Gangway and will be explained further in the following sections&lt;/p&gt;
&lt;h3 id=&#34;dex-and-gangway&#34;&gt;Dex and Gangway&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/identity/diagrams/dex-setup-02.png&#34; alt=&#34;Dex Gangway Setup&#34;  /&gt;
&lt;strong&gt;Figure 2: Dex - Gangway Configuration&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Dex provide common OIDC endpoints for multiple Identity providers. To configure
Dex and Gangway communication, you need to collect some information from Dex.
Following OIDC standard, Dex provides a URL where its OIDC configuration can
be gathered. This URL is located at &lt;code&gt;.well-known/openid-configuration&lt;/code&gt; and by
accessing the URL, Dex will produce the following response&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;c&#34;&gt;## Sample &amp;#39;.well-known/openid-configuration&amp;#39; DEX response&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;issuer&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;http://app.example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;authorization_endpoint&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;http://app.example.com/auth&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;token_endpoint&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;http://app.example.com/token&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;jwks_uri&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;http:/app.example.com/keys&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;response_types_supported&amp;#34;: &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;code&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;subject_types_supported&amp;#34;: &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;public&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;id_token_signing_alg_values_supported&amp;#34;: &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;RS256&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scopes_supported&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;openid&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;email&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;groups&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;profile&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;offline_access&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;token_endpoint_auth_methods_supported&amp;#34;: &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;client_secret_basic&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;claims_supported&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;aud&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;email&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;email_verified&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;exp&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;iat&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;iss&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;locale&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;sub&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With the above response from Dex, Gangway configuration can be defined
as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Yaml&#34; data-lang=&#34;Yaml&#34;&gt;&lt;span class=&#34;c&#34;&gt;## Sample Gangway ConfigMap configuration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConfigMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;gangway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gangway.yaml&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    serveTLS: false
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    certFile: /tls/tls.crt
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    keyFile: /tls/tls.key
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    clusterName: &amp;#34;{{Gangway cluster name}}&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    #!! Dex URL for token auth request
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    authorizeURL: &amp;#34;{{ Dex authorization_endpoint }}&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    #!! Dex URL to obtain access tokens.
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    tokenURL: &amp;#34;{{ Dex token_endpoint }} &amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # Where to redirect back to. This should be a URL where gangway is reachable.
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # Typically this also needs to be registered as part of the oauth application
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # with the oAuth provider.
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    redirectURL: &amp;#34;{{Gangway hostname}}/callback&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # Used to specify the scope of the requested Oauth authorization.
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    #!! Refer to dex `scopes_supported` response above
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    scopes: [&amp;#34;openid&amp;#34;, &amp;#34;profile&amp;#34;, &amp;#34;email&amp;#34;, &amp;#34;offline_access&amp;#34;]
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # API client ID as indicated by the identity provider
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    clientID: &amp;#34;{{Gangway Client Id}}&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    #!! refer to dex `claims_supported` response above.
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    usernameClaim: &amp;#34;email&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # The API server endpoint used to configure kubectl
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    apiServerURL: &amp;#34;{{ Kubernetes API hostname }}:6443/&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # The path to a root CA to trust for self signed certificates
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # at the Oauth2 URLs.
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    # the dex-ca.crt can be mounted as secret in kubernetes
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    trustedCAPath: /etc/dex/dex-ca.crt
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    idpCAPath: /etc/dex/dex-ca.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;registering-gangway&#34;&gt;Registering Gangway&lt;/h4&gt;
&lt;p&gt;In order to establish communication between Dex and Gangway, Dex require a
registration of Gangway through &lt;code&gt;Client id&lt;/code&gt;, and &lt;code&gt;Client secret&lt;/code&gt; exchange.
This allow Dex to authenticate that the intended requestor (in this case
Gangway) is registered within Dex and is allowed to retrieve access token
through Dex.&lt;/p&gt;
&lt;p&gt;The configuration for Client id and Secret in Dex and Gangway can be define
as follows&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;c&#34;&gt;## Sample Dex Config Map&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConfigMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;dex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;config.yaml&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    ...
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    staticClients: 
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    - id: {{Gangway Client Id}}
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      redirectURIs:
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      - &amp;#39;{{ Gangway Callback URL}}&amp;#39;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      name: &amp;#39;{{Gangway Client Id}}&amp;#39;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      secret: {{Decoded Gangway Client Secret}}
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    ....&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;&lt;span class=&#34;c&#34;&gt;## Sample Gangway Secret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Secret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;gangway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Opaque&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#! Key to generate secret session.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#! Command to run : openssl rand -base64 32 | pbcopy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sesssionKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;session key for dex } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#! base64 encoded client secret , shoudl match with Dex config Client Secret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#! echo -n &amp;#34;$clientSecret&amp;#34; | base64&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clientSecret&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;encoded Gangway Client Secret } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;identity-federation&#34;&gt;Identity Federation&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/identity/diagrams/dex-setup-03.png&#34; alt=&#34;dex-federation&#34;  /&gt;
&lt;strong&gt;Figure 3: Dex - Identity Federation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Dex acts as a portal to other identity providers through &lt;code&gt;connectors&lt;/code&gt;. This
lets Dex defer authentication to LDAP servers, SAML providers, or established
identity providers like GitHub, Google, and Active Directory. Clients write
their authentication logic once to talk to Dex, then Dex handles the protocols
for a given backend.&lt;/p&gt;
&lt;p&gt;Upon successful authentication, signed JWT token returned by Dex as part of the
authentication (OAuth2) response that attest to the end user&amp;rsquo;s identity. The JWT
token issued by Dex contains standard claims which can be consumed by other
system for service to service call.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;err&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Sample&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;JWT&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;claims&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Dex.&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;iss&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://127.0.0.1:5556/dex&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;sub&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;CgcyMzQyNzQ5EgZnaXRodWI&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;aud&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;example-app&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;exp&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1492882042&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;iat&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1492795642&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;at_hash&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;bi96gOXZShvlWYtal9Eqiw&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;email&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;jane.doe@ldap.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;email_verified&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;groups&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;admins&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;developers&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Jane Doe&amp;#34;&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;connector&#34;&gt;Connector&lt;/h4&gt;
&lt;p&gt;A &lt;code&gt;connector&lt;/code&gt; is a plugin that used by Dex for authenticating a user against
another identity provider. Dex adopted connectors that target specific platforms
such as LDAP, OIDC, Github, SAML, etc. A list of available connectors is available
&lt;a href=&#34;https://github.com/dexidp/dex/blob/master/README.md#connectors&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Depending on the connectors limitations in protocols can prevent Dex from
issuing refresh tokens or returning group membership claims. For example,
because SAML doesn&amp;rsquo;t provide a non-interactive way to refresh assertions, if a
user logs in through the SAML connector Dex won&amp;rsquo;t issue a refresh token to
its client.&lt;/p&gt;
&lt;p&gt;With the example from the above diagrams (figure 1), the configuration for the
connectors can be defined as follows&lt;/p&gt;
&lt;h5 id=&#34;_for-ldap-connector_&#34;&gt;&lt;em&gt;For LDAP Connector&lt;/em&gt;&lt;/h5&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;connectors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ldap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ldap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;LDAP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ldap.example.com:636&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;insecureNoSSL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;insecureSkipVerify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;startTLS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rootCA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/etc/dex/ldap.ca&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;bindDN&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;uid=serviceaccount,cn=users,dc=example,dc=com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;bindPW&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usernamePrompt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;SSO Username&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;userSearch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;baseDN&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cn=users,dc=example,dc=com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;(objectClass=person)&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;uid&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;idAttr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;uid&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;emailAttr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mail&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nameAttr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;groupSearch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;baseDN&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cn=groups,dc=freeipa,dc=example,dc=com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;(objectClass=group)&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;userMatchers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;userAttr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;uid&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;groupAttr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;member&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nameAttr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h5 id=&#34;_for-oidc-connector_&#34;&gt;&lt;em&gt;For OIDC Connector&lt;/em&gt;&lt;/h5&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;connectors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;oidc&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;oidcServer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;oidcServer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;issuer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://accounts.google.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clientID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;$CLIENT_ID&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clientSecret&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;$CLIENT_SECRET&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Dex&amp;#39;s issuer URL + &amp;#34;/callback&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;redirectURI&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http://127.0.0.1:5556/callback&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Some providers require passing client_secret via POST parameters instead&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# of basic auth, despite the OAuth2 RFC discouraging it. Many of these&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# cases are caught internally, but some may need to uncomment the&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# following field.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;basicAuthUnsupported&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# List of additional scopes to request in token response&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Default is profile and email&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Full list at https://github.com/dexidp/dex/blob/master/Documentation/custom-scopes-claims-clients.md&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scopes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;profile&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;email&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;groups&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;insecureSkipEmailVerified&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;insecureEnableGroups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# When enabled, the OpenID Connector will query the UserInfo endpoint for additional claims. UserInfo claims&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# take priority over claims returned by the IDToken. This option should be used when the IDToken doesn&amp;#39;t contain&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# all the claims requested.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# https://openid.net/specs/openid-connect-core-1_0.html#UserInfo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;getUserInfo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The set claim is used as user id.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Default: sub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Claims list at https://openid.net/specs/openid-connect-core-1_0.html#Claims&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;userIDKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nickname&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The set claim is used as user name.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Default: name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;userNameKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nickname&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# For offline_access, the prompt parameter is set by default to &amp;#34;prompt=consent&amp;#34;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# However this is not supported by all OIDC providers, some of them support different&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# value for prompt, like &amp;#34;prompt=login&amp;#34; or &amp;#34;prompt=none&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;promptType&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;consent&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h5 id=&#34;_for-saml-connector_&#34;&gt;&lt;em&gt;For SAML Connector&lt;/em&gt;&lt;/h5&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;connectors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;saml&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Required field for connector id.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;saml&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Required field for connector name.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;SAML&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# SSO URL used for POST value.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ssoURL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://saml.example.com/sso&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# CA to use when validating the signature of the SAML response.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ca&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/path/to/ca.pem&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Dex&amp;#39;s callback URL.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;redirectURI&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://dex.example.com/callback&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Name of attributes in the returned assertions to map to ID token claims.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usernameAttr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;emailAttr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;email&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;groupsAttr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;groups&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# optional&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# To skip signature validation, uncomment the following field. This should&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# only be used during testing and may be removed in the future.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;insecureSkipSignatureValidation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Optional: Manually specify dex&amp;#39;s Issuer value.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;entityIssuer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://dex.example.com/callback&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Optional: Issuer value expected in the SAML response.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ssoIssuer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://saml.example.com/sso&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Optional: Delimiter for splitting groups returned as a single string.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;groupsDelim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;, &amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Optional: Requested format of the NameID.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nameIDPolicyFormat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;persistent&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      
      <title>Guides: Contour Reference Architecture</title>
      
      <link>/guides/kubernetes/service-routing-contour-refarch/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/service-routing-contour-refarch/</guid>
      <description>

        
        &lt;p&gt;This document details a reference architecture for running
&lt;a href=&#34;https://projectcontour.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Contour&lt;/a&gt; as the ingress controller for a Kubernetes
cluster, such as &lt;a href=&#34;https://tanzu.vmware.com/kubernetes-grid&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Tanzu Kubernetes Grid
(TKG)&lt;/a&gt;. It covers deployment
considerations, multi-tenancy concerns, and best practices. This document
represents how the VMware field team approaches Contour deployments in large
enterprise Kubernetes environments.&lt;/p&gt;
&lt;p&gt;Throughout the document, &amp;ldquo;Contour&amp;rdquo; refers to the ingress controller as a whole.
In contrast, &amp;ldquo;contour&amp;rdquo; refers to the control plane of the ingress controller, or
the component of the ingress controller that interacts with the Kubernetes API.&lt;/p&gt;
&lt;p&gt;Each section covers architectural recommendations and, at times, configuration
for each concern in a Contour deployment. At a high-level, the key
recommendations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Follow the &lt;a href=&#34;#split-deployment&#34;&gt;split deployment architecture&lt;/a&gt; to deploy
Contour onto the cluster.
&lt;ul&gt;
&lt;li&gt;Use a Deployment to run at least two instances of contour&lt;/li&gt;
&lt;li&gt;Use a DaemonSet to deploy Envoy. (Use a Deployment if you want to auto-scale
Envoy pods.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use an external load balancer to distribute traffic across Envoy pods.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#avoiding-unnecessary-network-hops&#34;&gt;Set &lt;code&gt;externalTrafficPolicy: Local&lt;/code&gt; when exposing Envoy over a &lt;code&gt;NodePort&lt;/code&gt; or
&lt;code&gt;LoadBalancer&lt;/code&gt; service&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Consider using &lt;a href=&#34;#dedicated-ingress-nodes&#34;&gt;dedicated ingress nodes&lt;/a&gt; to minimize
variability in request latency and unexpected performance issues.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#envoy-and-host-networking&#34;&gt;Consider binding Envoy to the underlying host&amp;rsquo;s network&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Create a &lt;a href=&#34;#wildcard-dns&#34;&gt;wildcard DNS record&lt;/a&gt; that resolves to the load
balancer in front of Envoy.&lt;/li&gt;
&lt;li&gt;Leverage &lt;a href=&#34;#wildcard-certificates-and-tls-certificate-delegation&#34;&gt;TLS certificate
delegation&lt;/a&gt; to secure
wildcard TLS certificates.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#preventing-ingress-configuration-collisions&#34;&gt;Avoid ingress configuration
clashes&lt;/a&gt; by leveraging HTTPProxy
inclusion or an admission controller, such as OPA Gatekeeper.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;contour-overview&#34;&gt;Contour overview&lt;/h2&gt;
&lt;p&gt;Contour is an ingress controller for Kubernetes that leverages
&lt;a href=&#34;http://envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Envoy&lt;/a&gt; in the data plane. With Contour, you can route
external clients to network services (usually HTTP and HTTPS) running within
your Kubernetes cluster. Contour routes traffic according to rules defined in
Kubernetes Ingress resources and Contour-specific HTTPProxy custom resources.
The HTTPProxy custom resource enables advanced use-cases that are otherwise not
available through the Kubernetes Ingress resource, such as configuring the load
balancing strategies, header-based routing, TLS cert delegation, and
&lt;a href=&#34;https://projectcontour.io/docs/v1.6.1/httpproxy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;more&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Like other ingress controllers and Software-Defined Networking (SDN) solutions,
Contour is composed of a control plane and a data plane. The control plane is a
Kubernetes controller (&amp;ldquo;contour&amp;rdquo;) that watches various resources defined in the
Kubernetes API, such as the Ingress and HTTPProxy resources. The data plane is a
collection of Envoy proxies that use contour as their management server. The
following diagram shows a high-level overview of a typical Contour&amp;rsquo;s deployment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/contour-high-level-architecture.drawio.png&#34; alt=&#34;Contour Architecture&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;When Envoy starts up, it connects to contour and opens a persistent gRPC stream.
Using this stream, contour configures Envoy according to the Ingress and
HTTPProxy resources defined in the Kubernetes API. As these resources change,
contour sends updates to Envoy to reflect the latest configuration. This
API-driven configuration capability makes Envoy (and thus the Contour ingress
controller) an excellent fit for an environment as dynamic as Kubernetes. The
configuration is streamed as soon as it changes, and no restarts are required
for Envoy to start using the new configuration.&lt;/p&gt;
&lt;h3 id=&#34;shutdown-manager&#34;&gt;Shutdown manager&lt;/h3&gt;
&lt;p&gt;The shutdown manager is an ancillary component that enables the graceful
shutdown of Envoy. Its goal is to reduce the number of dropped connections or
requests during pod lifecycle events, such as an update.&lt;/p&gt;
&lt;p&gt;The shutdown manager is a sidecar that runs alongside the Envoy container. It
exposes an HTTP endpoint that accepts GET requests on &lt;code&gt;/shutdown&lt;/code&gt;. This endpoint
is wired up as the preStop hook in the Envoy container.&lt;/p&gt;
&lt;p&gt;When the Kubelet needs to terminate an Envoy pod, it sends a GET request to the
shutdown manager, according to the preStop hook configuration. The shutdown
manager, in turn, tells Envoy to drain existing connections. It also tells Envoy
to fail its readiness check, which prevents upstream load balancers from
establishing new connections. The shutdown manager then blocks and keeps the pod
running until Envoy drains all the connections, or until the shutdown grace
period is reached. To determine whether all connections have been drained, the
shutdown manager polls Envoy&amp;rsquo;s metrics endpoint and looks at the active
connections metrics.&lt;/p&gt;
&lt;h2 id=&#34;ingress-patterns&#34;&gt;Ingress Patterns&lt;/h2&gt;
&lt;p&gt;Contour supports different patterns to expose applications to requests from
outside of the cluster.&lt;/p&gt;
&lt;h3 id=&#34;http-proxying&#34;&gt;HTTP proxying&lt;/h3&gt;
&lt;p&gt;Exposing applications over HTTP is the most basic pattern. Clients send an HTTP
request that is routed to Envoy. Once there, Envoy inspects the HTTP request and
routes it to a backend pod according to the Ingress or HTTPProxy configuration.&lt;/p&gt;
&lt;p&gt;Given the following HTTPProxy resource, Envoy will route requests to the &lt;code&gt;app1&lt;/code&gt;
Service when the request has a Host header of &lt;code&gt;app1.example.com&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;virtualhost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fqdn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following diagrams shows the flow of the request:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/contour-ingress-patterns-http.drawio.png&#34; alt=&#34;HTTP Ingress&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;exposing-applications-with-tls-https&#34;&gt;Exposing applications with TLS (HTTPS)&lt;/h3&gt;
&lt;p&gt;Contour supports exposing applications over HTTPS. To make routing decisions
according to the request, Envoy needs to decrypt the incoming TLS connection.
That is, Envoy terminates the TLS connection and then routes the request to the
backend server over an unencrypted connection.&lt;/p&gt;
&lt;p&gt;Building on the previous example, the following configuration tells Envoy to
expose &lt;code&gt;app1&lt;/code&gt; over HTTPS using the certificate and private key contained in the
&lt;code&gt;tls-cert&lt;/code&gt; Secret.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;virtualhost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fqdn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tls-cert&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following diagram shows the request flow:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/contour-ingress-patterns-https.drawio.png&#34; alt=&#34;HTTPS Ingress&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;When TLS is enabled, Envoy redirects HTTP clients to the HTTPS endpoint. The
redirect is enabled by default when using TLS, but it can be disabled on
specific routes by setting &lt;code&gt;permitInsecure: true&lt;/code&gt;. The following diagram shows
the redirect to the secure endpoint:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/contour-ingress-patterns-https-redirect.drawio.png&#34; alt=&#34;HTTPS Ingress with redirect&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;tls-connection-to-an-http-backend&#34;&gt;TLS connection to an HTTP backend&lt;/h3&gt;
&lt;p&gt;As mentioned above, Envoy establishes an unencrypted connection to the backend
service when TLS is enabled. Envoy can, however, create a secure connection when
necessary. If the backend exposes a secure endpoint and expects a TLS
connection, you can set the protocol field to &lt;code&gt;tls&lt;/code&gt; in the route configuration.&lt;/p&gt;
&lt;p&gt;The following sample HTTPProxy resource sets the &lt;code&gt;protocol&lt;/code&gt; field of the &lt;code&gt;app1&lt;/code&gt;
service to &lt;code&gt;tls&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;virtualhost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fqdn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tls-cert&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following diagram shows the connections given the above configuration:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/contour-ingress-patterns-https-to-backend.drawio.png&#34; alt=&#34;HTTPS Ingress with TLS to backend&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;By default, Envoy &lt;strong&gt;does not&lt;/strong&gt; validate the certificate served by the backend.
To enable validation, you must specify a &lt;code&gt;caSecret&lt;/code&gt; and &lt;code&gt;subjectName&lt;/code&gt; in the
HTTPProxy configuration:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;virtualhost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fqdn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tls-cert&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;validation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;caSecret&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ca-cert&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subjectName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;app1.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;exposing-tcp-services&#34;&gt;Exposing TCP services&lt;/h3&gt;
&lt;p&gt;In addition to HTTP services, Contour can also expose TCP services through
Envoy. The only requirement is that the incoming TCP connection is encrypted
with TLS and that the client indicates the destination hostname using &lt;a href=&#34;https://tools.ietf.org/html/rfc6066#page-6&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Server
Name Indication (SNI)&lt;/a&gt;. Envoy needs
this indication to route the connection to the appropriate backend.&lt;/p&gt;
&lt;p&gt;TCP proxying is configured using the &lt;code&gt;tcpproxy&lt;/code&gt; field of the HTTPProxy custom
resource, as in the following example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp-svc&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;virtualhost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fqdn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp-app.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tls-secret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tcpproxy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With the above configuration, Envoy first inspects the SNI extension to
determine the destination server. Once identified, it terminates the TLS
connection and forwards the TCP traffic over an unencrypted connection.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/contour-ingress-patterns-tcp-proxying.drawio.png&#34; alt=&#34;TCP Proxying with TLS&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;tls-passthrough&#34;&gt;TLS passthrough&lt;/h3&gt;
&lt;p&gt;If the backend TCP service needs to handle the TLS connection, you can enable
TLS passthrough. In this mode, Envoy inspects the SNI extension to determine the
backend service but does not terminate the TLS connection. Instead, it forwards
the TLS connection to the backend service.&lt;/p&gt;
&lt;p&gt;To enable TLS passthrough, set &lt;code&gt;tls.passthrough = true&lt;/code&gt;, as in the following
HTTPProxy example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp-svc&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;virtualhost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fqdn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp-app.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;passthrough&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tcpproxy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/contour-ingress-patterns-tcp-proxying-passthrough.drawio.png&#34; alt=&#34;TCP Proxy with TLS passthrough&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;deployment-architecture&#34;&gt;Deployment architecture&lt;/h2&gt;
&lt;p&gt;You can deploy Contour onto a Kubernetes cluster in different ways. Because
Envoy and contour talk to each other over a gRPC connection, you can deploy them
as separate pods. Alternatively, you can deploy Envoy with contour as a sidecar.
These deployment models are discussed below.&lt;/p&gt;
&lt;h3 id=&#34;split-deployment&#34;&gt;Split deployment&lt;/h3&gt;
&lt;p&gt;In this model, you deploy contour and Envoy separately, contour as a Deployment
and Envoy as a DaemonSet. (Envoy can also be managed by a Deployment. More on
this below.) The contour deployment runs two or more replicas to ensure
high-availability of the control plane. The contour replicas are accessible
through a ClusterIP Service. Envoy uses this Service to connect to contour and
initiate the gRPC stream to get the routing configuration. The following diagram
shows the control plane architecture of the split deployment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/contour-split-deployment-architecture.drawio.png&#34; alt=&#34;Contour Split-Deployment Control Plane&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The main benefits of the split deployment model are scalability and efficiency.
Because contour and Envoy are deployed separately, you can scale the data plane
independently of the control plane. That is, you can horizontally scale the
Envoy pods to meet the traffic demands of your applications without increasing
the number of contour pods. By running the minimal amount of contour pods
necessary, you save on compute resources while also reducing the load on the
Kubernetes API server itself.&lt;/p&gt;
&lt;p&gt;As mentioned above, the split deployment model can be more scalable and
efficient than the same-pod deployment model. There is a tradeoff involved,
however, in that the split deployment model is more complex. Given that contour
and Envoy run as separate pods, (and thus live in different network namespaces),
they need to communicate over the pod network.&lt;/p&gt;
&lt;p&gt;The interaction between contour and Envoy exposes an attack surface that you
must mitigate, given that contour serves sensitive information such as TLS
secrets. These secrets must only be available to trusted Envoy clients and no
other workloads in the cluster. In other words, contour needs to authenticate
clients, and it does so using mutual TLS. In the split deployment model, contour
uses a serving certificate to expose an HTTPS endpoint, and Envoy uses a client
certificate to authenticate with contour. Having to manage these certificates
over time increases the complexity of the split deployment architecture.&lt;/p&gt;
&lt;h3 id=&#34;sidecar-deployment&#34;&gt;Sidecar deployment&lt;/h3&gt;
&lt;p&gt;The sidecar deployment architecture co-locates contour and Envoy in the same pod
(the &amp;ldquo;Contour pod&amp;rdquo;). This architecture is similar to other ingress controllers,
such as the NGINX ingress controller. Multiple replicas of the Contour pod run
in the cluster and are managed by a Kubernetes Deployment or DaemonSet.&lt;/p&gt;
&lt;p&gt;Because Envoy and contour are in the same pod, they can talk to each other over
localhost. This removes the need for mutual TLS between Envoy and contour, which
alleviates the operational burden of managing certificates. The following
diagram shows the sidecar deployment, focusing on the interaction between
contour and Envoy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/contour-sidecar-deployment-architecture.drawio.png&#34; alt=&#34;Contour Sidecar Deployment&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The main drawback of the sidecar deployment is an increase in load imposed on
the Kubernetes API server. Instead of running a couple of contour pods to serve
the configuration to n Envoy servers, you now have n contour processes
connecting to and watching the API server. Unless you plan to run a limited
number of Contour pods (by using dedicated ingress nodes, for example), you
should avoid this deployment model.&lt;/p&gt;
&lt;h2 id=&#34;envoy-deployment-considerations&#34;&gt;Envoy deployment considerations&lt;/h2&gt;
&lt;h3 id=&#34;dedicated-ingress-nodes&#34;&gt;Dedicated ingress nodes&lt;/h3&gt;
&lt;p&gt;The ingress tier is a critical component of an application platform. It is
shared across different applications, and it is in the data path between an
application and its customers. Due to the importance of the ingress data path,
dedicating cluster nodes to run Envoy is beneficial.&lt;/p&gt;
&lt;p&gt;The primary benefit is resource isolation. Even though Kubernetes has support
for setting up resource requests and limits, getting those parameters right can
be challenging. Furthermore, Kubernetes does not support resource isolation for
network I/O or file descriptors. When running Envoy by itself, you prevent any
potential noisy neighbor problems that could impact the performance of the
ingress data plane. You also don&amp;rsquo;t have to worry about Envoy getting evicted by
other pending pods when nodes are under resource contention.&lt;/p&gt;
&lt;p&gt;Another reason for running Envoy on dedicated nodes is compliance. Most
enterprise environments have predefined firewall rules that can be incompatible
with ingress requirements. If you are working in such an environment, dedicated
ingress nodes can help, as it is easier to get an exception for a subset of
nodes instead of all of them.&lt;/p&gt;
&lt;p&gt;Finally, limiting the number of nodes that run Envoy is helpful in bare-metal or
on-premises installations. In these deployments, the ingress tier is fronted by
a hardware load balancer that, in most cases, is manually configured to route
traffic to the ingress nodes. Having a small number of ingress nodes eases the
configuration and management of these external load balancers.&lt;/p&gt;
&lt;p&gt;Overall, dedicating nodes for ingress purposes can help with performance,
compliance, and managing external load balancers. With that said, ingress node
failures must be accounted for, as Envoy will not run on nodes other than those
reserved for ingress. In the ideal case, failed nodes are automatically replaced
with new nodes that can continue handling ingress traffic.&lt;/p&gt;
&lt;h3 id=&#34;envoy-and-host-networking&#34;&gt;Envoy and host networking&lt;/h3&gt;
&lt;p&gt;To optimize the ingress traffic path, you can bind Envoy to the underlying
host&amp;rsquo;s network. By doing so, incoming requests bypass the Kubernetes Service
fabric (usually iptables rules) and reach Envoy directly.&lt;/p&gt;
&lt;p&gt;While running Envoy directly on the host&amp;rsquo;s network can increase performance,
there are important caveats to keep in mind:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The Envoy process is no longer isolated in its own network namespace.
Therefore, the node&amp;rsquo;s network interfaces and network services running on
the node are accessible to Envoy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The shutdown manager sidecar binds to &lt;code&gt;0.0.0.0:8090&lt;/code&gt;, making it available on
all the host&amp;rsquo;s network interfaces when host networking is enabled. Ensure
that there are firewall rules in place that block requests to port 8090.
Otherwise, the shutdown manager endpoint can be exploited to bring down the
ingress data plane.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Envoy exposes Prometheus metrics on &lt;code&gt;0.0.0.0:8002&lt;/code&gt;. These metrics will be
accessible on the node&amp;rsquo;s port &lt;code&gt;8002&lt;/code&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you want to enable host networking in the Envoy pods, you must set the pod&amp;rsquo;s
&lt;code&gt;hostNetwork&lt;/code&gt; field to &lt;code&gt;true&lt;/code&gt; and set the &lt;code&gt;dnsPolicy&lt;/code&gt; field to
&lt;code&gt;ClusterFirstWithHostNet&lt;/code&gt;. The following manifest show the two modifications in
the Envoy pod specification:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DaemonSet&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;envoy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;envoy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hostNetwork&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Enable hostNetwork&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dnsPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterFirstWithHostNet&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Update dns policy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- -&lt;span class=&#34;l&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;/config/envoy.json&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;service-cluster $(CONTOUR_NAMESPACE)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;service-node $(ENVOY_POD_NAME)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;log-level info&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;envoy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/envoyproxy/envoy:v1.15.0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IfNotPresent&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;envoy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;avoiding-unnecessary-network-hops&#34;&gt;Avoiding unnecessary network hops&lt;/h3&gt;
&lt;p&gt;When using a Service to expose Envoy (such as a &lt;code&gt;NodePort&lt;/code&gt; or a &lt;code&gt;LoadBalancer&lt;/code&gt;
Service), set the &lt;code&gt;externalTrafficPolicy&lt;/code&gt; to &lt;code&gt;Local&lt;/code&gt;. The &lt;code&gt;Local&lt;/code&gt; policy ensures
that incoming traffic is routed to the Envoy instance running on the local node
instead of adding an extra hop to another node.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/contour-envoy-host-port.drawio.png&#34; alt=&#34;Envoy Binding Host Port&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;daemonset-versus-deployment&#34;&gt;DaemonSet versus Deployment&lt;/h3&gt;
&lt;p&gt;In the split deployment model, you can deploy Envoy as a DaemonSet or a
Deployment. In most cases, a DaemonSet is preferred because Envoy can
efficiently use the underlying node&amp;rsquo;s CPU cores. Thus, there is no real benefit
to running multiple instances of Envoy on the same node.&lt;/p&gt;
&lt;p&gt;Using a Deployment for Envoy is suitable when you are leveraging the
auto-scaling capabilities of Kubernetes. If you are working in a dynamic
environment, such as a cloud provider, you can auto-scale the Envoy deployment
according to its utilization using a Horizontal Pod Autoscaler. With that said,
you must set pod anti-affinity rules to spread the Envoy pods across different
nodes.&lt;/p&gt;
&lt;p&gt;If you are deploying Contour under the sidecar model and are not using dedicated
ingress nodes, avoid using a DaemonSet. The problem with using a DaemonSet is
that a controller runs on every node, which results in unnecessary load on the
Kubernetes API server. This overhead on the API server might not be notable in
small clusters but can become evident as you grow your clusters.&lt;/p&gt;
&lt;h2 id=&#34;high-availability&#34;&gt;High Availability&lt;/h2&gt;
&lt;p&gt;Contour supports running multiple replicas of the control plane component and
the data plane component.&lt;/p&gt;
&lt;p&gt;On the controller side, contour performs leader election. Once elected, the
leader starts serving configuration to the Envoy proxies. The leader election
mechanism prevents contour replicas from stepping on each other, mainly when writing
status updates back to the API server.&lt;/p&gt;
&lt;p&gt;When it comes to the data plane, you can run as many Envoy proxies as needed by
the applications running on the platform. The number of Envoy replicas is
typically dictated by the size of the nodes where Envoy is running and the
amount of traffic you need to handle. At a minimum, you should run two instances
to tolerate failure.&lt;/p&gt;
&lt;h2 id=&#34;handling-dns-records&#34;&gt;Handling DNS records&lt;/h2&gt;
&lt;p&gt;Applications running in the cluster share the ingress data plane, and thus share
a single entry point into the cluster. As with all ingress controllers, one of
Contour&amp;rsquo;s primary responsibilities is to disambiguate ingress traffic according
to the configuration defined in the Ingress and HttpProxy resources.&lt;/p&gt;
&lt;p&gt;A typical pattern used to expose multiple applications over the same ingress
point is to slice up a domain and assign subdomains to different applications.
When the incoming traffic reaches Envoy, it inspects the Host header of the
request and routes it according to the subdomain. For example, traffic with the
Host header set to &lt;code&gt;appA.cloud.example.com&lt;/code&gt; is forwarded to application A, while
a request with the Host header equal to &lt;code&gt;appB.cloud.example.com&lt;/code&gt; is forwarded to
application B. To implement this pattern, however, external clients must be able
to resolve the domain names configured in the Ingress and HttpProxy resources.&lt;/p&gt;
&lt;h3 id=&#34;wildcard-dns&#34;&gt;Wildcard DNS&lt;/h3&gt;
&lt;p&gt;Using a wildcard DNS is a viable approach to implement subdomain-based routing.
If you are looking to enable this use case, consider using a wildcard DNS record
pointing to the load balancer in front of the Envoy proxies. For example, to
support the scenario mentioned above, you would define a wildcard DNS entry for
&lt;code&gt;*.cloud.example.com&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;external-dns-controller&#34;&gt;External-DNS controller&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/kubernetes-sigs/external-dns&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;external-dns&lt;/a&gt; controller
is another approach for handling DNS records for ingress purposes. The
external-dns controller integrates Kubernetes with an upstream DNS provider. The
controller continuously creates and updates DNS records according to the
configuration defined in Ingress resources.&lt;/p&gt;
&lt;p&gt;If you are using a DNS provider that is compatible with external-dns, consider
using this controller to enable DNS resolution of services exposed via Ingress.
Keep in mind, however, that external-dns is not yet compatible with Contour&amp;rsquo;s
HTTPProxy custom resource. There is an &lt;a href=&#34;https://github.com/kubernetes-sigs/external-dns/pull/1628&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;open pull
request&lt;/a&gt; in the
core-dns project that adds support for it.&lt;/p&gt;
&lt;p&gt;The external-dns controller uses the Ingress resource&amp;rsquo;s status field to
determine the DNS record&amp;rsquo;s target IP address. If you are running Contour without
a LoadBalancer service, you must set the &lt;code&gt;ingress-status-address&lt;/code&gt; field in
Contour&amp;rsquo;s configuration file. Otherwise, Contour does not set the
&lt;code&gt;status.loadBalancer.ingress&lt;/code&gt; field of Ingress resources, which prevents the
external-dns controller from working.&lt;/p&gt;
&lt;h2 id=&#34;certificate-management-for-tls&#34;&gt;Certificate management for TLS&lt;/h2&gt;
&lt;p&gt;Contour can route traffic to HTTPS and TLS-enabled TCP services. Contour uses
the Kubernetes Secret API to access the certificates it needs to serve these
applications. There various considerations to make when exposing secure services
using Contour, and we discuss them in the following sections.&lt;/p&gt;
&lt;h3 id=&#34;wildcard-certificates-and-tls-certificate-delegation&#34;&gt;Wildcard certificates and TLS certificate delegation&lt;/h3&gt;
&lt;p&gt;Ingress and HTTPProxy resources that route to a TLS-enabled backend must
reference a Kubernetes Secret. This Secret contains the private key and serving
certificate used to serve traffic over TLS.&lt;/p&gt;
&lt;p&gt;Using a wildcard certificate to support a domain and its subdomains is a common
practice. In such scenarios, the wildcard certificate is typically owned and
managed by the platform operator. Because multiple applications use the wildcard
certificate, the cert needs to live in a Secret across various namespaces. This
is problematic, as the Secret is readily available to application developers
that should otherwise not have read access to this Secret.&lt;/p&gt;
&lt;p&gt;Contour addresses this problem with TLS certificate delegation. Instead of
creating the wildcard certificate Secret in all namespaces, you store the Secret
in a namespace owned by the platform team. Once the Secret is in place, you can
allow developers to reference that single Secret from their namespaces.&lt;/p&gt;
&lt;p&gt;If you are using wildcard certificates, consider using TLS certificate
delegation to protect the certs and minimize management overhead. See the &lt;a href=&#34;https://projectcontour.io/docs/v1.6.1/httpproxy/#tls-certificate-delegation&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;TLS
certificate delegation
documentation&lt;/a&gt;
for more details about this feature.&lt;/p&gt;
&lt;h3 id=&#34;cert-manager-integration&#34;&gt;Cert-manager integration&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://cert-manager.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cert-manager&lt;/a&gt; is a Kubernetes controller that
automates the issuance and management of certificates. You can use cert-manager
to issue certificates for services if you are using the Ingress API.
Unfortunately, however, the HTTPProxy API is not yet directly compatible with
cert-manager.&lt;/p&gt;
&lt;p&gt;If you are planning to use cert-manager with the HTTPProxy API, you must follow
a workaround. The workaround involves setting up a dummy Ingress resource that
cert-manager uses to issue the certificate. See the &lt;a href=&#34;https://projectcontour.io/guides/cert-manager/#making-cert-manager-work-with-httpproxy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Contour and cert-manager
guide&lt;/a&gt;
for additional information on the workaround.&lt;/p&gt;
&lt;h2 id=&#34;multi-tenancy-considerations&#34;&gt;Multi-tenancy considerations&lt;/h2&gt;
&lt;h3 id=&#34;preventing-ingress-configuration-collisions&#34;&gt;Preventing ingress configuration collisions&lt;/h3&gt;
&lt;p&gt;Multi-tenant platforms are prone to configuration clashes at the ingress layer.
The primary example is different teams trying to use the same FQDN to expose
their applications. Consider a scenario where an application team exposes their
app at &lt;code&gt;app.example.com&lt;/code&gt;. If another team creates an ingress configuration that
uses the same URL, they will create a collision. The same issue can arise with
path-based routing (for example, different teams trying to use &lt;code&gt;/app&lt;/code&gt; at
&lt;code&gt;example.com&lt;/code&gt;).&lt;/p&gt;
&lt;h4 id=&#34;root-httpproxy-resources-and-inclusion&#34;&gt;Root HTTPProxy resources and Inclusion&lt;/h4&gt;
&lt;p&gt;Contour addresses this issue with &lt;em&gt;root&lt;/em&gt; HTTPProxy resources. Root HTTPProxy
resources define the top-level configuration for a specific ingress point, such
as the FQDN and primary paths. As a platform operator, you &lt;a href=&#34;https://projectcontour.io/docs/v1.6.1/httpproxy/#restricted-root-namespaces&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;configure Contour
only to
accept&lt;/a&gt;
root HTTPProxy resources from namespaces under your control. You set this
configuration using the &lt;code&gt;--root-namespaces&lt;/code&gt; flag of the contour binary. Then,
when you create the root HTTPProxy resources, you &lt;em&gt;include&lt;/em&gt; HTTPProxy resources
from other namespaces.
&lt;a href=&#34;https://projectcontour.io/docs/v1.6.1/httpproxy/#conditions-and-inclusion&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Inclusion&lt;/a&gt;
enables you to control the root HTTPProxy configuration while delegating the
application-specific configuration to the respective application teams (or
namespaces).&lt;/p&gt;
&lt;p&gt;The following example shows a sample scenario for a micro-services application.
Assume the &lt;code&gt;--root-namespaces&lt;/code&gt; flag is set to &lt;code&gt;httpproxy-roots&lt;/code&gt;. The root
HTTPProxy sets the FQDN to &lt;code&gt;example.com&lt;/code&gt;. It then assigns the &lt;code&gt;/auth&lt;/code&gt; path to
the authentication team, the &lt;code&gt;/reservations&lt;/code&gt; path to the reservations team, and
the &lt;code&gt;/profile&lt;/code&gt; path to the user profile team. Each team gets to configure
ingress routing in their namespaces, but they can only configure their subpath
of &lt;code&gt;example.com&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;c&#34;&gt;# Example HTTPProxy owned by the platform team.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;example-com-root&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;httpproxy-roots&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Roots can only exist in this namespace&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;virtualhost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fqdn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;includes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;auth&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;authentication&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/auth&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The authentication team can use example.com/auth&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;reservations&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;reservations&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/reservations&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The reservations team can use example.com/reservations&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;user-profile&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;user-profile&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/profile&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The user profile team can use example.com/profile&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Example HTTPProxy created by the reservations team in their namespace.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;reservations&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;reservations&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Notice the `virtualhost` stanza is missing, as this is not a root HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# matches /reservations&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;reservations-home&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/cancel&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# matches /reservations/cancel&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cancellation-svc&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;admission-control&#34;&gt;Admission Control&lt;/h4&gt;
&lt;p&gt;Admission control is another mechanism to prevent ingress configuration
collisions and is the most common solution implemented with other ingress
controllers. When it comes to ingress, there are different admission strategies
you can apply. A straightforward approach is to reject any Ingress resource (or
HTTPProxy resource, for that matter) that conflicts with resources that already
exist in the cluster. The OPA Gatekeeper project, for example, has an &lt;a href=&#34;https://github.com/open-policy-agent/gatekeeper/tree/master/library/general/uniqueingresshost&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;example
implementation&lt;/a&gt;
of this strategy in their library. More advanced admission strategies are also
possible. For example, an admission controller can reach out to another system
to determine whether an application team can use a given FQDN.&lt;/p&gt;
&lt;h3 id=&#34;ingress-isolation&#34;&gt;Ingress Isolation&lt;/h3&gt;
&lt;p&gt;In some scenarios, different tenants or applications need a separate (or
dedicated) ingress path. This could be for performance, regulatory, or other
reasons. In such cases, you can run multiple Contour ingress controllers. Each
controller watches a specific set of Ingress/HTTPProxy resources, as determined
by the ingress class. Use the &lt;code&gt;--ingress-class-name&lt;/code&gt; flag on the &lt;code&gt;contour&lt;/code&gt;
binary to set the ingress class name.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;contour&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;contour&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;contour&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;serve&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;incluster&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;xds-address=0.0.0.0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;xds-port=8001&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;envoy-service-http-port=80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;envoy-service-https-port=443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;contour-cafile=/certs/ca.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;contour-cert-file=/certs/tls.crt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;contour-key-file=/certs/tls.key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;config-path=/config/contour.yaml&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- --&lt;span class=&#34;l&#34;&gt;ingress-class-name=my-ingress-class&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Set the ingress class here&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# removed for brevity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# ...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To target a specific ingress class in an Ingress or HTTPProxy resource,
developers can set the &lt;code&gt;kubernetes.io/ingress.class&lt;/code&gt; annotation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetes.io/ingress.class&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;my-ingress-class&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-svc.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;my-svc&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      
      <title>Guides: Developing OPA Policies</title>
      
      <link>/guides/kubernetes/platform-security-opa/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/platform-security-opa/</guid>
      <description>

        
        &lt;p&gt;&lt;a href=&#34;https://www.openpolicyagent.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Open Policy Agent&lt;/a&gt; (OPA) is a declarative
policy engine that helps an IT organization separate policies from software so
teams can support or modify policies without affecting the software.&lt;/p&gt;
&lt;p&gt;This guide demonstrates how to implement Open Policy Agent (kube-mgmt) in
Kubernetes. First, you will use OPA in your local machine to define and test
policies. Then, you will deploy OPA to a Kubernetes cluster and test the
policies there.&lt;/p&gt;
&lt;h2 id=&#34;assumptions&#34;&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;The guide assumes you understand policy management, admission webhooks, and the
Rego programming language. You can use the following resources if you need to
review these topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Policy Management Philosophy&lt;/strong&gt;: &lt;a href=&#34;https://www.openpolicyagent.org/docs/latest/philosophy/&#34;&gt;https://www.openpolicyagent.org/docs/latest/philosophy/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Admission Webhooks&lt;/strong&gt;: &lt;a href=&#34;https://kubernetes.io/blog/2019/03/21/a-guide-to-kubernetes-admission-controllers/&#34;&gt;https://kubernetes.io/blog/2019/03/21/a-guide-to-kubernetes-admission-controllers/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rego Policy Language&lt;/strong&gt;: &lt;a href=&#34;https://www.openpolicyagent.org/docs/latest/#rego&#34;&gt;https://www.openpolicyagent.org/docs/latest/#rego&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;install-opa-in-your-local-machine&#34;&gt;Install OPA in your local machine&lt;/h2&gt;
&lt;p&gt;Follow the &lt;a href=&#34;https://www.openpolicyagent.org/docs/latest/#running-opa&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Running
OPA&lt;/a&gt; documentation to
install OPA in your machine. Once installed, you will be able to test your OPA
policies locally.&lt;/p&gt;
&lt;h2 id=&#34;creating-policies&#34;&gt;Creating policies&lt;/h2&gt;
&lt;h3 id=&#34;directory-structure-setup&#34;&gt;Directory structure setup&lt;/h3&gt;
&lt;p&gt;In this guide, you will create OPA policy files, test files, and Kubernetes
manifests. Create a working directory to hold these files.&lt;/p&gt;
&lt;h3 id=&#34;policy-development&#34;&gt;Policy development&lt;/h3&gt;
&lt;p&gt;Create a policy file called &lt;code&gt;PolicyA.rego&lt;/code&gt; with the following contents. The
policy ensures that Deployments have CPU limits set. You will dissect the policy
in the following sections.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-rego&#34; data-lang=&#34;rego&#34;&gt;# PolicyA.rego
package kubernetes.admission

operations = {&amp;quot;CREATE&amp;quot;,&amp;quot;UPDATE&amp;quot;}

input_container[c] {
  c := input.request.object.spec.template.spec.containers[_]
}

deny[reason] {
  input.request.kind.kind == &amp;quot;Deployment&amp;quot;
  operations[input.request.operation]
  input_container[container]
  not container.resources.limits.cpu
  reason := sprintf(&amp;quot;container %v is missing CPU limits&amp;quot;, [container.name])
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;packages&#34;&gt;Packages&lt;/h4&gt;
&lt;p&gt;The first line of the policy is the package statement. &lt;code&gt;package kubernetes.admission&lt;/code&gt; defines hierarchical name to the rules in the rest of the
policy.&lt;code&gt;kubernetes.admission&lt;/code&gt; is the default package statement for OPA because
it assumes OPA is configured as an admission controller.&lt;/p&gt;
&lt;p&gt;As you create more policies you will want to revise and plan your package
statements. This
&lt;a href=&#34;https://www.openpolicyagent.org/docs/latest/faq/#collaboration-using-import&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;document&lt;/a&gt;
demonstrates one way you can define your package statement strategy. If your
package statements in different policies are the same, then you will run into
conflict issues when you test them. OPA may output an error even if the policy
is logically valid.&lt;/p&gt;
&lt;h4 id=&#34;operations&#34;&gt;Operations&lt;/h4&gt;
&lt;p&gt;The &lt;code&gt;operations&lt;/code&gt; variable defines the actions that will trigger the policy. In
this case, the policy is run when an API object is created or updated.&lt;/p&gt;
&lt;h4 id=&#34;input-document--dot-notation&#34;&gt;Input document &amp;amp; Dot notation&lt;/h4&gt;
&lt;p&gt;The &lt;code&gt;input&lt;/code&gt; variable is a reserved global variable whose value is equal to the
&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#admissionreview-request-0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Admission
Review&lt;/a&gt;
object. The API server takes this object and provides it to any admission
control webhook.&lt;/p&gt;
&lt;p&gt;In OPA, the dot notation is used to traverse through the YAML hierarchy. If the
path does not exist, the dot(.) operator does not throw an error but instead it
has a value of &lt;code&gt;undefined&lt;/code&gt;. The overall result of the policy will evaluate to
&lt;code&gt;undefined&lt;/code&gt; and &lt;strong&gt;not&lt;/strong&gt; &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In this example, under the &lt;code&gt;deny&lt;/code&gt; section, &lt;code&gt;input.request.kind.kind == &amp;quot;Deployment&amp;quot;&lt;/code&gt;, OPA is traversing through YAML hierarchy to check for the
Kubernetes resource type of &lt;code&gt;Deployment&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;iteration&#34;&gt;Iteration&lt;/h4&gt;
&lt;p&gt;You will want your policy to apply to multiple containers. If you use this line
in your policy &lt;code&gt;input.request.object.spec.container&lt;/code&gt;, OPA will only review the
first container. This is not practical as pods can have multiple containers.&lt;/p&gt;
&lt;p&gt;To iterate over multiple containers, use this line &lt;code&gt;c:= input.request.object.spec.containers[_]&lt;/code&gt; and create function of
&lt;code&gt;input_p_container&lt;/code&gt; with the variable of &lt;code&gt;c&lt;/code&gt;. This function iterates over the
indexes &lt;code&gt;input.request.object.spec.containers[_]&lt;/code&gt; array and the anonymous
variable &lt;code&gt;_&lt;/code&gt; allows you to use a built-in variable instead of defining a new one
strictly for iteration.&lt;/p&gt;
&lt;h4 id=&#34;deny-rules&#34;&gt;Deny rules&lt;/h4&gt;
&lt;p&gt;The &lt;code&gt;deny&lt;/code&gt; statement is the error message that will be returned to the user.
&lt;code&gt;deny[reason]&lt;/code&gt; states that the admission control should reject the request if
the conditions in the body (the statements between the &lt;code&gt;{}&lt;/code&gt;) are &lt;strong&gt;true&lt;/strong&gt; and
return the error message to the user.&lt;/p&gt;
&lt;p&gt;In this example, the policy evaluates to &lt;strong&gt;true&lt;/strong&gt; when the &lt;code&gt;Deployment&lt;/code&gt; does not
have a CPU resource limit. The &lt;code&gt;deny&lt;/code&gt; statement returns a message of &lt;code&gt;container %v (name of container) is missing CPU limits&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;test-case-development&#34;&gt;Test case development&lt;/h2&gt;
&lt;p&gt;To test the policy you created in the previous section, you have to create a
matching test case/file. Create a test policy called &lt;code&gt;test-PolicyA.rego&lt;/code&gt; with
the content below.&lt;/p&gt;
&lt;p&gt;The test case validates that the policy blocks Deployments without a CPU limit.
Here is the finished test policy. Let&amp;rsquo;s dissect the policy in the following
sections:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-rego&#34; data-lang=&#34;rego&#34;&gt;# test-PolicyA.rego
package kubernetes.admission

test_no_limits {
   no_limits := {
     &amp;quot;request&amp;quot;:{
       &amp;quot;kind&amp;quot;:{
         &amp;quot;kind&amp;quot;:&amp;quot;Deployment&amp;quot;
       },
       &amp;quot;operation&amp;quot;:&amp;quot;CREATE&amp;quot;,
       &amp;quot;object&amp;quot;:{
         &amp;quot;spec&amp;quot;:{
           &amp;quot;template&amp;quot;: {
             &amp;quot;spec&amp;quot;: {
               &amp;quot;containers&amp;quot;: [
                 {
                   &amp;quot;name&amp;quot;: &amp;quot;nginx-1&amp;quot;,
                   &amp;quot;resources&amp;quot;:{
                       &amp;quot;requests&amp;quot;:{
                          &amp;quot;cpu&amp;quot;: &amp;quot;10mi&amp;quot;,
                          &amp;quot;memory&amp;quot;: &amp;quot;10mi&amp;quot;
                       }
                    }
                 }
               ]
             }
           }
         }
       }
     }
   }
   count(deny) == 1 with input as no_limits
 }
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;packages-1&#34;&gt;Packages&lt;/h3&gt;
&lt;p&gt;Similarly to when developing policies, the first line of the policy test file
should be the package statement. The package should be the same as the
policy&amp;rsquo;s package: &lt;code&gt;package kubernetes.admission&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;test-case-name&#34;&gt;Test case name&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;test_no_limits {&lt;/code&gt; represents the name of the test case. This name should be
different for each test case in the test file.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;no_limits := {&lt;/code&gt; represents the name of the input value which will be JSON. This
variable is used in the test case.&lt;/p&gt;
&lt;h3 id=&#34;test-case-json&#34;&gt;Test case JSON&lt;/h3&gt;
&lt;p&gt;After the &lt;code&gt;no_limits :=&lt;/code&gt; statement you will see JSON data. This JSON is your
mock data that mimics an AdmissionReview request sent by the API server. Here
you will make the data as close to a real life scenario as possible for the best
testing results. In this example, the container has CPU and Memory requests but
not limits. Therefore, our policy should block the request.&lt;/p&gt;
&lt;h3 id=&#34;test-case&#34;&gt;Test case&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;count(deny) == 1 with input as no_limits&lt;/code&gt; statement has 2 key components.
First, the &lt;code&gt;count(deny)&lt;/code&gt; gets a count of the deny statements in the test case.
Second, the &lt;code&gt;with input as no_limits&lt;/code&gt; statement sets the &lt;code&gt;input&lt;/code&gt; to the
&lt;code&gt;no_limits&lt;/code&gt; variable, which is necessary to use our mock data.&lt;/p&gt;
&lt;p&gt;In this example, the &lt;code&gt;count(admission.deny)&lt;/code&gt; value should be equal to &lt;code&gt;1&lt;/code&gt;
because the container is missing the CPU limit. Therefore, OPA should return the
value of &lt;code&gt;count&lt;/code&gt; as &lt;code&gt;1&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;testing-policies&#34;&gt;Testing policies&lt;/h2&gt;
&lt;p&gt;Now that you have a policy file and corresponding test file, you are ready to
test your policy.&lt;/p&gt;
&lt;p&gt;This is the syntax of the command to run the test:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;opa test -v name_of_policy name_of_test_file&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Run the following command to test the policy you have created:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;opa &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; -v PolicyA.rego test-PolicyA.rego
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output should look similar to the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;data.kubernetes.admission.test_no_limits: PASS (601.648µs)
------------------------------------------------------------
PASS: 1/1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;All the tests &lt;code&gt;PASS&lt;/code&gt;. The results show the name of the test case and
pass/fail/error.&lt;/p&gt;
&lt;p&gt;If the test case &lt;code&gt;FAILS&lt;/code&gt;, the output will look like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;FAILURES
--------------------------------------------------------------
data.kubernetes.admission.test_no_limits: FAIL (568.467µs)

  Enter data.kubernetes.admission.test_no_limits = _
  | Enter data.kubernetes.admission.test_no_limits
  | | Enter data.kubernetes.admission.deny
  | | | Enter container.resources.limits.cpu
  | | | | Fail container.resources.limits.cpu
  | | Fail __local4__ = 3 with input as no_limits
  | Fail data.kubernetes.admission.test_no_limits = _

SUMMARY
---------------------------------------------------------------
data.kubernetes.admission.test_no_limits: FAIL (568.467µs)
---------------------------------------------------------------
FAIL: 1/1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ensure all your test cases &lt;code&gt;PASS&lt;/code&gt; before you move on to testing in your cluster.&lt;/p&gt;
&lt;h2 id=&#34;example-policies&#34;&gt;Example policies&lt;/h2&gt;
&lt;p&gt;Here are example policies that are used in production Kubernetes environments.
All these examples are simple examples that can be modified and customized to
your environment and needs.&lt;/p&gt;
&lt;h3 id=&#34;policy-to-prevent-users-from-deleting-customresourcedefinitions&#34;&gt;Policy to prevent users from deleting CustomResourceDefinitions&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-rego&#34; data-lang=&#34;rego&#34;&gt;### This policy block users from deleting CRDs.
### You have to enable the Validating Admission Webhook to include the DELETE operation if not already

package kubernetes.admission

deny[reason] {
    input.request.kind.kind == &amp;quot;CustomResourceDefinition&amp;quot;
    input.request.operation == &amp;quot;DELETE&amp;quot;
    reason := (&amp;quot;You do not have authority to delete a Custom Resource Definition&amp;quot;)
}

&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;policy-to-prevent-users-from-creating-unapproved-service-types&#34;&gt;Policy to prevent users from creating unapproved Service types&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-rego&#34; data-lang=&#34;rego&#34;&gt;### This policy blocks the user from creating or changing Service Types of LoadBalancer or NodePort.
package kubernetes.admission

operations = {&amp;quot;CREATE&amp;quot;,&amp;quot;UPDATE&amp;quot;}

deny[reason] {
    input.request.kind.kind == &amp;quot;Service&amp;quot;
    operations[input.request.operation]
    input.request.object.spec.type == &amp;quot;LoadBalancer&amp;quot;
    reason := (&amp;quot;Cannot have service type of LoadBalancer&amp;quot;)
}

deny[reason] {
    input.request.kind.kind == &amp;quot;Service&amp;quot;
    operations[input.request.operation]
    input.request.object.spec.type == &amp;quot;NodePort&amp;quot;
    reason := (&amp;quot;Cannot have service type of NodePort&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;policy-to-enforce-specific-labels-on-all-deployment-resources&#34;&gt;Policy to enforce specific labels on all Deployment resources&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-rego&#34; data-lang=&#34;rego&#34;&gt;package main

name = input.metadata.name

labels {
    input.metadata.labels[&amp;quot;app.kubernetes.io/name&amp;quot;]
    input.metadata.labels[&amp;quot;app.kubernetes.io/instance&amp;quot;]
}

deny[reason] {
  input.request.kind.kind == &amp;quot;Deployment&amp;quot;
  not labels
  reason = sprintf(&amp;quot;%s must include Kubernetes recommended labels: https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/#labels&amp;quot;, [name])
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Preferably, you should test and develop your policies locally before you proceed
to testing in your cluster. As you can see there are various ways you can design
your policies to fit your IT process.&lt;/p&gt;
&lt;h2 id=&#34;deploy-opa-to-a-cluster&#34;&gt;Deploy OPA to a cluster&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s move to test your policy in a Kubernetes cluster. We will use the policy
&lt;code&gt;PolicyA.rego&lt;/code&gt; for testing OPA in our cluster.&lt;/p&gt;
&lt;p&gt;To deploy OPA to you cluster, follow the &lt;a href=&#34;https://www.openpolicyagent.org/docs/latest/kubernetes-tutorial/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Deploying OPA on a Kubernetes Cluster
Guide&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;confirm-opa-is-deployed-to-the-cluster&#34;&gt;Confirm OPA is deployed to the cluster&lt;/h3&gt;
&lt;p&gt;Confirm that OPA has been deployed to the cluster by checking if the OPA Pods
are running. Use the &lt;code&gt;kubectl get pods -n opa&lt;/code&gt; command to verify. You should see
two OPA Pods running.&lt;/p&gt;
&lt;h3 id=&#34;load-the-policy-as-a-configmap&#34;&gt;Load the policy as a ConfigMap&lt;/h3&gt;
&lt;p&gt;You will test the policy file &lt;code&gt;PolicyA.rego&lt;/code&gt; in your cluster. Navigate to the
directory where &lt;code&gt;PolicyA.rego&lt;/code&gt; is stored. You will use this file to create a
ConfigMap in the &lt;code&gt;opa&lt;/code&gt; namespace that the OPA sidecar will notice and load into
OPA. OPA can also load policies from other namespaces if they are labeled
&lt;code&gt;openpolicyagent.org/policy=rego&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Load the policy using this command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create configmap cpulimits --from-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;PolicyA.rego -n opa
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Confirm that the ConfigMap has been created in the Kubernetes cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get configmap -n opa
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see the OPA ConfigMap and the ConfigMap you just created:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;NAME                      DATA   AGE
cpulimits                 1      36m
opa-default-system-main   1      107m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Also, confirm that OPA accepted the policy by checking the ConfigMap status and
looking at the &lt;code&gt;openpolicyagent.org/policy-status&lt;/code&gt; annotation. The status should
be equal to &amp;ldquo;ok&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Run the following command to view the annotations on the ConfigMap:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get configmap cpulimits -o yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output should be similar to this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConfigMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;openpolicyagent.org/policy-status&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{&amp;#34;status&amp;#34;:&amp;#34;ok&amp;#34;}&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;creationTimestamp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;2020-04-03T14:20:52Z&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpulimits&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;opa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Pro-Tip&lt;/strong&gt; Before you try to create the Deployment, delete the OPA pods in the
OPA namespace. This is not mandatory but sometimes the OPA pods need to be
restarted before it recognizes the ConfigMap you just created; even though the
ConfigMap status value equals &amp;ldquo;ok&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;exercise-the-policy&#34;&gt;Exercise the policy&lt;/h3&gt;
&lt;p&gt;To exercise the policy, you will create two Kubernetes manifest files: one with
a valid Deployment and the other with an invalid Deployment.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a file called &lt;code&gt;PolicyA-good.yaml&lt;/code&gt; with the following content. This
manifest contains a Deployment that OPA should allow because the container
has a CPU limit.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx-good&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;template&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;containerPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;200m&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;256Mi&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a file called &lt;code&gt;PolicyA-bad.yaml&lt;/code&gt;. This manifest contains a Deployment
that OPA should &lt;strong&gt;not&lt;/strong&gt; allow to get created because the container lacks CPU
limits.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx-bad&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;template&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;containerPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now that you have the Kubernetes manifests, lets verify that OPA is working as
expected.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;kubectl apply -f PolicyA-good.yaml&lt;/code&gt;. The Deployment should be created
successfully.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;kubectl apply -f PolicyA-bad.yaml&lt;/code&gt; and see the error message that is
returned. It should be the same message that you defined in the &lt;code&gt;reason&lt;/code&gt;
statement in the policy.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;Error from server (container nginx is missing CPU limits): error when creating &amp;#34;PolicyA-bad.yaml&amp;#34;: admission webhook &amp;#34;validating-webhook.openpolicyagent.org&amp;#34; denied the request: container nginx is missing CPU limits
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;p&gt;In this guide, you completed the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Installed OPA into your local environment&lt;/li&gt;
&lt;li&gt;Developed an OPA policy that blocks Deployments without CPU limits&lt;/li&gt;
&lt;li&gt;Tested the policy locally with mock data&lt;/li&gt;
&lt;li&gt;Reviewed sample OPA policies for different use-cases&lt;/li&gt;
&lt;li&gt;Installed OPA into a Kubernetes cluster&lt;/li&gt;
&lt;li&gt;Deployed your policy into the Kubernetes cluster as a ConfigMap&lt;/li&gt;
&lt;li&gt;Verified that the policy works as expected using &lt;code&gt;kubectl&lt;/code&gt; and sample
Deployment manifests&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Istio Reference Architecture</title>
      
      <link>/guides/kubernetes/service-routing-istio-refarch/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/service-routing-istio-refarch/</guid>
      <description>

        
        &lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;A lot of enterprises are embarking on a journey to adopt cloud native
technologies to meet their technology strategy goals and address internal and
external challenges. One of the key components of the technology stack is the
Platform as a Service (PaaS) which will be the target platform for a number of
migrated and new applications. These applications will be required to adopt
latest standards in security, performance, scalability and resilience in a
manner which is agile and efficient.&lt;/p&gt;
&lt;p&gt;In order to adopt these standards, enterprises are looking towards open source
&lt;a href=&#34;https://istio.io/latest/docs/concepts/what-is-istio/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Istio Service Mesh&lt;/a&gt; to
manage the ever-increasing mesh of microservices and to help simplify key
operational tasks.&lt;/p&gt;
&lt;p&gt;Istio implementation brings it&amp;rsquo;s own challenges, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Installation and upgrade process using istio-cni.&lt;/li&gt;
&lt;li&gt;Automation of certificate management at the edge (ingress/egress) of mesh.&lt;/li&gt;
&lt;li&gt;Different resource definitions
(gateway/VirtualService/DestinationRule/ServiceEntry) created while
communicating at the edges (ingress/egress) of mesh for different use cases.&lt;/li&gt;
&lt;li&gt;How to share responsibility across cluster-admin/Mesh Admin/Application
Developer.&lt;/li&gt;
&lt;li&gt;Operational aspects (monitoring/logging/tracing).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This document helps you to understand the concept and details the reference
architecture implementation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/istio-introduction.png&#34; alt=&#34;Inter service mesh communication&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Some salient features of the implementation are as follows.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assumption:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Each Kubernetes cluster has only one service mesh control plane and data
plane.&lt;/li&gt;
&lt;li&gt;All the communication within the service mesh takes place via mutual TLS.&lt;/li&gt;
&lt;li&gt;All external communication across two service meshes running in separate
clusters takes place via mutual TLS through ingress/egress gateways.&lt;/li&gt;
&lt;li&gt;In order to implement mutual TLS across service meshes, all TLS certificates
are provisioned via &lt;a href=&#34;https://www.vaultproject.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;centralized vault&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To automate the provisioning of certificate via centralized vault, a
&lt;a href=&#34;https://cert-manager.io/docs/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;cert-manager&lt;/a&gt; is used. All clusters have their
own cert-manager installed and connected to the centralized vault.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/istio-install-arch.png&#34; alt=&#34;Istio Architecture&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Istio installation refers to Istio control plane installation, which consists of
following component (pods).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;istio-cni plugin (running as DaemonSet) in the kube-system namespace&lt;/li&gt;
&lt;li&gt;ingress gateway in the istio-system namespace&lt;/li&gt;
&lt;li&gt;egress gateway in the istio-system namespace&lt;/li&gt;
&lt;li&gt;istiod in the istio-system namespace&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h3&gt;
&lt;p&gt;In order to install Istio, following are the prerequisites.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cluster-admin permission is required.&lt;/li&gt;
&lt;li&gt;To get istio-cni working, create the required pod security policy and it&amp;rsquo;s
corresponding role and role binding.&lt;/li&gt;
&lt;li&gt;It is recommended security practice to configure third party service account tokens.&lt;/li&gt;
&lt;li&gt;To install Istio in an offline/airgap environment, a container registry is required.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;istio-cni-plugin&#34;&gt;Istio CNI Plugin&lt;/h4&gt;
&lt;p&gt;Istio injects initContainer (istio-init) in any pod which is part Istio mesh. It
programs all the iptables rules required for intercepting all incoming and
outgoing request to application pod. These rules are programmed into the pod’s
network namespace. That requires some elevated privileges. Service accounts
deploying pods to the mesh need to have sufficient Kubernetes RBAC permissions
to deploy containers with the NET_ADMIN and NET_RAW capabilities.&lt;/p&gt;
&lt;p&gt;Running production workloads in most enterprises with such elevated privileges
is a not advisable. Here comes the
&lt;a href=&#34;https://istio.io/latest/docs/setup/additional-setup/cni/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Istio CNI plugin&lt;/a&gt; to
rescue. This plugin is a replacement for the istio-init container that performs
the same networking functionality but without requiring Istio users to enable
elevated privileges.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/diagrams/istio-cniandnoncni.png&#34; alt=&#34;istio-init vs istio-cni IPtables rules configuration
&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The istio-cni is installed as a DaemonSet in the kube-system namespace. The
rationale behind using kube-system namespace over istio-system is that istio-cni
does not support multitenancy and in the event that multiple control planes are
running (this is not possible at the moment) in a single Kubernetes cluster,
there is no confusion as to which Istio control namespace, istio-cni is running.
The istio-cni namespace is configurable using components.cni.namespace parameter
during Istio installation.&lt;/p&gt;
&lt;p&gt;To get istio-cni running, the corresponding
&lt;a href=&#34;#podsecuritypolicy-definition-for-istio-cni&#34;&gt;pod security policy, role and role binding&lt;/a&gt;
are required in the kube-system namespace.&lt;/p&gt;
&lt;p&gt;The following Pod security policy needs to be applied. Only important snippets
are shown here.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;policy/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;PodSecurityPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-control-plane&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsUser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rule&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;RunAsAny&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;allowedHostPaths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;pathPrefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/etc/cni/net.d&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;pathPrefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/opt/cni/bin&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The YAML config above defines a restricted PSP that enables Istio CNI components
to be running in a Kubernetes cluster. In particular, this PSP provides access
to the &lt;strong&gt;host network and host path&lt;/strong&gt; volumes.&lt;/p&gt;
&lt;h4 id=&#34;third-party-jwt-token&#34;&gt;Third Party JWT Token&lt;/h4&gt;
&lt;p&gt;To authenticate with the Istio control plane, the Istio proxy will use a Service
Account token. Kubernetes supports two forms of these tokens:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Third party tokens, which have a scoped audience and expiration.&lt;/li&gt;
&lt;li&gt;First party tokens, which have no expiration and are mounted into all pods.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To determine if your cluster supports third party tokens, look for the TokenRequest API.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get --raw /api/v1 &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; jq &lt;span class=&#34;s1&#34;&gt;&amp;#39;.resources[] | select(.name | index(&amp;#34;serviceaccounts/token&amp;#34;))&amp;#39;&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;serviceaccounts/token&amp;#34;&lt;/span&gt;,
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;singularName&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;,
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;namespaced&amp;#34;&lt;/span&gt;: true,
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;group&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;authentication.k8s.io&amp;#34;&lt;/span&gt;,
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;version&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;v1&amp;#34;&lt;/span&gt;,
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;kind&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;TokenRequest&amp;#34;&lt;/span&gt;,
    &lt;span class=&#34;s2&#34;&gt;&amp;#34;verbs&amp;#34;&lt;/span&gt;: &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;create&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the config above, the kind &lt;code&gt;TokenRequest&lt;/code&gt; indicates third party tokens are
supported by the Kubernetes cluster.&lt;/p&gt;
&lt;p&gt;Where third party support is needed, one can add the following flags to the
kube-apiserver&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;     - --service-account-key-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/etc/kubernetes/pki/sa.pub
     - --service-account-signing-key-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/etc/kubernetes/pki/sa.key
     - --service-account-issuer&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kubernetes.default.svc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In order to verify the installation of Istio create a pod which has istio-proxy
injected. Verify that the istio-proxy definition in the pod has the istio-token
mounted.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;volumeMounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/var/run/secrets/tokens&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Verify that token is generated at (/var/run/secrets/tokens/istio-token) in
istio-proxy container. Check it has an expiration date &lt;code&gt;exp&lt;/code&gt; and audience &lt;code&gt;aud&lt;/code&gt;
defined as &lt;code&gt;istio-ca&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-thirdpartytoken.png&#34; alt=&#34;JWT Token Contents&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;container-registry&#34;&gt;Container Registry&lt;/h4&gt;
&lt;p&gt;In order to install Istio in an offline/airgapped environment, a container registry
is required which contains all the requires container images needed for
installation.&lt;/p&gt;
&lt;p&gt;The following images are required for installing Istio 1.7.0&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;docker.io/istio/pilot:1.7.0&lt;/li&gt;
&lt;li&gt;docker.io/istio/proxyv2:1.7.0&lt;/li&gt;
&lt;li&gt;docker.io/istio/install-cni:1.7.0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example of pulling and pushing images to registry:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker pull docker.io/istio/install-cni:1.7.0
docker tag istio/install-cni:1.7.0 &lt;span class=&#34;o&#34;&gt;{{&lt;/span&gt; REGISTRY_HOSTNAME &lt;span class=&#34;o&#34;&gt;}}&lt;/span&gt;/istio/istio/install-cni:1.7.0
docker push &lt;span class=&#34;o&#34;&gt;{{&lt;/span&gt; REGISTRY_HOSTNAME &lt;span class=&#34;o&#34;&gt;}}&lt;/span&gt;/istio/istio/install-cni:1.7.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;All the worker nodes of the Kubernetes cluster need to be able to access this
registry and be able to pull required images from this registry.&lt;/p&gt;
&lt;h3 id=&#34;installation-method&#34;&gt;Installation Method&lt;/h3&gt;
&lt;p&gt;Istio uses the IstioOperator custom resource definition (CRD) for Istio
installation. An example of one such CRD is as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;install.istio.io/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IstioOperator&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;installed-state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;profile&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Istio can be installed in two different ways.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;istioctl command&lt;/strong&gt;: Providing the full configuration in an IstioOperator CR
is considered an Istio best practice for production environments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Istio operator&lt;/strong&gt;: One needs to consider security implications when using the
operator pattern in Kubernetes. With the istioctl install command, the
operation will run in the admin user’s security context, whereas with an
operator, an in-cluster pod will run the operation in its security context.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: All the following steps use the &lt;strong&gt;istioctl command&lt;/strong&gt; method.&lt;/p&gt;
&lt;p&gt;This command is just for reference to get installation quickly and highlighting
the important parameters.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl manifest install --set &lt;span class=&#34;nv&#34;&gt;profile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;demo --set components.cni.enabled&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt; --set components.cni.namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system --set values.global.istioNamespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;istio-system --set values.global.hub&lt;span class=&#34;o&#34;&gt;={{&lt;/span&gt; REGISTRY_HOSTNAME &lt;span class=&#34;o&#34;&gt;}}&lt;/span&gt;/istio --set meshConfig.outboundTrafficPolicy.mode&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;REGISTRY_ONLY --set values.global.controlPlaneSecurityEnabled&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt; --set meshConfig.enablePrometheusMerge&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt; --set &lt;span class=&#34;nv&#34;&gt;revision&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1-7-0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For a production-grade installation,
&lt;a href=&#34;#production-grade-istiooperator-v170&#34;&gt;istiooperator-airgap-1-7-0.yaml&lt;/a&gt; is used.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl install -f istiooperator-airgap-1-7-0.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;installation-validation&#34;&gt;Installation Validation&lt;/h4&gt;
&lt;p&gt;The istioctl command creates an IstioOperator custom resource called
&lt;code&gt;installed-state-1-7-0&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get IstioOperator -n istio-system
NAME                    REVISION   STATUS   AGE
installed-state-1-7-0   1-7-0               143m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To verify the istio-cni DaemonSet is deployed successfully:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get daemonset -n kube-system
NAME             DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE
istio-cni-node   &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;         &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;         &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;       &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;            &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To verify complete Istio installation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl verify-install -f istiooperator-airgap-1-7-0.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If successful, the above command results in following output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ConfigMap: istio.istio-system checked successfully
cont**
cont**
IstioOperator: installed-state.istio-system checked successfully
Checked &lt;span class=&#34;m&#34;&gt;21&lt;/span&gt; custom resource definitions
Checked &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; Istio Deployments
Istio is installed successfully
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To verify all images are coming from the centralized container registry:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get deployments istio-ingressgateway -n istio-system -o yaml&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;grep -i image:
        image: &lt;span class=&#34;o&#34;&gt;{{&lt;/span&gt; REGISTRY_HOSTNAME &lt;span class=&#34;o&#34;&gt;}}&lt;/span&gt;/istio/proxyv2:1.7.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;uninstall-method&#34;&gt;Uninstall Method&lt;/h3&gt;
&lt;p&gt;Uninstall control plane (istiod) only:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl x uninstall -f istiooperator-airgap-1-7-0.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Uninstall Istio completely (including CNI):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl x uninstall -f istiooperator-airgap-1-7-0.yaml --purge
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;integration-with-cicd&#34;&gt;Integration with CI/CD&lt;/h3&gt;
&lt;p&gt;Complete installation process can be integrated with existing CI/CD system. The
following considerations are required.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integration of istioctl with the pipeline.Pipeline running it required
cluster-admin permission.&lt;/li&gt;
&lt;li&gt;Integration of some security vulnerability tooling with the pipeline, which
ensures that there is no security vulnerability before installing Istio.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conformant-with-security-vulnerability&#34;&gt;Conformant with Security Vulnerability&lt;/h3&gt;
&lt;p&gt;All images are existing in centralized container registry.&lt;/p&gt;
&lt;p&gt;This centralized container registry has policy defined regarding content trust
and vulnerability scanning.&lt;/p&gt;
&lt;p&gt;For example, &lt;a href=&#34;https://goharbor.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Harbor&lt;/a&gt; registry interrogation services
provides two (Trivy and Clair) vulnerability scanners.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-harbor-config.png&#34; alt=&#34;policy defined in harbor&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Any image pushed to this registry passes through the vulnerability scanning.&lt;/p&gt;
&lt;p&gt;The following is an example of one result of Harbor registry vulnerability
scanning with Trivy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-trivy-result.png&#34; alt=&#34;vulnerability scanner result by Trivy&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Vulnerability scanners ensure that any new/existing vulnerability is tagged and
that no new pod can be created/scaled in cases where images have not passed
vulnerability criteria defined by the security team.&lt;/p&gt;
&lt;p&gt;Following are examples of how vulnerability scanners prevent any new pods being
created.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Warning  Failed     9s               kubelet, ip-10-0-1-75.us-east-2.compute.internal  Failed to pull image &amp;quot;harbor-k8s.xxxx.com/istio/install-cni:1.7.0&amp;quot;: rpc error: code = Unknown desc = failed to pull and unpack image &amp;quot;harb│
│or-k8s.xxxx.com/istio/install-cni:1.7.0&amp;quot;: failed to copy: httpReaderSeeker: failed open: unexpected status code https://harbor-k8s.xxxx.com/v2/istio/install-cni/manifests/sha256:09ac572eabda6b242aa5140f6bee0cbf809a4eb13b668d047│
│23cc7e8a1c272c6: 412 Precondition Failed - Server message: unknown: The image is not signed in Notary.
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;  Warning  Failed     6s               kubelet, ip-10-0-1-75.us-east-2.compute.internal  Failed to pull image &amp;quot;harbor-k8s.xxxx.com/istio/install-cni:1.7.0&amp;quot;: rpc error: code = Unknown desc = failed to pull and unpack image &amp;quot;harb│
│or-k8s.xxxx.com/istio/install-cni:1.7.0&amp;quot;: failed to copy: httpReaderSeeker: failed open: unexpected status code https://harbor-k8s.xxxx.com/v2/istio/install-cni/manifests/sha256:09ac572eabda6b242aa5140f6bee0cbf809a4eb13b668d047│
│23cc7e8a1c272c6: 412 Precondition Failed - Server message: unknown: current image with 268 vulnerabilities cannot be pulled due to configured policy in &#39;Prevent images with vulnerability severity of &amp;quot;High&amp;quot; or higher from runnin│
│g.&#39; To continue with pull, please contact your project administrator to exempt matched vulnerabilities through configuring the CVE allowlist.                                                                                      │
│  Warning  Failed     6s               kubelet, ip-10-0-1-75.us-east-2.compute.internal  Error: ErrImagePull
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For any pod which is already running and a new security vulnerability is
detected, int is continuously monitored by security team and it is for them to
decide whether to kill the pod or keep it running depending upon the level and
nature of vulnerability.&lt;/p&gt;
&lt;h3 id=&#34;sidecar-injection&#34;&gt;Sidecar Injection&lt;/h3&gt;
&lt;p&gt;There are different ways of injecting the Istio sidecar into a pod.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Manual sidecar injection&lt;/strong&gt;: Manual injection directly modifies
configuration, like deployments, and injects the proxy configuration into it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Automatic sidecar injection&lt;/strong&gt;: Sidecars are automatically added to
Kubernetes pods using a mutating webhook admission controller provided by
Istio.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The default configuration injects the sidecar into pods in any namespace
with the &lt;code&gt;istio.io/rev=1-7-3&lt;/code&gt; label.&lt;/li&gt;
&lt;li&gt;Disable the injection policy in configmap and add &lt;code&gt;sidecar.istio.io/inject&lt;/code&gt;
annotation with value &lt;code&gt;true&lt;/code&gt; to the pod template spec to override the
default and enable injection.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Application teams organize the workloads participating in a mesh in single or
multiple namespaces depending upon the architecture (microservices bounded
context/non microservices). Our general recommendation is to keep the mesh and
non mesh related workloads in different namespaces. Automatic sidecar injection
with &lt;strong&gt;default configuration&lt;/strong&gt; is recommended as it is easier to maintain during
the upgrade process. In this case, the Mesh Admin has clear visibility which
workload is running with which version and can take action accordingly.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n istio-system get configmap istio-sidecar-injector-1-7-0 -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{.data.config}&amp;#39;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep policy:
policy: enabled
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get mutatingwebhookconfiguration istio-sidecar-injector-1-7-0 -o yaml &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep &lt;span class=&#34;s2&#34;&gt;&amp;#34;namespaceSelector:&amp;#34;&lt;/span&gt; -A7
  namespaceSelector:
    matchExpressions:
    - key: istio-injection
      operator: DoesNotExist
    - key: istio.io/rev
      operator: In
      values:
      - 1-7-0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get ns -l istio.io/rev&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1-7-0
NAME       STATUS   AGE
bookinfo   Active   15h
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;upgrade-processpatch-management&#34;&gt;Upgrade Process/Patch Management&lt;/h3&gt;
&lt;p&gt;Upgrading Istio can be done by first running a canary deployment of the new
control plane, allowing you to monitor the effect of the upgrade with a small
percentage of the workloads, before migrating all of the traffic to the new
version. This is much safer than doing an in-place upgrade and is the
recommended upgrade method.&lt;/p&gt;
&lt;p&gt;Note: Upgrading across more than one minor version (e.g., 1.5.x to 1.7.x) in one
step is not officially tested or recommended.&lt;/p&gt;
&lt;p&gt;To illustrate the upgrade process please see below (sample &lt;code&gt;bookinfo&lt;/code&gt; example
and an upgrade from 1.7.0 to 1.7.3 is considered as an example).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-upgrade1.png&#34; alt=&#34;Current Installation state &#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The above picture shows the important labels and component versions in current
installed state (1.7.0).&lt;/p&gt;
&lt;p&gt;In order to upgrade Istio to 1.7.3, set &lt;code&gt;revision: 1-7-3&lt;/code&gt; in IstioOperator
definition file as shown in sample
&lt;a href=&#34;#production-grade-istiooperator-v173&#34;&gt;istiooperator-airgap-1-7-3.yaml&lt;/a&gt; and
install it using istioctl:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl install -f istiooperator-airgap-1-7-3.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: istioctl version is the target version (e.g. 1.7.3).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-upgrade2.png&#34; alt=&#34;Control plane upgrade&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;After running the command, you will have two control plane deployments and
services and mutating webhook running side-by-side:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pods -n istio-system -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;istiod
NAME                            READY   STATUS    RESTARTS   AGE
istiod-1-7-0-57f6b5cc56-cn7tr   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          33m
istiod-1-7-3-57c6c6d9d7-99w68   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          7m9s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get svc -n istio-system -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;istiod
NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;                                         AGE
istiod-1-7-0   ClusterIP   10.111.81.116   &amp;lt;none&amp;gt;        15010/TCP,15012/TCP,443/TCP,15014/TCP,853/TCP   34m
istiod-1-7-3   ClusterIP   10.109.95.131   &amp;lt;none&amp;gt;        15010/TCP,15012/TCP,443/TCP,15014/TCP,853/TCP   11m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get mutatingwebhookconfigurations
NAME                           WEBHOOKS   AGE
istio-sidecar-injector-1-7-0   &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          34m
istio-sidecar-injector-1-7-3   &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;          11m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Istio CNI plugin is also upgraded to targeted version.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get ds istio-cni-node -n kube-system -o yaml&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;grep image:
        image: &lt;span class=&#34;o&#34;&gt;{{&lt;/span&gt; hostname &lt;span class=&#34;o&#34;&gt;}}&lt;/span&gt;/istio/install-cni:1.7.3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Unlike istiod, Istio gateways do not run revision-specific instances, but are
instead in-place upgraded to use the new control plane revision.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl proxy-config endpoints &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl -n istio-system get pod -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;istio-ingressgateway -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{.items..metadata.name}&amp;#39;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;.istio-system --cluster xds-grpc -ojson &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep hostname
                &lt;span class=&#34;s2&#34;&gt;&amp;#34;hostname&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;istiod-1-7-3.istio-system.svc&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This in-place upgrade makes gateways unavailable for fraction of time. Thorough
testing is required to see how much time it is down. Depending upon the result
minReplicas can be adjusted.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;hpaSpec&lt;/code&gt; in IstioOperator resource:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;ingressGateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Number of &lt;code&gt;replicas&lt;/code&gt; in istio-ingressgateway deployment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;RollingUpdate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using multiple replicas can help in ensuring availability of ingress gateway
during upgrade. This need to be tested thoroughly.&lt;/p&gt;
&lt;p&gt;Simply installing the new revision has no impact on the existing sidecar
proxies. All the workloads are still running with the old version of Istio
proxy, e.g. proxyv2:1.7.0, and pointing to the old control plane.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl proxy-config endpoints &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl -n bookinfo get pod -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;productpage -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{.items..metadata.name}&amp;#39;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;.bookinfo --cluster xds-grpc -ojson &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep hostname
                &lt;span class=&#34;s2&#34;&gt;&amp;#34;hostname&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;istiod-1-7-0.istio-system.svc&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To upgrade these, one must configure them to point to the new istiod-1-7-3 control plane. This is controlled during sidecar injection based on the namespace label &lt;code&gt;istio.io/rev&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-upgrade3.png&#34; alt=&#34;Data plane upgrade&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Figure: Data plane upgrade&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To upgrade the namespace bookinfo, remove the &lt;code&gt;istio.io/rev=1-7-0 label&lt;/code&gt;, and
add &lt;code&gt;istio.io/rev=1-7-3 revision&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl label namespace bookinfo istio.io/rev&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1-7-3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Restart the deployment in bookinfo namespace:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl rollout restart deployment -n bookinfo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Verify that all pods are running with new labels:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pods -n bookinfo -l istio.io/rev&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1-7-3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Verify that the workloads are running new version of Istio proxy, e.g.
proxyv2:1.7.3, and pointing to the new control plane:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl proxy-config endpoints &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl -n bookinfo get pod -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;productpage -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{.items..metadata.name}&amp;#39;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;.bookinfo --cluster xds-grpc -o json &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep hostname
                &lt;span class=&#34;s2&#34;&gt;&amp;#34;hostname&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;istiod-1-7-3.istio-system.svc&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Grading both the control plane and data plane, you can uninstall the old control
plane:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl x uninstall -f istiooperator-airgap-1-7-0.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-upgrade4.png&#34; alt=&#34;targeted(1.7.3) installed state&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Confirm that the old control plane has been removed and only the new one still
exists in the cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pods -n istio-system -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;istiod
NAME                            READY   STATUS    RESTARTS   AGE
istiod-1-7-3-57c6c6d9d7-99w68   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          68m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In case new version is not working properly and want to revert back to previous
version:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl install -f istiooperator-airgap-1-7-0.yaml
kubectl label namespace bookinfo istio.io/rev&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1-7-0
kubectl rollout restart deployment -n bookinfo
istioctl x uninstall -f istiooperator-airgap-1-7-3.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;build--release-cadence&#34;&gt;Build &amp;amp; Release Cadence&lt;/h4&gt;
&lt;p&gt;Istio produces new builds of Istio for each commit. Around once a quarter or so,
Istio build a Long Term Support (LTS) release, and run through a bunch more
tests and release qualifications. Finally, if they find something wrong with an
LTS release, they issue patches.&lt;/p&gt;
&lt;p&gt;The different types represent different product quality levels and different
levels of support from the Istio team. In this context, support means that they
will produce patch releases for critical issues and offer technical assistance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-cadence.png&#34; alt=&#34;Build &amp;amp;amp; Release Cadence&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;network-isolation&#34;&gt;Network isolation&lt;/h3&gt;
&lt;p&gt;To further tighten the security of your applications, the following network
policy are created.&lt;/p&gt;
&lt;h4 id=&#34;deny-by-default&#34;&gt;Deny by Default&lt;/h4&gt;
&lt;p&gt;To ensure no inter-pod communication is possible, this policy can be applied
globally. The idea here is to ensure that if an application developer wants to
have a pod communicating with other pods, they need to create another network
policy which is specific to their pod&amp;rsquo;s needs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cluster Admin&lt;/strong&gt; creates this as default network policy in all the namespaces:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;NetworkPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;deny-by-default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;policyTypes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;allow-from-istio-namespace&#34;&gt;Allow from Istio Namespace&lt;/h4&gt;
&lt;p&gt;In order to access workloads running in the service mesh from outside of the
service mesh, all requests needs to come from Istio ingress gateway. The general
pattern is to expose one service which receives communication from outside
(ingress gateway) and interacts with other services internally within the
namespace.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mesh Admin&lt;/strong&gt; creates a label on the namespace where Istio ingress gateway is
running (istio-system).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl label namespace istio-system istio-control-namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Application Developer&lt;/strong&gt; creates a network policy.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;NetworkPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;allow-from-istio-namespace&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;productpage&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ingress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;namespaceSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio-control-namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;allow-from-same-namespace&#34;&gt;Allow from Same Namespace&lt;/h4&gt;
&lt;p&gt;This is suggested policy whereby all the pods in the same namespace needs to
interact without any policy restriction and because of global network policy
(deny-by-default), cannot interact. Please check with the cluster-admin before
applying this policy.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Application Developer&lt;/strong&gt; creates a network policy:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;NetworkPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;allow-same-namespace&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ingress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;podSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ingress-controller-in-kubernetes-with-istio&#34;&gt;Ingress Controller in Kubernetes with Istio&lt;/h2&gt;
&lt;h3 id=&#34;cloud-consideration&#34;&gt;Cloud Consideration&lt;/h3&gt;
&lt;p&gt;Once Istio is installed on any cloud, e.g. AWS, Azure, a Service of Type
LoadBalancer provisions an external LoadBalancer. For example, an Elastic Load
Balancer is created by default in AWS.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get svc istio-ingressgateway -n istio-system
NAME                   TYPE           CLUSTER-IP     EXTERNAL-IP                        PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
istio-ingressgateway   LoadBalancer   10.97.48.212   xxxx.us-east-2.elb.amazonaws.com   15021:31413/TCP,80:32673/TCP,443:31820/TCP,31400:30472/TCP,15443:31916/TCP
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A workload from outside service mesh is accessed using the ELB EXTERNAL-IP.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://xxxx.us-east-2.elb.amazonaws.com/productpage
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In order to use multiple hostnames, a CNAME type Record is required to be
configured. In AWS, a Route 53 entry is required.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-route53-cname.png&#34; alt=&#34;An example of CNAME record configuration.&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;With the above DNS setting, and after creating the required
&lt;a href=&#34;#gateway-definition&#34;&gt;Gateway Definition&lt;/a&gt; and
&lt;a href=&#34;#virtual-service-definition&#34;&gt;Virtual Service Definition&lt;/a&gt;, workloads are
accessed with different hostnames.&lt;/p&gt;
&lt;p&gt;Hostnames can be defined using following convention: &lt;app
name&gt;.&lt;namespace&gt;.appk8s.com. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://productpage.bookinfo.appk8s.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Istio by default creates an Elastic Load Balancer when installed on AWS. A
network load balancer (NLB) can also be created by specifying following
annotation during annotation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;gateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceAnnotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;nlb&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; AWS ELBs and NLBs both support layer 4 load balancing. There has not been
much adoption of NLB with open source Istio. But we don&amp;rsquo;t have any strong
opinion when it comes to comparing these two. When it comes to Istio, Istio&amp;rsquo;s
Gateway resource just lets you configure layer 4-6 load balancing properties
such as ports to expose TLS settings and so on. Application-layer traffic
routing (L7) are configured in virtual service which is bound to Istio gateway.&lt;/p&gt;
&lt;h3 id=&#34;existing-ingress-control&#34;&gt;Existing Ingress Control&lt;/h3&gt;
&lt;p&gt;If an ingress controller such as HAProxy, Contour or NGINX is in use and you do
not wish to replace it with Istio&amp;rsquo;s ingress gateway, they can be used in
conjunction. In this case, the ingress controller will direct traffic intended
for Istio service mesh by creating an Ingress object and using
istio-ingressgateway as backend.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get svc istio-ingressgateway -n istio-system
NAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;                                        AGE
istio-ingressgateway   ClusterIP   10.106.162.8   &amp;lt;none&amp;gt;        15021/TCP,80/TCP,443/TCP,31400/TCP,15443/TCP   70s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;productpage.bookinfo.appk8s.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If using a HTTPS host for the Ingress, create with passthrough mode
so that mutual authentication can take place at Istio ingress gateway.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: The above Ingress definition is just for reference. In this document,
only Istio ingress controller using &lt;a href=&#34;#gateway-definition&#34;&gt;Gateway Definition&lt;/a&gt;
and &lt;a href=&#34;#virtual-service-definition&#34;&gt;Virtual Service Definition&lt;/a&gt; is used.&lt;/p&gt;
&lt;p&gt;With the above setting, and after creating required
&lt;a href=&#34;#gateway-definition&#34;&gt;Gateway Definition&lt;/a&gt; and
&lt;a href=&#34;#virtual-service-definition&#34;&gt;Virtual Service Definition&lt;/a&gt;, workloads are
accessed with different hostnames.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://productpage.bookinfo.appk8s.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If routing traffic to the Istio ingress gateway through an ingress controller,
you will put an additional hop on the request path. The following picture
illustrates on the left side cluster the additional hop to reach to Istio
ingress gateway as compared to without it on right side.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-ingresscontroller.png&#34; alt=&#34;Number of hops when using ingress controller in addition to Istio&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;istio-secure-ingress-gateway-with-mtls&#34;&gt;Istio Secure Ingress Gateway with mTLS&lt;/h3&gt;
&lt;p&gt;By default the TLS protocol only proves the identity of the &lt;strong&gt;server to the
client&lt;/strong&gt; using X.509 certificate and the authentication of the client to the
server is left to the application layer. TLS also offers &lt;strong&gt;client-to-server&lt;/strong&gt;
authentication using client-side X.509 authentication.This two-way
authentication, when two parties authenticating each other at the same time is
also called Mutual TLS authentication (mTLS).&lt;/p&gt;
&lt;p&gt;Following is an example depicting the difference between two (TLS vs mTLS)
certificate exchanges. Notice how the client certificate is requested and
verified depicted by yellow line in mTLS traffic flow.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-tlsvsmtls.png&#34; alt=&#34;TLS(left) vs mTLS(right) handshake&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;As an mTLS service provider, the following certificates are required:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Server certificate and key&lt;/li&gt;
&lt;li&gt;CA certificate to verify client&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These certificates need to be provided as a secret in the namespace where
ingress gateway pod is running. In this example it is running in istio-system
namespace.&lt;/p&gt;
&lt;p&gt;The service provider creates the following gateway definition in the application
namespace:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo-gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;productpage.bookinfo.appk8s.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;credentialName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo-ingressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;MUTUAL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In order to automate server certificate and CA certificate and their associated
secret, the following integrations are required.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integration with vault&lt;/li&gt;
&lt;li&gt;Integration with cert-manager&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;integration-with-vault&#34;&gt;Integration with Vault&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-ingress.png&#34; alt=&#34;Certificates Signed with Vault&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Enterprise Root CA exists in centralize vault. This Root CA is required to sign the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;server certificate provided by the service provider of the
application/microservice.&lt;/li&gt;
&lt;li&gt;client certificate which is used to access the above microservice.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In order to access vault from Istio control plane namespace (istio-system), the
following needs to be configured:&lt;/p&gt;
&lt;p&gt;Configure allowed domain (appk8s.com):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vault-0 -- vault write pki/roles/appk8s-dot-com &lt;span class=&#34;nv&#34;&gt;allowed_domains&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;appk8s.com &lt;span class=&#34;nv&#34;&gt;allow_subdomains&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;max_ttl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;72h
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Configure Kubernetes authentication to vault:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vault &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; vault-0 -- vault auth &lt;span class=&#34;nb&#34;&gt;enable&lt;/span&gt; kubernetes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Configure Kubernetes authentication with service account:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vault-0 -- vault write auth/kubernetes/config &lt;span class=&#34;nv&#34;&gt;token_reviewer_jwt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;cat /var/run/secrets/kubernetes.io/serviceaccount/token&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;kubernetes_host&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;https://&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$KUBERNETES_PORT_443_TCP_ADDR&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;:443&amp;#34;&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;kubernetes_ca_cert&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;@/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A role needs to be created that specify which ServiceAccount in which namespace
can access Vault:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vault &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; vault-0 -- vault write auth/kubernetes/role/issuer &lt;span class=&#34;nv&#34;&gt;bound_service_account_names&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;issuer &lt;span class=&#34;nv&#34;&gt;bound_service_account_namespaces&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;={{&lt;/span&gt; controlPlaneNamespace &lt;span class=&#34;o&#34;&gt;}}&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;policies&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;pki &lt;span class=&#34;nv&#34;&gt;ttl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;20m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;integration-with-cert-manager&#34;&gt;Integration with Cert-Manager&lt;/h4&gt;
&lt;p&gt;Helm base installation is required. A cluster-admin who has permission to create
CRDs, should be able to install it.&lt;/p&gt;
&lt;p&gt;Cert-manager is a Kubernetes add-on to automate the management and issuance of
TLS certificates from various issuing sources like vault.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-cert-manager-vault-integration.png&#34; alt=&#34;Cert-Manager and Vault Integration&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The diagram above describes interaction among different namespaces and vault:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Mesh admin creates&lt;/strong&gt; an Issuer in istio-system namespace.&lt;/li&gt;
&lt;li&gt;Once Issuer is created, cert-manager auto discovers new certificate-issuer .&lt;/li&gt;
&lt;li&gt;cert-manager connects certificate-issuer to centralized Vault PKI engine.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Application Developer creates&lt;/strong&gt; Istio gateway definition in dev namespace
with credentialName required for mutual TLS.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Application Developer creates&lt;/strong&gt; certificate in istio-system namespace with
the required dnsNames and commonName.&lt;/li&gt;
&lt;li&gt;cert-manager, which is watching istio-system namespace for any new
certificate created, picks up the certificate and creates corresponding
CertificateRequests in istio-system namespace.&lt;/li&gt;
&lt;li&gt;cert-manager sends Certificate Sign Request (CSR) to centralized Vault PKI
engine to sign certificate. Vault signs the certificate. CertificateRequests
and Certificate turns into Ready state.&lt;/li&gt;
&lt;li&gt;cert-manager generates Kubernetes secret in istio-system namespace.&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;mesh-admin-responsibility&#34;&gt;Mesh Admin Responsibility&lt;/h5&gt;
&lt;p&gt;Mesh Admin needs to perform following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;create ServiceAccount, which is configured above in Vault.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n istio-system create serviceaccount issuer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;get the secret from above ServiceAccount.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n istio-system  get serviceaccount issuer -o json &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; jq -r .secrets&lt;span class=&#34;o&#34;&gt;[]&lt;/span&gt;.name
issuer-token-6qr6j
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Configure following Issuer in Istio control plane namespace.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cert-manager.io/v1alpha2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vault&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http://vault.vault&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pki/sign/appk8s-dot-com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;auth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/v1/auth/kubernetes&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;role&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;issuer-token-6qr6j&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h5 id=&#34;application-developer-responsibility&#34;&gt;Application Developer Responsibility&lt;/h5&gt;
&lt;p&gt;Application Developer needs to perform following steps.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create gateway definition.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo-gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;productpage.bookinfo.appk8s.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;credentialName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo-ingressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;MUTUAL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Create the Certificate required for the gateway definition.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cert-manager.io/v1alpha2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Certificate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo-ingressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo-ingressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;issuerRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;commonName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;productpage.bookinfo.appk8s.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dnsNames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;productpage.bookinfo.appk8s.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Verify the CertificateRequests is created successfully.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get certificaterequests -n istio-system
NAME                                            READY   AGE
bookinfo-ingressgateway-certs-1409582587        True    5h25m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Verify the Certificate is created successfully.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get certificate bookinfo-ingressgateway-certs -n istio-system
NAME                            READY   SECRET                          AGE
bookinfo-ingressgateway-certs   True    bookinfo-ingressgateway-certs   174m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Verify the corresponding secret is created.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get secret bookinfo-ingressgateway-certs -n istio-system
NAME                            TYPE                DATA   AGE
bookinfo-ingressgateway-certs   kubernetes.io/tls   &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;      174m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;secret-structure&#34;&gt;Secret Structure&lt;/h4&gt;
&lt;p&gt;Get the detail of secret data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n istio-system get secret appk8s-dot-com -o&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{$.data}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following describes the contents of the secrets created (ca.crt, tls.crt,
tls.key). What goes where depends upon the integration with cert-manager and
what Root CA or Intermediate CA is configured in vault.&lt;/p&gt;
&lt;p&gt;ca.crt:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the case that vault is configured as Intermediate CA cert, it will consist
of Intermediate CA cert only.&lt;/li&gt;
&lt;li&gt;In case vault is configured as Root CA cert, it will consist Root CA cert
only.&lt;/li&gt;
&lt;li&gt;The thing to notice here is that it does not consist of the full chain of
authority.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;tls.crt:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cert Issued by Root CA in vault.&lt;/li&gt;
&lt;li&gt;Issuing CA certificate.&lt;/li&gt;
&lt;li&gt;In case vault is configured as Intermediate CA cert, it will consist of
Intermediate CA cert and complete chain of authority.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;tls.key:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TLS key generated&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Full automation can be achieved in case that the Root CA is configured in
vault.&lt;/li&gt;
&lt;li&gt;Full automation &lt;strong&gt;can not&lt;/strong&gt; be achieved in the case that an intermediate CA
certificate in vault.&lt;/li&gt;
&lt;li&gt;In the case that the intermediate certificate is configured in vault, it must
get the full chain of CA certificate in tls.crt field but not in ca.crt field
of the certificate generated.&lt;/li&gt;
&lt;li&gt;ca.crt contains the CA certificate which has issued the certificate not the
full chain.&lt;/li&gt;
&lt;li&gt;In order to get mTLS working, ca.crt field should have the complete chain.
&lt;a href=&#34;https://github.com/jetstack/cert-manager/issues/2358&#34;&gt;https://github.com/jetstack/cert-manager/issues/2358&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;This issue can partially be resolved by creating
bookinfo-ingressgateway-certs-ca manually. This will bring challenges in day 2
operations. You will need to write a utility which keeps track of CA cert in
vault and the moment it changes, recreate all the secrets
(bookinfo-ingressgateway-certs-ca) in istio-system automatically.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;access-privilege-required-to-create-a-certificate&#34;&gt;Access Privilege Required to Create a Certificate&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;An Application team can have following namespaces segregated by network policy.
&lt;ul&gt;
&lt;li&gt;istio-system&lt;/li&gt;
&lt;li&gt;cert-manager&lt;/li&gt;
&lt;li&gt;Dev&lt;/li&gt;
&lt;li&gt;Test&lt;/li&gt;
&lt;li&gt;Prod&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Depending upon their role in the application team, different namespace admins
may be appropriate.&lt;/li&gt;
&lt;li&gt;Admins of Dev, Test and Prod do not have complete access on istio-system and
cert-manager.&lt;/li&gt;
&lt;li&gt;App developers and pipelines for Dev, Test and Prod do require permission to
create certificate in istio-system namespace.&lt;/li&gt;
&lt;li&gt;Create a ClusterRole which has privilege to create certificate in
istio-system.&lt;/li&gt;
&lt;li&gt;Create a RoleBinding for different tenants which have privilege to create
certificate in istio-system.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;high-availability-for-gateway&#34;&gt;High Availability for Gateway&lt;/h3&gt;
&lt;p&gt;Depending upon load, the number of gateway increases/decreases when the
horizontal pod autoscaler is enabled.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;ingressGateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Resource&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1024Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;40Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;istio-ingress-gateway-with-jwt&#34;&gt;Istio Ingress Gateway with JWT&lt;/h3&gt;
&lt;h4 id=&#34;request-authentication&#34;&gt;Request Authentication&lt;/h4&gt;
&lt;p&gt;Request auth is used for end-user authentication to verify the credential
attached to the request. Istio enables request-level authentication with JSON
Web Token (JWT) validation and a streamlined developer experience using a custom
authentication provider or any OpenID Connect providers.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -H &lt;span class=&#34;s2&#34;&gt;&amp;#34;Authorization: Bearer &amp;lt;JWT_TOKEN&amp;gt;&amp;#34;&lt;/span&gt; https://productpage.bookinfo.appk8s.com/productpage
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As a &lt;strong&gt;MeshAdmin&lt;/strong&gt;, RequestAuthentication definition can be applied globally
(across all the namespaces) in istio-system namespace.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```yaml
apiVersion: &amp;quot;security.istio.io/v1beta1&amp;quot;
kind: &amp;quot;RequestAuthentication&amp;quot;
metadata:
  name: &amp;quot;reqauth-istio-system&amp;quot;
  namespace: istio-system
spec:
  jwtRules:
  - issuer: http://&amp;lt;OIDC_PROVIDER&amp;gt;/auth/realms/istio
    jwksUri: http://&amp;lt;OIDC_PROVIDER&amp;gt;/auth/realms/istio/protocol/openid-connect/certs
    forwardOriginalToken: true
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;issuer&lt;/code&gt;: JSON Web Token (JWT) issuer&lt;/p&gt;
&lt;p&gt;&lt;code&gt;jwksUri&lt;/code&gt;: The JSON Web Key Set (JWKS) is a set of keys containing the public keys used to verify any JSON Web Token (JWT).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;forwardOriginalToken&lt;/code&gt;: By default, JWT request tokens are not passed from one
service to another service. It is the responsibility of &lt;strong&gt;Application Developer&lt;/strong&gt;
to pass these tokens from one service to another. This can be set to true to
pass the JWT Request token to next service. This forward is valid only for first
hop.&lt;/p&gt;
&lt;p&gt;Istio checks the presented token, if presented against the rules in the request
authentication policy, it rejects requests with invalid tokens. When requests
carry no token, &lt;strong&gt;they are accepted by default&lt;/strong&gt;. To reject requests without
tokens, &lt;strong&gt;provide authorization rules&lt;/strong&gt; that specify the restrictions for
specific operations.&lt;/p&gt;
&lt;p&gt;As &lt;strong&gt;MeshAdmin&lt;/strong&gt; an AuthorizationPolicy definition can be applied in
istio-system namespace so that Istio ingress gateway does not let any request
through without passing valid JWT.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;security.istio.io/v1beta1&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;AuthorizationPolicy&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;frontend-ingress&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DENY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;notRequestPrincipals&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above AuthorizationPolicy says that any request coming to ingress gateway
with label &lt;code&gt;istio: ingressgateway&lt;/code&gt; is denied if it does not have a JWT in
request header.&lt;/p&gt;
&lt;p&gt;A token can be obtained as follows. This is an example of one of the OIDC
providers: keycloak. This can vary depending upon the provider.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -X POST &lt;span class=&#34;s1&#34;&gt;&amp;#39;http://&amp;lt;OIDC_PROVIDER&amp;gt;/auth/realms/istio/protocol/openid-connect/token&amp;#39;&lt;/span&gt; -H &lt;span class=&#34;s2&#34;&gt;&amp;#34;Content-Type: application/x-www-form-urlencoded&amp;#34;&lt;/span&gt; -d &lt;span class=&#34;s1&#34;&gt;&amp;#39;username=prod001&amp;amp;password=&amp;lt; PASSWORD &amp;gt;&amp;amp;grant_type=password&amp;amp;client_id=servicemesh&amp;#39;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;jq -r .access_token
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: In above example username is &lt;code&gt;prod001&lt;/code&gt;. This will be used to illustrate
some examples in the next section.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-jwttoken.png&#34; alt=&#34;Sample JWT structure&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;One can access the service by passing the token obtained in the above step to
the &amp;lt;JWT_TOKEN&amp;gt; placeholder.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -H &lt;span class=&#34;s2&#34;&gt;&amp;#34;Authorization: Bearer &amp;lt;JWT_TOKEN&amp;gt;&amp;#34;&lt;/span&gt; https://productpage.bookinfo.appk8s.com/productpage
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As an &lt;strong&gt;Application developer&lt;/strong&gt;, one can specify their application-specific
AuthorizationPolicy based on the token attribute. In following example only a
specific user(prod001) can access the service.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;security.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;AuthorizationPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;policy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;productpage&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ALLOW&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespaces&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;istio-system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;when&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;request.auth.claims[preferred_username]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;prod001&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note: Using JWT alone does not encrypt the traffic. One should use mTLS and JWT
together.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -H --cacert ca.crt --cert tls.crt --key /tls.key -H &lt;span class=&#34;s2&#34;&gt;&amp;#34;Authorization: Bearer &amp;lt;JWT_TOKEN&amp;gt;&amp;#34;&lt;/span&gt; https://productpage.bookinfo.appk8s.com/productpage
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;service-mesh-communication&#34;&gt;Service Mesh Communication&lt;/h2&gt;
&lt;h3 id=&#34;istio-identity&#34;&gt;Istio Identity&lt;/h3&gt;
&lt;p&gt;Identity is a fundamental concept of any security infrastructure. At the
beginning of a service-to-service communication, the two parties must exchange
credentials with their identity information for mutual authentication. In
Kubernetes, Service Accounts are treated as service Identities. Istio uses X.509
certificates to carry identities in SPIFFE format. Istio provisions identities
through the secret discovery service (SDS).&lt;/p&gt;
&lt;h3 id=&#34;istio-ca&#34;&gt;Istio CA&lt;/h3&gt;
&lt;p&gt;By default, Istio&amp;rsquo;s CA generates a self-signed root certificate and key, and
uses them to sign the workload certificates. By default this certificate is
valid for 10 years. It&amp;rsquo;s mounted in istiod pod.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get secret istio-ca-secret -o&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{$.data.ca-cert\.pem}&amp;#39;&lt;/span&gt; -n istio-system &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; base64 --decode &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;openssl x509 -noout -text &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;grep -A4 -i Issuer
        Issuer: &lt;span class=&#34;nv&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;cluster.local
        Validity
            Not Before: Oct &lt;span class=&#34;m&#34;&gt;28&lt;/span&gt; 17:17:26 &lt;span class=&#34;m&#34;&gt;2020&lt;/span&gt; GMT
            Not After : Oct &lt;span class=&#34;m&#34;&gt;26&lt;/span&gt; 17:17:26 &lt;span class=&#34;m&#34;&gt;2030&lt;/span&gt; GMT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;One can plug in their own root/intermediate certificate by creating a secret
named &lt;code&gt;cacerts&lt;/code&gt; in istio-system namespace.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create secret generic cacerts -n istio-system &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;              --from-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;ca-cert.pem &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;              --from-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;ca-key.pem &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;              --from-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;root-cert.pem &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;              --from-file&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;cert-chain.pem
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;mtls-mode&#34;&gt;mTLS Mode&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-intracluster-mtls.png&#34; alt=&#34;In-cluster mTLS communication&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mesh Admin&lt;/strong&gt; can ensure that all the services inside the mesh are
communicating via mTLS by applying following PeerAuthentication definition:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;security.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;PeerAuthentication&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mtls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;STRICT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above Global (in istio-system namespace) PeerAuthentication policy enforces
&lt;strong&gt;Application Developer&lt;/strong&gt; always specify traffic policy as ISTIO_MUTUAL as
follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DestinationRule&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;productpage&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;productpage&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;trafficPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ISTIO_MUTUAL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subsets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With the DestinationRule TLS mode policy set to ISTIO_MUTUAL, the Istio CA
generates all the required client and server certificates
&lt;a href=&#34;https://istio.io/latest/docs/concepts/security/#pki&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;automatically&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The certificate can be verified if they are created using the SPIFFE format
based on service account.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n bookinfo &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl -n bookinfo get pod -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;productpage -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;={&lt;/span&gt;.items..metadata.name&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; -c istio-proxy -- openssl s_client -showcerts -connect details:9080 &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; openssl x509 -noout -text &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep -B1 -A2 spiffe
            X509v3 Subject Alternative Name: critical
                URI:spiffe://cluster.local/ns/bookinfo/sa/bookinfo-details
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The issuer of the certificate can be verified by executing the following
command. By default, the workload certificates are provisioned for 24 hours.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n bookinfo &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl -n bookinfo get pod -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;productpage -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;={&lt;/span&gt;.items..metadata.name&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; -c istio-proxy -- openssl s_client -showcerts -connect details:9080 &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; openssl x509 -noout -text &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep -A3 Issuer
        Issuer: &lt;span class=&#34;nv&#34;&gt;O&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;cluster.local
        Validity
            Not Before: Oct &lt;span class=&#34;m&#34;&gt;29&lt;/span&gt; 07:26:19 &lt;span class=&#34;m&#34;&gt;2020&lt;/span&gt; GMT
            Not After : Oct &lt;span class=&#34;m&#34;&gt;30&lt;/span&gt; 07:26:19 &lt;span class=&#34;m&#34;&gt;2020&lt;/span&gt; GMT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;egress-gateway-in-istio&#34;&gt;Egress Gateway in Istio&lt;/h2&gt;
&lt;h3 id=&#34;istio-secure-egress-gateway-mtls-origination&#34;&gt;Istio Secure Egress Gateway mTLS Origination&lt;/h3&gt;
&lt;h4 id=&#34;within-cluster&#34;&gt;Within Cluster&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-egress-arch-withcluster.png&#34; alt=&#34;Istio Egress&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use case:&lt;/strong&gt; An app running in a namespace &lt;code&gt;sleep&lt;/code&gt; which is part of service
mesh is connecting to a Kubernetes service, e.g.
&lt;code&gt;my-nginx.mesh-external.svc.cluster.local&lt;/code&gt;, residing in the same Kubernetes
cluster but not in the service mesh.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-egress-within-cluster.png&#34; alt=&#34;Egress Vault and Cert-Manager Flow&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The diagram above describes the interaction between different namespaces and vault.&lt;/p&gt;
&lt;h5 id=&#34;within-cluster-steps&#34;&gt;&lt;strong&gt;Within Cluster Steps&lt;/strong&gt;&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Mesh admin creates&lt;/strong&gt; an Issuer in istio-system namespace.&lt;/li&gt;
&lt;li&gt;Once Issuer is created, cert-manager auto discovers new certificate-issuer.&lt;/li&gt;
&lt;li&gt;cert-manager connects certificate-issuer to Centralized Vault PKI engine.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Application Developer creates&lt;/strong&gt; the following in &lt;code&gt;sleep&lt;/code&gt; namespace:
&lt;ul&gt;
&lt;li&gt;Istio egress gateway definition and destination rule (for egress service).&lt;/li&gt;
&lt;li&gt;virtual service which routes
&lt;ul&gt;
&lt;li&gt;traffic coming from app container on port 80 to egress service on port 443.&lt;/li&gt;
&lt;li&gt;traffic coming to egress service on port 443 to external service.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Application Developer creates&lt;/strong&gt; Certificate in &lt;code&gt;istio-system&lt;/code&gt; namespace
with the required dnsNames and commonName.&lt;/li&gt;
&lt;li&gt;cert-manager, which is watching &lt;code&gt;istio-system&lt;/code&gt; namespace for any new
Certificate created, picks up the Certificate and creates corresponding
CertificateRequests in &lt;code&gt;istio-system&lt;/code&gt; namespace.&lt;/li&gt;
&lt;li&gt;cert-manager sends Certificate Sign Request (CSR) to Centralized Vault PKI
engine to sign certificate. Vault signs the certificate. CertificateRequests
and Certificate turns into Ready state.&lt;/li&gt;
&lt;li&gt;cert-manager generates Kubernetes secret in &lt;code&gt;istio-system&lt;/code&gt; namespace.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Application Developer creates&lt;/strong&gt; DestinationRule (for external service) with
credentialName required for mutual TLS.&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;mesh-admin-responsibility-1&#34;&gt;&lt;strong&gt;Mesh Admin Responsibility&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;Mesh Admin needs to perform following steps.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create ServiceAccount, which is configured above in vault.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n istio-system create serviceaccount issuer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Get the secret from above ServiceAccount.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n istio-system  get serviceaccount issuer -o json &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; jq -r .secrets&lt;span class=&#34;o&#34;&gt;[]&lt;/span&gt;.name
issuer-token-6qr6j
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Configure the following Issuer in Istio control plane namespace.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cert-manager.io/v1alpha2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vault&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http://vault.vault&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pki/sign/appk8s-dot-com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;auth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/v1/auth/kubernetes&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;role&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;issuer-token-6qr6j&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h5 id=&#34;application-developer-responsibility-1&#34;&gt;&lt;strong&gt;Application Developer Responsibility&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: EXTERNAL_SERVICE_HOST=my-nginx-client.mesh-external.svc.cluster.local&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create egress gateway definition in &lt;code&gt;sleep&lt;/code&gt; namespace as all traffic external
to mesh goes via this Egress Gateway.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- {&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EXTERNAL_SERVICE_HOST } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ISTIO_MUTUAL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Create destination rule in &lt;code&gt;sleep&lt;/code&gt; namespace. It is required as it determines
how ISTIO_MUTUAL service residing in service mesh communicates with egress
gateway.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DestinationRule&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;egressgateway-for-nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway.istio-system.svc.cluster.local&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subsets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;trafficPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;loadBalancer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;simple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ROUND_ROBIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;portLevelSettings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ISTIO_MUTUAL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sni&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EXTERNAL_SERVICE_HOST } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Create virtual service in &lt;code&gt;sleep&lt;/code&gt; namespace. This virtual service has two functions:
&lt;ul&gt;
&lt;li&gt;HTTP (port:80) traffic originating from app container is redirected to istio-egressgateway.istio-system.svc.cluster.local on port 443&lt;/li&gt;
&lt;li&gt;Any traffic coming to istio-egressgateway.istio-system.svc.cluster.local on port 443 is redirected to external service (EXTERNAL_SERVICE_HOST)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;VirtualService&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;direct-nginx-through-egress-gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- {&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EXTERNAL_SERVICE_HOST } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;mesh&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;match&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;gateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;mesh&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;route&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway.istio-system.svc.cluster.local&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;match&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;gateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;route&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EXTERNAL_SERVICE_HOST } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Create Certificate in &lt;code&gt;istio-system&lt;/code&gt; namespace. It is required because a
client certificate is required to communicate to the external service with
mutual TLS. This Certificate definition creates a secret (client-credential)
mentioned in the destination rule below.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cert-manager.io/v1alpha2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Certificate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;client-credential&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;client-credential&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;issuerRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;commonName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EXTERNAL_SERVICE_HOST } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dnsNames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- {&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EXTERNAL_SERVICE_HOST } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Create DestinationRule in &lt;code&gt;istio-system&lt;/code&gt; namespace. It is required as it
determines how MUTUAL external service communicates with egress gateway.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DestinationRule&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;originate-tls-for-nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EXTERNAL_SERVICE_HOST } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;trafficPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;loadBalancer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;simple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ROUND_ROBIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;portLevelSettings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;MUTUAL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;credentialName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;client-credential&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sni&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EXTERNAL_SERVICE_HOST } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;inter-cluster&#34;&gt;Inter Cluster&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-egress-arch-intra-cluster.png&#34; alt=&#34;Egress Inter-Cluster Communication&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use case:&lt;/strong&gt; An app running in a namespace &lt;code&gt;sleep&lt;/code&gt; which is part of service
mesh is connecting to an external Kubernetes service, e.g.
&lt;code&gt;my-nginx.mesh-external.svc.cluster.local&lt;/code&gt;, residing in &lt;strong&gt;different&lt;/strong&gt; Kubernetes
cluster.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-egress-intra-cluster.png&#34; alt=&#34;Egress Vault Cert-Manager Flow&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The diagram above describes the interaction between different namespaces and Vault.&lt;/p&gt;
&lt;p&gt;Please see the &lt;a href=&#34;#within-cluster-steps&#34;&gt;Within cluster steps&lt;/a&gt; section for all
different steps involved. The only difference here is in &lt;strong&gt;step 4&lt;/strong&gt; where an
additional service entry is required in order to access the service residing in
different Kubernetes cluster. This is required to make sure external service is
available in Istio&amp;rsquo;s internal service registry.&lt;/p&gt;
&lt;h5 id=&#34;mesh-admin-responsibility-2&#34;&gt;&lt;strong&gt;Mesh Admin Responsibility&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;Mesh Admin needs to perform following steps.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a ServiceAccount which is configured above in vault.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n istio-system create serviceaccount issuer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Get the secret from the above ServiceAccount.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n istio-system  get serviceaccount issuer -o json &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; jq -r .secrets&lt;span class=&#34;o&#34;&gt;[]&lt;/span&gt;.name
issuer-token-6qr6j
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Configure the following Issuer in Istio control plane namespace.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cert-manager.io/v1alpha2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;vault-issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;vault&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http://vault.vault&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pki/sign/appk8s-dot-com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;auth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/v1/auth/kubernetes&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;role&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;issuer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;issuer-token-6qr6j&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;token&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h5 id=&#34;application-developer-responsibility-2&#34;&gt;&lt;strong&gt;Application Developer Responsibility&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: EXTERNAL_SERVICE_HOST=my-nginx-client.mesh-external.appk8s.com&lt;/p&gt;
&lt;p&gt;Please see &lt;a href=&#34;#application-developer-responsibility-1&#34;&gt;Within cluster&lt;/a&gt; section for
all required responsibilities. Note that an additional service entry is
required. This is required to make sure external service is available in Istio&amp;rsquo;s
internal service registry.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ServiceEntry&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx-k8s&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- {&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;EXTERNAL_SERVICE_HOST } }&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resolution&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;DNS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;access-privilege-required-to-create-a-certificate-and-gateway&#34;&gt;Access Privilege Required to Create a Certificate and Gateway&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;All application teams are responsible for their service mesh.&lt;/li&gt;
&lt;li&gt;An application team can have the following namespaces segregated by network policy.
&lt;ul&gt;
&lt;li&gt;istio-system&lt;/li&gt;
&lt;li&gt;cert-manager&lt;/li&gt;
&lt;li&gt;Dev&lt;/li&gt;
&lt;li&gt;Test&lt;/li&gt;
&lt;li&gt;Prod&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Depending upon their role in application teams, different namespace admins may
be appropriate.&lt;/li&gt;
&lt;li&gt;Admins of Dev, Test and Prod do not have complete access on istio-system and
cert-manager.&lt;/li&gt;
&lt;li&gt;App developers and pipelines for Dev, Test and Prod do require permission to
create certificate in istio-system namespace.&lt;/li&gt;
&lt;li&gt;Create a ClusterRole which has privileges to create Certificate and Gateway in
&lt;code&gt;istio-system&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Create a RoleBinding for different tenants which has permission to create
Certificate in &amp;lsquo;istio-system&amp;rsquo;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;high-availability-for-gateway-1&#34;&gt;High Availability for Gateway&lt;/h3&gt;
&lt;p&gt;Depending upon load, the number of gateway increases/decreases when the
horizontal pod autoscaler is enabled.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;egressGateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Resource&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1024Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;40Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;observability&#34;&gt;Observability&lt;/h2&gt;
&lt;h3 id=&#34;telemetry--prometheus&#34;&gt;Telemetry &amp;amp; Prometheus&lt;/h3&gt;
&lt;p&gt;Istio generates metrics for all service traffic into, out from, and within an
Istio service mesh. These metrics provide information on behaviors such as the
overall volume of traffic, the error rates within the traffic, and the response
times for requests. By default, Istio configures Envoy to record minimal
statistics.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl -n bookinfo &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; -it &lt;span class=&#34;o&#34;&gt;{{&lt;/span&gt; SOURCE_POD_NAME&lt;span class=&#34;o&#34;&gt;}}&lt;/span&gt; -c istio-proxy -- pilot-agent request GET stats &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; more
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cluster_manager.cds.version_text: &lt;span class=&#34;s2&#34;&gt;&amp;#34;2020-10-21T10:31:01Z/6&amp;#34;&lt;/span&gt;
listener_manager.lds.version_text: &lt;span class=&#34;s2&#34;&gt;&amp;#34;2020-10-21T10:31:01Z/6&amp;#34;&lt;/span&gt;
cluster.xds-grpc.assignment_stale: &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;
cluster.xds-grpc.assignment_timeout_received:
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Istio control plane components export metrics on their own internal behaviors to
provide insight on the health and function of the mesh control plane.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://prometheus.io/docs/introduction/overview/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus&lt;/a&gt; is an
open-source metrics and alerting toolkit. Prometheus works on pull based
mechanism. That means our applications or the Istio service proxy expose an
endpoint with the latest metrics from which Prometheus can the pull/scrape the
metrics.&lt;/p&gt;
&lt;h4 id=&#34;proxy-level-metrics&#34;&gt;Proxy-Level Metrics&lt;/h4&gt;
&lt;p&gt;Each proxy generates a rich set of metrics about all traffic passing through the
proxy (both inbound and outbound). The proxies also provide detailed statistics
about the administrative functions of the proxy itself, including configuration
and health information.&lt;/p&gt;
&lt;p&gt;Some examples are as follows.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;envoy_cluster_upstream_rq_completed{cluster_name=&amp;quot;xds-grpc&amp;quot;} 7164
envoy_cluster_ssl_connection_error{cluster_name=&amp;quot;xds-grpc&amp;quot;} 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-envoy-level-metrics.png&#34; alt=&#34;Proxy-level metrics in Prometheus&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;service-level-metrics&#34;&gt;Service-Level Metrics&lt;/h4&gt;
&lt;p&gt;Istio provides a set of service-oriented metrics for monitoring service
communications. These metrics cover the four basic service monitoring needs:
&lt;strong&gt;latency, traffic, errors, and saturation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://istio.io/latest/docs/reference/config/policy-and-telemetry/metrics/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Standard Istio metrics &lt;/a&gt;
are exposed for scraping by Prometheus by default.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-service-level-metrics.png&#34; alt=&#34;Service-level metrics in Prometheus&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;control-plane-metrics&#34;&gt;Control Plane Metrics&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://istio.io/latest/docs/reference/commands/pilot-discovery/#metrics&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;These metrics&lt;/a&gt;
allow monitoring of the behavior of Istio itself.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-controlplane-metrics.png&#34; alt=&#34;Control-Plane metrics in Prometheus&#34;  /&gt;&lt;/p&gt;
&lt;h4 id=&#34;prometheus-architecture&#34;&gt;Prometheus Architecture&lt;/h4&gt;
&lt;p&gt;In an Istio mesh, each component exposes an endpoint that emits metrics. To
gather metrics for the entire mesh, configure Prometheus to scrape:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The control plane (istiod deployment)&lt;/li&gt;
&lt;li&gt;Ingress and Egress gateways&lt;/li&gt;
&lt;li&gt;The Envoy sidecar&lt;/li&gt;
&lt;li&gt;The user applications (if they expose Prometheus metrics)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The recommended approach for production-scale monitoring of Istio with
Prometheus is to use
&lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/federation/#hierarchical-federation&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;hierarchical federation&lt;/a&gt;
in combination with a collection of recording rules.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-prometheus-arch.png&#34; alt=&#34;Prometheus architecture in production&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The Istio pods in the control and data planes declare they are ready to have
metrics scraped by Prometheus by way of annotations in pod definition.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/stats/prometheus&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;15090&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/scrape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;One can verify that the pod metrics are ready to be scraped by checking targets
in Prometheus.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-promethus-bookinfo-metrics.png&#34; alt=&#34;Prometheus status target&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Prometheus instances that are deployed locally to each cluster for Istio act as
initial collectors. A local Prometheus scrapes the metrics from different
services. Metrics fill up underlying storage very fast over a period of days or
weeks.The recommended approach is to keep a short retention window on this local
cluster. If you deploy this Prometheus server to the &lt;code&gt;istio-system&lt;/code&gt; namespace,
you do not need to worry about additional network policy.&lt;/p&gt;
&lt;p&gt;Modify the configuration of your production-ready deployment of Prometheus to
scrape the federation endpoint of the Istio Prometheus. It is not required to
scrape all the metrics. Only production relevant metrics are scraped.&lt;/p&gt;
&lt;h4 id=&#34;grafana&#34;&gt;Grafana&lt;/h4&gt;
&lt;p&gt;Prometheus is a time-series database and collection toolkit. Once metrics are
collected, Prometheus brings a simple expression browser to help explore trends
and metrics, Grafana is a popular and powerful open-source graph and
visualization tool that works well with Prometheus.&lt;/p&gt;
&lt;p&gt;Istio comes with some pre built
&lt;a href=&#34;https://istio.io/latest/docs/tasks/observability/metrics/using-istio-dashboard/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;dashboards&lt;/a&gt;
which consist of following sections.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mesh Summary View:&lt;/strong&gt; provides Global Summary view of the Mesh which shows
HTTP/gRPC and TCP workloads in the Mesh.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Individual Services View:&lt;/strong&gt; provides metrics about requests and responses for
each individual service within the mesh (HTTP/gRPC and TCP).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Individual Workloads View:&lt;/strong&gt; provides metrics about requests and responses for
each individual workload within the mesh (HTTP/gRPC and TCP).&lt;/p&gt;
&lt;h4 id=&#34;installing-prometheus-and-grafana&#34;&gt;Installing Prometheus and Grafana&lt;/h4&gt;
&lt;h5 id=&#34;prometheus-installation&#34;&gt;&lt;strong&gt;Prometheus Installation&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;Istio comes with
&lt;a href=&#34;https://istio.io/latest/docs/ops/integrations/prometheus/#option-1-quick-start&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;built-in&lt;/a&gt;
Prometheus installation, which contains all the required scraping
configurations.&lt;/p&gt;
&lt;p&gt;To use an existing Prometheus instance, add the scraping configurations from
&lt;a href=&#34;https://raw.githubusercontent.com/istio/istio/release-1.7/manifests/charts/istio-telemetry/prometheus/templates/configmap.yaml&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;prometheus/configmap.yaml&lt;/a&gt;
to your configuration.&lt;/p&gt;
&lt;p&gt;In both the above cases, access to metrics are provided using Grafana with RBAC.&lt;/p&gt;
&lt;h5 id=&#34;grafana-installation&#34;&gt;&lt;strong&gt;Grafana Installation&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;Istio provides a
&lt;a href=&#34;https://istio.io/latest/docs/ops/integrations/grafana/#option-1-quick-start&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;basic sample&lt;/a&gt;
installation to quickly get Grafana up and running. It is bundled with all of
the Istio dashboards already installed. One can remotely access Grafana
&lt;a href=&#34;https://istio.io/latest/docs/tasks/observability/gateways/#option-1-secure-access-https&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;securely&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If using an existing Grafana instance, the following dashboards can be imported
into its dashboard:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/7639&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Mesh Dashboard&lt;/a&gt; provides an
overview of all services in the mesh.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/7636&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Service Dashboard&lt;/a&gt; provides a
detailed breakdown of metrics for a service.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/7630&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Workload Dashboard&lt;/a&gt; provides a
detailed breakdown of metrics for a workload.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/11829&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Performance Dashboard&lt;/a&gt; monitors
the resource usage of the mesh.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/7645&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Control Plane Dashboard&lt;/a&gt;
monitors the health and performance of the control plane.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;prometheus-annotations&#34;&gt;Prometheus Annotations&lt;/h4&gt;
&lt;p&gt;By passing &lt;strong&gt;&amp;ndash;set meshConfig.enablePrometheusMerge=true&lt;/strong&gt; during installation,
appropriate prometheus.io annotations will be added to all data plane pods to
expose metrics for scraping. With this option, the Envoy sidecar will merge
Istio’s metrics with the application metrics. The merged metrics will be scraped
from /stats/prometheus:15020. This option exposes all the metrics in plain text.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/stats/prometheus&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;15020&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/scrape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the case that the application is also exposing custom app metrics in
Prometheus format, &lt;strong&gt;Application Developer&lt;/strong&gt; needs to provide application
specific Prometheus annotation in pod definition.&lt;/p&gt;
&lt;p&gt;Following is an example of a Spring Boot application pod definition exposing JVM
specific metrics:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/manage/prometheus&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;8383&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/scrape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the above pod definition is applied in a namespace that is part of the
service mesh, istio-proxy is injected and the above annotations are merged as
shown in the following pod definition.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/stats/prometheus&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;15020&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus.io/scrape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;At the same time ISTIO_PROMETHEUS_ANNOTATIONS environment variable is updated to
the application specific Prometheus annotation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ISTIO_PROMETHEUS_ANNOTATIONS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;&amp;#39;{&amp;#34;scrape&amp;#34;:&amp;#34;true&amp;#34;,&amp;#34;path&amp;#34;:&amp;#34;/manage/prometheus&amp;#34;,&amp;#34;port&amp;#34;:&amp;#34;8383&amp;#34;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-proxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Application specific metrics can be queried from Prometheus as follows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-application-level-metrics.png&#34; alt=&#34;Querying Application-specific metrics&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;If you pass &lt;strong&gt;&amp;ndash;set meshConfig.enablePrometheusMerge=false&lt;/strong&gt; during
installation, &lt;strong&gt;Application Developer&lt;/strong&gt; will need to provide appropriate
prometheus.io annotations inside the pod/deployment.&lt;/p&gt;
&lt;h3 id=&#34;logging&#34;&gt;Logging&lt;/h3&gt;
&lt;p&gt;Istio uses &lt;code&gt;meshConfig.accessLogFile&lt;/code&gt; parameter during installation to specify
where the logs should be redirected.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meshConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;accessLogFile&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/dev/stdout&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It&amp;rsquo;s &lt;a href=&#34;https://12factor.net/logs&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;recommended&lt;/a&gt; practice for containerized
applications to write logs to the standard output and error streams. These
streams are redirected by container engine to its configured location (usually
/var/log/containers).&lt;/p&gt;
&lt;h4 id=&#34;log-aggregation&#34;&gt;Log Aggregation&lt;/h4&gt;
&lt;p&gt;Logs are produced by containers at the configured location on their respective
nodes, where they are running.&lt;/p&gt;
&lt;p&gt;An example of Istio control plane logs are as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ls -al /var/log/containers/
istiod-1-7-3-_istio-system_discovery-xx.log -&amp;gt; /var/log/pods/istio-system_istiod-1-7-3-xx/discovery/0.log
istio-egressgateway_istio-system_istio-proxy-xx.log -&amp;gt; /var/log/pods/istio-system_istio-egressgateway_xx/istio-proxy/0.log
istio-ingressgateway_istio-system_istio-proxy-xx.log -&amp;gt; /var/log/pods/istio-system_istio-ingressgateway_xx/istio-proxy/0.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;An example of Istio data plane logs are as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ls -al /var/log/containers/
productpage-v1_bookinfo_istio-proxy-xx.log -&amp;gt; /var/log/pods/bookinfo_productpage-v1-xx/istio-proxy/0.log
productpage-v1_bookinfo_istio-validation-xx.log -&amp;gt; /var/log/pods/bookinfo_productpage-v1-xx/istio-validation/0.log
productpage-v1_bookinfo_productpage-xx.log -&amp;gt; /var/log/pods/bookinfo_productpage-v1-xx/productpage/0.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;An example of Istio CNI logs are as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ls -al /var/log/containers/
istio-cni-node-cfxml_kube-system_install-cni-xx.log -&amp;gt; /var/log/pods/kube-system_istio-cni-node-xx/install-cni/0.log
istio-cni-node-cfxml_kube-system_repair-cni-xx.log -&amp;gt; /var/log/pods/kube-system_istio-cni-node-xx/repair-cni/0.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These logs are created on all the nodes where pods are running. A logging agent
such as Fluentd, FluentBit or Logstash is required to be running on all the
nodes and have access to log directories. It collects logs from those
directories and forwards it to a back end log storage such as ElasticSearch,
Splunk or Kafka. Most of the logging agents provided by different vendors are
implemented as a DaemonSet.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-logging-architecture.png&#34; alt=&#34;Logging architecture&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;An example of a &lt;strong&gt;FluentBit integration with Splunk&lt;/strong&gt; is as follows. It runs as
DaemonSet using a ConfigMap to provide a configuration file. This configuration
file has two sections: input and output.&lt;/p&gt;
&lt;p&gt;This example is provided to explain the concept. Complete details are omitted.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Input Config&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;input-kubernetes.conf: &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;INPUT&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
Name              tail
Tag               kube.*
Path              /var/log/containers/*.log
Parser            docker
DB                /var/log/flb_kube.db
Mem_Buf_Limit     5MB
Skip_Long_Lines   On
Refresh_Interval  &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Things to note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Path:&lt;/strong&gt; From where logs need to be collected.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tag:&lt;/strong&gt; An internal string used to filter logs for Output phase.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Output Config&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;output-splunk.conf: &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;OUTPUT&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
Name           splunk
Match          kube.*
Host           &amp;lt;SPLUNK_HOST_NAME&amp;gt;
Port           &lt;span class=&#34;m&#34;&gt;8088&lt;/span&gt;
Splunk_Token   98706938-a99d-459f-9255-ca7e192d05a9
TLS            On
TLS.Verify     Off
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Things to note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Name:&lt;/strong&gt; shows output sent to Splunk&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tag:&lt;/strong&gt; Which tag is used to filter logs for Output phase.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Splunk_Token:&lt;/strong&gt; Splunk index specific token for HTTP Event Collector.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-splunk-event-collector.png&#34; alt=&#34;Splunk HTTP Event Collector&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Once a FluentBit DaemonSet is created with the above configuration, the
FluentBit agent starts sending logs to Splunk.&lt;/p&gt;
&lt;h4 id=&#34;log-display&#34;&gt;Log Display&lt;/h4&gt;
&lt;p&gt;In Splunk, one can view the logs by entering the appropriate query. Some
screenshots follow.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-splunk-istiod.png&#34; alt=&#34;splunk: logs for istiod&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-splunk-ingress.png&#34; alt=&#34;splunk: logs for ingress gateway&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-splunk-dataplane-istioproxy.png&#34; alt=&#34;splunk: logs for Istio data plane proxy&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/service-routing/istio-splunk-dataplane-productpage.png&#34; alt=&#34;splunk: logs for Istio data plane app container&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;known-bugs&#34;&gt;Known Bugs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Istio control plane only installs in istio-system namespace
&lt;a href=&#34;https://github.com/istio/istio/issues/24037&#34;&gt;https://github.com/istio/istio/issues/24037&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;
&lt;h3 id=&#34;gateway-definition&#34;&gt;Gateway Definition&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo-gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;productpage.bookinfo.appk8s.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;virtual-service-definition&#34;&gt;Virtual Service Definition&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;VirtualService&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bookinfo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;bookinfo-gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;productpage.bookinfo.appk8s.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;match&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;uri&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;exact&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/productpage&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;uri&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/static&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;uri&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;exact&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/login&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;uri&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;exact&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/logout&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;uri&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/api/v1/products&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;route&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;productpage&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;podsecuritypolicy-definition-for-istio-cni&#34;&gt;PodSecurityPolicy Definition for Istio CNI&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;policy/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;PodSecurityPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-control-plane&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;seccomp.security.alpha.kubernetes.io/allowedProfileNames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker/default,runtime/default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;seccomp.security.alpha.kubernetes.io/defaultProfileName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;runtime/default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;allowPrivilegeEscalation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hostNetwork&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;configMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;emptyDir&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;projected&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;secret&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;downwardAPI&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;persistentVolumeClaim&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;hostPath&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;runAsUser&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rule&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;RunAsAny&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;seLinux&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rule&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;RunAsAny&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;supplementalGroups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ranges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;65535&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rule&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;RunAsAny&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fsGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ranges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;65535&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rule&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;MustRunAs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;allowedHostPaths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;pathPrefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/etc/cni/net.d&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;pathPrefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/opt/cni/bin&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Following Role is required in kube-system namespace&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Role&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-control-plane&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;apiGroups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;extensions&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;podsecuritypolicies&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resourceNames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;istio-control-plane&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;verbs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Following RoleBinding is required in kube-system namespace&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;RoleBinding&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-control-plane&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subjects&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ServiceAccount&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-cni&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;roleRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;rbac.authorization.k8s.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Role&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-control-plane&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;production-grade-istiooperator-v170&#34;&gt;Production-Grade IstioOperator v1.7.0&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;install.istio.io/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IstioOperator&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;installed-state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;addonComponents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istiocoredns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;components&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;base&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cni&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;egressGateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ISTIO_META_ROUTER_MODE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sni-dnat&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Resource&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1024Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;40Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ingressGateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ISTIO_META_ROUTER_MODE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sni-dnat&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Resource&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1024Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;40Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;status-port&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15021&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15021&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;31400&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;31400&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istiodRemote&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;pilot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;PILOT_TRACE_SAMPLING&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;100&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readinessProbe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;httpGet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/ready&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;initialDelaySeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;periodSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;timeoutSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;100Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;policy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;POD_NAMESPACE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;valueFrom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fieldRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fieldPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;metadata.namespace&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Resource&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-policy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;telemetry&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;POD_NAMESPACE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;valueFrom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fieldRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fieldPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;metadata.namespace&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GOMAXPROCS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;6&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Resource&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-telemetry&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicaCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;4800m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;4G&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1G&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meshConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;accessLogFile&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/dev/stdout&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;defaultConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;proxyMetadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enablePrometheusMerge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;outboundTrafficPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;REGISTRY_ONLY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;profile&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;revision&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1-7-0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;base&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableCRDTemplates&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;validationURL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clusterResources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretVolumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/etc/istio/egressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;egressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/etc/istio/egressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;egressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;zvpn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;applicationPorts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;info&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;domain&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meshExpansionPorts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp-istiod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15012&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15012&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp-dns-tls&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;853&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8853&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretVolumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/etc/istio/ingressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/etc/istio/ingressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;LoadBalancer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;zvpn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;global&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;arch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;amd64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ppc64le&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;s390x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configValidation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;controlPlaneSecurityEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;defaultNodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;defaultPodDisruptionBudget&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;defaultResources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableHelmTest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;harbor-k8s.shk8s.de/istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullSecrets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istioNamespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istiod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableAnalysis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;jwtPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;third-party-jwt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logAsJson&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logging&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;level&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default:info&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meshExpansion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;useILB&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meshNetworks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mountMtlsCerts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;multiCluster&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clusterName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;network&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;omitSidecarInjectorConfigMap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;oneNamespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;operatorManageWebhooks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;pilotCertProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istiod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;priorityClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;proxy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoInject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clusterDomain&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cluster.local&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;componentLogLevel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;misc:error&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableCoreDump&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;excludeIPRanges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;excludeInboundPorts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;excludeOutboundPorts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;proxyv2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;includeIPRanges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logLevel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;warning&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;privileged&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readinessFailureThreshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readinessInitialDelaySeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readinessPeriodSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1024Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;40Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;statusPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15020&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tracer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;zipkin&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;proxy_init&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;proxyv2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1024Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;token&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;aud&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ca&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tracer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;datadog&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;$(HOST_IP):8126&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;lightstep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;accessToken&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stackdriver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxNumberOfAnnotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxNumberOfAttributes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxNumberOfMessageEvents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;zipkin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;trustDomain&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cluster.local&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;useMCP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;grafana&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;accessMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ReadWriteMany&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;contextPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/grafana&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dashboardProviders&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dashboardproviders.yaml&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;providers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;disableDeletion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;folder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;options&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/var/lib/grafana/dashboards/istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;orgId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;datasources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;datasources.yaml&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;envSecrets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;repository&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;grafana/grafana&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;7.0.5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;persist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityTermLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;security&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;passphraseKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;passphrase&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;grafana&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usernameKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;externalPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;storageClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istiocoredns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;coreDNSImage&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;coredns/coredns&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;coreDNSPluginImage&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio/coredns-plugin:0.2-istio-1.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;coreDNSTag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.6.2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istiodRemote&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;injectionURL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mixer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;adapters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetesenv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metricsExpiryDuration&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stackdriver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;auth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;appCredentials&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceAccountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tracer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sampleProbability&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stdio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;outputAsJson&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;useAdapterCRDs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;policy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;adapters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetesenv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;useAdapterCRDs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mixer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sessionAffinityEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;telemetry&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;GOMAXPROCS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;6&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mixer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;loadshedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;latencyThreshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;100ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;enforce&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityTermLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicaCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sessionAffinityEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;pilot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;appNamespaces&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleMax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleMin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configMap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configNamespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableProtocolSniffingForInbound&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableProtocolSniffingForOutbound&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pilot&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;keepaliveMaxServerConnectionAge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;30m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityTermLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;policy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicaCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;traceSampling&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;contextPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/prometheus&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/prom&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityTermLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;provisionPrometheusCert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;retention&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;6h&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scrapeInterval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;15s&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;security&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v2.19.2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sidecarInjectorWebhook&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableNamespacesByDefault&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;injectLabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-injection&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;objectSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoInject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rewriteAppHTTPProbe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;telemetry&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;v2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadataExchange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;wasmEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;wasmEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stackdriver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configOverride&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logging&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;monitoring&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;topology&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tracing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;jaeger&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;accessMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ReadWriteMany&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/jaegertracing&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;max_traces&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;50000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;persist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spanStorageType&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;badger&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;storageClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;1.18&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;opencensus&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;exporters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stackdriver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enable_tracing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/omnition&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2Gi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;200m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;400Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.1.9&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityTermLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;provider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;jaeger&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;externalPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9411&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http-query&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;zipkin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/openzipkin&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;javaOptsHeap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;700&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSpans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;500000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpus&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;probeStartupDelay&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;queryPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9411&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2048Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;150m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;900Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2.20.0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;production-grade-istiooperator-v173&#34;&gt;Production-Grade IstioOperator v1.7.3&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;install.istio.io/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IstioOperator&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;installed-state&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;addonComponents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istiocoredns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;components&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;base&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cni&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;egressGateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ISTIO_META_ROUTER_MODE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sni-dnat&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Resource&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1024Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;40Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ingressGateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ISTIO_META_ROUTER_MODE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sni-dnat&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Resource&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1024Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;40Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;status-port&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15021&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15021&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;31400&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;31400&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istiodRemote&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;pilot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;PILOT_TRACE_SAMPLING&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;100&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readinessProbe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;httpGet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/ready&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;initialDelaySeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;periodSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;timeoutSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;100Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;policy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;POD_NAMESPACE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;valueFrom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fieldRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fieldPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;metadata.namespace&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Resource&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-policy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;telemetry&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;POD_NAMESPACE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;valueFrom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fieldRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fieldPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;metadata.namespace&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GOMAXPROCS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;6&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hpaSpec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Resource&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-telemetry&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicaCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;4800m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;4G&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1G&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rollingUpdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSurge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxUnavailable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;25&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meshConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;accessLogFile&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/dev/stdout&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;defaultConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;proxyMetadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enablePrometheusMerge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;outboundTrafficPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;REGISTRY_ONLY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;profile&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;revision&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1-7-3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;base&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableCRDTemplates&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;validationURL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clusterResources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretVolumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/etc/istio/egressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;egressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/etc/istio/egressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;egressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-egressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;zvpn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;applicationPorts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;info&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;domain&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meshExpansionPorts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp-istiod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15012&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15012&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;tcp-dns-tls&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;853&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8853&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretVolumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/etc/istio/ingressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/etc/istio/ingressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingressgateway-ca-certs&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;LoadBalancer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;zvpn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;global&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;arch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;amd64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ppc64le&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;s390x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configValidation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;controlPlaneSecurityEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;defaultNodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;defaultPodDisruptionBudget&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;defaultResources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableHelmTest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;harbor-k8s.shk8s.de/istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullSecrets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istioNamespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istiod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableAnalysis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;jwtPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;third-party-jwt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logAsJson&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logging&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;level&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default:info&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meshExpansion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;useILB&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meshNetworks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mountMtlsCerts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;multiCluster&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clusterName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;network&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;omitSidecarInjectorConfigMap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;oneNamespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;operatorManageWebhooks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;pilotCertProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istiod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;priorityClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;proxy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoInject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;clusterDomain&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cluster.local&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;componentLogLevel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;misc:error&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableCoreDump&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;excludeIPRanges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;excludeInboundPorts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;excludeOutboundPorts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;proxyv2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;includeIPRanges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logLevel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;warning&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;privileged&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readinessFailureThreshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readinessInitialDelaySeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readinessPeriodSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1024Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;40Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;statusPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15020&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tracer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;zipkin&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;proxy_init&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;proxyv2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1024Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;token&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;aud&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ca&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tracer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;datadog&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;$(HOST_IP):8126&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;lightstep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;accessToken&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stackdriver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxNumberOfAnnotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxNumberOfAttributes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxNumberOfMessageEvents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;zipkin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;trustDomain&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cluster.local&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;useMCP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;grafana&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;accessMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ReadWriteMany&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;contextPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/grafana&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dashboardProviders&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dashboardproviders.yaml&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;providers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;disableDeletion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;folder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;options&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/var/lib/grafana/dashboards/istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;orgId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;datasources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;datasources.yaml&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;envSecrets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;repository&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;grafana/grafana&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;7.0.5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;persist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityTermLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;security&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;passphraseKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;passphrase&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;grafana&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usernameKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;externalPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;storageClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istiocoredns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;coreDNSImage&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;coredns/coredns&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;coreDNSPluginImage&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio/coredns-plugin:0.2-istio-1.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;coreDNSTag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.6.2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istiodRemote&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;injectionURL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mixer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;adapters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetesenv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metricsExpiryDuration&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;10m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stackdriver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;auth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;appCredentials&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceAccountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tracer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sampleProbability&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stdio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;outputAsJson&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;useAdapterCRDs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;policy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;adapters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetesenv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;useAdapterCRDs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mixer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sessionAffinityEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;telemetry&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;GOMAXPROCS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;6&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;mixer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;loadshedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;latencyThreshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;100ms&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;enforce&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityTermLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicaCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sessionAffinityEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;pilot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;appNamespaces&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleMax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoscaleMin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configMap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configNamespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetAverageUtilization&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableProtocolSniffingForInbound&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableProtocolSniffingForOutbound&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pilot&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;keepaliveMaxServerConnectionAge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;30m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityTermLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;policy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;replicaCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;traceSampling&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;contextPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/prometheus&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/prom&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityTermLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;provisionPrometheusCert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;retention&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;6h&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scrapeInterval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;15s&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;security&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v2.19.2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;sidecarInjectorWebhook&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableNamespacesByDefault&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;injectLabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-injection&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;objectSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoInject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rewriteAppHTTPProbe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;telemetry&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;v2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadataExchange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;wasmEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prometheus&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;wasmEnabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stackdriver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;configOverride&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;logging&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;monitoring&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;topology&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tracing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;jaeger&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;accessMode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ReadWriteMany&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/jaegertracing&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;max_traces&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;50000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;persist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spanStorageType&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;badger&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;storageClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;1.18&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;opencensus&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;exporters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stackdriver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enable_tracing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/omnition&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2Gi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;200m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;400Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.1.9&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;podAntiAffinityTermLabelSelector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;provider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;jaeger&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;externalPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9411&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http-query&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterIP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;zipkin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;docker.io/openzipkin&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;javaOptsHeap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;700&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxSpans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;500000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpus&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;probeStartupDelay&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;queryPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9411&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;limits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;1000m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;2048Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;150m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;900Mi&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2.20.0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      
      <title>Guides: Kubernetes Monitoring Checklist</title>
      
      <link>/guides/kubernetes/observability-k8s-monitoring-checklist/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/observability-k8s-monitoring-checklist/</guid>
      <description>

        
        &lt;p&gt;To run a Kubernetes platform effectively, cluster administrators need visibility
into the behavior of the system. Furthermore, platform administrator need to be
alerted when any of the critical platform components are unavailable or behaving
erratically.&lt;/p&gt;
&lt;p&gt;This guide provides a list of components that platform operators should monitor.
More importantly, it lists important conditions that operators should use to
generate alerts. The guide does not prescribe a specific monitoring or alerting
tool. Instead, it focuses on &lt;em&gt;what&lt;/em&gt; to monitor.&lt;/p&gt;
&lt;h2 id=&#34;how-to-use-this-guide&#34;&gt;How to Use This Guide&lt;/h2&gt;
&lt;p&gt;The sections below outline &lt;em&gt;conditions&lt;/em&gt; that platform operators must monitor when
operating Kubernetes. For each condition, the guide provides the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; The magnitude that must be exceeded to generate an alert.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; The severity of the condition, given the threshold is met.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; The available metrics to monitor.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; Additional information applicable to the condition.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the condition is true and above the given threshold, the monitoring system
should generate an alert with the given severity. To keep things simple, we use
two severities in this guide: &lt;em&gt;Warning&lt;/em&gt; and &lt;em&gt;Critical&lt;/em&gt;. We advise treating
critical alerts as urgent, and alerting via a pager or equivalent. Warnings are
less severe and can typically be tied to an asynchronous notification such as
email, Slack, or a ticketing system.&lt;/p&gt;
&lt;p&gt;It is important to keep in mind that thresholds and the severity of alerts will
vary for each environment. Platform operators can use this guide as a starting
point for their monitoring implementation.&lt;/p&gt;
&lt;h2 id=&#34;etcd&#34;&gt;etcd&lt;/h2&gt;
&lt;h3 id=&#34;member-down&#34;&gt;Member Down&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 3 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Warning&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;up&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; A single member failure does not have a direct impact on the
Kubernetes cluster. However, it increases the risk of experiencing etcd quorum
loss if additional members fail.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;majority-of-members-down&#34;&gt;Majority of Members Down&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 3 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;up&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; When the majority of members are down, the cluster loses quorum and
cannot accept writes. Existing workloads on the Kubernetes cluster continue to
function, but any operations that require writing to etcd are not possible.
These operations include deploying new applications, scaling existing
workloads, adding new nodes, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;no-leader&#34;&gt;No Leader&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 1 minute&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;etcd_server_has_leader&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; The cluster cannot accept writes without a leader. Existing workloads
on the Kubernetes cluster continue to function, but any operations that
require writing to etcd are not possible. These operations include deploying
new applications, scaling existing workloads, adding new nodes, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;increased-grpc-request-failures&#34;&gt;Increased gRPC Request Failures&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; &amp;gt;5% failure rate for 5 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;grpc_server_handled_total&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; An increase in the number of gRPC request failures can impact the
operation of the Kubernetes cluster. The &lt;code&gt;--metrics&lt;/code&gt; etcd command line flag
must be set to &lt;code&gt;extensive&lt;/code&gt; for etcd to generate request-related metrics.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;slow-grpc-requests&#34;&gt;Slow gRPC Requests&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 99th percentile response time &amp;gt;150 milliseconds for 10 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;grpc_server_handling_seconds_bucket&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; An increase in latency of gRPC requests can impact the operation of
the Kubernetes cluster. The &lt;code&gt;--metrics&lt;/code&gt; etcd command line flag must be set to
&lt;code&gt;extensive&lt;/code&gt; for etcd to generate latency-related metrics.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-api-server&#34;&gt;Kubernetes API Server&lt;/h2&gt;
&lt;h3 id=&#34;api-server-down&#34;&gt;API Server Down&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Warning&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_pod_status_phase&lt;/code&gt; (via
&lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;) (when the API server is running as
a pod)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; The loss of a single API server does not have an immediate impact on
the cluster’s operations. However, it increases the risk of a control plane
outage if additional API servers fail.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;high-request-latency&#34;&gt;High Request Latency&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 99th percentile response time &amp;gt;4 seconds for 10 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;apiserver_request_duration_seconds_sum&lt;/code&gt;,
&lt;code&gt;apiserver_request_duration_seconds_count&lt;/code&gt;,
&lt;code&gt;apiserver_request_duration_seconds_bucket&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; An increase in the request latency can impact the operation of the
Kubernetes cluster. This abnormal increase should be investigated and
remediated.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;high-error-rate&#34;&gt;High Error Rate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; &amp;gt;3% failure rate for 10 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;apiserver_request_total&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; An increase in the request error rate can impact the operation of the
Kubernetes cluster. This abnormal increase should be investigated and
remediated.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;client-certificate-expiring&#34;&gt;Client Certificate Expiring&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; Expiration within 24 hours&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;apiserver_client_certificate_expiration_seconds_count&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; A client certificate expiration will prevent cluster components from
authenticating with each other, rendering them unable to carry out their
function.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-controller-manager&#34;&gt;Kubernetes Controller Manager&lt;/h2&gt;
&lt;p&gt;Monitoring the Controller Manager is critical to ensure the cluster can
reconcile the current state of the cluster with the users&#39; desired state.&lt;/p&gt;
&lt;h3 id=&#34;controller-manager-down&#34;&gt;Controller Manager Down&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Warning&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_pod_container_status_restarts_total&lt;/code&gt; and
&lt;code&gt;kube_pod_status_phase&lt;/code&gt; (via &lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;) (when
the Controller Manager is running as a pod)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; If the cluster has multiple control plane nodes, the loss of a single
controller manager does not have an immediate impact on the cluster&amp;rsquo;s
operations. However, it increases the risk of losing reconciliation loops if
additional controller managers fail.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-scheduler&#34;&gt;Kubernetes Scheduler&lt;/h2&gt;
&lt;p&gt;Monitoring the scheduler is critical to ensure the cluster can place new
workloads and move existing workloads to other nodes.&lt;/p&gt;
&lt;h3 id=&#34;scheduler-down&#34;&gt;Scheduler Down&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Warning&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_pod_container_status_restarts_total&lt;/code&gt; and
&lt;code&gt;kube_pod_status_phase&lt;/code&gt; (via &lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;) (when
the scheduler is running as a pod)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; If the cluster has multiple control plane nodes, the loss of a single
scheduler does not have an immediate impact on cluster&amp;rsquo;s operations. However,
it increases the risk of losing scheduling functionality if additional
schedulers fail.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;node&#34;&gt;Node&lt;/h2&gt;
&lt;h3 id=&#34;kubelet-down&#34;&gt;Kubelet Down&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;up&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; If the kubelet is down, it is deemed not ready. Nodes that are not
ready cannot accept pods. The platform evicts Pods running on a not-ready Node
if the Node remains in that condition for longer than the pod eviction
timeout.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;node-not-ready&#34;&gt;Node Not Ready&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Warning&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_node_status_condition&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; Nodes that are not ready cannot accept pods. The platform evicts Pods
running on a not-ready Node if the Node remains in that condition for longer
than the pod eviction timeout.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;node-unreachable&#34;&gt;Node Unreachable&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Warning&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_node_spec_taint&lt;/code&gt; (via &lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; Nodes that are unreachable cannot accept pods. The platform evicts
Pods running on an unreachable Node if the Node remains in that condition for
longer than the pod eviction timeout.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;too-many-pods&#34;&gt;Too Many Pods&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 95% pod count capacity&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Warning&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kubelet_running_pod_count&lt;/code&gt;, &lt;code&gt;kube_node_status_capacity_pods&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;file-system-utilization&#34;&gt;File System Utilization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;node_filesystem_avail_bytes&lt;/code&gt; and &lt;code&gt;node_filesystem_size_bytes&lt;/code&gt; (via
&lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;) kube-state-metrics),
&lt;code&gt;node_filesystem_files_free&lt;/code&gt; (via &lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;persistent-volume-usage&#34;&gt;Persistent Volume Usage&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; &amp;lt;3% available&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kubelet_volume_stats_available_bytes&lt;/code&gt;, &lt;code&gt;kubelet_volume_stats_capacity_bytes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;clock-skew-detected&#34;&gt;Clock Skew Detected&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; Clock Skew &amp;gt;50 milliseconds&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;node_timex_offset_seconds&lt;/code&gt; (via &lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; Kubernetes does not tolerate clock skew between nodes in the cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kube-proxy&#34;&gt;kube-proxy&lt;/h2&gt;
&lt;p&gt;Monitoring kube-proxy is critical to ensure workloads can access Pods and
Services running on other nodes.&lt;/p&gt;
&lt;h3 id=&#34;kube-proxy-down&#34;&gt;kube-proxy Down&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_pod_container_status_restarts_total&lt;/code&gt; and
&lt;code&gt;kube_pod_status_phase&lt;/code&gt; (via &lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;) (when
kube-proxy is running as a pod)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; When kube-proxy is unavailable, Services are not reflected on a
node&amp;rsquo;s IPtables or IPVS configuration. Thus, applications running on the
affected node cannot communicate with other pods using Service IPs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kube-state-metrics&#34;&gt;kube-state-metrics&lt;/h2&gt;
&lt;p&gt;kube-state-metrics exposes metrics about the state of the objects within a
Kubernetes cluster. The metrics cover, but are not limited to, Deployments,
ReplicaSets, Pods and Nodes.&lt;/p&gt;
&lt;p&gt;kube-state-metrics is not built into Kubernetes. It is an extra component that
platform operators must deploy onto the cluster. For more information, see the
kube-state-metrics &lt;a href=&#34;https://github.com/kubernetes/kube-state-metrics&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;GitHub
repository&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;pod-crash-looping&#34;&gt;Pod Crash Looping&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_pod_container_status_restarts_total&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; Pods stuck in a crash-loop for extended periods of time indicate an
issue with the application.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pod-not-ready&#34;&gt;Pod Not Ready&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_pod_status_phase&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; Pods stuck in the not-ready condition for extended periods of time
indicate an issue with the application.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deployment-rollout-stuck&#34;&gt;Deployment Rollout Stuck&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_deployment_spec_replicas&lt;/code&gt;,
&lt;code&gt;kube_deployment_status_replicas_available&lt;/code&gt; (via &lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; The number of ready pods of a given Deployment does not match the
number of desired replicas.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;daemonset-rollout-stuck&#34;&gt;DaemonSet Rollout Stuck&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_daemonset_status_number_ready&lt;/code&gt;,
&lt;code&gt;kube_daemonset_status_desired_number_scheduled&lt;/code&gt; (via &lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; The number of ready pods of a given DaemonSet does not match the
number of nodes in the cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;statefulset-rollout-stuck&#34;&gt;StatefulSet Rollout Stuck&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_statefulset_status_replicas_ready&lt;/code&gt;,
&lt;code&gt;kube_statefulset_status_replicas&lt;/code&gt; (via &lt;a href=&#34;#kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; The number of ready pods of a given StatefulSet does not match the
number of desired replicas.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;elevated-list-errors&#34;&gt;Elevated List Errors&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; &amp;gt;10% error rate for 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_state_metrics_list_total&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; If kube-state-metrics is experiencing an elevated error rate in list
operations, it will not be able to expose metrics about Kubernetes objects
correctly.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;elevated-watch-errors&#34;&gt;Elevated Watch Errors&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; &amp;gt;10% error rate for 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_state_metrics_watch_total&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; If kube-state-metrics is experiencing an elevated error rate in watch
operations, it will not be able to expose metrics about Kubernetes objects
correctly.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;coredns&#34;&gt;CoreDNS&lt;/h2&gt;
&lt;p&gt;Monitoring CoreDNS is important to ensure that applications running in the
cluster can perform service discovery using DNS. CoreDNS is essential for the
proper functioning of the Service resource in Kubernetes.&lt;/p&gt;
&lt;h3 id=&#34;coredns-is-down&#34;&gt;CoreDNS is Down&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;up&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; When CoreDNS is down, applications are unable to use DNS for service
discovery.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;high-response-latency&#34;&gt;High Response Latency&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; &amp;gt;20ms latency&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;coredns_dns_request_duration_seconds&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; An increase in the response latency of DNS queries can impact
application performance. The increase in latency might indicate the need to
scale out the CoreDNS deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cni-plugin&#34;&gt;CNI Plugin&lt;/h2&gt;
&lt;h3 id=&#34;pod-not-ready-1&#34;&gt;Pod Not Ready&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_pod_status_phase&lt;/code&gt; and
&lt;code&gt;kube_pod_container_status_restarts_total&lt;/code&gt; (via kube-state-metrics)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; Nodes with a not-ready or crashing CNI plugin are unable to start new
pods. Network connectivity of existing pods might also be impacted.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ingress-controller&#34;&gt;Ingress Controller&lt;/h2&gt;
&lt;h3 id=&#34;pod-down&#34;&gt;Pod Down&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_pod_status_phase&lt;/code&gt; and
&lt;code&gt;kube_pod_container_status_restarts_total&lt;/code&gt; (via kube-state-metrics)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; Applications exposed via the Ingress API are not accessible if
Ingress controller pods are unavailable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;count-of-healthy-pods-not-equal-to-number-of-ingress-nodes&#34;&gt;Count of Healthy Pods not equal to number of ingress nodes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; Only applicable if deploying Ingress Controller as a DaemonSet that
selects specific nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;log-forwarder&#34;&gt;Log Forwarder&lt;/h2&gt;
&lt;h3 id=&#34;pod-down-1&#34;&gt;Pod Down&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Threshold:&lt;/em&gt; 15 minutes&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Severity:&lt;/em&gt; Critical&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Metrics:&lt;/em&gt; &lt;code&gt;kube_pod_status_phase&lt;/code&gt; and
&lt;code&gt;kube_pod_container_status_restarts_total&lt;/code&gt; (via kube-state-metrics)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Notes:&lt;/em&gt; Application and platform logs are not forwarded to the centralized
logging system if the log forwarding pods are unavailable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;monitoring-system&#34;&gt;Monitoring System&lt;/h2&gt;
&lt;p&gt;In addition to monitoring the platform components mentioned above, it is of
critical importance that platform operators monitor their monitoring system. To
achieve this, operators typically implement a &lt;a href=&#34;https://en.wikipedia.org/wiki/Dead_man%27s_switch&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&amp;ldquo;Dead man&amp;rsquo;s
switch&amp;rdquo;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Implementations can vary across monitoring systems. But typically, the Dead
man&amp;rsquo;s switch is implemented as an alert that is always triggering. The alert is
delivered to an external system that expects the alert to be triggering
constantly. In the case that the alert stops, the external system alerts the
platform operator to let them know the monitoring system is down.&lt;/p&gt;
&lt;p&gt;Another approach is to implement a watchdog pattern, where a test alert is
generated every N seconds and sent to an external system. If the alert does not
flow through the system, then platform operators know there is an issue.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Kubernetes Platform Monitoring</title>
      
      <link>/guides/kubernetes/observability-k8s-platform-monitoring/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/observability-k8s-platform-monitoring/</guid>
      <description>

        
        &lt;p&gt;This document details platform monitoring and alerting for Kubernetes clusters,
such as those provided by Tanzu Kubernetes Grid (TKG). It covers architectural
considerations, best practices, and will provide guidance for offering alerting
and monitoring to resident applications . This document represents how the
VMware field team approaches monitoring in large enterprise Kubernetes
environments.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/observability/diagrams/platform-monitoring.svg&#34; alt=&#34;Platform Monitoring Diagram&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;tooling&#34;&gt;Tooling&lt;/h2&gt;
&lt;p&gt;For new implementations of monitoring, it is suggested to run Prometheus inside
of Kubernetes. The recommended approach is to utilize the existing
&lt;a href=&#34;https://github.com/coreos/kube-prometheus&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kube-prometheus&lt;/a&gt; repository provided
by CoreOS (Red Hat). This project allows an administrator to deploy and tune an
end-to-end Prometheus solution within a Kubernetes cluster. It contains the
following components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prometheus operator&lt;/li&gt;
&lt;li&gt;Highly available &lt;code&gt;alert-manager&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Prometheus node-exporter&lt;/li&gt;
&lt;li&gt;Prometheus Adapter for Kubernetes Metrics APIs&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kube-state-metrics&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Grafana&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kube-state-metrics&#34;&gt;&lt;code&gt;kube-state-metrics&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/kube-state-metrics&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kube-state-metrics&lt;/a&gt; is a
first-party project of Kubernetes. Running as a DaemonSet on the Kubernetes
cluster, this component generates metrics from API events that occur within
Kubernetes. Its focus is on exposing events related to Kubernetes objects within
the cluster in a raw and unmodified format.&lt;/p&gt;
&lt;h3 id=&#34;prometheus&#34;&gt;Prometheus&lt;/h3&gt;
&lt;p&gt;Prometheus is a CNCF project widely used for Kubernetes platform monitoring as
well as metrics collection and aggregation. Prometheus works by scraping data
from configured endpoints, parsing it and storing it in its internal time-series
database. This data can then be easily queried directly with
&lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/basics&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;PromQL&lt;/a&gt;, or
displayed using a visualization tool such as Grafana.&lt;/p&gt;
&lt;p&gt;Prometheus has &lt;a href=&#34;https://prometheus.io/docs/practices/pushing/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;push-gateway&lt;/a&gt;
facility as well, for instrumenting applications with the available client
libraries to push metrics when exposing an endpoint to scrape is not suitable.
Ephemeral jobs such as pipelines are a good example of tasks in which pushing
data to the metrics server make sense.&lt;/p&gt;
&lt;h3 id=&#34;prometheus-node-exporter&#34;&gt;Prometheus node-exporter&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/prometheus/node_exporter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;node-exporter&lt;/a&gt; is a separate
binary in the Prometheus project. It exposes metrics for underlying container
platform, os, and hardware of each Kubernetes node to be consumed by Prometheus.
It can be configured with various collectors to determine what kind of system
data to be provided. The &lt;code&gt;node-exporter&lt;/code&gt; is implemented as a DaemonSet running
as a service on each node in the Kubernetes cluster.&lt;/p&gt;
&lt;h3 id=&#34;prometheus-adapter-for-kubernetes-metrics-apis&#34;&gt;Prometheus Adapter for Kubernetes Metrics APIs&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/DirectXMan12/k8s-prometheus-adapter&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;k8s-prometheus-adapter&lt;/a&gt;
is an agent that runs as an application Deployment in your cluster. It is an
implementation of the Kubernetes resource metrics API and custom metrics API
that acts downstream of Prometheus to provide feedback on applications using
metrics data. It implements &lt;code&gt;HorizontalPodAutoscaler&lt;/code&gt; functionality that can
react and scale applications based on real-time metrics data.&lt;/p&gt;
&lt;h3 id=&#34;prometheus-alertmanager&#34;&gt;Prometheus Alertmanager&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/prometheus/alertmanager&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;alert-manager&lt;/a&gt; is the handler for
alerts sent by the Prometheus server. Alertmanager handles integrating with
external services by responding to metric-related events such as notifying
email, PagerDuty, or OpsGenie. Alertmanager provides a CRD that can be tuned via
replica-count and other parameters.&lt;/p&gt;
&lt;h3 id=&#34;grafana&#34;&gt;Grafana&lt;/h3&gt;
&lt;p&gt;Grafana is a second UI layer that is optional, however provides much more
flexibility in visualizing metrics data through the creation of custom
dashboards. Grafana is suggested for operational environments because of its
rich set of RBAC, authentication, and customizable dashboards.&lt;/p&gt;
&lt;h2 id=&#34;installation--configuration&#34;&gt;Installation &amp;amp; Configuration&lt;/h2&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Customizing kube-prometheus&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    
The installation in this guide follows the kube-prometheus &lt;a
href=&#34;https://github.com/coreos/kube-prometheus#quickstart&#34;&gt; Quick-start
Guide&lt;/a&gt;. As an alternate to the quick-start, it is recommended to customize
the kube-prometheus library via compiling the kube-prometheus manifests
yourself. In order to address long-term maintenance, it is difficult to manage
YAML customizations made in the quick-start method. Please refer to &lt;a
href=&#34;https://github.com/coreos/kube-prometheus#customizing-kube-prometheus&#34;&gt;Customizing
kube-prometheus&lt;/a&gt; for the advanced compilation method via &lt;a
href=&#34;http://jsonnet.org/&#34;&gt;Jsonnet&lt;/a&gt;.

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;In order to install platform monitoring, clone the
&lt;a href=&#34;https://github.com/coreos/kube-prometheus&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kube-prometheus&lt;/a&gt; git repository and
apply the manifests specified in the install guide:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Create the namespace and CRDs, and then wait for them to be availble before creating the remaining resources&lt;/span&gt;
kubectl create -f manifests/setup
&lt;span class=&#34;k&#34;&gt;until&lt;/span&gt; kubectl get servicemonitors --all-namespaces &lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; date&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; sleep 1&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
kubectl create -f manifests/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;expose-route&#34;&gt;Expose Route&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/coreos/kube-prometheus&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kube-prometheus&lt;/a&gt; is installed by
simply applying the manifest to the existing Kubernetes cluster. In order to
access the Prometheus, Alert-manager, and Grafana UIs, their Service will need
to be exposed. Depending on the security-model and end-users, they can be
exposed publicly via DNS, or temporarily using &lt;code&gt;kubectl port-forward&lt;/code&gt; . This
example uses &lt;a href=&#34;https://github.com/projectcontour/contour&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Contour&lt;/a&gt; ingress, and
therefore the following objects can be created:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ui&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;monitoring&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableWebsockets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;loadBalancerPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Cookie&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;prometheus-k8s&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9090&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;virtualhost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fqdn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ui-monitoring.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;grafana&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;monitoring&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableWebsockets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;loadBalancerPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Cookie&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;grafana&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;virtualhost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fqdn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;grafana-monitoring.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;projectcontour.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPProxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;alertmanager&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;monitoring&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;conditions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableWebsockets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;loadBalancerPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Cookie&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;alertmanager-main&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9093&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;virtualhost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;fqdn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;alertmanager-monitoring.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/observability/prometheus.png&#34; alt=&#34;Prometheus&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;prometheus-scrape-configs&#34;&gt;Prometheus Scrape Configs&lt;/h3&gt;
&lt;p&gt;Out of the box, &lt;code&gt;kube-prometheus&lt;/code&gt; ships with a set of default &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus
rules&lt;/a&gt;
configured to scrape &lt;code&gt;kube-state-metrics&lt;/code&gt;. The Prometheus operator does this by
generating a ConfigMap containing the Prometheus configuration. In order to add
additional scrape configuration, you can create an additional ConfigMap and
specify it in the Prometheus CRD. Please see &lt;a href=&#34;https://github.com/coreos/prometheus-operator/blob/master/Documentation/additional-scrape-config.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Additional Scrape
Configuration&lt;/a&gt;
for the specific steps.&lt;/p&gt;
&lt;h3 id=&#34;grafana-data-sources--dashboards&#34;&gt;Grafana Data Sources &amp;amp; Dashboards&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;kube-prometheus&lt;/code&gt; also ships with a default datastore for Prometheus already set
up with the parameters needed to ingest time-series data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/observability/grafana-ds.png&#34; alt=&#34;Grafana Data Source&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kube-prometheus&lt;/code&gt; also provides a set of default &lt;a href=&#34;http://grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Grafana
Dashboards&lt;/a&gt; that provide a number of windows into viewing
this data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/observability/grafana-dashboards.png&#34; alt=&#34;Grafana Dashboards&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;It is possible that a custom dashboard is required, for example, visualizing
metrics from a custom application. This can manually be added in via the Grafana
UI, or through additional configuration specified in ConfigMap resources
attached to the Grafana Deployment object.&lt;/p&gt;
&lt;h3 id=&#34;alert-manager&#34;&gt;Alert Manager&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/observability/alertmanager.png&#34; alt=&#34;Alert Manager&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Alert Manager is provided with a default set of rules and a watchdog input. A
&amp;ldquo;watchdog&amp;rdquo; refers to a Dead Man&amp;rsquo;s switch. The alert is always firing from
Prometheus, and therefore should fire in Alert Manager. If it ever ceases to
fire, then it is possible to detect failure in the alerting system.&lt;/p&gt;
&lt;p&gt;This configuration is defined in a Secret from the file
&lt;code&gt;alertmanager-secret.yaml&lt;/code&gt; and may be modified after deploying &lt;code&gt;kube-prometheus&lt;/code&gt;
by modifying the secret and redeploying the Alert Manager StatefulSet.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get secret alertmanager-main -n monitoring --template &lt;span class=&#34;s1&#34;&gt;&amp;#39;{{ index .data &amp;#34;alertmanager.yaml&amp;#34; }}&amp;#39;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; base64 -d
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;global&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;resolve_timeout&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;5m&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;inhibit_rules&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;equal&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;namespace&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;alertname&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;source_match&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;severity&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;critical&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;target_match_re&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;severity&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;warning|info&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;equal&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;namespace&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;alertname&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;source_match&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;severity&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;warning&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;target_match_re&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;severity&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;info&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;receivers&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Default&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Watchdog&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Critical&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;route&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;group_by&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;namespace&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;group_interval&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;5m&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;group_wait&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;30s&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;receiver&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Default&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;repeat_interval&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;12h&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;routes&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;match&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;alertname&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Watchdog&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;receiver&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Watchdog&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;match&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;severity&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;critical&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;receiver&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Critical&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Downstream services that receive alerts will need to be specified in the
&lt;strong&gt;receivers&lt;/strong&gt; section. Alert Manager provides many capabilities to alert with
external systems like email, Slack, Wechat, etc. For example, in order to add
WeChat functionality to the &lt;code&gt;Critical&lt;/code&gt; receiver, you would add a &lt;code&gt;wechat_config&lt;/code&gt;
field to your receiver titled &lt;strong&gt;Critical&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;It is important to lock down Alertmanager from unauthorized access. This can be
done by removing the Ingress or securing the route using TLS certificates. As
stated in the documentation: &amp;ldquo;Any user with access to the Alertmanager HTTP
endpoint has access to its data. They can create and resolve alerts. They can
create, modify and delete silences.&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;monitoring-cluster&#34;&gt;Monitoring Cluster&lt;/h2&gt;
&lt;p&gt;Grafana provides the cluster administrator with a single pane of glass view into
the Kubernetes cluster operations. Using dashboards, Grafana can present the
monitoring data with respect to time in a way that is meaningful for measuring
the health of infrastructure, workloads, and network related data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/observability/grafana-compute.png&#34; alt=&#34;Grafana Compute&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;ingesting-custom-application-metrics&#34;&gt;Ingesting Custom Application Metrics&lt;/h2&gt;
&lt;p&gt;When developing an application, Prometheus will by default expect metrics to be
accessible via &lt;code&gt;/metrics&lt;/code&gt;. This can also be configured. This is specified
through the ServiceMonitor resource, which monitors Service resources for your
particular application and updates Prometheus with the necessary corresponding
scrape configuration. This allows Prometheus to ingest these metrics like it
would normally expect from a Prometheus config file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ServiceMonitor&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;monitoring.coreos.com/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;endpoints&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;interval&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;5s&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above resource will monitor a Service &lt;code&gt;sample-app&lt;/code&gt; and the Prometheus
operator will add the necessary scrape configuration. This will allow the
metrics to be recorded by Prometheus.&lt;/p&gt;
&lt;h2 id=&#34;scaling-applications-in-response-to-monitoring&#34;&gt;Scaling Applications in Response to Monitoring&lt;/h2&gt;
&lt;p&gt;Now that this custom application is recording metrics in Prometheus, what if you
wanted Kubernetes to respond to changes in a specific metric and scale the
application? Kubernetes provides a &lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/custom-metrics-api.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Custom Metrics
API&lt;/a&gt;
which can be leveraged to automatically scale application deployments in
real-time. This is highly flexible and also evolving.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/observability/diagrams/platform-monitoring-app.svg&#34; alt=&#34;App Platform Monitoring Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The Custom Metrics API is a framework for exposing arbitrary metrics as
Kubernetes API metrics. It allows them to appear via
&lt;code&gt;/apis/custom.metrics.k8s.io/&lt;/code&gt; and be fetched internally by
&lt;a href=&#34;https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;HorizontalPodAutoscalers&lt;/a&gt;.
While Horizontal Pod Autoscalers ship with built-in CPU and memory
resource-based scaling, it is sometimes necessary to utilize custom
application-supplied metrics to scale the application. This is necessary for
scaling beyond the built-in CPU and memory metrics. The example below is based
on the in-depth
&lt;a href=&#34;https://github.com/DirectXMan12/k8s-prometheus-adapter/blob/master/docs/walkthrough.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;guide&lt;/a&gt;
provided with &lt;code&gt;k8s-prometheus-adapter&lt;/code&gt;.&lt;/p&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Note&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Currently scaling on memory and custom metrics are
only supported by &lt;code&gt;HorizontalPodAutoscaler&lt;/code&gt; &lt;code&gt;autoscaling/v2beta2&lt;/code&gt; API version.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The following is an example &lt;code&gt;HorizontalPodAutoScaler&lt;/code&gt; that watches the
&lt;code&gt;http_requests&lt;/code&gt; metric of the &lt;strong&gt;sample-app&lt;/strong&gt; Deployment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HorizontalPodAutoscaler&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;autoscaling/v2beta2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;scaleTargetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apps/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Deployment&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sample-app&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxReplicas&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metrics&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pods&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;pods&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metric&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http_requests&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;AverageValue&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;averageValue&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;500m&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Behind the scenes, the HPA controller detects the presence of this object, and
determines the custom metrics required.&lt;/p&gt;
&lt;p&gt;The metrics endpoint is specified by an &lt;code&gt;APIService&lt;/code&gt; resource:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;apiregistration.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;APIService&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1beta1.custom.metrics.k8s.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;prometheus-adapter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;monitoring&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;custom.metrics.k8s.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;insecureSkipTLSVerify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;groupPriorityMinimum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;versionPriority&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above resource is what ties the custom API endpoint to the Kubernetes
Prometheus Adapter. The adapter runs as a sort-of translation layer between
Kubernetes API requests, and the Prometheus server.&lt;/p&gt;
&lt;p&gt;Therefore, if an application &lt;code&gt;sample-app&lt;/code&gt; is deployed and configured with a HPA
resource, this application can be scaled horizontally as &lt;code&gt;http_requests&lt;/code&gt;
increases.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl describe hpa.v2beta2.autoscaling sample-app
Name:                       sample-app
Namespace:                  default
Labels:                     &amp;lt;none&amp;gt;
Annotations:                &amp;lt;none&amp;gt;
CreationTimestamp:          Fri, &lt;span class=&#34;m&#34;&gt;17&lt;/span&gt; Apr &lt;span class=&#34;m&#34;&gt;2020&lt;/span&gt; 13:30:15 -0500
Reference:                  Deployment/sample-app
Metrics:                    &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt; current / target &lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;http_requests&amp;#34;&lt;/span&gt; on pods:  386m / 500m
Min replicas:               &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
Max replicas:               &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;
Deployment pods:            &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt; current / &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt; desired
Conditions:
  Type            Status  Reason              Message
  ----            ------  ------              -------
  AbleToScale     True    ReadyForNewScale    recommended size matches current size
  ScalingActive   True    ValidMetricFound    the HPA was able to successfully calculate a replica count from pods metric http_requests
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;Every 2.0s: kubectl get pods                archlinux: Fri Apr &lt;span class=&#34;m&#34;&gt;17&lt;/span&gt; 15:18:43 &lt;span class=&#34;m&#34;&gt;2020&lt;/span&gt;

NAME                          READY   STATUS    RESTARTS   AGE
sample-app-579bc6774c-cdpd2   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          103m
sample-app-579bc6774c-dv865   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          103m
sample-app-579bc6774c-lbm5k   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          21h
sample-app-579bc6774c-zp482   1/1     Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          103m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      
      <title>Guides: Cluster Tuning Guide</title>
      
      <link>/guides/kubernetes/workload-tenancy-cluster-tuning/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/workload-tenancy-cluster-tuning/</guid>
      <description>

        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This document aims to provide a sensible workflow for understanding and tuning
available parameters in Kubernetes. This guide is for application owners and
cluster managers. It is intended to help illustrate and inform configuration
decisions. Whereas the Kubernetes documentation provides in-depth information on
individual parameters, this guide highlights the relationships between them and
implications of each one on the rest of the cluster. By the end of this
document, you will have a clearer understanding of how your responsibilities
impact the stability, utilization, and performance of your overall Kubernetes
environment.&lt;/p&gt;
&lt;p&gt;The content of this guide was presented at the 2019 KubeCon in San Diego. This
presentation may be viewed &lt;a href=&#34;https://youtu.be/uodXrKk7I-o&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;motivations&#34;&gt;Motivations&lt;/h3&gt;
&lt;p&gt;IT organizations deploy applications to cloud environments, public or private,
with one primary goal: keep applications online to maximize the value add for
their business and keep costs to a minimum. More specifically, they want to
optimize stability and utilization of their environment while meeting the
availability and performance requirements of their applications. Kubernetes
enables them to achieve these goals by providing a framework to run distributed
systems
&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/#why-you-need-kubernetes-and-what-can-it-do&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;resiliently&lt;/a&gt;.
Kubernetes offers various features and options to help mitigate disruption to
application workloads. Application owners and cluster managers are encouraged to
work together to mitigate the risks posed by these disruptions to maximize the
value of Kubernetes for their organizations.&lt;/p&gt;
&lt;h4 id=&#34;involuntary-disruptions&#34;&gt;Involuntary Disruptions&lt;/h4&gt;
&lt;p&gt;Disruptions are classified into two
&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/disruptions/#voluntary-and-involuntary-disruptions&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;categories&lt;/a&gt;:
involuntary and voluntary. &lt;em&gt;Involuntary&lt;/em&gt; &lt;em&gt;disruptions&lt;/em&gt; are any case of an
unavoidable hardware or software failure. Examples of this include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;physical hardware failure&lt;/li&gt;
&lt;li&gt;cloud provider or hypervisor failure&lt;/li&gt;
&lt;li&gt;kernel panic&lt;/li&gt;
&lt;li&gt;network partition&lt;/li&gt;
&lt;li&gt;pod eviction caused by resource contention&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Among these examples, pod eviction is the only one unique to Kubernetes, and it
is discussed in-depth throughout this guide. The other types of involuntary
disruptions are common across all cloud environments, whether a container
orchestrator such as Kubernetes is used or not.&lt;/p&gt;
&lt;h4 id=&#34;voluntary-disruptions&#34;&gt;Voluntary Disruptions&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Voluntary disruptions&lt;/em&gt; are those caused by an application owner or cluster
manager. Unlike involuntary disruptions, voluntary disruptions are actions
performed to Kubernetes. Examples of disruptions caused by an application owner
include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;deleting the controller responsible for managing a pod&lt;/li&gt;
&lt;li&gt;updating a deployment’s pod template&lt;/li&gt;
&lt;li&gt;directly deleting a pod&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples of disruptions caused by a cluster manager include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;draining a node for a repair or upgrade&lt;/li&gt;
&lt;li&gt;scaling the cluster up or down (can also be caused by an
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#cluster-autoscaling&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;autoscaler&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;removal of a pod to permit another one to schedule on a node&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A cluster manager, application owner, automation, or an underlying hosting
provider can all cause the above listed voluntary disruptions. Fortunately,
Kubernetes provides several constructs to application owners and cluster
managers to mitigate the risks presented by each of these disruptions.&lt;/p&gt;
&lt;h3 id=&#34;topics&#34;&gt;Topics&lt;/h3&gt;
&lt;p&gt;It is helpful to categorize tunable parameters by the persona that may be
responsible for them: application owner or cluster manager. For each parameter,
you will learn the risks posed by the default Kubernetes configuration, the
benefit of tuning this parameter, and the implications of your tuning decisions
on the rest of your cluster.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Managed by application owners:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/disruptions/#how-to-perform-disruptive-actions-on-your-cluster&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Disruption-Tolerant Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Limits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Requests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/disruptions/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Pod Disruption Budgets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Affinity &amp;amp; Anti-Affinity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Pod Priority &amp;amp; Preemption&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Managed by cluster operators:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/config/containers/live-restore/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Live Restore&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.openshift.com/container-platform/4.1/nodes/nodes/nodes-nodes-managing-max-pods.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;PodsPerCore&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/policy/limit-range/#enabling-limit-range&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;LimitRanges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/policy/resource-quotas/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Resource Quotas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#soft-eviction-thresholds&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Soft Eviction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#hard-eviction-thresholds&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Hard Eviction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#kube-reserved&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kube Reserved&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;System Reserved&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#eviction-monitoring-interval&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Housekeeping Interval&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For both audiences, topics are listed top-to-bottom by their relative
impact-to-risk. The top-most items will have the greatest impact on your
environment while introducing minimal risk. As you approach the bottom of the
list, parameters have less of an impact (relative to the others) and/or
introduce risk if implemented incorrectly. Examples of misconfigured parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;for Application Owners, misconfigured or “abuse” of pod priority can
negatively impact scheduling of other teams&#39; workloads&lt;/li&gt;
&lt;li&gt;for Cluster Operators, misconfigured Kubernetes &amp;amp; System reserved flags can cause
significant instability in the cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;application-owner&#34;&gt;Application Owner&lt;/h2&gt;
&lt;p&gt;The parameters discussed in this section are of primary concern to application
owners, although understanding them will help anyone who works with Kubernetes.&lt;/p&gt;
&lt;h3 id=&#34;disruption-tolerant-applications&#34;&gt;Disruption Tolerant Applications&lt;/h3&gt;
&lt;p&gt;This guide assumes that the applications you are deploying are prepared to take
advantage of Kubernetes. This includes Kubernetes-specific configuration such as
liveness probes, readiness probes, logging to stdout etc. This guide also
assumes your application can tolerate &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/disruptions/#how-to-perform-disruptive-actions-on-your-cluster&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;temporary
disruptions&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;resource-limits&#34;&gt;Resource Limits&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Resource
limits&lt;/a&gt;&lt;/em&gt;
provide a way to limit pod resource consumption and contribute to the overall
stability of the cluster. By default, pods do not have resource limits and their
consumption of resources is unbounded. This is problematic because a pod is free
to consume all available resources on a node.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-1.png&#34; alt=&#34;No limits or requests&#34;  /&gt;
&lt;strong&gt;Figure 1: BestEffort pod (no limits or requests)&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;quality-of-service&#34;&gt;Quality-of-Service&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Quality of
Service&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;(QoS) is a classification assigned to each pod by Kubernetes for the purposes of
scheduling and pod
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#eviction-policy&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;eviction&lt;/a&gt;.
A
&lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/#create-a-pod-that-gets-assigned-a-qos-class-of-besteffort&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;BestEffort&lt;/a&gt;&lt;/em&gt;
pod is one with no resource limits or requests (requests are discussed in the
next section), and is the lowest QoS assigned by Kubernetes. Figure 1 shows a
pod with a QoS of BestEffort. The green bar represents utilization and the
dotted line indicates it is a variable quantity. In this case, utilization is
unbounded and free to consume all available CPU and memory.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-2.png&#34; alt=&#34;Best Effort Pod&#34;  /&gt;
&lt;strong&gt;Figure 2: Two replicas of a BestEffort pod&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;compressible-vs-incompressible-resources&#34;&gt;Compressible vs. Incompressible Resources&lt;/h4&gt;
&lt;p&gt;Figure 2 shows a node with two replicas of Pod A. Notice the CPU is fully
utilized and each replica is using 50% of the available capacity, yet the single
replica in Figure 1 is using over 50% of the available CPU capacity. The CPU
consumption of each replica in Figure 2 has been throttled down to 50%. This is
because CPU is a &lt;em&gt;&lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;compressible
resource&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When a compressible resource (such as CPU) is fully utilized, its consumers will
be throttled.&lt;/p&gt;
&lt;p&gt;Figure 2 also shows the memory consumption of both pods, however memory is an
example of an &lt;em&gt;incompressible resource&lt;/em&gt;. The red bar in Figure 2 indicates
memory that the second replica of Pod A attempted to consume, but the node did
not have available. At this point, the node must reclaim resources to ensure
stable operation. Although there are ways for a node to protect itself when this
occurs, it does introduce uncertainty and put the stability of the node at risk.&lt;/p&gt;
&lt;h4 id=&#34;risk-of-unbounded-resource-consumption&#34;&gt;Risk of Unbounded Resource Consumption&lt;/h4&gt;
&lt;p&gt;When memory approaches full utilization, a node’s kubelet invokes &lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#evicting-end-user-pods&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;pod
eviction&lt;/a&gt;&lt;/em&gt;
to reclaim resources and ensure the node remains stable. If pods consume all
available memory before the kubelet begins the eviction process, then Kubernetes
workloads will be competing with system daemons for memory and it is up to the
node’s &lt;a href=&#34;https://lwn.net/Articles/391222/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;oom_killer&lt;/a&gt; to respond. Once this
occurs, the best case scenario is for the pod to be killed by the oom_killer.
Unlike pod eviction, a pod killed by the oom_killer may be restarted on the same
node by the kubelet based on its restart policy. This means a pod may enter a
cycle of consuming too much memory, being killed by the oom_killer and restarted
by the kubelet. This cycle may continue without the pod being rescheduled
because it is never successfully evicted. This is problematic because it raises
the possibility of system daemons, such as Docker, crashing and causing the
entire node to become unstable.&lt;/p&gt;
&lt;h4 id=&#34;risk-of-docker-termination&#34;&gt;Risk of Docker Termination&lt;/h4&gt;
&lt;p&gt;If you use Docker for your container runtime, under its default configuration,
it will terminate all pods under its
supervision when it terminates. This means that resource contention between pods
and node daemons could potentially crash Docker and all other containers on the
node. This setting is configurable and discussed later in the
&lt;a href=&#34;#live-restore&#34;&gt;Live Restore&lt;/a&gt; section.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-3.png&#34; alt=&#34;Pod with limit&#34;  /&gt;
&lt;strong&gt;Figure 3: Pod with limit&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;resource-limits-1&#34;&gt;Resource Limits&lt;/h4&gt;
&lt;p&gt;Figure 3 shows a pod with a limit, indicating the point at which compressible
resources (CPU) are throttled and incompressible resources (memory) are limited.
If the pod consumes more memory than its memory limit specifies, it will be
killed by the kubelet to prevent overconsumption of resources, mitigate the
&lt;a href=&#34;https://searchcloudcomputing.techtarget.com/definition/noisy-neighbor-cloud-computing-performance&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;noisy
neighbor&lt;/a&gt;
problem and ensure node stability.&lt;/p&gt;
&lt;p&gt;While resource limits do help mitigate overconsumption of resources, they do not
help the scheduling process within Kubernetes. In other words, resource limits
help optimize stability, but do not have a big impact on utilization. For
example, resource limits would not prevent the situation described in Figure 2
from occurring. The Kubernetes scheduler may still attempt to schedule a pod on
a node without sufficient resources, resulting in the pod being evicted and
rescheduled on another node. Scheduling may be influenced by resource requests,
which will be discussed in the next section.&lt;/p&gt;
&lt;h4 id=&#34;setting-appropriate-resource-limits&#34;&gt;Setting Appropriate Resource Limits&lt;/h4&gt;
&lt;p&gt;A resource limit set too low may result in a pod being throttled or evicted.
However, a resource limit set too high may result in underutilization of node
resources. &lt;em&gt;Slack&lt;/em&gt; is the difference between a pod’s resource limit and its
actual utilization. The optimal resource limit for a pod depends on application
performance characteristics and requirements, and may be determined manually by
observing the workload with monitoring tools. &lt;em&gt;&lt;a href=&#34;https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Vertical Pod
Autoscaler&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;is an upstream effort aimed at automating the process of optimizing pod slack to
achieve high utilization and effective scheduling.&lt;/p&gt;
&lt;h4 id=&#34;effect-of-cpu-limits-on-latency-sensitive-workloads&#34;&gt;Effect of CPU Limits on Latency-Sensitive Workloads&lt;/h4&gt;
&lt;p&gt;The diagrams in this document use memory as an example of an overcommitted
resource to trigger pod eviction. Memory is a good example because memory
overcommit poses the greatest risk to node stability. Although CPU overcommit
isn’t a risk to node stability, it does have significant performance
implications. If your workloads are latency-sensitive, we recommend viewing a
&lt;a href=&#34;https://www.youtube.com/watch?v=eBChCFD9hfs&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Zalando presentation&lt;/a&gt; that goes
into depth on this topic. We also recommend reviewing the Kubernetes
documentation on &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;CPU Management
Policies&lt;/a&gt;
and &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/topology-manager/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Topology
Manager&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;resource-requests&#34;&gt;Resource Requests&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Resource
requests&lt;/a&gt;&lt;/em&gt;
allow you to specify a minimum amount of a resource required for a pod to
function and allow the scheduler to optimize utilization.&lt;/p&gt;
&lt;h4 id=&#34;burstable-pods&#34;&gt;Burstable Pods&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-4.png&#34; alt=&#34;Burstable Pod&#34;  /&gt;
&lt;strong&gt;Figure 4: Burstable pod (request &amp;lt; limit)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A pod with a QoS of &lt;em&gt;burstable&lt;/em&gt; has at least a resource request assigned to it.
If a limit is assigned, the request must be less than the limit for the pod to
be classified by Kubernetes as burstable (Kubernetes will not allow pods with
requests configured to be higher than limits). Figure 4 shows a burstable pod,
indicated by having requests and limits specified and the request lower than the
limit. The darker shade of green indicates the amount of resource that is
indicated by the request.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-5.png&#34; alt=&#34;Scheduler Node&#34;  /&gt;
&lt;strong&gt;Figure 5: Node from scheduler’s point-of-view&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Kubernetes scheduler considers resource requests when evaluating whether a
node has sufficient capacity for a pod to be scheduled. Figure 5 is an
illustration of a node from the scheduler’s point of view. For the pod
illustrated in Figure 4, the Kubernetes scheduler evaluated the node by
considering whether the specified request would have fit on the node. Figure 5
illustrates this by showing how many resource requests would have fit on the
node. Although an implementation of resource requests does affect scheduling, it
will not always prevent the problem illustrated in Figure 2. This is not always
a problem however, as the difference between a pod’s limit and request is what
allows for the node to be overcommitted.&lt;/p&gt;
&lt;h4 id=&#34;resource-overcommit&#34;&gt;Resource Overcommit&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Overcommit&lt;/em&gt; allows a node’s aggregate resource limits to be greater than the
available capacity for a given resource, which optimizes cluster utilization at
the expense of stability. This is acceptable when the workloads do not always
consume resources up to their limit, but instead infrequently burst up to that
limit. This does introduce risk, as it allows multiple workloads to burst at the
same time and force pod eviction or node instability to occur. An appropriate
amount of overcommit depends on your application requirements.&lt;/p&gt;
&lt;h4 id=&#34;guaranteed-pods&#34;&gt;Guaranteed Pods&lt;/h4&gt;
&lt;p&gt;A QoS of &lt;em&gt;guaranteed&lt;/em&gt; is assigned to pods where the request is equal to the
limit.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-6.png&#34; alt=&#34;Guaranteed Pods&#34;  /&gt;
&lt;strong&gt;Figure 6: Two replicas of Pod A scheduled across two nodes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Figure 6 shows two replicas of Pod A across two nodes, each pod with a QoS of
guaranteed. The entirety of the available utilization is indicated by dark
green. Figure 6 is an example of how the scheduler may avoid the problem
illustrated in Figure 2. Because the request is equal to the limit, the
scheduler sees that Node 1 cannot provide sufficient resources for a second
replica of Pod A. The scheduler concludes Node 2 is sufficient because Pod A’s
resource request is less than Node 2’s available capacity.&lt;/p&gt;
&lt;h3 id=&#34;pod-priority-and-preemption&#34;&gt;Pod Priority and Preemption&lt;/h3&gt;
&lt;p&gt;Pod
&lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;priority&lt;/a&gt;&lt;/em&gt;
indicates a pod’s importance relative to other pods. It is also used to
prioritize which pods will be evicted when a node is out of resources or when a
higher-priority workload is being scheduled (also known as
&lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;preemption&lt;/a&gt;&lt;/em&gt;).
Pod priority ensures stability of high-priority workloads when nodes are
highly-utilized.&lt;/p&gt;
&lt;h4 id=&#34;pod-eviction-order&#34;&gt;Pod Eviction Order&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-7.png&#34; alt=&#34;Node under memory pressure&#34;  /&gt;
&lt;strong&gt;Figure 7: Node under memory pressure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Figure 7 shows a node with multiple pods (all of varying QoS classifications)
scheduled to it. The node is also under memory pressure, which means it will
begin the &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#evicting-end-user-pods&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;eviction
process.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;




&lt;table class=&#34;table&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Eviction Order&lt;/th&gt;
&lt;th&gt;QoS&lt;/th&gt;
&lt;th&gt;Priority&lt;/th&gt;
&lt;th&gt;Utilization&lt;/th&gt;
&lt;th&gt;Usage / Request&lt;/th&gt;
&lt;th&gt;Pod Label&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;BestEffort&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2%&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;BestEffort&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;5%&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;BestEffort&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;20%&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;BestEffort&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Burstable&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;F&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;Burstable&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;E&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;Guaranteed&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;strong&gt;Table 3: Eviction prioritization of pods from Figure 7&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Table 3 outlines the details of each pod illustrated in Figure 7, and the order
in which the pod would be evicted. Note that the kubelet only evicts pods until
the node is no longer under pressure, this table is just an example of how pods
are prioritized.&lt;/p&gt;
&lt;p&gt;The
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#evicting-end-user-pods&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;prioritization&lt;/a&gt;
of pods during the eviction process first considers a pod’s QoS class.
BestEffort and Burstable pods are considered first. Then, pods are ranked by
priority and usage above request. BestEffort pods do not have a request, so this
value is considered to be zero during the eviction process. After this,
Guaranteed pods and Burstable pods whose usage is below their request are
considered.&lt;/p&gt;
&lt;h4 id=&#34;node-out-of-memory-behavior&#34;&gt;Node Out-of-Memory Behavior&lt;/h4&gt;
&lt;p&gt;If a node’s resources are consumed faster than the eviction process can reclaim
resources, the node must rely on the oom_killer to ensure node stability. This
document will not go into detail on this process, as the process is not
configurable and our goal is to avoid this situation as it puts node stability
at risk. Refer to the Kubernetes
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#node-oom-behavior&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;documentation&lt;/a&gt;
for details on this process.&lt;/p&gt;
&lt;h3 id=&#34;pod-disruption-budgets&#34;&gt;Pod Disruption Budgets&lt;/h3&gt;
&lt;p&gt;A Kubernetes cluster will experience various disruptions throughout its
lifecycle. Some are
&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/disruptions/#voluntary-and-involuntary-disruptions&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;involuntary&lt;/a&gt;
such as a VM failing or a network partition, and others are voluntary such as
cluster scaling or node draining. To optimize stability, you should strive to
mitigate risk across all lifecycle events. &lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/run-application/configure-pdb/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Pod Disruption
Budgets&lt;/a&gt;&lt;/em&gt;
(PDBs) allow an application owner to optimize application stability and
availability by indicating how many concurrent voluntary disruptions their
application can tolerate. This information is used by Kubernetes to block
voluntary disruptions if the PDB requirement would be violated by performing the
voluntary disruption.&lt;/p&gt;
&lt;p&gt;By default, Kubernetes is unaware of the availability requirements of the
applications that are deployed to it. As a result, PDBs are a crucial interface
between application owners and cluster managers because they enable a way for
Kubernetes to track an application’s availability requirements. PDBs are
especially important for stateful applications with data sharded across
replicas, or high priority deployments where application-level availability is
of concern.&lt;/p&gt;
&lt;h4 id=&#34;pdb-example&#34;&gt;PDB Example&lt;/h4&gt;
&lt;p&gt;The following example is an illustration of the example given in the Kubernetes
&lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/disruptions/#pdb-example&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-8.png&#34; alt=&#34;Cluster prior to draining&#34;  /&gt;
&lt;strong&gt;Figure 8: Cluster prior to node draining&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Figure 8 shows a 3-node cluster with its respective Deployment and PDB objects.
There is also an unrelated pod, Pod X, deployed to node 1.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-9.png&#34; alt=&#34;Cluster during draining&#34;  /&gt;
&lt;strong&gt;Figure 9: Cluster during node draining with pods rescheduled&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When a voluntary disruption occurs, such as a cluster manager draining a node in
preparation for a node upgrade, Kubernetes will consult each deployment’s
respective PDB and block the operation if the PDB would be violated by the
operation. Figure 9 shows the state of a cluster during a node draining
operation that was allowed by Kubernetes because the deployment’s PDB would not
have been violated.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-10.png&#34; alt=&#34;Cordoned Node&#34;  /&gt;
&lt;strong&gt;Figure 10: Cluster with node cordoned and rescheduled pods running&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once a node is drained, its state is considered to be “cordoned”. Figure 10
shows the Kubernetes cluster after a node is successfully cordoned and its pods
have been rescheduled.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-11.png&#34; alt=&#34;Cordoned Node&#34;  /&gt;
&lt;strong&gt;Figure 11: Cluster with node cordoned and rescheduled pods running&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As mentioned earlier, if a voluntary disruption is attempted on a cluster that
would result in a PDB being violated, the action will be blocked by Kubernetes.
Figure 11 shows the Kubernetes cluster after a cluster manager attempts to
perform a drain operation on Node 2. Pod E, a part of the deployment, is stuck
in “Pending” state because there are not enough resources remaining to schedule
it. Furthermore, Kubernetes will refuse to drain Pod D from the node because
that would violate the PDB. This operation would block, and Figure 11 represents
the state the cluster would be in at this point.&lt;/p&gt;
&lt;h3 id=&#34;affinity--anti-affinity&#34;&gt;Affinity &amp;amp; Anti-Affinity&lt;/h3&gt;
&lt;p&gt;It is a common requirement for highly-available applications to be dispersed
across physical hardware, or for an application to require hardware that is
specific to a node in the cluster. By default, Kubernetes is unaware of these
topology requirements. &lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Affinity &amp;amp;
anti-affinity&lt;/a&gt;&lt;/em&gt;
allow an application owner to express these requirements to optimize application
availability during voluntary disruptions.&lt;/p&gt;
&lt;p&gt;In the previous example, if the cluster had a fourth node then anti-affinity
could have been used to influence the scheduler to reschedule Pod D to it. This
would have prevented two pods from the deployment to land on the same node.&lt;/p&gt;
&lt;h4 id=&#34;hard-requirement-vs-soft-preference&#34;&gt;Hard Requirement vs. Soft Preference&lt;/h4&gt;
&lt;p&gt;A &lt;em&gt;hard requirement&lt;/em&gt; is one that would prevent a pod from being scheduled if it
is not met. A &lt;em&gt;soft preference&lt;/em&gt; would not prevent a pod from being scheduled if
it is not met. For example, the
&lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;nodeSelector&lt;/a&gt;
field should be implemented to express a hard requirement for a pod that
requires a specific hostPath volume to be present. An example of a soft
preference is an application with high-availability requirements that needs to
spread across physical machines and can be expressed by &lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;affinity &amp;amp;
anti-affinity&lt;/a&gt;
or &lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;taints &amp;amp;
tolerations&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This requirement may be preferred, but not required during voluntary disruptions
for example.&lt;/p&gt;
&lt;h2 id=&#34;cluster-operator&#34;&gt;Cluster Operator&lt;/h2&gt;
&lt;p&gt;The parameters discussed in this section are of primary concern to cluster
managers, although understanding them will help anyone who works with
Kubernetes. The diagrams in this section build off of those found in the
previous Application Owners section.&lt;/p&gt;
&lt;h3 id=&#34;live-restore&#34;&gt;Live Restore&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://docs.docker.com/config/containers/live-restore/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Live restore&lt;/a&gt;&lt;/em&gt; is a
feature of Docker that allows containers to continue running when the Docker
daemon is unavailable. By default, this feature is disabled when installing
Docker. Docker configuration is also out of scope for
&lt;a href=&#34;https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubeadm&lt;/a&gt;,
resulting in cluster managers often overlooking this setting. If using Docker
for your container runtime, we recommend
enabling this feature to prevent containers from being shutdown if the Docker
daemon is terminated to optimize node stability.&lt;/p&gt;
&lt;h3 id=&#34;pods-per-node&#34;&gt;Pods Per Node&lt;/h3&gt;
&lt;p&gt;Kubernetes is configured with a default limit of 110 pods per node. VMware
recommends Cluster Managers remain aware of this default and adjust it as
necessary according to workload requirements to optimize utilization. This value
is configurable as a &lt;a href=&#34;https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubelet
flag&lt;/a&gt;
and may be set when
&lt;a href=&#34;https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/kubelet-integration/#workflow-when-using-kubeadm-init&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;installing&lt;/a&gt;
Kubernetes with kubeadm.&lt;/p&gt;
&lt;h3 id=&#34;limitranges-and-resource-quotas&#34;&gt;LimitRanges and Resource Quotas&lt;/h3&gt;
&lt;p&gt;As mentioned earlier, containers are configured to run with unbounded resources
by default._
&lt;a href=&#34;https://kubernetes.io/docs/concepts/policy/limit-range/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;LimitRanges&lt;/a&gt;_ allow
cluster managers to set a default resource request and limit requirements for
all pods in a namespace. If a pod is created without this requirement being met,
it will automatically be added by the
&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#limitranger&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;LimitRanger&lt;/a&gt;
&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;admission
controller&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/policy/resource-quotas/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Resource quotas&lt;/a&gt;&lt;/em&gt;
allow cluster managers to limit aggregate resource consumption on a
per-namespace basis. These are easy ways to bound resource consumption across
all pods and namespaces to optimize stability and utilization (as detailed in
&lt;a href=&#34;#resource-limits&#34;&gt;Resource Limits&lt;/a&gt; and &lt;a href=&#34;#resource-requests&#34;&gt;Resource Requests&lt;/a&gt;).&lt;/p&gt;
&lt;h3 id=&#34;eviction-thresholds&#34;&gt;Eviction Thresholds&lt;/h3&gt;
&lt;p&gt;As mentioned earlier, kubelet evicts pods on a node when it is under pressure
for a resource to ensure node stability. &lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#eviction-thresholds&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Eviction
thresholds&lt;/a&gt;&lt;/em&gt;
define the threshold at which the eviction process begins on a node. A &lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#hard-eviction-thresholds&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;hard
eviction
threshold&lt;/a&gt;&lt;/em&gt;
is one in which pods are immediately evicted after being crossed. A &lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#soft-eviction-thresholds&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;soft
eviction
threshold&lt;/a&gt;&lt;/em&gt;
is one in which a grace period must pass before kubelet begins to evict pods.&lt;/p&gt;
&lt;h4 id=&#34;visualizing-eviction-thresholds&#34;&gt;Visualizing Eviction Thresholds&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-12.png&#34; alt=&#34;Unbound Utilization&#34;  /&gt;
&lt;strong&gt;Figure 12: Unbounded utilization of workloads and daemons&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A node’s resources are consumed by Kubernetes workloads or by system daemons.
Figure 12 illustrates this concept by showing workload and daemon utilization
increasing from left-to-right. A fully utilized resource would be indicated by
these two bars filling the rectangle.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-13.png&#34; alt=&#34;Eviction Thresholds&#34;  /&gt;
&lt;strong&gt;Figure 13: Node with eviction thresholds shown&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Figure 13 shows a node’s memory resources with default eviction threshold. Note
that eviction thresholds are bounded by a solid line. Furthermore, eviction
thresholds are only affected by workload utilization surpassing them and not by
daemon utilization. By default, the resource consumption of system daemons on a
cluster is unbounded. Bearing this in mind, Figure 13 is also representative of
a Kubernetes cluster configured by kubeadm in its default configuration.
(unbounded workload utilization, unbounded daemon utilization and a hard
eviction threshold for memory).&lt;/p&gt;
&lt;h4 id=&#34;configuring-eviction-thresholds&#34;&gt;Configuring Eviction Thresholds&lt;/h4&gt;
&lt;p&gt;By default, kubelet is configured with only a hard eviction threshold with these
parameters as
of&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/v1.16.2/pkg/kubelet/apis/config/v1beta1/defaults_others.go&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;v1.16.2&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;evictionHard:
  imagefs.available: 15%
  memory.available: 100Mi
  nodefs.available: 10%
  evictionPressureTransitionPeriod: 5m0s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These values represent the defaults configured for kubelet regardless of the
resources available on a particular node. To override these parameters,
&lt;a href=&#34;https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/kubelet-integration/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;override&lt;/a&gt;
them when installing your cluster with kubeadm. VMware recommends cluster
managers remain aware of this default and configure their cluster with the node
resources and application requirements in mind.&lt;/p&gt;
&lt;h3 id=&#34;kube--system-reserved&#34;&gt;Kube &amp;amp; System Reserved&lt;/h3&gt;
&lt;p&gt;Kubernetes also provides a means for cluster managers to limit resource
consumption of daemons to optimize utilization. &lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#kube-reserved&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kube
reserved&lt;/a&gt;&lt;/em&gt;
reserves compute resources for Kubernetes-related daemons and &lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;system
reserved&lt;/a&gt;&lt;/em&gt;
reserves compute resources for other daemons.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-15.png&#34; alt=&#34;Kube Reserved&#34;  /&gt;
&lt;strong&gt;Figure 15: Node with eviction threshold, kube, and system reserved&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;node-allocatable-constraints&#34;&gt;Node Allocatable Constraints&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-16a.png&#34; alt=&#34;CPU Constraints&#34;  /&gt;
&lt;strong&gt;Figure 16a: Node CPU with Node Allocatable and Node Allocatable Constraints highlighted&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-16b.png&#34; alt=&#34;Memory and Storage Constraints&#34;  /&gt;
&lt;strong&gt;Figure 16b: Node Memory &amp;amp; Ephemeral Storage with Node Allocatable and Node Allocatable Constraints highlighted&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Node allocatable constraints&lt;/em&gt; are what eviction thresholds, kube reserved and
system reserved are collectively referred to as. This name is derived from the
fact that they are what determines &lt;em&gt;node allocatable&lt;/em&gt;, which is how much of a
resource is available for consumption by pods. In other words, a node’s
allocatable capacity is equal to its capacity minus node allocatable
constraints. Figures 16a and 16b illustrate the relation between these values
for &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;CPU, memory and
ephemeral-storage&lt;/a&gt;.
Note that Figure 16a does not contain an eviction threshold. This is because
eviction thresholds only apply to non-compressible resources such as memory and
ephemeral storage.&lt;/p&gt;
&lt;p&gt;Note that the addition of kube and/or system reserved will introduce a second
eviction threshold for non-compressible resources (for example, memory and
ephemeral-storage). In Figure 16b, eviction is triggered either when pod
utilization exceeds allocatable, or when the total utilization (pods and
daemons) exceeds the eviction threshold. For compressible resources (CPU), the
addition of kube and/or system reserved will move the threshold at which that
resource is compressed because it affects the size of allocatable.&lt;/p&gt;
&lt;h4 id=&#34;tuning-node-allocatable-constraints&#34;&gt;Tuning Node Allocatable Constraints&lt;/h4&gt;
&lt;p&gt;When configuring eviction thresholds, keep in mind that kube reserved and system
reserved flags have a direct effect on the allocatable capacity of each node.&lt;/p&gt;
&lt;p&gt;As a cluster manager, your primary means of tuning stability vs. utilization of
your cluster is by adjusting node allocatable constraints. Always have eviction
policies configured and tuned appropriately relative to node size and workload
resource consumption. Only after adequate monitoring is in place,
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#general-guidelines&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;consider&lt;/a&gt;
enforcing kube reserved to bound resource consumption of Kubernetes-related
daemons. Finally, only enforce system reserved if absolutely necessary and after
exhaustive profiling of daemon resource consumption via monitoring tools.&lt;/p&gt;
&lt;h3 id=&#34;housekeeping-interval&#34;&gt;Housekeeping Interval&lt;/h3&gt;
&lt;p&gt;Kubernetes does not maintain a real-time understanding of resource consumption
on its nodes. Instead, kubelet periodically evaluates the eviction thresholds on
each node at a preconfigured &lt;em&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#eviction-monitoring-interval&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;housekeeping
interval&lt;/a&gt;&lt;/em&gt;.
Because of this, it is possible for a rapid increase in memory consumption to
cause instability on a node. Kubernetes’ default housekeeping interval is 10
seconds, but VMware recommends cluster managers adjust this parameter if they
know their workloads can rapidly increase in memory consumption.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-17.png&#34; alt=&#34;Increased memory consumption&#34;  /&gt;
&lt;strong&gt;Figure 17: Linear increase in memory consumption with default housekeeping interval (10 seconds)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The risk posed by the default housekeeping interval is illustrated in Figure 17.
Notice that the utilization captured by the kubelet is only updated every 10
seconds even though the memory is increasing linearly with time. In this
example, eviction thresholds would not be triggered until the moment utilization
hit 100%, which may be too late to mitigate the risk posed by out-of-memory
handling.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-18.png&#34; alt=&#34;Memory Spike&#34;  /&gt;
&lt;strong&gt;Figure 18: Spike in memory consumption with default housekeeping interval (10 seconds)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The worst-case scenario is for memory to become fully utilized for some amount
of time before the utilization captured by the kubelet is updated to reflect
this. Figure 18 shows this scenario with the actual utilization at 100% for 5
seconds before the kubelet notices.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-19.png&#34; alt=&#34;Memory Spike&#34;  /&gt;
&lt;strong&gt;Figure 19: Spike in memory consumption with default housekeeping interval of 10 seconds&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For deployments that consume memory rapidly and are at risk of the situation
described in Figure 18, consider reducing the housekeeping interval. Figure 19
shows how changing the housekeeping interval to 5 seconds (from the default of
10 seconds) can mitigate this problem.&lt;/p&gt;
&lt;h3 id=&#34;fault-tolerance&#34;&gt;Fault Tolerance&lt;/h3&gt;
&lt;p&gt;One of the greatest benefits of tuning the parameters discussed in this guide is
that failover scenarios become much more predictable. A node failure in a
Kubernetes cluster with default configuration will have an unpredictable outcome
because it is unknown what would be required to reschedule the workloads of a
given node.&lt;/p&gt;
&lt;h4 id=&#34;before-unpredictable-failover&#34;&gt;Before: Unpredictable Failover&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-20.png&#34; alt=&#34;Default Settings&#34;  /&gt;
&lt;strong&gt;Figure 20: Kubernetes cluster default settings&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Figure 20 shows a cluster that has not been configured beyond the default
kubeadm configuration. While it is possible to configure a monitoring tool to
observe the current utilization of nodes within your cluster, a lack of requests
and limits makes it difficult to tell whether or not the cluster could
accommodate a node failure.&lt;/p&gt;
&lt;h4 id=&#34;after-predictable-failover&#34;&gt;After: Predictable Failover&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-21.png&#34; alt=&#34;With Node Allocatable Constraints&#34;  /&gt;
&lt;strong&gt;Figure 21: Kubernetes cluster with Node Allocatable Constraints configured&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On the other hand, a cluster with bounded resource consumption makes this task
relatively simple. Monitoring tools may be configured to consume the cluster’s
resource requests, limits, eviction thresholds, kube reserved and system
reserved settings. With these values known, it is possible to configure an alert
that will warn a cluster manager when the cluster will no longer be able to
tolerate a node failure. Figure 21 is a visualization of this concept with a
node in its most general form, with a resource’s allocatable capacity limited by
node allocatable constraints. This illustration applies to &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;CPU, memory and
ephemeral
storage&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;calculating-max-utilization&#34;&gt;Calculating Max Utilization&lt;/h4&gt;
&lt;p&gt;Similar to calculating whether or not a cluster could afford a node failure, it
is also possible to calculate the maximum utilization of each node such that the
cluster could tolerate a node failure. Note that this calculation is only an
estimation, and does not take into account scheduling complexities such as
affinity. The broader point here is that having well-defined limits and requests
allows us to be proactive in reasoning about different failure scenarios.&lt;/p&gt;
&lt;h5 id=&#34;estimate-function&#34;&gt;Estimate Function&lt;/h5&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-22.png&#34; alt=&#34;Maximum Node Utilization&#34;  /&gt;
&lt;strong&gt;Figure 22: Simple function for maximum utilization of nodes while allowing for 1 failure, where &lt;em&gt;n&lt;/em&gt; represents the number of nodes in a cluster&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A simple version of calculating this value is shown in Figure 22, with sample
input and output shown in Table 2. Calculating maximum utilization with this
function makes the following assumptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;allocatable constraints (eviction threshold, kube &amp;amp; system reserved) == 0&lt;/li&gt;
&lt;li&gt;number of failures is 1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;




&lt;table class=&#34;table&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;# of nodes (n)&lt;/th&gt;
&lt;th&gt;maxUtilization(n)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;50%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;66%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;90%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;strong&gt;Table 4: Example calculations of maximum node utilization with function from Figure 22&lt;/strong&gt;&lt;/p&gt;
&lt;h5 id=&#34;full-function&#34;&gt;Full Function&lt;/h5&gt;
&lt;p&gt;Maximum utilization may also be calculated without making any of the previous
assumptions. Figure 23 shows how to calculate maximum utilization while also
taking into account the number of node failures, &lt;em&gt;f&lt;/em&gt;, and node allocatable
constraints (summed up across all nodes), &lt;em&gt;c&lt;/em&gt;. Table 3 shows example input and
output for this function.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/diagrams/cluster-tuning-figure-23.png&#34; alt=&#34;Maximum Node Utilization&#34;  /&gt;
&lt;strong&gt;Figure 23: Full function for maximum utilization of nodes while accounting for an arbitrary number of node failures (f) and node allocatable constraints.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;




&lt;table class=&#34;table&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;# of nodes (n)&lt;/th&gt;
&lt;th&gt;max # of node failures&lt;/th&gt;
&lt;th&gt;node allocatable constraints&lt;/th&gt;
&lt;th&gt;max utilization of nodes&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;50%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;66%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;90%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.2&lt;/td&gt;
&lt;td&gt;40%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.3&lt;/td&gt;
&lt;td&gt;56%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;75%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;strong&gt;Table 5: Example calculation of maximum node utilization with function from Figure 23&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;tying-it-all-together&#34;&gt;Tying it All Together&lt;/h2&gt;
&lt;p&gt;The beginning of this document categorized disruptions into two categories:
involuntary and voluntary. By now, it should be clear how each of the constructs
discussed in this document mitigate the risks presented by these disruptions.&lt;/p&gt;
&lt;h3 id=&#34;before-tuning&#34;&gt;Before Tuning&lt;/h3&gt;
&lt;p&gt;Figure 20 provides a good visual for the risks that are present in an untuned
Kubernetes cluster. This cluster is not resilient to involuntary disruptions
because its workload and daemon resource consumption is unbounded, putting nodes
at risk of instability and causing failover to be unpredictable. During
voluntary disruptions such as scaling or node draining, there are no PDBs in
place to protect stateful or high-priority applications from losing
high-availability. Scheduling is inefficient as it is unaware of pod priority,
affinity, anti-affinity requirements. Overall, its behavior is not well-defined
and the only way to ensure stability is by minimizing utilization.&lt;/p&gt;
&lt;h3 id=&#34;after-tuning&#34;&gt;After Tuning&lt;/h3&gt;
&lt;p&gt;The cluster shown in Figure 21 is a good visual for a tuned cluster. It is
resilient to involuntary disruptions because workload and daemon resource
consumption is bounded, which mitigates the risk of node instability also
results in predictable failover scenarios. During voluntary disruptions such as
scaling or node draining, PDBs, affinity, and anti-affinity now help
applications maintain high-availability. Scheduling is efficient as it is aware
of pod priority, affinity and anti-affinity requirements. Overall, stability and
utilization of the cluster is optimized.&lt;/p&gt;
&lt;h3 id=&#34;refocusing-on-bigger-problems&#34;&gt;Refocusing on Bigger Problems&lt;/h3&gt;
&lt;p&gt;Prior to tuning your cluster, it will be exposed to a number of risks that
detract from the
&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/#why-you-need-kubernetes-and-what-can-it-do&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;benefits&lt;/a&gt;
Kubernetes has to offer. A tuned cluster gives you peace of mind and an ability
to focus on broader architectural tradeoffs such as those between utilization,
fault tolerance and scheduling complexity.&lt;/p&gt;
&lt;h4 id=&#34;utilization-vs-fault-tolerance&#34;&gt;Utilization vs. Fault Tolerance&lt;/h4&gt;
&lt;p&gt;How many nodes can your environment tolerate losing? This depends on many
factors including your application’s service-level-agreement (SLA), disruption
tolerance and other organizational requirements. It is a complicated question to
answer, but with a tuned cluster it is much easier to approach. As discussed,
bounded resource consumption allows you determine the max utilization of your
nodes based on your fault tolerance requirements.&lt;/p&gt;
&lt;h4 id=&#34;utilization-vs-scheduling-complexity&#34;&gt;Utilization vs. Scheduling Complexity&lt;/h4&gt;
&lt;p&gt;If your workloads have relatively simple resource requirements, the scheduler’s
job will be straightforward and you may be able to increase the utilization of
your cluster by scaling the number of nodes down. On the other hand, complex
resource requirements will complicate scheduling. This may be may be remedied by
adding capacity to the cluster, which reduces cluster utilization.&lt;/p&gt;
&lt;h2 id=&#34;testing&#34;&gt;Testing&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://kind.sigs.k8s.io/docs/user/quick-start&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kind&lt;/a&gt;&lt;/em&gt; is a tool for running
clusters locally using Docker containers as nodes, and may be used to
familiarize with configuring the kubelet parameters discussed in this document.
You may also experiment with application-level parameters (those discussed in
the &lt;a href=&#34;#application-owner&#34;&gt;Application Owner&lt;/a&gt; section) upon cluster creation.
Follow the &lt;a href=&#34;https://kind.sigs.k8s.io/docs/user/quick-start&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;getting started&lt;/a&gt;
guide with the following configuration to deploy a kind cluster with default
node allocatable constraints:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kind: Cluster
apiVersion: kind.sigs.k8s.io/v1alpha3
kubeadmConfigPatches:
- |
  apiVersion: kubelet.config.k8s.io/v1beta1
  kind: KubeletConfiguration
  metadata:
    name: config
  maxPods: 110
#  systemReserved:
#      memory: &amp;quot;500Mi&amp;quot;
#  kubeReserved:
#      memory: &amp;quot;500Mi&amp;quot;
  evictionHard:
      memory.available:  &amp;quot;100Mi&amp;quot;
      imagefs.available: &amp;quot;15%&amp;quot;
      nodefs.available: &amp;quot;10%&amp;quot;
      nodefs.inodesFree: &amp;quot;5%&amp;quot;
- |
  apiVersion: kubeadm.k8s.io/v1beta2
  kind: InitConfiguration
  metadata:
    name: config
  nodeRegistration:
    kubeletExtraArgs:
      &amp;quot;housekeeping-interval&amp;quot;: &amp;quot;10s&amp;quot;
      &amp;quot;enforce-node-allocatable&amp;quot;: &amp;quot;pods&amp;quot;
nodes:
- role: control-plane
- role: worker
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To enforce system or kube reserved flags, be sure to
&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;configure&lt;/a&gt;
your cgroup driver and update the enforce-node-allocatable.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Create a Multi-Cluster Monitoring Dashboard with Thanos, Grafana and Prometheus</title>
      
      <link>/guides/kubernetes/prometheus-multicluster-monitoring/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/prometheus-multicluster-monitoring/</guid>
      <description>

        
        &lt;p&gt;&lt;a href=&#34;https://prometheus.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus&lt;/a&gt;, coupled with
&lt;a href=&#34;https://grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Grafana&lt;/a&gt;, is a popular monitoring solution for Kubernetes
clusters. It allows SRE teams and developers to capture metrics and telemetry
data for applications running in a cluster, allowing deeper insights into
application performance and reliability.&lt;/p&gt;
&lt;p&gt;The Prometheus/Grafana combination works well for individual clusters, but as
teams scale out and start working with multiple clusters, monitoring
requirements become correspondingly more complex. For effective multi-cluster
monitoring, a &amp;ldquo;single pane of glass&amp;rdquo; with centralized real-time monitoring, time
series comparisons across and within clusters and high availability is essential
for teams operating with multiple clusters and multiple providers.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://thanos.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Thanos&lt;/a&gt; is a monitoring system that aggregates data from
multiple Prometheus deployments. This data can then be inspected and analyzed
using Grafana, just as with regular Prometheus metrics. Although this setup
sounds complex, it&amp;rsquo;s actually very easy to achieve with the following Bitnami
Helm charts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/prometheus-operator&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami&amp;rsquo;s Prometheus Operator Helm chart&lt;/a&gt;
lets you deploy Prometheus in your Kubernetes cluster with an additional
Thanos sidecar container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/thanos&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami&amp;rsquo;s Thanos Helm chart&lt;/a&gt;
lets you deploy all the Thanos components together with MinIO and Alertmanager
so you can quickly bootstrap a Thanos deployment.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/grafana&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami&amp;rsquo;s Grafana Helm chart&lt;/a&gt;
lets you deploy Grafana in your Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This guide walks you through the process of using these charts to create a
Thanos deployment that aggregates data from Prometheus Operators in multiple
clusters and allows further monitoring and analysis using Grafana.&lt;/p&gt;
&lt;h2 id=&#34;assumptions-and-prerequisites&#34;&gt;Assumptions and prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You have three separate multi-node Kubernetes clusters running on the same
cloud provider:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Two &amp;ldquo;data producer&amp;rdquo; clusters which will host Prometheus deployments and
applications that expose metrics via Prometheus.&lt;/li&gt;
&lt;li&gt;One &amp;ldquo;data aggregator&amp;rdquo; cluster which will host Thanos and aggregate the data
from the data producers. This cluster will also host Grafana for data
visualization and reporting.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You have the &lt;em&gt;kubectl&lt;/em&gt; CLI and the Helm v3.x package manager installed and configured to work with your Kubernetes clusters. &lt;a href=&#34;https://docs.bitnami.com/kubernetes/get-started-kubernetes#step-3-install-kubectl-command-line&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Learn how to install &lt;em&gt;kubectl&lt;/em&gt; and Helm v3.x&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This guide uses clusters hosted on the Google Kubernetes Engine (GKE) service
but you can use any Kubernetes provider. Learn about
&lt;a href=&#34;https://docs.bitnami.com/kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;deploying a Kubernetes cluster on different cloud platforms&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;step-1-install-the-prometheus-operator-on-each-cluster&#34;&gt;Step 1: Install the Prometheus Operator on each cluster&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/prometheus-operator&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami&amp;rsquo;s Prometheus Operator chart&lt;/a&gt;
provides easy monitoring definitions for Kubernetes services and management of
Prometheus instances. It also includes an optional Thanos sidecar container,
which can be used by your Thanos deployment to access cluster metrics.&lt;/p&gt;
&lt;p&gt;Only one instance of the Prometheus Operator component should be running in a
cluster.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Add the Bitnami charts repository to Helm:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the Prometheus Operator in the first &amp;ldquo;data producer&amp;rdquo; cluster using the command below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install prometheus-operator &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set prometheus.thanos.create&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set operator.service.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;ClusterIP &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set prometheus.service.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;ClusterIP &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set alertmanager.service.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;ClusterIP &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set prometheus.thanos.service.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;LoadBalancer &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set prometheus.externalLabels.cluster&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data-producer-0&amp;#34;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  bitnami/prometheus-operator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;em&gt;prometheus.thanos.create&lt;/em&gt; parameter creates a Thanos sidecar container,
while the &lt;em&gt;prometheus.thanos.service.type&lt;/em&gt; parameter makes the sidecar service
available at a public load balancer IP address. Note the
&lt;em&gt;prometheus.externalLabels&lt;/em&gt; parameter which lets you define one or more unique
labels per Prometheus instance - these labels are useful to differentiate
different stores or data sources in Thanos.&lt;/p&gt;
&lt;p&gt;The command above exposes the Thanos sidecar container in each cluster at a
public IP address using a &lt;em&gt;LoadBalancer&lt;/em&gt; service. This makes it easy for
Thanos to access Prometheus metrics in different clusters without needing any
special firewall or routing configuration. However, this approach is highly
insecure and should be used only for demonstration or testing purposes. In
production environments, it is preferable to deploy an NGINX Ingress
Controller to control access from outside the cluster and further limit access
using whitelisting and other security-related configuration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the command below to obtain the public IP address of the sidecar service.
You will use this IP address in the next step.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get svc | grep prometheus-operator-prometheus-thanos
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Repeat the steps shown above for the second &amp;ldquo;data producer&amp;rdquo; cluster. Use a
different value for the &lt;em&gt;prometheus.externalLabels.cluster&lt;/em&gt; parameter, such as
&lt;em&gt;data-producer-1&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;step-2-install-and-configure-thanos&#34;&gt;Step 2: Install and configure Thanos&lt;/h2&gt;
&lt;p&gt;The next step is to install Thanos in the &amp;ldquo;data aggregator&amp;rdquo; cluster and
integrate it with Alertmanager and MinIO as the object store.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Modify your Kubernetes context to reflect the cluster on which you wish to install Thanos.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;em&gt;values.yaml&lt;/em&gt; file as shown below. Replace the KEY placeholder with a
hard-to-guess value and the SIDECAR-SERVICE-IP-ADDRESS-X placeholders with the
public IP addresses of the Thanos sidecar containers in the &amp;ldquo;data producer&amp;rdquo;
clusters.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;objstoreConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|-&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;  type: s3
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;  config:
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    bucket: thanos
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    endpoint: {{ include &amp;#34;thanos.minio.fullname&amp;#34; . }}.monitoring.svc.cluster.local:9000
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    access_key: minio
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    secret_key: KEY
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    insecure: true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;querier&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;SIDECAR-SERVICE-IP-ADDRESS-1:10901&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;SIDECAR-SERVICE-IP-ADDRESS-2:10901&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;bucketweb&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;compactor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;storegateway&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ruler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;alertmanagers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;http://prometheus-operator-alertmanager.monitoring.svc.cluster.local:9093&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|-&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;    groups:
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      - name: &amp;#34;metamonitoring&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;        rules:
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;          - alert: &amp;#34;PrometheusDown&amp;#34;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;            expr: absent(up{prometheus=&amp;#34;monitoring/prometheus-operator&amp;#34;})&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;minio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enabled&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;accessKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;minio&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;KEY&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;defaultBuckets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;thanos&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install Thanos using the command below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install thanos bitnami/thanos &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --values values.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wait for the deployment to complete and note the DNS name and port number for
the Thanos Querier service in the deployment output, as shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/querier-service.png&#34; alt=&#34;Thanos Querier service&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the instructions shown in the chart output to connect to the Thanos
Querier Web interface and navigate to the &amp;ldquo;Stores&amp;rdquo; tab. Confirm that both
sidecar services are running and registered with Thanos, as shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/querier-stores.png&#34; alt=&#34;Thanos Querier stores&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Confirm also that each service displays a unique &lt;em&gt;cluster&lt;/em&gt; labelset, as configured in &lt;a href=&#34;#step-1-install-the-prometheus-operator-on-each-cluster&#34;&gt;Step 1&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-3-install-grafana&#34;&gt;Step 3: Install Grafana&lt;/h2&gt;
&lt;p&gt;The next step is to install Grafana, also on the same &amp;ldquo;data aggregator&amp;rdquo; cluster
as Thanos.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use the command below, replacing GRAFANA-PASSWORD with a password for the
Grafana application:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install grafana bitnami/grafana &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set service.type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;LoadBalancer &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set admin.password&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;GRAFANA-PASSWORD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wait for the deployment to complete and obtain the public IP address for the
Grafana load balancer service:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get svc &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep grafana
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm that you are able to access Grafana by browsing to the load balancer
IP address on port 3000 and logging in with the username &lt;em&gt;admin&lt;/em&gt; and the
configured password. Here is what you should see:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/grafana-dashboard.png&#34; alt=&#34;Grafana dashboard&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-4-configure-grafana-to-use-thanos-as-a-data-source&#34;&gt;Step 4: Configure Grafana to use Thanos as a data source&lt;/h2&gt;
&lt;p&gt;Follow these steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the Grafana dashboard, click the &amp;ldquo;Add data source&amp;rdquo; button.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the &amp;ldquo;Choose data source type&amp;rdquo; page, select &amp;ldquo;Prometheus&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/grafana-add-data-source.png&#34; alt=&#34;Grafana data source&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the &amp;ldquo;Settings&amp;rdquo; page, set the URL for the Prometheus server to
&lt;em&gt;http://NAME:PORT&lt;/em&gt;, where NAME is the DNS name for the Thanos service obtained
at the end of &lt;a href=&#34;#step-2-install-and-configure-thanos&#34;&gt;Step 2&lt;/a&gt; and PORT is the
corresponding service port. Leave all other values at their default.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/grafana-thanos-url.png&#34; alt=&#34;Grafana data source configuration&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &amp;ldquo;Save &amp;amp; Test&amp;rdquo; to save and test the configuration. If everything is
configured correctly, you should see a success message like the one below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/grafana-success.png&#34; alt=&#34;Grafana test&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-5-test-the-system&#34;&gt;Step 5: Test the system&lt;/h2&gt;
&lt;p&gt;At this point, you can start deploying applications into your &amp;ldquo;data producer&amp;rdquo;
clusters and collating the metrics in Thanos and Grafana. For demonstration
purposes, this guide will deploy a MariaDB replication cluster using Bitnami&amp;rsquo;s
MariaDB Helm chart in each &amp;ldquo;data producer&amp;rdquo; cluster and display the metrics
generated by each MariaDB service in Grafana.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Deploy MariaDB in each cluster with one master and one slave using the
production configuration with the commands below. Replace the
MARIADB-ADMIN-PASSWORD and MARIADB-REPL-PASSWORD placeholders with the
database administrator account and replication account password respectively.
You can also optionally create a MariaDB user account for application use by
specifying values for the USER-PASSWORD, USER-NAME and DB-NAME placeholders.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install mariadb &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set rootUser.password&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;MARIADB-ADMIN-PASSWORD &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set replication.password&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;MARIADB-REPL-PASSWORD &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set db.user&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;USER-NAME &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set db.password&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;USER-PASSWORD &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set db.name&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;DB-NAME &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set slave.replicas&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set metrics.enabled&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --set metrics.serviceMonitor.enabled&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  bitnami/mariadb 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note the &lt;em&gt;metrics.enabled&lt;/em&gt; parameter, which enables the Prometheus exporter
for MySQL server metrics, and the &lt;em&gt;metrics.serviceMonitor.enabled&lt;/em&gt; parameter,
which creates a Prometheus Operator ServiceMonitor.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once deployment in each cluster is complete, note the instructions to connect
to each database service.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/mariadb-service.png&#34; alt=&#34;MariaDB service&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Browse to the
&lt;a href=&#34;https://github.com/percona/grafana-dashboards/blob/master/dashboards/MySQL_Overview.json&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;MySQL Overview dashboard in the Percona GitHub repository&lt;/a&gt;
and copy the JSON model.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Log in to Grafana. From the Grafana dashboard, click the &amp;ldquo;Import -&amp;gt; Dashboard&amp;rdquo;
menu item.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the &amp;ldquo;Import&amp;rdquo; page, paste the JSON model into the &amp;ldquo;Or paste JSON&amp;rdquo; field.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/grafana-dashboard-import.png&#34; alt=&#34;Grafana dashboard import&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &amp;ldquo;Load&amp;rdquo; to load the data and then &amp;ldquo;Import&amp;rdquo; to import the dashboard. The
new dashboard should appear in Grafana, as shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/grafana-mysql-dashboard.png&#34; alt=&#34;Grafana MySQL dashboard&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connect to the MariaDB service in the first &amp;ldquo;data producer&amp;rdquo; cluster and
perform some actions, such as creating a database, adding records to a table
and executing a query. Perform similar actions in the second &amp;ldquo;data producer&amp;rdquo;
cluster. You should see your activity in each cluster reflected in the MySQL
Overview chart in Grafana, as shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/grafana-metrics.png&#34; alt=&#34;MariaDB metrics in Grafana&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;You can view metrics from individual master and slave nodes in each cluster by
selecting a different host in the &amp;ldquo;Host&amp;rdquo; drop down of the dashboard, as shown
below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/prometheus-multicluster-monitoring/grafana-hosts.png&#34; alt=&#34;MariaDB hosts in Grafana&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can now continue adding more applications to your clusters. So long as you
enable Prometheus metrics and a Prometheus Operator ServiceMonitor for each
deployment, Thanos will continuously receive and aggregate the metrics and you
can inspect them using Grafana.&lt;/p&gt;
&lt;h2 id=&#34;useful-links&#34;&gt;Useful links&lt;/h2&gt;
&lt;p&gt;To learn more about the topics discussed in this guide, use the links below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/prometheus-operator&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami Prometheus Operator Helm chart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/thanos&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami&amp;rsquo;s Thanos Helm chart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/grafana&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami&amp;rsquo;s Grafana Helm chart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/mariadb&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami MariaDB Helm chart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/ingress/tree/master/controllers/nginx&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;NGINX Ingress controller documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.bitnami.com/tutorials/secure-kubernetes-services-with-ingress-tls-letsencrypt/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Secure Kubernetes Services with Ingress, TLS and Let&amp;rsquo;s Encrypt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Pod Priority and Preemption</title>
      
      <link>/guides/kubernetes/workload-tenancy-priority-preemption/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/workload-tenancy-priority-preemption/</guid>
      <description>

        
        &lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;This section aims to provide guidance on pod priority and preemption. It allows
application owners and cluster administrators to have an in-depth understanding
of Kubernetes preemption features and the relationship between the various
components, namely: Pod Disruption Budget Violation, Kubelet Pod QoS, and
PriorityClass.&lt;/p&gt;
&lt;p&gt;After reading this document, you will have a better understanding of how to plan
for application prioritization to ensure minimal outage of the entire system.&lt;/p&gt;
&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Most organizations categorize their applications based on their business impact.
Each category defines specific metrics for applications, such as maximum
downtime and acceptable response times. The category also specifies the
remediation process in the event of application failure. Typically, applications
in one category have higher priority than applications in another.&lt;/p&gt;
&lt;p&gt;In Kubernetes, the scheduler handles pods on a first-come, first-serve basis. In
other words, there is no guarantee that applications with higher importance get
scheduled when the cluster is under heavy utilization. To inform the scheduler
about application priorities, Kubernetes has a feature called Pod Priority and
Preemption. It ensures that pods with a higher priority have a front slot in the
scheduler queue and even evicts lower priority pods if necessary.&lt;/p&gt;
&lt;h2 id=&#34;system-wide-priority-class&#34;&gt;System-Wide Priority Class&lt;/h2&gt;
&lt;p&gt;Kubernetes is managed by system-wide pods to provide services to the respective
tenants. These system-wide pods are critical to the functioning of the cluster.
To ensure that these critical pods remain scheduled and running, they are
assigned the &lt;code&gt;system-cluster-critical&lt;/code&gt; and &lt;code&gt;system-node-critical&lt;/code&gt; priority
classes during the installation.&lt;/p&gt;
&lt;p&gt;Run the following command to check the value of the priority class.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get priorityclass

&lt;span class=&#34;c1&#34;&gt;# the greater the value, the higher the priority&lt;/span&gt;
NAME                      VALUE        GLOBAL-DEFAULT   AGE
system-cluster-critical   &lt;span class=&#34;m&#34;&gt;2000000000&lt;/span&gt;   &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;            10d
system-node-critical      &lt;span class=&#34;m&#34;&gt;2000001000&lt;/span&gt;   &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;            10d
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When defining priority classes for your applications, make sure that you use a
value that is lower than the built-in &lt;code&gt;system-cluster-critical&lt;/code&gt; priority class.
By doing so, you can be sure that your applications will not evict
system-critical pods.&lt;/p&gt;
&lt;p&gt;If you plan to host cluster-wide critical services such as logging agents,
metrics server, or an SSO IDP provider; &lt;code&gt;system-cluster-critical&lt;/code&gt; or another
level below (you organization&amp;rsquo;s definition of priority) should be used and this
will give a guaranteed prioritization for the service.&lt;/p&gt;
&lt;h2 id=&#34;priority-class-planning&#34;&gt;Priority Class Planning&lt;/h2&gt;
&lt;p&gt;Most IT organizations have a classification of severity. Let’s assume they have
business criticality categories from 1 to 3, 1 having the lowest priority, while
3 having the highest priority for applications that require extremely high
levels of reliability. With this assumption, you can reflect these categories in
PriorityClasses and use them to prioritize the pods in the cluster.&lt;/p&gt;
&lt;p&gt;With the above assumptions, we can define the following priority classes for
your entire application needs.&lt;/p&gt;
&lt;p&gt;




&lt;table class=&#34;table&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;PriorityClass Name&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;th&gt;preemptionPolicy&lt;/th&gt;
&lt;th&gt;globalDefault&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;cat-1&lt;/td&gt;
&lt;td&gt;10000&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cat-2&lt;/td&gt;
&lt;td&gt;20000&lt;/td&gt;
&lt;td&gt;PreemptLowerPriority&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cat-3&lt;/td&gt;
&lt;td&gt;30000&lt;/td&gt;
&lt;td&gt;PreemptLowerPriority&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cluster-service&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;PreemptLowerPriority&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;strong&gt;&lt;em&gt;Table 1: Sample PriorityClass Allocation&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;


&lt;div class=&#34;aside aside-warning&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Maximum value of priority classes&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;When defining priority classes, make sure that the &lt;strong&gt;&lt;code&gt;value&lt;/code&gt;&lt;/strong&gt; field does not
exceed the value specified by &lt;code&gt;system-cluster-critical&lt;/code&gt; which is &lt;code&gt;2000000000&lt;/code&gt;&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;PreemptionPolicy if enabled, allows the scheduler to evict existing pods.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cat-1&lt;/code&gt; has been deliberately configured as default preemptionPolicy&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;cat-1&lt;/code&gt; priority class is assigned to deployments by default. The remaining
priority classes can be used to prioritize applications according to their
availability requirements. You can leverage the &lt;code&gt;cluster-service&lt;/code&gt; class for the
workloads that provide common services, such as logging and monitoring.&lt;/p&gt;
&lt;h3 id=&#34;who-gets-evicted&#34;&gt;Who Gets Evicted?&lt;/h3&gt;
&lt;p&gt;Lets assume the scenario where your cluster has pods defined with the following
disruption budgets.&lt;/p&gt;
&lt;p&gt;




&lt;table class=&#34;table&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Application&lt;/th&gt;
&lt;th&gt;Disruption Budget&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Blue Pod&lt;/td&gt;
&lt;td&gt;Min Available : 3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Purple Pod&lt;/td&gt;
&lt;td&gt;Min Available : 3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Green Pod&lt;/td&gt;
&lt;td&gt;Min Available : 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Red Pod&lt;/td&gt;
&lt;td&gt;Min Available : 2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;strong&gt;&lt;em&gt;Table 2: Scenario Disruption Budget&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s assume your cluster is full but you need to deploy another &lt;code&gt;cat-3&lt;/code&gt;
application. Kubernetes will attempt to schedule the pod as shown on the
following diagram:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/workload-tenancy/pod-priority-01.png&#34; alt=&#34;pod-priority&#34;  /&gt;
&lt;strong&gt;&lt;em&gt;Figure 1: Scenario: Green Application is Preempted&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;


&lt;div class=&#34;aside aside-info&#34;&gt;
    &lt;div class=&#34;aside aside-title&#34;&gt;
        &lt;i class=&#34;fas fa-exclamation-circle&#34;&gt;&lt;/i&gt;
        &lt;div&gt;Pod Disruption Budgets&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;aside aside-content&#34;&gt;
    &lt;p&gt;Even though blue pod has lowest priority (&lt;code&gt;cat-1&lt;/code&gt;), the Kubernetes scheduler will
not pick that pod due to the disruption budget requirement. Removing any blue
pod will cause a violation.&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The scheduling will run with 2 passes. If the first attempt failed with
&lt;code&gt;fitError&lt;/code&gt; which is an indication from scheduler that it could not find the best
fit for the pod under the current situations, the Kubernetes scheduler will
attempt to run the 2 passes as long as the new pod priority class has
&lt;code&gt;PreemptLowerPriority&lt;/code&gt; flagged.&lt;/p&gt;
&lt;p&gt;During the second attempt, various variables are taken into consideration to
select one victim (worker node) for preemption.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;It starts by looking for worker nodes that are marked with
&lt;a href=&#34;https://pkg.go.dev/k8s.io/kubernetes/pkg/scheduler/framework/v1alpha1?tab=doc#Code&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;Unschedulable&lt;/code&gt;&lt;/a&gt;,
which is an indication for possibility to preempt some of the pods&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Followed by dry-run reprieve logic on the valid worker nodes and to check if
the new pod (orange pod) can be scheduled on the node when all lower priority
pod (&lt;code&gt;cat-1&lt;/code&gt; or &lt;code&gt;cat-2&lt;/code&gt;) has been successfully evicted. If there is possibility
for preemption, Kubernetes scheduler will sort all the pods by their priority
and put them into 2 sorted groups based on their &lt;code&gt;PodDisruptionBudget&lt;/code&gt;
conditions; &lt;code&gt;violated&lt;/code&gt; and &lt;code&gt;non-violated&lt;/code&gt; pods, if preemption happen on the
worker node.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If there are potential pods to preempt, the Kubernetes scheduler selects the
worker node based on the below sequence.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The node with minimum number of &lt;code&gt;PodDisruptionBudget&lt;/code&gt; violations.&lt;/li&gt;
&lt;li&gt;If ties, the node with minimum highest priority victim is picked.&lt;/li&gt;
&lt;li&gt;If ties, ties are broken by sum of priorities of all victims.&lt;/li&gt;
&lt;li&gt;If ties, the node with the minimum number of victims is picked.&lt;/li&gt;
&lt;li&gt;If ties, the node with the latest start time of all highest priority
victims is picked.&lt;/li&gt;
&lt;li&gt;If ties, the first such node is picked randomly.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Trigger the kubelet to start executing preemption logic.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With the algorithm shown above, the example on &amp;lsquo;&lt;strong&gt;Preemption on Green App&lt;/strong&gt;&amp;rsquo;
remove the green pod with &lt;code&gt;cat-2&lt;/code&gt; (rather than the blue pod &lt;code&gt;cat-1&lt;/code&gt;) as they do not
violate &lt;code&gt;PodDisruptionBudget&lt;/code&gt; upon removal.&lt;/p&gt;
&lt;p&gt;Pod Priority algorithms do not take
&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;QoS&lt;/a&gt;
into consideration as these two features are less likely to interact
with each other except for &lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes out-of-resource
eviction&lt;/a&gt;
scenario.&lt;/p&gt;
&lt;h2 id=&#34;key-takeaways&#34;&gt;Key Takeaways&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Always have a default PriorityClass. Use the one with lowest value.&lt;/li&gt;
&lt;li&gt;Priority classes should not have a value greater than your cluster-wide,
critical PriorityClass.&lt;/li&gt;
&lt;li&gt;Preemption logic will respect pod disruption budget rules. Make sure you have
this specified during deployment.&lt;/li&gt;
&lt;li&gt;For business-critical systems, it is recommended to specify the minimum
availability, together with higher priority value. In the sample above, this
would be the &lt;code&gt;cat-3&lt;/code&gt; category.&lt;/li&gt;
&lt;li&gt;Pod &lt;code&gt;affinity&lt;/code&gt; and &lt;code&gt;anti-affinity&lt;/code&gt; rules impact the selection of victims. If
any of those exist, the worker node will not be considered as part of
selection.&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Showback Reference Architecture</title>
      
      <link>/guides/kubernetes/observability-showback-refarch/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/observability-showback-refarch/</guid>
      <description>

        
        &lt;p&gt;This document discusses showback for Kubernetes clusters, such as those provided
by Tanzu Kubernetes Grid (TKG). It covers concepts, and implementation
considerations. This document represents how the VMware field team approaches
showback in large enterprise Kubernetes environments.&lt;/p&gt;
&lt;p&gt;At a high level, the key observations and recommendations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use resource requests to represent a tenant&amp;rsquo;s resource consumption&lt;/li&gt;
&lt;li&gt;Overlay resource usage and resource requests to find workloads that have
requested too many resources&lt;/li&gt;
&lt;li&gt;Enforce a consistent label across workloads to map pods to tenants&lt;/li&gt;
&lt;li&gt;Persist showback metrics in long-term storage for reporting and analytics&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;Showback and chargeback are IT practices implemented by an organization. The
goal of these practices is to understand the allocation and costs associated
with each department or division’s usage of IT systems. On the one hand,
showback provides visibility into the allocation and costs of resources.
Chargeback, on the other hand, builds on showback, in that it cross-charges the
IT costs to each business unit. This document focuses on showback in the context
of Kubernetes.&lt;/p&gt;
&lt;p&gt;Kubernetes-based application platforms can host applications that belong to
different business units or application teams. By implementing showback, the
platform team gains visibility into how the cluster resources are allocated to
the different platform tenants. With this information, platform teams can inform
tenants about their resource allocations, increase infrastructure utilization,
inform their capacity planning, and potentially reduce IT spend.&lt;/p&gt;
&lt;h3 id=&#34;resource-requests-versus-usage&#34;&gt;Resource requests versus usage&lt;/h3&gt;
&lt;p&gt;Kubernetes exposes different metrics that you can use to build a showback model.
When considering showback, organizations sometimes jump to the conclusion that
they should report exclusively on resource usage. However, resource usage is
only half the picture. The other half, and the more important one, is resource
requests.&lt;/p&gt;
&lt;p&gt;When deploying applications to Kubernetes, developers request resources for
their workloads. The scheduler uses the resource requests to assign the workload
to a node on the cluster. Once scheduled, the cluster’s capacity is reduced by
the workload’s requests. In other words, the resources requested by the workload
are reserved for the workload. From the platform perspective, those resources
are considered fully utilized, regardless of the workload’s actual resource
consumption.&lt;/p&gt;
&lt;p&gt;Reporting on resource requests enables platform operators to understand how
tenants are sharing cluster resources. Consider the following diagram, which
shows the CPU requests of two platform tenants over time. As the workloads of
each tenant are scheduled and unscheduled, the CPU requests increase and
decrease accordingly.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/observability/showback-tenant-requests.png&#34; alt=&#34;showback: tenant requests&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;By aggregating the CPU requests of all tenants, platform operators can
understand how the CPU capacity of the cluster is being used. The following
diagram shows the aggregate CPU requests of all tenants and the cluster’s CPU
capacity. The difference between the total CPU requests and the total CPU
capacity is the available CPU capacity for additional workloads.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/observability/showback-cluster-cpu-capacity.png&#34; alt=&#34;showback: cluster CPU capacity&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Building a showback system based on resource requests is a good foundation. As
you can see from the previous diagrams, resource requests provide insight into
how tenants are sharing the cluster resources. Furthermore, the aggregate of all
resource requests can help platform operators with capacity planning.&lt;/p&gt;
&lt;p&gt;Platform operators gain additional insight when they evaluate resource usage in
addition to resource requests. By comparing usage versus requests, platform
operators can derive cluster utilization. Furthermore, they can identify tenants
that are wasting resources by not consuming their requests.&lt;/p&gt;
&lt;p&gt;The following diagram shows the CPU usage and requests of a platform tenant over
time. There are two important aspects to consider in this diagram. First, the
tenant’s workload exceeded the resource requests. From a showback perspective,
burst CPU usage can be regarded as a freebie. The second, more important thing
to consider is the wasted CPU capacity. Based on the diagram, the tenant is
requesting more CPU than necessary, thus wasting CPU capacity that could
otherwise be used to schedule additional workloads on the cluster.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/observability/showback-requests-vs-usage.png&#34; alt=&#34;showback: requests vs usage&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;One of the most common causes of low utilization is the improper sizing of
workloads. Showback reports that show both resource usage and requests help
identify workloads that need adjustment. Platform operators can use these
reports to ask tenants to adjust their requests to avoid
wasting resources.&lt;/p&gt;
&lt;h2 id=&#34;implementing-showback&#34;&gt;Implementing showback&lt;/h2&gt;
&lt;p&gt;The core of a showback system involves collecting metrics from the platform,
storing them over time, and building tenant-specific reports or dashboards.
Various monitoring tools can be used for showback, ranging from general-purpose
monitoring systems such as &lt;a href=&#34;https://prometheus.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Prometheus&lt;/a&gt;, to
showback/chargeback specific tools such as
&lt;a href=&#34;https://www.cloudhealthtech.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;CloudHealth&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;collecting-metrics&#34;&gt;Collecting metrics&lt;/h3&gt;
&lt;h4 id=&#34;resource-requests&#34;&gt;Resource requests&lt;/h4&gt;
&lt;p&gt;The resource requests of a pod are specified in the pod object. Each container
in the pod declares the resource requests in the &lt;code&gt;resources.requests&lt;/code&gt; field.
Because resource requests are part of the pod’s configuration, Kubernetes does
not expose this information via metrics.&lt;/p&gt;
&lt;p&gt;To collect resource request metrics, you must install
&lt;a href=&#34;https://github.com/kubernetes/kube-state-metrics&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kube-state-metrics&lt;/a&gt; in your
platform. kube-state-metrics is a service that queries the Kubernetes API and
exposes useful metrics about the API objects (Deployments, Pods, Nodes, etc.).
The CPU and memory requests for all pods on the cluster are available through
the &lt;code&gt;kube_pod_container_resource_requests&lt;/code&gt; and
&lt;code&gt;kube_pod_container_resource_requests_memory_bytes&lt;/code&gt; metrics. You can leverage
these metrics for the showback report.&lt;/p&gt;
&lt;h4 id=&#34;resource-usage&#34;&gt;Resource usage&lt;/h4&gt;
&lt;p&gt;Resource usage information for each pod is captured by the
&lt;a href=&#34;https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubelet&lt;/a&gt;
and exposed through a Prometheus-compatible endpoint. As opposed to resource
requests, these metrics are readily available for consumption by your monitoring
stack. The CPU usage of a pod is available through the
&lt;code&gt;container_cpu_usage_seconds_total&lt;/code&gt; metric, while the memory usage is available
through the &lt;code&gt;container_memory_usage_bytes&lt;/code&gt; metric. You can use these metrics to
build the usage side of your showback reports.&lt;/p&gt;
&lt;h4 id=&#34;workload-metadata&#34;&gt;Workload metadata&lt;/h4&gt;
&lt;p&gt;In addition to the resource requests and usage metrics, the showback system
captures workload metadata to map workloads to tenants. What metadata to capture
depends on the tenancy model of the cluster. If a tenant maps to a single
namespace, the workload&amp;rsquo;s namespace can be used to determine the workload&amp;rsquo;s
owner. This approach, however, results in strong coupling between the cluster
namespacing strategy and the showback strategy. An alternative, more flexible
approach is to determine the tenant based on a pod label, such as
&lt;code&gt;cloud.example.com/owner&lt;/code&gt;. This method enables tenants to evolve and change
namespaces without affecting the showback implementation.&lt;/p&gt;
&lt;h4 id=&#34;metrics-collection-interval&#34;&gt;Metrics collection interval&lt;/h4&gt;
&lt;p&gt;The metrics collection interval determines how often the showback metrics are
collected from the platform. This interval is important because it impacts the
accuracy of the showback system. Short collection intervals produce more data
and thus more accurate showback reports. However, short collection intervals
also increase the performance burden on the cluster.&lt;/p&gt;
&lt;p&gt;While finding the right collection interval requires iteration and
experimentation, collecting metrics every minute is typically a good starting
point.&lt;/p&gt;
&lt;p&gt;Another consideration to make when it comes to the collection interval is the
type of workloads running on the cluster. For example, short-lived ephemeral
jobs most likely require shorter collection intervals than long-running
services.&lt;/p&gt;
&lt;h3 id=&#34;metrics-storage&#34;&gt;Metrics storage&lt;/h3&gt;
&lt;p&gt;Once the metrics are captured, they must be stored in a database for long-term
storage and reporting. In the case of Prometheus, the metrics are stored in a
time-series database that can then be queried for building dashboards and
reports. Prometheus does not support clustering or replication of the data.
Thus, high availability and long term storage of metrics are achieved through an
additional system, such as &lt;a href=&#34;https://thanos.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Thanos&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;reports--dashboards&#34;&gt;Reports / Dashboards&lt;/h3&gt;
&lt;p&gt;The showback system produces reports based on the metrics collected from the
cluster. The reports account for a given period, and they aggregate the metrics
by tenant. Platform operators can send tenant-specific showback reports to each
tenant on a schedule. Operators can also leverage interactive dashboards to show
the data.&lt;/p&gt;
&lt;p&gt;If using Prometheus, you can use &lt;a href=&#34;https://grafana.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Grafana&lt;/a&gt; to create
dashboards that display the showback information according to your needs.
SaaS-based showback implementations, such as CloudHealth, have pre-configured
dashboards that you can leverage.&lt;/p&gt;
&lt;h2 id=&#34;extending-to-chargeback&#34;&gt;Extending to chargeback&lt;/h2&gt;
&lt;p&gt;This document focuses on showback and the considerations you need to make to
implement a showback system. In some cases, organizations need to bill platform
tenants for the resources used by their applications. This is achieved through a
chargeback system.&lt;/p&gt;
&lt;p&gt;You can build a chargeback system on top of showback by translating the resource
allocations into dollar amounts that can be billed to the tenants. To perform
the translation, you first have to assign dollar costs to each resource. For
example, how much does one hour of CPU cost?&lt;/p&gt;
&lt;p&gt;There are multiple factors to consider when establishing costs. If the cluster
is running on the cloud, the cost of a node is easier to determine than if the
cluster is on-premises (the cloud provider establishes node costs). At the same
time, there are additional costs when running on the cloud that might not apply
when running on-premises, such as network usage, load balancers, etc. Another
factor to consider is whether the cluster has multiple node types with different
costs. If so, the cost of a workload will depend on the node where it is
running.&lt;/p&gt;
&lt;p&gt;Establishing the cost model is perhaps the most challenging step to implement a
chargeback system. Once you have assigned costs to each consumable resource,
however, evolving a showback system into a chargeback system is straightforward.
By grabbing the resource allocation of each tenant, and multiplying it by the
resource costs, you obtain the dollar amounts that must be charged to each
tenant.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Assign Pods to Nodes With Bitnami Helm Chart Affinity Rules</title>
      
      <link>/guides/kubernetes/assign-pods-to-nodes-with-bitnami-helm-chart-affinity-rules/</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/kubernetes/assign-pods-to-nodes-with-bitnami-helm-chart-affinity-rules/</guid>
      <description>

        
        &lt;p&gt;First published on &lt;a href=&#34;https://docs.bitnami.com/tutorials/assign-pod-nodes-helm-affinity-rules/&#34;&gt;https://docs.bitnami.com/tutorials/assign-pod-nodes-helm-affinity-rules/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When you install an application in a Kubernetes cluster, the &lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes scheduler&lt;/a&gt; decides in which nodes the application pods will be installed unless certain constraints are defined. For example, Kubernetes scheduler may decide to install application pods in a node with more available memory. This is mostly useful except when cluster administrators prefer to distribute a group of pods across the cluster in a specific manner. For this use case, they need a tool that can force Kubernetes to follow custom rules specified by the user.&lt;/p&gt;
&lt;p&gt;Affinity rules supply a way to force the scheduler to follow specific rules that determine where pods should be distributed. To help users to implement affinity rules, Bitnami has enhanced its Helm charts by including opinionated affinities in their manifest files. Cluster administrators now only need to define the criteria to be followed by the scheduler when placing application pods in cluster nodes. They can then enable this feature via a simple install-time parameter&lt;/p&gt;
&lt;p&gt;This tutorial will demonstrate the available affinity rules and how they can be adapted to your needs.&lt;/p&gt;
&lt;h2 id=&#34;assumptions-and-prerequisites&#34;&gt;Assumptions and Prerequisites&lt;/h2&gt;
&lt;p&gt;This article assumes that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You have a Google Cloud account. &lt;a href=&#34;https://cloud.google.com/free&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Register for a Google Cloud account&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You have a Kubernetes cluster running with Helm v3.x and &lt;code&gt;kubectl&lt;/code&gt; installed. &lt;a href=&#34;https://docs.bitnami.com/kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Learn more about getting started with Kubernetes and Helm using different cloud providers&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&#34;callout td-box--gray-darkest p-3 mx-5 border-bottom border-right border-left border-top&#34;&gt;
    &lt;p&gt;This guide uses a Kubernetes cluster created in GKE. These steps are the same for all Kubernetes engines. They don’t work, however, in Minikube, since with Minikube you only can create single-node clusters.&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&#34;how-affinity-rules-work-in-bitnami-helm-charts&#34;&gt;How Affinity Rules Work in Bitnami Helm Charts&lt;/h2&gt;
&lt;p&gt;All Bitnami infrastructure solutions available in the &lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami Helm charts catalog&lt;/a&gt; now include pre-defined affinity rules exposed through the &lt;code&gt;podAffinityPreset&lt;/code&gt; and &lt;code&gt;podAntiAffinitypreset&lt;/code&gt; parameters in their &lt;code&gt;values.yml&lt;/code&gt; file:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/bitnami-helm-chart-affinity-rules/image-1.png&#34; alt=&#34;Pod affinity rules&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Pod affinity and anti-affinity rules allow you to define how the scheduler should behave when locating application pods in your cluster eligible nodes. Depending on the option you choose, the scheduler will behave as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;podAffinityPreset&lt;/code&gt; - Using the &lt;code&gt;podAffinity&lt;/code&gt; rule, the scheduler will locate a new pod on the same node where other pods with the same label are located. This approach is especially helpful to group under the same node pods that meet specific pre-defined patterns.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;podAntiAffinitypreset&lt;/code&gt; - Using the &lt;code&gt;podAntiAffinity&lt;/code&gt; parameter lets the scheduler locates one pod in each node. Thus, you will prevent locating a new pod on the same node as other pods are running. This option is convenient if your deployment will demand high availability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Having the pods distributed across all nodes allows Kubernetes to ensure high availability of your cluster by keeping running the remaining nodes when one node fails.&lt;/p&gt;
&lt;p&gt;These are the values you can set for both pod affinity and anti-affinity rules:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Soft&lt;/strong&gt; - Use this value to make the scheduler enforce a rule wherever it can be met (best-effort approach). If the rule cannot be met, the scheduler will deploy the required pods in the nodes with enough resources.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hard&lt;/strong&gt; - Use this value to make the scheduler enforce a rule. This means that if there are remaining pods that do not comply with the pre-defined rule, they won&amp;rsquo;t be allocated in any node.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bitnami Helm charts have the &lt;code&gt;podAntiAffinity&lt;/code&gt; rule with the &lt;code&gt;soft&lt;/code&gt; value enabled by default. Hence, if there are not enough nodes to place one pod per node, it will leave the scheduler to decide where the remaining pods should be located.&lt;/p&gt;
&lt;p&gt;The following section shows two different use cases of configuring &lt;code&gt;podAntiaffinity&lt;/code&gt; parameter.&lt;/p&gt;
&lt;h2 id=&#34;deploying-a-chart-using-the-podantiaffinity-rule&#34;&gt;Deploying a Chart Using the &lt;code&gt;podAntiAffinity&lt;/code&gt; Rule&lt;/h2&gt;
&lt;p&gt;The following examples illustrate how the &lt;code&gt;podAntiAffinity&lt;/code&gt; rule works in the context of the Bitnami MySQL Helm chart. They cover two use cases: installing the chart with the default &lt;code&gt;podAntiAffinity&lt;/code&gt; value and changing the &lt;code&gt;podAntiAffinity&lt;/code&gt; value from &lt;code&gt;soft&lt;/code&gt; to &lt;code&gt;hard&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;use-case-1-install-the-chart-with-the-default-podantiaffinity-value&#34;&gt;Use Case 1: Install the Chart with the Default &lt;code&gt;podAntiaffinity&lt;/code&gt; Value&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install the Bitnami Helm charts repository by running:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;helm repo add bitnami https://charts.bitnami.com/bitnami 
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Deploy the MySQL Helm chart by executing the command below. Note that the chart will deploy the cluster with three nodes and two replicas - one primary and one secondary. To make the scheduler follow the default &lt;code&gt;podAntiAffinity&lt;/code&gt; rule, set the parameter as follows:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;helm install mysql bitnami/mysql --set architecture=replication --set secondary.replicaCount=2 --set secondary.podAntiAffinityPreset=soft 
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Verify the cluster by checking the nodes. Use the following command to list the connected nodes:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;kubectl get nodes 
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;You will see an output message like this:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/bitnami-helm-chart-affinity-rules/image-2.png&#34; alt=&#34;Example kubectl get pods output&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Three nodes are running in the cluster.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check how the pods are distributed. Execute the command below:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;kubectl get pods -o wide 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/bitnami-helm-chart-affinity-rules/image-3.png&#34; alt=&#34;Example kubectl get pods -o wide output&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;As expected, both the primary and the secondary pods are in different nodes.&lt;/p&gt;
&lt;p&gt;To verify how the scheduler acts when the &lt;em&gt;soft&lt;/em&gt; value is defined, scale up the cluster by setting the number of secondary replicas to three instead of one. Thus, the resulting number of pods will be four, instead of two.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To scale the cluster, use the command below:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;kubectl scale sts/mysql-secondary --replicas 3 
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Check the pods by running again the &lt;code&gt;kubectl get pods&lt;/code&gt; command. The &lt;code&gt;soft&lt;/code&gt; value left the scheduler to locate the remaining pod that didn&amp;rsquo;t comply with the &amp;ldquo;one pod per node&amp;rdquo; rule:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/bitnami-helm-chart-affinity-rules/image-4.png&#34; alt=&#34;Example kubectl get pods output&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Note that two pods are running in the same node.&lt;/p&gt;
&lt;h3 id=&#34;use-case-2-change-the-podantiaffinity-value-from-soft-to-hard&#34;&gt;Use Case 2: Change the &lt;code&gt;podAntiAffinity&lt;/code&gt; Value from Soft to Hard&lt;/h3&gt;
&lt;p&gt;To try the &lt;code&gt;hard&lt;/code&gt; type of the &lt;code&gt;podAntiAffinity&lt;/code&gt; rule, deploy the chart again by changing the &lt;code&gt;secondary.podAntiAffinityPreset&lt;/code&gt; value from &lt;code&gt;soft&lt;/code&gt; to &lt;code&gt;hard&lt;/code&gt; as shown below. The chart will deploy the cluster with three nodes and two replicas - one primary and one secondary.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;helm install mysql-hard bitnami/mysql --set architecture=replication --set secondary.replicaCount=2 --set secondary.podAntiAffinityPreset=hard
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Check the nodes and the pods by running the &lt;code&gt;kubectl get nodes&lt;/code&gt; and the &lt;code&gt;kubectl get pods –o wide&lt;/code&gt; commands:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/bitnami-helm-chart-affinity-rules/image-5.png&#34; alt=&#34;Example kubectl get pods -o wide output&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Both the primary and secondary pods are running in the same node.&lt;/p&gt;
&lt;p&gt;To verify how the scheduler acts when the &lt;code&gt;hard&lt;/code&gt; value is defined, scale up the cluster by setting the number of secondary replicas to three instead of one. Thus, the resulting number of pods will be four, instead of two.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scale up the cluster by executing the command below:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;kubectl scale sts/mysql-hard secondary --replicas 3 
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;When checking the pods, you will see that the scheduler has ignored the &amp;ldquo;one pod per node&amp;rdquo; rule and also located only as many pods as there are nodes. The fourth pod was not deployed as there are only three nodes available.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/kubernetes/bitnami-helm-chart-affinity-rules/image-6.png&#34; alt=&#34;Example kubectl get pods -o wide output&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;podAntiAffinity&lt;/code&gt; rule is an easy way to control how application pods will be distributed across the cluster nodes when installing a Helm chart. Deploy your favorite Bitnami applications and enable this feature via a simple install-time parameter.&lt;/p&gt;
&lt;h2 id=&#34;useful-links&#34;&gt;Useful Links&lt;/h2&gt;
&lt;p&gt;To learn more about the topics discussed in this article, use the links below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/charts&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami Helm charts catalog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.bitnami.com/kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami Helm charts documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes scheduler documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kubernetes pod affinity documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
