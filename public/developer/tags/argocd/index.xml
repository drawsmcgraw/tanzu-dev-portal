<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>VMware Tanzu Developer Center – ArgoCD</title>
    <link>/tags/argocd/</link>
    <description>Recent content in ArgoCD on VMware Tanzu Developer Center</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 09 Jul 2021 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="/tags/argocd/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      
      <title>Guides: Automated Code to URL on Kubernetes using Cloud Native Buildpacks, Knative and ArgoCD</title>
      
      <link>/guides/ci-cd/cnbp-knative-argocd/</link>
      <pubDate>Wed, 12 May 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/ci-cd/cnbp-knative-argocd/</guid>
      <description>

        
        &lt;p&gt;Technologies like Docker and Kubernetes simplify the process of building, running and maintaining cloud native applications. At the same time taking source code, building it into a container image and turning it into a deployed application on Kubernetes can be a time consuming process. A large part of the process can be automated with Continuous Integration Systems (CI) and Continuous Deployment(CD) Systems. However there are stages in the build and deployment phases that still need to be defined manually. Most CI systems aren&amp;rsquo;t application aware. They cannot build automated Docker images from source code unless explicitly defined in a spec file like &lt;a href=&#34;https://docs.docker.com/engine/reference/builder/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Dockerfiles&lt;/a&gt; or a config file that a CI system can understand. Due to which, Apart from writing application code, you also need to manually define and test Dockerfiles or config files to convert source code into an executable container image. When deploying the image onto Kubernetes, you need to then define various Kubernetes constructs needed to run the application. Like &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Deployments&lt;/a&gt;, &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;StatefulSets&lt;/a&gt;, &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Services&lt;/a&gt;, &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Ingress&lt;/a&gt; etc. This process can add errors, security gaps and overhead.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/ci-cd/cnbp-knative-argocd/dev-process.png&#34; alt=&#34;Building and Running Applications on Kubernetes&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;In this Guide we are going to show how to automate building of Container Images and buildout of Kubernetes Resources using Cloud Native Buildpacks and Knative respectively. We will also demonstrate how this can process can be further optimized using &lt;strong&gt;GitOps&lt;/strong&gt; style practices via ArgoCD. We will work with a sample application based on Spring and run the application on Kubernetes with an addressable URL. We will use:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://buildpacks.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Cloud Native Buildpacks&lt;/a&gt; to automate Container Image build process. Cloud Native Buildpacks is a specification that defines how OCI compliant containers can be build, removing the need to specify or build &lt;code&gt;Dockerfiles&lt;/code&gt;. They can automatically detect the language an application is written in and determine the best and most secure way to package applications in a container image. Cloud Native Buildpacks can also be used to update container images easily for any changes. For this guide we will use an implementation of Cloud Native Buildpacks called &lt;a href=&#34;https://github.com/pivotal/kpack&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kpack&lt;/a&gt;. kpack lets you use deploy Cloud Native Buildpacks on a Kubernetes Cluster. (See &lt;a href=&#34;../../containers/cnb-what-is/&#34;&gt;What are Cloud Native Buildpacks?&lt;/a&gt; for more on Cloud Native Buildpacks, and kpack.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://knative.dev/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Knative&lt;/a&gt; to automatically generate an Ingress Service with URL and other Kubernetes Resources for the container image that was built using Cloud Native Buildpacks. Knative Serving automates the process of creating Kubernetes objects needed for an application like Deployment, Replicasets, Services etc.,  eliminating the need to write complex Kubernetes YAML files.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://argoproj.github.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;ArgoCD&lt;/a&gt; to automate deployment pipeline pushing container images on to Kubernetes using Knative. ArgoCD helps deploy application continuously using GitOps methodology. It can take specifications like Kubernetes resources, Knative, Kustomize etc. to deploy application on Kubernetes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A sample application called &lt;a href=&#34;https://github.com/Boskey/spring-petclinic&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Petclinic&lt;/a&gt; that is based on &lt;a href=&#34;https://spring.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Spring&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://kind.sigs.k8s.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kind&lt;/a&gt; as a local Kubernetes Cluster&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In summary, our overall workflow will be to take the sample application in Spring, use Cloud Native Buildpacks/kpack to convert source code into a container image, use Knative Serving to create a deployment using ArgoCD. This process will eliminate the need to write &lt;code&gt;Dockerfiles&lt;/code&gt; or any &lt;code&gt;Kubernetes&lt;/code&gt; resource &lt;code&gt;YAML&lt;/code&gt; files.&lt;/p&gt;
&lt;h2 id=&#34;assumptions-and-prerequisites&#34;&gt;Assumptions and prerequisites&lt;/h2&gt;
&lt;p&gt;There are a few things you will need before getting started&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You have &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubectl&lt;/a&gt;, a tool to interact with Kubernetes Cluster installed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.docker.com/products/docker-desktop&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Docker Desktop&lt;/a&gt; is installed on your laptop/machine with at least 4 GB of memory and 4 CPU&amp;rsquo;s allocated to Docker Resources.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You have access to &lt;a href=&#34;https://hub.docker.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Docker Hub Repository&lt;/a&gt; to store container images.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You have an account in &lt;a href=&#34;https://github.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Github&lt;/a&gt; to clone the app &lt;em&gt;Petclinic&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-prepare-a-kubernetes-cluster-and-clone-sample-application&#34;&gt;1. Prepare a Kubernetes Cluster and clone Sample Application&lt;/h3&gt;
&lt;p&gt;We will deploy a Kind cluster using Docker Desktop and install &lt;a href=&#34;https://projectcontour.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Contour&lt;/a&gt; on it to help provide Ingress management. Contour along with &lt;a href=&#34;https://www.envoyproxy.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Envoy&lt;/a&gt; Proxy will help create service and URL management for Knative.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;brew install kind
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Create a Kubernetes Cluster called &lt;em&gt;tdp-guide&lt;/em&gt; and set &lt;strong&gt;Kubectl&lt;/strong&gt; context to &lt;em&gt;tdp-guide&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kind create cluster --name tdp-guide
kubectl cluster-info --context kind-tdp-guide
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Log onto Github and Fork the repository for our sample app &lt;a href=&#34;https://github.com/Boskey/spring-petclinic&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Petclinic&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;2-install-knative-serving&#34;&gt;2. Install Knative Serving&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;kubectl apply -f https://github.com/knative/serving/releases/download/v0.22.0/serving-crds.yaml
kubectl apply -f https://github.com/knative/serving/releases/download/v0.22.0/serving-core.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;3-install-contour-ingress-controller&#34;&gt;3. Install Contour Ingress Controller&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;kubectl apply -f https://github.com/knative/net-contour/releases/download/v0.22.0/contour.yaml
kubectl apply -f https://github.com/knative/net-contour/releases/download/v0.22.0/net-contour.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Change Knative Serving config to use Contour Ingress&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl patch configmap/config-network \
  --namespace knative-serving \
  --type merge \
  --patch &#39;{&amp;quot;data&amp;quot;:{&amp;quot;ingress.class&amp;quot;:&amp;quot;contour.ingress.networking.knative.dev&amp;quot;}}&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;4-install-and-configure-cloud-native-buildpack-using-kpack&#34;&gt;4. Install and Configure Cloud Native Buildpack using &lt;em&gt;kpack&lt;/em&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;kubectl apply -f https://github.com/pivotal/kpack/releases/download/v0.2.2/release-0.2.2.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cloud Native Buildpacks will need a Repository to Store container images that it will be building. This could be any OCI compliant repository, for this guide we will use Docker Hub. You can easily create and account in Docker Hub if you don&amp;rsquo;t have one.&lt;/p&gt;
&lt;p&gt;We need to create a Docker Hub account credentials &lt;em&gt;secret&lt;/em&gt; in Kubernetes. Use the below command and change the &lt;code&gt;docker-username&lt;/code&gt; to the your repo name in Docker Hub. Change the &lt;code&gt;docker-password&lt;/code&gt; to your account password.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create secret docker-registry tutorial-registry-credentials \
    --docker-username=abc \
    --docker-password=********* \
    --docker-server=https://index.docker.io/v1/\
    --namespace default
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cloud Native Buildpacks create Container images using a &lt;code&gt;builder&lt;/code&gt; that uses a predefined &lt;code&gt;stack&lt;/code&gt; of container image layers. You can define custom stack, store and builders. For this guide, we are using standard definitions.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl apply -f https://raw.githubusercontent.com/Boskey/spring-petclinic/main/kpack-config/sa.yaml
kubectl apply -f https://raw.githubusercontent.com/Boskey/spring-petclinic/main/kpack-config/store.yaml
kubectl apply -f https://raw.githubusercontent.com/Boskey/spring-petclinic/main/kpack-config/stack.yaml
kubectl apply -f https://raw.githubusercontent.com/Boskey/spring-petclinic/main/kpack-config/builder.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;5-install-and-configure-argocd&#34;&gt;5. Install and Configure ArgoCD&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Install ArgoCD CLI&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;brew install argocd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Since ArgoCD is installed on a Kind cluster, it does not have a &lt;em&gt;Kubernetes Load Balancing Service type&lt;/em&gt; to expose the ArgoCD service. We will manually expose the ArgoCD service using &lt;code&gt;port-forward&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;On a new Terminal,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl port-forward svc/argocd-server -n argocd 8080:443
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Fetch ArgoCD credentials to login via CLI&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=&amp;quot;{.data.password}&amp;quot; | base64 -d
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Copy the output of the above command, that is the &lt;code&gt;admin&lt;/code&gt; password for ArgoCD
Login to ArgoCD&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argocd login localhost:8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;username: &lt;code&gt;admin&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;password: &lt;code&gt;&amp;lt;copy-paste from the command above&amp;gt;&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We have now installed Knative Serving, Cloud Native Buildpacks and ArgoCD. Its time to implement a workflow that will take our source code and convert it into a URL.&lt;/p&gt;
&lt;h3 id=&#34;6-build-container-image-using-cloud-native-buildpacks&#34;&gt;6. Build Container Image using Cloud Native Buildpacks&lt;/h3&gt;
&lt;p&gt;We will be using the &lt;em&gt;Petclinic&lt;/em&gt; app, the file &lt;code&gt;petclinic-image-build.yaml&lt;/code&gt; tells kpack where the source code is via the &lt;code&gt;spec.source.git.url&lt;/code&gt; , where to upload and what tag to use for the final container image using &lt;code&gt;spec.tag&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Copy this file and change the &lt;code&gt;spec.tag&lt;/code&gt; to your &lt;code&gt;&amp;lt;docker-repo&amp;gt;/&amp;lt;app-name&amp;gt;&lt;/code&gt; and change the &lt;code&gt;spec.source.git.url&lt;/code&gt; to your Git Repo for Petclinic you forked in Step 1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: kpack.io/v1alpha1
kind: Image
metadata:
  name: petclinic-image
  namespace: default
spec:
  tag: boskey/app
  serviceAccount: tutorial-service-account
  builder:
    name: my-builder
    kind: Builder
  source:
    git:
      url: https://github.com/spring-projects/spring-petclinic
      revision: 82cb521d636b282340378d80a6307a08e3d4a4c4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Apply the file using &lt;code&gt;Kubectl&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl apply -f petclinic-image-build.yaml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This process will take around 5 -10 Minutes to finish depending on the resources Docker Desktop has. Keep watching the images CRD to see if the images is finished building.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get images.kpack.io
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once the image is build you should see the output of the Docker Hub URL where the Container image is located. The output should be similar to this.
Capture the Image location from your command to list images.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[bsavla] ci-cd 🐘kubectl get images.kpack.io
NAME        LATESTIMAGE                                                                                          READY
ttv-image   index.docker.io/boskey/app@sha256:949a72120f888b2f37fdf3be0c439422ce4d2225529aa533aae6f6cb85da9424   True
[bsavla] ci-cd 🐘
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;7-update-knative-service-definition&#34;&gt;7. Update Knative Service Definition&lt;/h3&gt;
&lt;p&gt;So far we have built a container image based on the sample app &lt;em&gt;Petclinic&lt;/em&gt;, Now we will deploy the app onto Kubernetes via Knative Serving. ArgoCD will help us automate the deployment. We now need to define a &lt;code&gt;knative-serving&lt;/code&gt; spec for our app. The Git repository you forked already has the below spec in a file called &lt;code&gt;knative-service.yaml&lt;/code&gt; under the &lt;code&gt;knative&lt;/code&gt; folder. This spec file tells Knative where to fetch the container image for the application that needs to be deployed on Kubernetes. Edit the file &lt;code&gt;knative-service.yaml&lt;/code&gt; in the Git repository you forked in step 1. Change the &lt;code&gt;image&lt;/code&gt; property to the image URL you got from kpack (step 6). The file should be under the folder &lt;code&gt;knative&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: serving.knative.dev/v1 # Current version of Knative
kind: Service
metadata:
  name: petclinic-knative # The name of the app
  namespace: default # The namespace the app will use
spec:
  template:
    spec:
      containers:
       - image: index.docker.io/boskey/app@sha256:9595c435357a6105bbd26405d6eaa15bd6a7d4ae4b2e5f42946b169ef9257f76  # generated by kpack
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;8-use-argocd-to-deploy-application&#34;&gt;8. Use ArgoCD to deploy application.&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s create an application using ArgoCD, &lt;strong&gt;Replace the  &lt;code&gt;--repo&lt;/code&gt; URL with the Github repo you forked in Step 1&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argocd app create petclinic --repo https://github.com/Boskey/spring-petclinic.git --path knative --dest-server https://kubernetes.default.svc --dest-namespace default
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This tells ArgoCD to create an application called &lt;em&gt;petclinic&lt;/em&gt; on the local cluster and the &lt;em&gt;&lt;code&gt;--path&lt;/code&gt;&lt;/em&gt; variable tells ArgoCD &lt;em&gt;how&lt;/em&gt; to deploy. In our case the &lt;code&gt;--path&lt;/code&gt; variable points to the &lt;code&gt;knative-serving&lt;/code&gt; specification. So ArgoCD will pass the &lt;code&gt;knative-serving&lt;/code&gt; specification to the local Kubernetes cluster, where the CRD for Knative will understand how to deploy the application and will automatically create Deployments, resource pools, Services etc.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s Sync the app in ArgoCD&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argocd app sync petclinic
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will deploy PetClinic on the Kubernetes Cluster along with a URL petclinic-knative.default.example.com. You can look at all the resource that were created&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get all
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can look at the application deployed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl -n contour-external port-forward svc/envoy 8080:80 
curl -H &amp;quot;Host: petclinic-knative.default.example.com&amp;quot; localhost:8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you want to look at the application on your browser, create a DNS entry in your &lt;code&gt;/etc/hosts&lt;/code&gt; file as below&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;127.0.0.1       petclinic-knative.default.example.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And browse to &lt;a href=&#34;http://localhost:8080&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You should see the Petclinic Application deployed there.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s say you have an update to the PetClinic application, you apply your changes and push them to the repo on Github. To deploy the newer version, all you have to do is create a new container image using &lt;code&gt;kpack&lt;/code&gt; and update the knative-serving specification file with the new image location at &lt;code&gt;knative-service.yaml&lt;/code&gt;. When synced, ArgoCD will detect the change in the file, and re-deploy the application with the newer container image using knative-serving. Knative will detect that this is an updated version of the same application and will deploy the new version with an updated revision.&lt;/p&gt;
&lt;p&gt;You can also create a new deployment for different pipelines like &lt;code&gt;staging&lt;/code&gt; by creating a new application in ArgoCD and pointing them to the same &lt;code&gt;knative-service.yaml&lt;/code&gt; file.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Workshops: SpringOne Tour DevOps</title>
      
      <link>/workshops/lab-springone-tour-devops/</link>
      <pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>/workshops/lab-springone-tour-devops/</guid>
      <description>

        
        &lt;p&gt;During this workshop you will automate the testing and deployment of a Spring Boot app and its backing database to Kubernetes, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the app locally to understand its behavior&lt;/li&gt;
&lt;li&gt;Review embedded testing
&lt;ul&gt;
&lt;li&gt;Unit testing&lt;/li&gt;
&lt;li&gt;Integration testing for APIs using contracts&lt;/li&gt;
&lt;li&gt;Integration testing for databases using Flyway and Testcontainers&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Automate testing using GitHub Actions&lt;/li&gt;
&lt;li&gt;Automate container builds using kpack&lt;/li&gt;
&lt;li&gt;Automate deployment to Kubernetes using GitOps and ArgoCD&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Getting Started with ArgoCD on Kubernetes</title>
      
      <link>/guides/ci-cd/argocd-gs/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/ci-cd/argocd-gs/</guid>
      <description>

        
        &lt;p&gt;ArgoCD is a declarative GitOps tool built to deploy applications to Kubernetes. While the continuous delivery (CD) space is seen by some as crowded these days, ArgoCD does bring some interesting capabilities to the table.&lt;/p&gt;
&lt;p&gt;Unlike other tools, ArgoCD is lightweight and easy to configure. It is purpose-built to deploy applications to Kubernetes so it doesn’t have the UI overhead of many tools built to deploy to multiple locations.&lt;/p&gt;
&lt;p&gt;It was also built with a &lt;a href=&#34;https://www.weave.works/technologies/gitops/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;GitOps&lt;/a&gt; flow in mind. That means everything ArgoCD sees as its source of truth is stored in a repository, which makes permissions and access control easier to handle since no one can change files locally to impact the behavior of ArgoCD. It also increases security by not storing any of these configuration files locally.&lt;/p&gt;
&lt;p&gt;And it’s fast! After using it I am sure you will agree that ArgoCD is very performant. It feels like a native, local application even though it&amp;rsquo;s running distributed microservices on Kubernetes.&lt;/p&gt;
&lt;p&gt;In this guide, you will install ArgoCD onto Kubernetes. Then you will configure ArgoCD to pull Kubernetes configuration files from GitHub, and a Docker image to run from Docker Hub. Then you will “sync” that image to another Kubernetes cluster.&lt;/p&gt;
&lt;p&gt;Ready to get started? Here you go!&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;Before you get started, you will need to do a number of things.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Install &lt;a href=&#34;https://minikube.sigs.k8s.io/docs/start/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Minikube&lt;/a&gt;&lt;/strong&gt;: You will use Minikube to build the Kubernetes clusters referenced in this guide. Other options for running local Kubernetes clusters may also work but have not been tested in this guide.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;kubectl&lt;/a&gt;&lt;/strong&gt;: If you have worked with Kubernetes before, you likely already have kubectl installed. If not, you will need it to manage your clusters, as well as give ArgoCD a way to connect to them through the kubeconfig file.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install &lt;a href=&#34;https://docs.docker.com/desktop/#download-and-install&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Docker&lt;/a&gt; and log in (optional)&lt;/strong&gt;: If you choose, there are some optional steps in this guide for building your own demo application. To perform these steps, you will use Docker to build and push your container to Docker Hub.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Have a &lt;a href=&#34;http://dockerhub.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;DockerHub&lt;/a&gt; account (optional)&lt;/strong&gt;: As discussed above, if you choose to go through the optional steps, you will need a Docker Hub account to push your container to.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set aside 10-15 minutes&lt;/strong&gt;: About how long this guide will take to complete unless you do the optional steps.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;create-the-kubernetes-clusters&#34;&gt;Create the Kubernetes clusters&lt;/h2&gt;
&lt;p&gt;Once you have these config files, the next step is to create two Kubernetes clusters: On one, you will install ArgoCD; the other is where you will push your application and run it.&lt;/p&gt;
&lt;p&gt;You will use &lt;a href=&#34;https://minikube.sigs.k8s.io/docs/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Minikube&lt;/a&gt; to create these clusters. Other options may work, but Minikube is an easy tool for creating multiple clusters without too much troubleshooting when it comes to managing ingress and external connections.&lt;/p&gt;
&lt;p&gt;First, start the target Kubernetes cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;minikube start -p target-k8s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, start the cluster on which you will install ArgoCD.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;minikube start -p argocd-k8s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the next section, you will be working on the &lt;code&gt;argocd-k8s&lt;/code&gt; cluster to complete the install of ArgoCD. Because of the order you created these clusters in, your &lt;code&gt;kubectl context&lt;/code&gt; should already be pointed at this cluster, but it’s good to be sure. The following will confirm that your context is set correctly.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl config use-context argocd-k8s
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;optional-download-the-git-repo&#34;&gt;Optional: Download the git repo&lt;/h2&gt;
&lt;p&gt;As the “&lt;a href=&#34;https://argoproj.github.io/argo-cd/getting_started/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Getting Started&lt;/a&gt;” documentation from ArgoCD will show, the install process is very straightforward (much of this guide uses commands found there). Even so, you will still need some configuration files to get your pipeline to start delivering applications to production.&lt;/p&gt;
&lt;p&gt;Rather than creating everything from scratch, the environment has been created for you. Look through these files and understand their function. If you have some experience with Kubernetes configuration files, they will be fairly straightforward.&lt;/p&gt;
&lt;p&gt;To make this viewing easier, you may decide to clone the repo locally. You will not be changing these files in this guide, as ArgoCD pulls them directly from the repository.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/anthonyvetter/argocd-getting-started.git &amp;amp;&amp;amp; cd argocd-getting-started
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You will have the option of creating these environments using your own GitHub and Docker Hub images later in this post, but it’s not required to get started.&lt;/p&gt;
&lt;h2 id=&#34;install-argocd&#34;&gt;Install ArgoCD&lt;/h2&gt;
&lt;p&gt;Now that you have created your Kubernetes clusters, you can start the install process. It’s really just two commands. The first is to create a namespace where you will install ArgoCD.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create namespace argocd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The second—and mostly final step—is to apply this script from the ArgoCD team, which will take care of the rest.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This command will complete quickly, but pods will still be spinning up on the back end. These need to be in a running state before you can move forward. Use the watch command to ensure the pods are running and ready.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;watch kubectl get pods -n argocd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;: I and several others have run into an issue at this step, where pods will enter a &lt;code&gt;CrashLoopBackOff&lt;/code&gt; or &lt;code&gt;ImgPullError&lt;/code&gt; state. These install steps are exactly the same as on the ArgoCD “Getting Started” guide. If it happens to you, know that I had good luck simply using Minikube to stop and start the Kubernetes cluster again and retrying.&lt;/p&gt;
&lt;p&gt;Once the pods are ready, ArgoCD will be running. But it will not be accessible from outside the cluster. Since this is a demo environment, use port-forward to expose a port to the service, and forward it to &lt;code&gt;localhost&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl port-forward svc/argocd-server -n argocd 8080:443
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once run, your ArgoCD cluster will be available at &lt;a href=&#34;https://localhost:8080&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;https://localhost:8080&lt;/a&gt;. Since you didn’t deploy any certificates, you will need to accept your browser’s certificate exception. The &lt;code&gt;port-forward&lt;/code&gt; command will also now be running in the foreground of your terminal. Open another terminal window or tab and cd back into the working directory.&lt;/p&gt;
&lt;p&gt;In the UI, you will not be able to log in yet. ArgoCD uses the unique name of its server pod as a default password, so every installation will be different. Pretty clever! The following command will list the pods and format the output to provide just the line you want. It will have the format &lt;code&gt;argocd-server-&amp;lt;number&amp;gt;-&amp;lt;number&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get pods -n argocd -l app.kubernetes.io/name=argocd-server -o name | cut -d&#39;/&#39; -f 2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To log in to the ArgoCD UI, the default username is &lt;code&gt;admin&lt;/code&gt; and the default password is the output of the above command. Save this password; you will need it for the next step of installing and configuring the ArgoCD command-line agent.&lt;/p&gt;
&lt;p&gt;At this stage, take some time to familiarize yourself with the ArgoCD UI. While the rest of the steps in this guide can be done either through the UI or the CLI, you will be using the CLI.&lt;/p&gt;
&lt;h2 id=&#34;install-and-set-up-the-argocd-cli&#34;&gt;Install and set up the ArgoCD CLI&lt;/h2&gt;
&lt;p&gt;There are two primary methods for installing the ArgoCD CLI tool. If you are on a Mac computer running brew, there is a tap for argocd. Otherwise, you will need to install the binary from &lt;a href=&#34;https://github.com/argoproj/argo-cd/releases/latest&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;To install with brew&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;brew tap argoproj/tap &amp;amp;&amp;amp; brew install argoproj/tap/argocd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;To install the binary&lt;/strong&gt;: First, you need to confirm the version of ArgoCD you are running. The script does install the latest stable version, but it’s good to ensure version compatibility.
Log in to the ArgoCD UI. In the upper left-hand corner, you will see the ArgoCD squid, and underneath that, you will see the major version listed. Hovering your cursor over it will show the full version string.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/ci-cd/argocd/screenshots/version.png&#34; alt=&#34;ArgoCD Version&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Then go to the &lt;a href=&#34;https://github.com/argoproj/argo-cd/releases&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;releases page&lt;/a&gt; on the ArgoCD GitHub site and find the version associated with your ArgoCD version. Under the Assets section, download the argocd version appropriate for your platform.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/ci-cd/argocd/screenshots/releases.png&#34; alt=&#34;ArgoCD Releases&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Once downloaded, rename the file and move it into your &lt;code&gt;$PATH&lt;/code&gt;. Modify this command for your platform.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mv argocd-darwin-amd64 argocd &amp;amp;&amp;amp; mv argocd /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now that the &lt;code&gt;argocd&lt;/code&gt; client is installed, you can log it into your ArgoCD installation. Use the password from the previous section.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argocd login localhost:8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Again, as with the UI, you will need to accept the server certificate error.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Optional step&lt;/strong&gt;: You can change your password at this stage if you like. This command will prompt you for your current password, your new password, then to confirm that new password.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argocd account update-password
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You are now almost ready to deploy your application. But first you need to tell ArgoCD about your deployment target. By default, if you do not add an additional Kubernetes cluster target, ArgoCD will deploy applications to the cluster on which it is installed. To add your target Kubernetes cluster to ArgoCD, use the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argocd cluster add target-k8s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will add an ArgoCD service account onto the cluster, which will allow ArgoCD to deploy applications to it.&lt;/p&gt;
&lt;h2 id=&#34;optional-the-demo-application&#34;&gt;Optional: The demo application&lt;/h2&gt;
&lt;p&gt;For an application to deploy, you are going to be using &lt;a href=&#34;https://github.com/spring-projects/spring-petclinic&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;spring-petclinic&lt;/a&gt;. It’s an application that is pretty easy to understand, and packaged into a container to run on Kubernetes. It&amp;rsquo;s been packaged already on a public &lt;a href=&#34;https://hub.docker.com/repository/docker/anthonyvetter/spring-petclinic&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;DockerHub&lt;/a&gt; repo. No steps are required in this guide to package your own. You will configure ArgoCD to pull this image.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Optional steps&lt;/strong&gt;: You may, at some point, want to create your own container to pull from your own registry. It is recommended that you run through this guide once as-is so you understand how things work in ArgoCD. But if you are ready to package your own application, these are the steps.&lt;/p&gt;
&lt;p&gt;Within the optional directory of the GitHub repo you cloned, there is a Dockerfile for building spring-petclinic. To build it, run the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker build optional/. -t spring-petclinic
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This Dockerfile uses &lt;a href=&#34;https://maven.apache.org/what-is-maven.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Maven&lt;/a&gt; to package the application in an OCI container image; it will take some time to run. In the end, you will have a container on your local system called spring-petclinic.&lt;/p&gt;
&lt;p&gt;To push this container to DockerHub, first tag your container. Modify this command and the next to add your DockerHub username.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker tag spring-petclinic &amp;lt;your-dh-username&amp;gt;/spring-petclinic:latest
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then push your container to Docker Hub.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker push &amp;lt;your-dh-username&amp;gt;/spring-petclinic
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The configuration files you may have cloned earlier are still written to call from my DockerHub account. And if you have run through this guide once already, you know that ArgoCD pulls those files directly from GitHub (modifying them locally will have no effect on this behavior).&lt;/p&gt;
&lt;p&gt;There are many methods to create your own configuration files for ArgoCD, but the easiest is probably to &lt;a href=&#34;https://help.github.com/en/github/getting-started-with-github/fork-a-repo&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;fork&lt;/a&gt; my repository into your own, then modify the &lt;code&gt;deployment.yml&lt;/code&gt; to pull the image from your DockerHub account. You will then need to modify the later &lt;code&gt;argo app create&lt;/code&gt; flags in the next section to use your GitHub repo.&lt;/p&gt;
&lt;h2 id=&#34;add-your-app-to-argocd&#34;&gt;Add your app to ArgoCD&lt;/h2&gt;
&lt;p&gt;You are now ready to add your application to ArgoCD to monitor and push to your target. But first you need to set up a couple of environment variables so as to make some of the following commands a little easier.&lt;/p&gt;
&lt;p&gt;This variable will tell the argocd CLI client where our ArgoCD installation resides. It gets the cluster information from your kubectl context, but it needs the namespace. Without setting this variable, you will need to add the &lt;code&gt;--port-forward-namespace&lt;/code&gt; flag to all commands run with argocd.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export ARGOCD_OPTS=&#39;--port-forward-namespace argocd&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This variable you will use to tell ArgoCD where your target cluster API URL is.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export MINIKUBE_IP=https://$(minikube ip -p target-k8s):8443
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With these variables set, use argocd to create the application record. Here you are telling ArgoCD to pull in configuration files from my GitHub repository, and that the files are in the root directory. Then you are telling it to deploy that application onto your target cluster, in the default namespace.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argocd app create spring-petclinic --repo https://github.com/anthonyvetter/argocd-getting-started.git --path . --dest-server $MINIKUBE_IP --dest-namespace default
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once this completes, you can see the status and configuration of your app by running the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argocd app list
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Notice the &lt;code&gt;STATUS: OutOfSync&lt;/code&gt; and &lt;code&gt;HEALTH: Missing&lt;/code&gt;. That’s because ArgoCD creates applications with manual triggers by default. Automated triggers are available and are &lt;a href=&#34;https://argoproj.github.io/argo-cd/user-guide/auto_sync/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;straightforward to configure&lt;/a&gt;, but in this guide , you will stick with manual triggers in order to go through the process slowly.&lt;/p&gt;
&lt;p&gt;“Sync” is the terminology ArgoCD uses to describe the application on your target cluster as being up to date with the sources ArgoCD is pulling from. You have set up ArgoCD to monitor the GitHub repository with the configuration files as well as the spring-petclinic container image in Docker Hub. Once the initial sync is completed, a change to either of these sources will cause the status in ArgoCD to change to &lt;code&gt;OutOfSync&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For a more detailed view of your application configuration, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argocd app get spring-petclinic
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now you are ready to sync your application to your target cluster. To do this, simply use the sync command for your application:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argocd app sync spring-petclinic
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once completed, your target Kubernetes cluster will be creating the pod on which spring-petclinic will be running. But as with ArgoCD, the UI will not be available outside the cluster. To forward a port, you first need to change kubectl contexts to your target cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl config use-context target-k8s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Since the argocd CLI client uses your kubectl context to connect to your cluster, any argocd commands you run from this point won’t work. You will need to change contexts back to your argocd-k8s cluster to manage ArgoCD.&lt;/p&gt;
&lt;p&gt;Now simply forward the port as you did for the ArgoCD UI. Once completed, spring-petclinic will be available at &lt;a href=&#34;http://localhost:9090&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;http://localhost:9090&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl port-forward svc/spring-petclinic -n default 9090:8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And there you have it! You have a running application deployed to Kubernetes with ArgoCD. For further learning, try setting up your own environment using the optional steps provided throughout this guide. Find out how to set up &lt;a href=&#34;https://argoproj.github.io/argo-cd/user-guide/auto_sync/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;automated triggers&lt;/a&gt;, and maybe configure ArgoCD with your own custom Kubernetes application. Finally, look at adding ArgoCD into your CI/CD pipeline and deploying applications into external Kubernetes environments.&lt;/p&gt;
&lt;p&gt;For further learning, the &lt;a href=&#34;https://argoproj.github.io/argo-cd/operator-manual/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Operator Manual&lt;/a&gt; from ArgoCD is a terrific resource. If you want to look at developing a third-party integration for ArgoCD, see the Developer &lt;a href=&#34;https://argoproj.github.io/argo-cd/developer-guide/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Guides&lt;/a&gt;.&lt;/p&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/css/faq.css&#34;&gt;
&lt;div class=&#34;faqs&#34; id=&#34;faqs&#34;&gt;
    &lt;div class=&#34;flex-container jc-between&#34;&gt;&lt;/div&gt;
        &lt;h2 class=&#34;h2 mb-md&#34;&gt;Frequently Asked Questions&lt;/h2&gt;
        &lt;div class=&#34;faq&#34;&gt;
            
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;How do you install ArgoCD on Kubernetes?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;After creating a Kubernetes cluster, ArgoCD can be installed with two simple commands. First, create a namespace to install the ArgoCD and run the command &lt;code&gt;kubectl create namespace argocd&lt;/code&gt;. Finally, apply the script &lt;code&gt;kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml&lt;/code&gt; to finish the install.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;What are the benefits of using ArgoCD on Kubernetes?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Because ArgoCD can apply git repository configurations to Kubernetes, it assists in the lifecycle management and accelerated deployment of &lt;a href=&#34;https://tanzu.vmware.com/cloud-native&#34;&gt;cloud-native applications&lt;/a&gt;.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;How do you install ArgoCD CLI?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;On Mac, the ArgoCD CLI can be installed with &lt;code&gt;brew&lt;/code&gt;, where there is a tap for ArgoCD. Otherwise, the binary will need to be installed by navigating to ArgoCD releases page, installing the correct version appropriate for your platform, renaming the file, modifying the command, logging in, and deploying your application.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;How do you deploy apps to ArgoCD in Kubernetes?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;After Installation of the ArgoCD CLI, to deploy your applications with ArgoCD, first tell ArgoCD about your deployment target Kubernetes cluster using the command &lt;code&gt;argocd cluster add target-k8s&lt;/code&gt;, then configure ArgoCD to pull the image using &lt;a href=&#34;https://github.com/spring-projects/spring-petclinic&#34;&gt;spring-petclinic&lt;/a&gt;. Finally, push your container to DockerHub and create your own configuration files, or &lt;a href=&#34;https://docs.github.com/en/get-started/quickstart/fork-a-repo&#34;&gt;fork our repository&lt;/a&gt; into your own.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;How do you add a Kubernetes cluster to ArgoCD?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Kubernetes clusters can be added to ArgoCD by installing the proper configuration files, installing ArgoCD on a Kubernetes cluster, then starting both the target cluster and the cluster in which you installed ArgoCD.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;What is ArgoCD sync?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;“Sync” is the terminology ArgoCD uses to describe the application on your target cluster as being up to date with the sources ArgoCD is pulling from.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

        &lt;/div&gt;
    &lt;/div&gt;
    
&lt;/div&gt;

&lt;script type=&#34;text/javascript&#34;&gt;
    $(&#34;.faq-item&#34;).each( function() {
        $(this).click(function () {
            $(this).find(&#34;#arrow&#34;).toggleClass(&#34;flip&#34;); 
            $(this).find(&#34;.faq-answer&#34;).slideToggle(200); 
        });
    });
&lt;/script&gt;

      </description>
    </item>
    
  </channel>
</rss>
