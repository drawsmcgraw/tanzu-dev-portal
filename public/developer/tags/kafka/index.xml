<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>VMware Tanzu Developer Center – Kafka</title>
    <link>/tags/kafka/</link>
    <description>Recent content in Kafka on VMware Tanzu Developer Center</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 24 Feb 2021 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      
      <title>Guides: What are Spring Cloud Connectors?</title>
      
      <link>/guides/spring/spring-cloud-connectors/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/guides/spring/spring-cloud-connectors/</guid>
      <description>

        
        &lt;p&gt;&lt;a href=&#34;https://cloud.spring.io/spring-cloud-connectors/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Spring Cloud Connectors&lt;/a&gt; is a project that simplifies the process of connecting Spring applications to services in cloud platforms and gaining operational awareness of those platforms. It is designed for extensibility: you can use one of the provided cloud connectors or write one for your cloud platform, you can use the built-in support for commonly-used services (like relational databases, MongoDB, Redis, RabbitMQ), or extend Spring Cloud Connectors to work with your own services.&lt;/p&gt;
&lt;h2 id=&#34;cloud-platform-support&#34;&gt;Cloud Platform Support&lt;/h2&gt;
&lt;p&gt;Out of the box, Spring Cloud Connectors offers support for the Cloud Foundry and Heroku platforms. You can also extend Spring Cloud Connectors to provide support for other cloud platforms and providers.&lt;/p&gt;
&lt;p&gt;Spring Cloud Connectors uses the &lt;code&gt;CloudConnector&lt;/code&gt; interface to provide cloud platform support. A &lt;code&gt;CloudConnector&lt;/code&gt; implementation for a particular cloud platform is responsible for detecting when the application is running in that cloud platform, obtaining information about the application from the cloud platform, and obtaining information about the services that are bound to the application.&lt;/p&gt;
&lt;h2 id=&#34;cloud-service-support&#34;&gt;Cloud Service Support&lt;/h2&gt;
&lt;p&gt;You can extend Spring Cloud Connectors to support additional services, including services that are specific to your own environment or application. Spring Cloud Connectors uses two interfaces to provide cloud service support:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;ServiceInfo&lt;/code&gt; models the information required to connect to the service. In the case of a database service, a ServiceInfo implementation might include fields for host, port, database name, username, and password; in the case of a web service, it might include fields for URL and API key.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;ServiceInfoCreator&lt;/code&gt; creates &lt;code&gt;ServiceInfo&lt;/code&gt; objects based on the service information collected by a cloud connector. A ServiceInfoCreator implementation is specific to a cloud platform.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;application-framework-support&#34;&gt;Application Framework Support&lt;/h2&gt;
&lt;p&gt;The Spring Cloud Spring Service Connector creates service connectors with Spring Data data types. You can extend Spring Cloud Connectors to provide service connection objects using another framework.&lt;/p&gt;
&lt;p&gt;Spring Cloud Connectors uses the &lt;code&gt;ServiceConnectorCreator&lt;/code&gt; interface to provide framework support. A &lt;code&gt;ServiceConnectorCreator&lt;/code&gt; creates service connectors using the service connection information provided by a &lt;code&gt;ServiceInfo&lt;/code&gt; object.&lt;/p&gt;
&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;
&lt;h3 id=&#34;using-the-cloud-foundry-connector&#34;&gt;Using the Cloud Foundry Connector&lt;/h3&gt;
&lt;p&gt;The Cloud Foundry connector discovers services that are bound to an application running in Cloud Foundry. (Since Cloud Foundry enumerates each service in a consistent format, Spring Cloud Connectors does not care which service provider is providing it.)&lt;/p&gt;
&lt;p&gt;This connector checks for the presence of a &lt;code&gt;VCAP_APPLICATION&lt;/code&gt; environment variable. This is a system-provided environment variable which is specific to Cloud Foundry. If the variable exists, the connector will be activated.&lt;/p&gt;
&lt;p&gt;Cloud Foundry users may define their own user-provided service using the &lt;code&gt;cf&lt;/code&gt; CLI. The command is of the format:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;cf cups &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;service-name&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; -p &lt;span class=&#34;s2&#34;&gt;&amp;#34;comma,separated,list,of,params&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example: &lt;code&gt;cf cups oracle-db-service -p &amp;quot;jdbcUrl&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Once the service is defined, you bind the service to your application and then consume the &lt;code&gt;VCAP_SERVICES&lt;/code&gt; environment variable, which stores connection and identification information for service instances that are bound to Cloud Foundry apps.&lt;/p&gt;
&lt;p&gt;A sample &lt;code&gt;VCAP_SERVICES&lt;/code&gt; entry looks like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;VCAP_SERVICES&amp;#34;: &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;user-provided&amp;#34;: &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;credentials&amp;#34;: &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;jdbcUrl&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;oracle://$user:$password@$hostname:$port/$name&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;}&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;label&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;user-provided&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;oracle-db-service&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;syslog_drain_url&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;tags&amp;#34;: &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;volume_mounts&amp;#34;: &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;}&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;credentials&amp;#34;: &lt;/span&gt;{&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;hosts&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;localhost:8080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;password&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;welcome&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;username&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;}&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;label&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;user-provided&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;cassandra-service&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;syslog_drain_url&amp;#34;: &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;tags&amp;#34;: &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;volume_mounts&amp;#34;: &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In your code, you can parse this information to retrieve connection details or create a custom Spring Cloud connector.&lt;/p&gt;
&lt;h3 id=&#34;creating-a-kafka-connector&#34;&gt;Creating a Kafka Connector&lt;/h3&gt;
&lt;p&gt;Let’s look at creating a Kafka connector to consume a Kafka user-provided service. This is accomplished in three steps:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Create a &lt;code&gt;KafkaServiceInfo&lt;/code&gt; by extending the &lt;code&gt;BaseServiceInfo&lt;/code&gt; from the spring-cloud-connector library:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;com.example.kafka&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;org.springframework.cloud.service.BaseServiceInfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;KafkaServiceInfo&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;extends&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;BaseServiceInfo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;

    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;KafkaServiceInfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   	 &lt;span class=&#34;kd&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;KafkaServiceInfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;url&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   	 &lt;span class=&#34;kd&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
   	 &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;url&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;url&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
   	 &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;username&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
   	 &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;password&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;url&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;

    &lt;span class=&#34;nd&#34;&gt;@ServiceProperty&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;getUrl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   	 &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;url&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;nd&#34;&gt;@ServiceProperty&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;getUsername&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   	 &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;nd&#34;&gt;@ServiceProperty&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;getPassword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   	 &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;toString&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   	 &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;KafkaServiceInfo [url=&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;url&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;, username=&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;username&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;, password=&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;password&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;2. Create a &lt;code&gt;KafkaServiceInfoCreator&lt;/code&gt; by extending &lt;code&gt;CloudFoundryServiceInfoCreator&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;com.example.kafka&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;java.util.Map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;org.springframework.cloud.cloudfoundry.CloudFoundryServiceInfoCreator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;org.springframework.cloud.cloudfoundry.Tags&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;KafkaServiceInfoCreator&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;extends&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CloudFoundryServiceInfoCreator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KafkaServiceInfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;

    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;KafkaServiceInfoCreator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   	 &lt;span class=&#34;kd&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Tags&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;kafka&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KafkaServiceInfo&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;createServiceInfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;serviceData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   	 &lt;span class=&#34;nd&#34;&gt;@SuppressWarnings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;unchecked&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
   	 &lt;span class=&#34;n&#34;&gt;Map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;credentials&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;serviceData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;credentials&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

   	 &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;serviceData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
   	 &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;servers&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;credentials&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;servers&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
   	 &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;clientId&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;credentials&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;clientId&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

   	 &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KafkaServiceInfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;servers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;clientId&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;boolean&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;accept&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;serviceData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   	 &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;serviceData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
   	 &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;startsWith&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;kafka&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Kicks in only if the service name starts with kafka
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;KafkaServiceInfoCreator&lt;/code&gt; parses the JSON presented by the &lt;code&gt;VCAP_SERVICES&lt;/code&gt; and creates the &lt;code&gt;KafkaServiceInfo&lt;/code&gt; and it&amp;rsquo;s ready for use in the code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. To allow these classes to be discovered by spring cloud connectors when using Cloud Foundry, create a file &lt;code&gt;org.springframework.cloud.cloudfoundry.CloudFoundryServiceInfoCreator&lt;/code&gt; in &lt;code&gt;src/main/resources/META-INF/services/&lt;/code&gt; and add the &lt;code&gt;com.example.kafka.KafkaServiceInfoCreator&lt;/code&gt; to it&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;To consume the &lt;code&gt;kafka-service&lt;/code&gt; that is created using the &lt;code&gt;cf cli``cf cups kafka-service -p &#39;servers,clientId&#39;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The following code is required:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;  &lt;span class=&#34;n&#34;&gt;Cloud&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cloud&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CloudFactory&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getCloud&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;KafkaServiceInfo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kafkaServiceInfo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KafkaServiceInfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cloud&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getServiceInfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;kafka-service&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Now the &lt;code&gt;KafkaServiceInfo&lt;/code&gt; is ready for creating a connection to Kafka service&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;creating-a-cloud-database-connection&#34;&gt;Creating a Cloud Database Connection&lt;/h3&gt;
&lt;p&gt;Creating and using a cloud database connection is a simple three-step process.&lt;/p&gt;
&lt;h4 id=&#34;1-include-the-maven-dependency&#34;&gt;1. Include the maven dependency&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
   &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&#34;nt&#34;&gt;&amp;lt;/group&amp;gt;&lt;/span&gt;
   &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-boot-starter-cloud-connectors&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;2-create-a-cloud-configuration-class&#34;&gt;2. Create a Cloud Configuration class&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Configuration&lt;/span&gt;
&lt;span class=&#34;nd&#34;&gt;@Profile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;cloud&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;CloudConfig&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;extends&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AbstractCloudConfig&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;

    &lt;span class=&#34;nd&#34;&gt;@Bean&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DataSource&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;dataSource&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;connectionFactory&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;dataSource&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;3-optionally-create-an-application-cloudproperties-file&#34;&gt;3. Optionally, create an &lt;code&gt;application-cloud.properties&lt;/code&gt; file&lt;/h4&gt;
&lt;p&gt;This file should contain information about the DB used in the cloud if different than test/standalone. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-property&#34; data-lang=&#34;property&#34;&gt;spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.MySQL5Dialects
spring.datasource.platform=mysql
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;keep-learning&#34;&gt;Keep Learning&lt;/h2&gt;
&lt;p&gt;For more information about Spring Cloud Connectors and a Quick Start tutorial, refer to the &lt;a href=&#34;https://cloud.spring.io/spring-cloud-connectors/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Spring Cloud Connectors page on Spring.io&lt;/a&gt;. You may also want to learn more about &lt;a href=&#34;http://cloud.spring.io/spring-cloud-connectors/spring-cloud-connectors.html#_extending_spring_cloud_connectors&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Extending Spring Cloud Connectors&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To learn about connecting to external datasources, see the guide &lt;a href=&#34;/guides/spring/spring-cloud-connectors-datasources&#34;&gt;Spring Cloud Connectors and Datasources&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Blog: Understanding the Differences Between RabbitMQ vs Kafka</title>
      
      <link>/blog/understanding-the-differences-between-rabbitmq-vs-kafka/</link>
      <pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/understanding-the-differences-between-rabbitmq-vs-kafka/</guid>
      <description>

        
        &lt;p&gt;Three years ago, a colleague of mine wrote a post to help readers understand when to use RabbitMQ and when to use Apache Kafka, which many found to be very useful. While the two solutions take very different approaches architecturally and can solve very different problems, many find themselves comparing them for overlapping solutions. In an increasingly distributed environment where more and more services need to communicate with each other, RabbitMQ and Kafka have both come to be popular services that facilitate that communication.&lt;/p&gt;
&lt;p&gt;It has been three years since that post was published, however, which in technology can be lifetime. We thought this would be a great opportunity to revisit how RabbitMQ and Kafka have changed, check if their strengths have shifted, and see how they fit into today’s use case.&lt;/p&gt;
&lt;h2 id=&#34;what-are-rabbitmq-and-apache-kafka&#34;&gt;What Are RabbitMQ and Apache Kafka?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.rabbitmq.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;RabbitMQ&lt;/a&gt; is often summarized as an “open source &lt;a href=&#34;https://www.rabbitmq.com/tutorials/amqp-concepts.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;distributed message broker&lt;/a&gt;.” Written in Erlang, it facilitates the efficient delivery of messages in complex routing scenarios. Initially built around the popular &lt;a href=&#34;https://www.amqp.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;AMQP&lt;/a&gt; protocol, it’s also highly compatible with existing technologies, while its capabilities can be expanded through plug-ins enabled on the server. RabbitMQ brokers can be &lt;a href=&#34;https://www.rabbitmq.com/distributed.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;distributed&lt;/a&gt; and configured to be reliable in case of network or server failure.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://kafka.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Apache Kafka,&lt;/a&gt; on the other hand, is described as a “distributed event streaming platform.” Rather than focusing on flexible routing, it instead facilitates raw throughput. Written in Scala and Java, Kafka builds on the idea of a “distributed append-only log” where messages are written to the end of a log that’s persisted to disk, and clients can choose where they begin reading from that log. Likewise, Kafka clusters can be distributed and clustered across multiple servers for a higher degree of availability.&lt;/p&gt;
&lt;h2 id=&#34;rabbitmq-vs-kafka&#34;&gt;RabbitMQ vs. Kafka&lt;/h2&gt;
&lt;p&gt;While they’re not the same service, many often narrow down their messaging options to these two, but are left wondering which of them is better. I’ve long believed that’s not the correct question to ask. Instead, you want to focus on what each service excels at, analyze their differences, and then decide which of the two best fits your use case. Even outside of the features of either service, you should also take into consideration the skills needed to operate the services and the developer communities around them.&lt;/p&gt;
&lt;h2 id=&#34;requirements-and-use-cases&#34;&gt;Requirements and Use Cases&lt;/h2&gt;
&lt;p&gt;When the initial blog post was written, there was a pretty clear-cut difference in design between RabbitMQ and Kafka, and as such, a difference in use cases. RabbitMQ’s message broker design excelled in use cases that had specific routing needs and per-message guarantees, whereas Kafka’s append-only log allowed developers access to the stream history and more direct stream processing. While the Venn diagram of use cases these two technologies could fulfill was very tight, there were scenarios in which one was a demonstrably better choice than the other.&lt;/p&gt;
&lt;p&gt;Work is currently underway that will alter  that balance, however. While RabbitMQ will continue to offer its traditional queue model, it will also  introduce a new data structure modeling an append-only log, with non-destructive consuming semantics. This new data structure will work much like Kafka’s persistent log, and will be an exciting addition for RabbitMQ users looking to expand their streaming use case. And while this feature will be compatible with the AMQP protocol, it will also introduce a binary-based stream protocol.&lt;/p&gt;
&lt;h2 id=&#34;developer-experience&#34;&gt;Developer Experience&lt;/h2&gt;
&lt;p&gt;The developer experience of the two services has largely remained the same, with the list of clients and libraries continuing to grow thanks to the work of their respective communities. Both &lt;a href=&#34;https://www.rabbitmq.com/devtools.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;RabbitMQ’s&lt;/a&gt; and &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/Clients&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kafka’s&lt;/a&gt; client library lists have seen steady growth. As more languages and frameworks have grown in popularity, finding a well-supported and complete library for either service has become easier.&lt;/p&gt;
&lt;p&gt;One thing to note is the growth of &lt;a href=&#34;https://kafka.apache.org/documentation/streams/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kafka Streams&lt;/a&gt;, a client library implementation that makes it easier for developers to process streaming data. It’s used for the common use case of reading data from Kafka, processing it, and writing it to another Kafka queue. Additionally, &lt;a href=&#34;https://ksqldb.io&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;ksqlDB&lt;/a&gt; is well worth checking out for developers looking to build streaming applications while taking advantage of their familiarity with relational databases.&lt;/p&gt;
&lt;p&gt;A similar thing can be accomplished with RabbitMQ with the help of some other pieces, such as &lt;a href=&#34;https://dataflow.spring.io/docs/stream-developer-guides/streams/standalone-stream-rabbitmq/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Spring Cloud Data Flow&lt;/a&gt;. Furthermore, note the upcoming streaming changes coming for RabbitMQ mentioned in the previous section, keeping in mind that this can open new ways of interacting with RabbitMQ for the developer.&lt;/p&gt;
&lt;h2 id=&#34;security-and-operations&#34;&gt;Security and Operations&lt;/h2&gt;
&lt;p&gt;As noted in the initial post, RabbitMQ ships with a useful administration interface to manage users and queues, while Kafka relies on &lt;a href=&#34;https://www.rabbitmq.com/ssl.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;TLS&lt;/a&gt; and &lt;a href=&#34;https://www.rabbitmq.com/access-control.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;JAAS&lt;/a&gt;. Whether you choose RabbitMQ or Kafka will of course depend on your specific requirements and your use case, but most security scenarios can have a proper conclusion with either technology.&lt;/p&gt;
&lt;p&gt;It’s important to note the rise of Kubernetes over the last few years and how it affects the operations of services. Substantial work has been done to allow infrastructure operators to run both RabbitMQ and Kafka on Kubernetes. The &lt;a href=&#34;https://www.rabbitmq.com/blog/2020/11/17/rabbitmq-kubernetes-operator-reaches-1-0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;RabbitMQ operator&lt;/a&gt; and &lt;a href=&#34;https://bitnami.com/stack/kafka/helm&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kafka Helm chart&lt;/a&gt; both have very fine control over how these services are configured as well as how to run them on Kubernetes specifically. This makes it extremely easy to get up and running with both of them configured and clustered out of the box.&lt;/p&gt;
&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;
&lt;p&gt;Performance, as was also noted in the initial post, can be hard to quantify with so many variables coming into play, including how the service is configured, how your code interacts with it, and of course the hardware it&amp;rsquo;s running on. Everything from network to memory and disk speed can dramatically impact the performance of the service. Of course, both RabbitMQ and Kafka optimize for performance, but you should also make sure your use case leverages them to maximize efficiency.&lt;/p&gt;
&lt;p&gt;For RabbitMQ, there are some great how-to resources  about maximizing performance, such as how to &lt;a href=&#34;https://www.rabbitmq.com/blog/2020/06/04/how-to-run-benchmarks/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;benchmark&lt;/a&gt; and &lt;a href=&#34;https://www.rabbitmq.com/blog/2020/06/18/cluster-sizing-and-other-considerations/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;size your cluster&lt;/a&gt;. These guides detail best practices for how to configure your clusters and how your code should interact with them for the best performance possible. Much of this advice revolves around things like managing queue size and connections, and being careful about how your client consumes messages. The &lt;a href=&#34;https://www.rabbitmq.com/clustering.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;RabbitMQ clustering guide&lt;/a&gt;  also includes things to keep in mind when building a cluster.&lt;/p&gt;
&lt;p&gt;Likewise, Confluent has a great &lt;a href=&#34;https://docs.confluent.io/current/kafka/deployment.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Running Kafka in Production&lt;/a&gt; guide that covers many of the same concerns for when you’re building the hardware that will run your Kafka cluster, as well as how you configure the cluster itself. There are a couple of things you’ll need to keep in mind since Kafka runs on top of the JVM, but it does a great job of pointing those out.&lt;/p&gt;
&lt;p&gt;If you’re interested in raw numbers, both the &lt;a href=&#34;https://www.rabbitmq.com/blog/category/performance-2/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;RabbitMQ team&lt;/a&gt; and the &lt;a href=&#34;https://www.confluent.io/blog/kafka-fastest-messaging-system/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Confluent team&lt;/a&gt; have recently put out their respective benchmarks. Both include a lot of details on how the clusters were configured and the workload that was placed on them, so make sure you take that information into consideration when reading the results. Use case and operations should significantly factor into your decision as well.&lt;/p&gt;
&lt;h2 id=&#34;making-the-call&#34;&gt;Making the Call&lt;/h2&gt;
&lt;p&gt;Deciding whether to use RabbitMQ or Kafka was never easy, and with both technologies improving every day, the margins of advantage have only gotten smaller.  The decision you make will depend on your individual scenario. Make use of the knowledge contained both in this post and the &lt;a href=&#34;https://tanzu.vmware.com/content/blog/understanding-when-to-use-rabbitmq-or-apache-kafka&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;original one&lt;/a&gt; and apply it to the familiarity you have with your use case along with any proof of concepts.&lt;/p&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/css/faq.css&#34;&gt;
&lt;div class=&#34;faqs&#34; id=&#34;faqs&#34;&gt;
    &lt;div class=&#34;flex-container jc-between&#34;&gt;&lt;/div&gt;
        &lt;h2 class=&#34;h2 mb-md&#34;&gt;Frequently Asked Questions&lt;/h2&gt;
        &lt;div class=&#34;faq&#34;&gt;
            
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;What is the difference between Kafka and RabbitMQ?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Kafka is a distributed event streaming platform that facilitates raw throughput, focused on a distributed append-only log that can be clustered across multiple servers for a higher degree of availability. This differs from RabbitMQ, an open source distributed message broker that efficiently facilitates the delivery of messages in complex routing scenarios. RabbitMQ capabilities can be expanded through the use of plug-ins enabled on the server. They can also be distributed and configured to be reliable in the case of server or network failure.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;When should you use Kafka vs RabbitMQ?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Kafka&amp;rsquo;s append-only log allows developers to access stream history and direct stream processing, while RabbitMQ&amp;rsquo;s message broker design excels in use cases that have specific routing needs and per-message guarantees. However, RabbitMQ is developing a new data structure model to the append-only log that will close the gap in streaming use cases.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;Can Kafka and RabbitMQ be deployed on Kubernetes?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Yes, both Kafka and RabbitMQ can be deployed on Kubernetes.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;Should you use Kafka or RabbitMQ for microservices?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;While Kafka utilizes a straightforward, high performance routing approach ideal for big data use cases, RabbitMQ is ideal for blocking tasks and allows for faster server response time. Both options are suitable depending on your specific use case.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;Is Kafka higher performance than RabbitMQ?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Both Kafka and RabbitMQ optimize for performance, which can be very hard to quantify depending on your specific use case. While Kafka has a very high throughput, RabbitMQ excels at low latency message delivery. Of course, service configuration, code interaction, hardware, and network speed will dramatically impact the performance of either service.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
  &lt;div class=&#34;faq-item&#34; id=&#34;faq-item&#34;&gt;
    &lt;div class=&#34;flex jc-between ai-center&#34;&gt;
        &lt;h4 class=&#34;faq-question&#34;&gt;What are the different use cases for Kafka vs. RabbitMQ?&lt;/h4&gt;
        &lt;i class=&#34;fa fa-angle-down&#34; id=&#34;arrow&#34;&gt;&lt;/i&gt;
    &lt;/div&gt;
    &lt;div class=&#34;faq-answer&#34;&gt;
        &lt;div&gt;Kafka is ideal for big data use cases that require the best throughput, while RabbitMQ is ideal for low latency message delivery, guarantees on a per-message basis, and complex routing.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

        &lt;/div&gt;
    &lt;/div&gt;
    
&lt;/div&gt;

&lt;script type=&#34;text/javascript&#34;&gt;
    $(&#34;.faq-item&#34;).each( function() {
        $(this).click(function () {
            $(this).find(&#34;#arrow&#34;).toggleClass(&#34;flip&#34;); 
            $(this).find(&#34;.faq-answer&#34;).slideToggle(200); 
        });
    });
&lt;/script&gt;
&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;
&lt;p&gt;If you’re new to messaging services, a great place to start learning is with our resources for &lt;a href=&#34;/patterns/eventing/&#34;&gt;event-driven architecture&lt;/a&gt;. If you’re a Spring developer, make sure to check out our guides to get started with &lt;a href=&#34;/guides/messaging-and-integration/rabbitmq-gs&#34;&gt;RabbitMQ&lt;/a&gt;, &lt;a href=&#34;/guides/messaging-and-integration/kafka-gs/&#34;&gt;Kafka&lt;/a&gt;, and &lt;a href=&#34;/guides/event-streaming/scs-gs/&#34;&gt;Spring Cloud Stream&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Build a Scalable, Fault-Tolerant Messaging Cluster on Kubernetes with Apache Kafka and MongoDB</title>
      
      <link>/guides/messaging-and-integration/kafka-mongodb/</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/messaging-and-integration/kafka-mongodb/</guid>
      <description>

        
        &lt;p&gt;&lt;a href=&#34;https://kafka.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Apache Kafka&lt;/a&gt; is a popular open source tool for real-time publish/subscribe messaging. It uses a scalable, fault-tolerant cluster for message storage, and it can also be integrated with other open source data-oriented solutions such as &lt;a href=&#34;https://hadoop.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&#34;https://spark.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Apache Spark&lt;/a&gt; or &lt;a href=&#34;https://hbase.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Apache HBase&lt;/a&gt; for real-time analysis and rendering of streaming data.&lt;/p&gt;
&lt;p&gt;Apache Kafka provides a &lt;a href=&#34;https://kafka.apache.org/documentation/#connectapi&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Connect API&lt;/a&gt;, which allows external storage systems to be integrated with Kafka. One such example is the &lt;a href=&#34;https://www.mongodb.com/kafka-connector&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;MongoDB Kafka Connector&lt;/a&gt;, which allows Kafka messages to be stored in MongoDB, or MongoDB data to be published to Kafka. This integration allows users to combine Kafka&amp;rsquo;s real-time messaging features with the powerful document-oriented data querying capabilities of MongoDB.&lt;/p&gt;
&lt;p&gt;Bitnami offers secure and up-to-date Helm charts for &lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/kafka&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Apache Kafka&lt;/a&gt; and &lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/mongodb&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;MongoDB&lt;/a&gt;. These charts can be used to deploy and integrate Apache Kafka and MongoDB on Kubernetes, adding improved scalability and reliability and ensuring that the deployments conform to current best practices. This article walks you through the integration.&lt;/p&gt;
&lt;h2 id=&#34;assumptions-and-prerequisites&#34;&gt;Assumptions and prerequisites&lt;/h2&gt;
&lt;p&gt;This article explains the process of integrating Apache Kafka and MongoDB on Kubernetes, such that messages published on Kafka topics are automatically stored as documents in a MongoDB collection using a sink connector. It assumes that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You have a Docker environment installed and configured. &lt;a href=&#34;https://docs.docker.com/engine/installation/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Learn more about installing Docker&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You have a Docker Hub account. &lt;a href=&#34;https://hub.docker.com&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Register for a free account&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You have a Kubernetes cluster running with Helm v3.x and &lt;em&gt;kubectl&lt;/em&gt; installed. &lt;a href=&#34;https://docs.bitnami.com/kubernetes/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Learn more about getting started with Kubernetes and Helm using different cloud providers&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-1-deploy-mongodb-on-kubernetes&#34;&gt;Step 1: Deploy MongoDB on Kubernetes&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;If you already have a MongoDB deployment, you can use that instead and skip to &lt;a href=&#34;#step-2-create-and-publish-a-custom-mongodb-kafka-connector-image&#34;&gt;Step 2&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The first step is to deploy a MongoDB service on Kubernetes. The simplest way to do this is with Bitnami&amp;rsquo;s MongoDB Helm chart. Follow the steps below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Add the Bitnami chart repository to Helm:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Execute the following command to deploy MongoDB. Remember to replace the MONGODB-ROOT-PASSWORD placeholder with a custom password for the MongoDB administrator account.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install mongodb bitnami/mongodb --set auth.rootPassword&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;MONGODB-ROOT-PASSWORD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Wait for a few minutes until the chart is deployed.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;See the &lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/mongodb#parameters&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;complete list of parameters supported by the Bitnami MongoDB Helm chart&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the commands shown in the &amp;ldquo;Notes&amp;rdquo; section to create a MongoDB client and connect to the MongoDB service. Remember to replace the MONGODB-ROOT-PASSWORD placeholder with the password defined at deployment time.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl run --namespace default mongodb-client --rm --tty -i --restart&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Never&amp;#39;&lt;/span&gt; --image docker.io/bitnami/mongodb:4.2.8-debian-10-r39 --command -- bash
mongo admin --host &lt;span class=&#34;s2&#34;&gt;&amp;#34;mongodb&amp;#34;&lt;/span&gt; --authenticationDatabase admin -u root -p MONGODB-ROOT-PASSWORD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At the MongoDB command prompt, create a new MongoDB database and user, and grant the user access to the database. The commands below create a new database named &lt;em&gt;mydb&lt;/em&gt; and a user account named &lt;em&gt;user&lt;/em&gt; with full privileges on that database. Replace the MONGODB-USER-PASSWORD placeholder with a custom password.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;use mydb
db.createUser&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;
  &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
    user: &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;,
    pwd: &lt;span class=&#34;s2&#34;&gt;&amp;#34;MONGODB-USER-PASSWORD&amp;#34;&lt;/span&gt;,
    roles: &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt; role: &lt;span class=&#34;s2&#34;&gt;&amp;#34;dbOwner&amp;#34;&lt;/span&gt;, db: &lt;span class=&#34;s2&#34;&gt;&amp;#34;mydb&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
  &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exit the MongoDB CLI and terminate the client pod.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-2-create-and-publish-a-custom-mongodb-kafka-connector-image&#34;&gt;Step 2: Create and publish a custom MongoDB Kafka Connector image&lt;/h2&gt;
&lt;p&gt;The next step is to create a container image with the MongoDB Connector for Apache Kafka. This image should also include the Kafka Connect application, which takes care of streaming data between Apache Kafka and other storage systems (such as MongoDB). Follow these steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Create a file named &lt;em&gt;Dockerfile&lt;/em&gt; with the following content:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM bitnami/kafka:latest

RUN mkdir -p /opt/bitnami/kafka/plugins &amp;amp;&amp;amp; \
    cd /opt/bitnami/kafka/plugins &amp;amp;&amp;amp; \
    curl --remote-name --location --silent https://search.maven.org/remotecontent?filepath=org/mongodb/kafka/mongo-kafka-connect/1.2.0/mongo-kafka-connect-1.2.0-all.jar

CMD /opt/bitnami/kafka/bin/connect-standalone.sh /opt/bitnami/kafka/config/connect-standalone.properties /opt/bitnami/kafka/config/mongo.properties
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This &lt;em&gt;Dockerfile&lt;/em&gt; uses Bitnami&amp;rsquo;s Kafka container image as its base image. This is because the Bitnami Kafka container image already contains a working Apache Kafka environment, including the Kafka Connect application and other required dependencies, configuration files and libraries.&lt;/p&gt;
&lt;p&gt;After selecting the base image, this &lt;em&gt;Dockerfile&lt;/em&gt; performs two main actions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It downloads the latest version of the MongoDB Connector for Apache Kafka and adds it to the image.&lt;/li&gt;
&lt;li&gt;It starts the Kafka Connect application in &amp;ldquo;standalone mode&amp;rdquo;, passing it a set of configuration files. These files contain the information needed for Kafka Connect to integrate with both Apache Kafka and MongoDB. The files are not included in the image at this point; instead, they will be defined using a Kubernetes &lt;em&gt;ConfigMap&lt;/em&gt; in a later step.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;At the time of writing, the latest version of the MongoDB Connector for Apache Kafka is v1.2.0. Replace this with the most recent version when using the Dockerfile shown above. You can find the latest version on &lt;a href=&#34;https://github.com/mongodb/mongo-kafka/releases&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;the project&amp;rsquo;s GitHub page&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Build the image using the command below. Replace the DOCKER-USERNAME placeholder in the command below with your Docker account username.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker build -t DOCKER-USERNAME/mykafka:1.0 .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The result of this command is a Docker image containing Apache Kafka, Kafka Connect, the MongoDB Connector for Apache Kafka and all the related dependencies.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Log in to Docker Hub and publish the image. Replace the DOCKER-USERNAME placeholder in the command below with your Docker account username.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker login
docker push DOCKER-USERNAME/mykafka:1.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-3-deploy-apache-kafka-and-kafka-connect-on-kubernetes&#34;&gt;Step 3: Deploy Apache Kafka and Kafka Connect on Kubernetes&lt;/h2&gt;
&lt;p&gt;The next step is to deploy Apache Kafka and the custom Kafka Connect container on Kubernetes. Although you can do this as two separate deployments, an easier way is to combine the two steps into one using the Bitnami Kafka Helm chart. This chart supports an &lt;em&gt;extraDeploy&lt;/em&gt; parameter which lets you deploy a set of extra objects with your Apache Kafka deployment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Begin by creating the following &lt;em&gt;values.yml&lt;/em&gt; file holding the values that will be supplied to the Helm chart. Replace the KAFKA-USERNAME and KAFKA-PASSWORD with a custom username and password for Kafka client authentication. Replace the DOCKER-USERNAME placeholder with your Docker account username and the MONGODB-USER-PASSWORD placeholder with the password set for the MongoDB &lt;em&gt;user&lt;/em&gt; account in &lt;a href=&#34;#step-1-deploy-mongodb-on-kubernetes&#34;&gt;Step 1&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;auth:
  clientProtocol: sasl
  interBrokerProtocol: plaintext
  jaas:
    clientUser: KAFKA-USERNAME
    clientPassword: KAFKA-PASSWORD
extraDeploy: |-
  - apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: {{ include &amp;quot;kafka.fullname&amp;quot; . }}-connect
      labels: {{- include &amp;quot;kafka.labels&amp;quot; . | nindent 6 }}
        app.kubernetes.io/component: connector
    spec:
      replicas: 1
      selector:
        matchLabels: {{- include &amp;quot;kafka.matchLabels&amp;quot; . | nindent 8 }}
          app.kubernetes.io/component: connector
      template:
        metadata:
          labels: {{- include &amp;quot;kafka.labels&amp;quot; . | nindent 10 }}
            app.kubernetes.io/component: connector
        spec:
          containers:
            - name: connect
              image: DOCKER-USERNAME/mykafka:1.0
              imagePullPolicy: IfNotPresent
              command:
                - /bin/bash
                - -ec
                - |
                  /opt/bitnami/kafka/bin/connect-standalone.sh /config/connect-standalone.properties /config/mongodb.properties
              ports:
                - name: connector
                  containerPort: 8083
              volumeMounts:
                - name: configuration
                  mountPath: /config
          volumes:
            - name: configuration
              configMap:
                name: {{ include &amp;quot;kafka.fullname&amp;quot; . }}-connect
  - apiVersion: v1
    kind: ConfigMap
    metadata:
      name: {{ include &amp;quot;kafka.fullname&amp;quot; . }}-connect
      labels: {{- include &amp;quot;kafka.labels&amp;quot; . | nindent 6 }}
        app.kubernetes.io/component: connector
    data:
      connect-standalone.properties: |-
        bootstrap.servers = {{ include &amp;quot;kafka.fullname&amp;quot; . }}-0.{{ include &amp;quot;kafka.fullname&amp;quot; . }}-headless.{{ .Release.Namespace }}.svc.{{ .Values.clusterDomain }}:{{ .Values.service.port }}
        key.converter=org.apache.kafka.connect.json.JsonConverter
        value.converter=org.apache.kafka.connect.json.JsonConverter
        key.converter.schemas.enable=true
        value.converter.schemas.enable=true
        offset.storage.file.filename=/tmp/connect.offsets
        offset.flush.interval.ms=10000
        plugin.path=/opt/bitnami/kafka/plugins
        sasl.mechanism=PLAIN
        security.protocol=SASL_PLAINTEXT
        sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
          username=&amp;quot;KAFKA-USERNAME&amp;quot; \
          password=&amp;quot;KAFKA-PASSWORD&amp;quot;;
        consumer.sasl.mechanism=PLAIN
        consumer.security.protocol=SASL_PLAINTEXT
        consumer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
          username=&amp;quot;KAFKA-USERNAME&amp;quot; \
          password=&amp;quot;KAFKA-PASSWORD&amp;quot;;
      mongodb.properties: |-
        connection.uri=mongodb://user:MONGODB-ROOT-PASSWORD@mongodb.default.svc.cluster.local:27017/mydb
        name=mongo-sink
        topics=mytopic
        connector.class=com.mongodb.kafka.connect.MongoSinkConnector
        tasks.max=1
        key.converter=org.apache.kafka.connect.json.JsonConverter
        value.converter=org.apache.kafka.connect.json.JsonConverter
        key.converter.schemas.enable=false
        value.converter.schemas.enable=false
        database=mydb
        collection=sink
  - apiVersion: v1
    kind: Service
    metadata:
      name: {{ include &amp;quot;kafka.fullname&amp;quot; . }}-connect
      labels: {{- include &amp;quot;kafka.labels&amp;quot; . | nindent 6 }}
        app.kubernetes.io/component: connector
    spec:
      ports:
        - protocol: TCP
          port: 8083
          targetPort: connector
      selector: {{- include &amp;quot;kafka.matchLabels&amp;quot; . | nindent 6 }}
        app.kubernetes.io/component: connector
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This file contains a lot of information, so let&amp;rsquo;s step through it in detail:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;em&gt;auth&lt;/em&gt; parameters define the protocol that Kafka will use for client and inter-broker communication. It also specifies the username and password for JAAS-based client authentication.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;em&gt;extraDeploy&lt;/em&gt; parameter creates an additional deployment using the custom Kafka Connect image created in &lt;a href=&#34;#step-2-create-and-publish-a-custom-mongodb-kafka-connector-image&#34;&gt;Step 2&lt;/a&gt;. It also mounts a configuration volume at the &lt;em&gt;/config&lt;/em&gt; mount point. This volume will hold the configuration files for Kafka Connect.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The file defines an additional &lt;em&gt;ConfigMap&lt;/em&gt; which is mounted at &lt;em&gt;/config&lt;/em&gt; and holds two minimal configuration files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;connect-standalone.properties&lt;/em&gt; file defines the standalone mode configuration for Kafka Connect. It specifies the host name of the Apache Kafka server and the client credentials to use when connecting to it. It also tells Kafka Connect which converter to use (JSON) when serializing messages for MongoDB.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;mongodb.properties&lt;/em&gt; file contains additional configuration for the MongoDB sink connector. This configuration includes the MongoDB connection URI, database and collection to use for the saved messages. It also specifies the converter to use for the data (JSON again). In particular, note the &lt;em&gt;topics&lt;/em&gt; parameter, which specifies the list of topics to monitor/save in MongoDB.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Find additional properties to control how data is handled by the sink connector in the official &lt;a href=&#34;https://docs.mongodb.com/kafka-connector/master/kafka-sink/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kafka Sink Connector documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the configuration file has been created, deploy Apache Kafka on Kubernetes using the Helm chart:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;helm install kafka bitnami/kafka -f values.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Wait for a few minutes until the chart is deployed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm that the Apache Kafka and Kafka Connect pods are running:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pods
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see something like the output below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/messaging-and-integration/kafka-mongodb/pods.png&#34; alt=&#34;Running pods&#34;  /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;See the &lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/kafka#parameters&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;complete list of parameters supported by the Bitnami Apache Kafka Helm chart&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;step-4-test-the-integration&#34;&gt;Step 4: Test the integration&lt;/h2&gt;
&lt;p&gt;You can now proceed to test the integration, by publishing messages to the Apache Kafka topic &lt;em&gt;mytopic&lt;/em&gt; and then checking if the messages were streamed and saved to MongoDB. Follow the steps below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;em&gt;kafka_jaas.conf&lt;/em&gt; file with the content below. Replace the KAFKA-USER and KAFKA-PASSWORD placeholders with the values used in &lt;a href=&#34;#step-3-deploy-apache-kafka-and-kafka-connect-on-kubernetes&#34;&gt;Step 3&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;KafkaClient &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
    org.apache.kafka.common.security.plain.PlainLoginModule required
    &lt;span class=&#34;nv&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;KAFKA-USER&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;nv&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;KAFKA-PASSWORD&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;em&gt;client.properties&lt;/em&gt; file with the content below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;security.protocol&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;SASL_PLAINTEXT
sasl.mechanism&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;PLAIN
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create an Apache Kafka client pod and copy the files above to it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl run kafka-client --restart&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Never&amp;#39;&lt;/span&gt; --image docker.io/bitnami/kafka:2.5.0-debian-10-r96 --namespace default --command -- sleep infinity
kubectl cp --namespace default client.properties kafka-client:/tmp/client.properties
kubectl cp --namespace default kafka_jaas.conf kafka-client:/tmp/kafka_jaas.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Log in to the Apache Kafka client pod console:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; --tty -i kafka-client --namespace default -- bash
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;KAFKA_OPTS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;-Djava.security.auth.login.config=/tmp/kafka_jaas.conf&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At the pod console, publish one or more messages to the &lt;em&gt;mytopic&lt;/em&gt; topic. Ensure that the messages are formatted in JSON, as shown in the example below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kafka-console-producer.sh --producer.config /tmp/client.properties --broker-list kafka-0.kafka-headless.default.svc.cluster.local:9092 --topic mytopic
&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;hello&amp;#34;&lt;/span&gt;:&lt;span class=&#34;s2&#34;&gt;&amp;#34;world&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;foo&amp;#34;&lt;/span&gt;:&lt;span class=&#34;s2&#34;&gt;&amp;#34;bar&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exit the Apache Kafka client pod.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a new MongoDB client pod:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl run --namespace default mongodb-client --rm --tty -i --restart&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Never&amp;#39;&lt;/span&gt; --image docker.io/bitnami/mongodb:4.2.8-debian-10-r39 --command -- bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At the MongoDB client pod console, log in to the MongoDB client pod using the &lt;em&gt;user&lt;/em&gt; account credentials defined in &lt;a href=&#34;#step-1-deploy-mongodb-on-kubernetes&#34;&gt;Step 1&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mongo admin --host &lt;span class=&#34;s2&#34;&gt;&amp;#34;mongodb&amp;#34;&lt;/span&gt; --authenticationDatabase mydb -u user -p MONGODB-USER-PASSWORD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm that the messages sent previously are saved in the &lt;em&gt;sink&lt;/em&gt; collection in the &lt;em&gt;mydb&lt;/em&gt; database:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;use mydb
db.sink.find&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see the output below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/messaging-and-integration/kafka-mongodb/mongodb.png&#34; alt=&#34;Query results&#34;  /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point, the integration between Apache Kafka and MongoDB is complete. Messages sent to specified topics in Apache Kafka will be automatically transferred and saved in MongoDB, where they can be further queried, analyzed or modified.&lt;/p&gt;
&lt;h2 id=&#34;useful-links&#34;&gt;Useful links&lt;/h2&gt;
&lt;p&gt;To learn more about the topics discussed in this guide, use the links below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/bitnami-docker-node&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami Apache Kafka Helm chart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitnami/charts/tree/master/bitnami/node&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bitnami MongoDB Helm chart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kafka.apache.org/documentation/#connectapi&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Apache Kafka Connect API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.mongodb.com/kafka-connector/master/kafka-sink/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;MongoDB Kafka Sink Connector guide &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Getting Started with Kafka</title>
      
      <link>/guides/messaging-and-integration/kafka-gs/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/guides/messaging-and-integration/kafka-gs/</guid>
      <description>

        
        &lt;h2 id=&#34;what-is-kafka&#34;&gt;What Is Kafka?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://kafka.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Apache Kafka&lt;/a&gt; is a distributed streaming platform built for publishing, consuming, storing, and processing streams of records. It’s built to run as a cluster of servers potentially across multiple data centers, and to focus on performance and reliability.&lt;/p&gt;
&lt;h2 id=&#34;before-you-begin&#34;&gt;Before You Begin&lt;/h2&gt;
&lt;p&gt;Before you begin, there are a few tools you will need:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/get-docker/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Docker Desktop&lt;/a&gt;. You’ll run your Kafka server in a container to ease the setup. If you’d prefer to run Kafka natively, checkout the&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kafka.apache.org/quickstart&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kafka Quickstart guide&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/compose/install/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Docker Compose&lt;/a&gt;. Kafka has a dependency on &lt;a href=&#34;https://zookeeper.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Zookeeper&lt;/a&gt;, so instead you can use a &lt;code&gt;docker-compose.yml&lt;/code&gt; file, referenced later, to make standing up your Kafka server easier.
Your text editor or IDE of choice.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.oracle.com/java/technologies/javase-downloads.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;JDK 1.8&lt;/a&gt; or newer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This example has been written in Java, but if you’d like to see the example in other languages, to see the whole thing put together, you can find these &lt;a href=&#34;https://github.com/BrianMMcClain/kafka-getting-started&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;using-kafka&#34;&gt;Using Kafka&lt;/h2&gt;
&lt;p&gt;To ease the setup of your Kafka server, you can run Kafka and Zookeeper in containers, already built and configured, ready to go. Ensure that Docker is running, and then stand up your Kafka server by running the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ curl  https://raw.githubusercontent.com/BrianMMcClain/kafka-getting-started/master/docker-compose.yml -o docker-compose.yml

$ docker-compose up
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will do a few things:&lt;/p&gt;
&lt;p&gt;Start the Zookeeper container and expose port 2182
Start the Kafka container and expose ports 9092 and 29092
Configure Kafka so it knows where Zookeeper is&lt;/p&gt;
&lt;p&gt;You’ll see quite a few logs fly by, but it should end with something like the following, letting you know that Kafka is up and running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka_1      | [2020-04-17 16:36:02,261] INFO Kafka startTimeMs: 1587141362239 (org.apache.kafka.common.utils.AppInfoParser)
kafka_1      | [2020-04-17 16:36:02,263] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;building-the-application&#34;&gt;Building the Application&lt;/h2&gt;
&lt;p&gt;The application has two parts: the emitter, which will generate and send messages to Kafka, and the receiver, which will constantly listen for messages from Kafka and print them to the console. Both applications share a similar &lt;code&gt;pom.xml&lt;/code&gt; file, which only has one dependency:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.apache.kafka&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;kafka-clients&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;2.5.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This Kafka client will handle everything from the connection to the server, to sending messages, to polling the server for new messages.&lt;/p&gt;
&lt;h3 id=&#34;building-the-emitter&#34;&gt;Building The Emitter&lt;/h3&gt;
&lt;p&gt;The entirety of the code for the emitter can be found in the &lt;code&gt;emitter.java&lt;/code&gt; file. There’s a few things going on in this code, so as usual it’s best to walk through it step  by step:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// Set the properties to use when connecting to Kafka
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Properties&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;props&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Properties&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;props&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;bootstrap.servers&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;localhost:29092&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;props&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;key.serializer&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;org.apache.kafka.common.serialization.StringSerializer&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;props&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;value.serializer&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;org.apache.kafka.common.serialization.StringSerializer&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;Producer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;producer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;props&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is where the connection and communication with Kafka is configured. First, &lt;code&gt;bootstrap.servers&lt;/code&gt; is defined, providing one or more servers to the client to make the initial connection with Kafka. In this example, there’s only one server, but in a production cluster you could provide multiple servers. This will tell the Kafka client who to talk to so that it can find out the information for the rest of the Kafka cluster.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;key.serializer&lt;/code&gt; and &lt;code&gt;value.serializer&lt;/code&gt; tell the client how to serialize the data sent to the Kafka server. There’s a couple of options for which serializer to use, but to keep the example simple and knowing you’ll only be sending strings to Kafka, you can set both to use the &lt;code&gt;StringSerializer&lt;/code&gt;. As always, if you’re interested in learning more, make sure to check out the &lt;a href=&#34;https://kafka.apache.org/090/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;c1&#34;&gt;//Begin reading user input
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Ready to send messages. Type \&amp;#34;exit\&amp;#34; to quit.&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&amp;gt; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;readLine&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;

    &lt;span class=&#34;c1&#34;&gt;// Close application when user types &amp;#34;exit&amp;#34;
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;equalsIgnoreCase&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;exit&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
    	&lt;span class=&#34;n&#34;&gt;producer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;close&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
		&lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;exit&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
	&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

	&lt;span class=&#34;c1&#34;&gt;// Send the message to the queue
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;producer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;send&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TOPIC_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;key-&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;));&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Sent &amp;#39;&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;&amp;#39;&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once connected to Kafka, the code begins a loop of taking the user input, checking if they wish to exit, and—if not—sending their input to Kafka. Earlier in the code, the constant &lt;code&gt;TOPIC_NAME&lt;/code&gt; is set to &lt;code&gt;hello&lt;/code&gt;, which is where all messages will be sent to. None  of this code is specific to Kafka, except for this line:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;n&#34;&gt;producer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;send&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TOPIC_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This creates a new &lt;code&gt;ProducerRecord&lt;/code&gt;, taking in three arguments: a topic, key, and message. This record is then sent to Kafka using the &lt;code&gt;producer&lt;/code&gt; created earlier in the code. While the &lt;code&gt;message&lt;/code&gt; is simply the input that was read from the user, the &lt;code&gt;key&lt;/code&gt; is a bit less obvious. In short, keys in Kafka are used to figure out how to distribute messages. This key can be set to the same value for all messages if you want to guarantee all messages go to one consumer. This could be a unique key to distribute messages across multiple consumers. In this case, the key is set to &lt;code&gt;null&lt;/code&gt; so that the consumer will be chosen at random.&lt;/p&gt;
&lt;p&gt;With this, your producer is ready to start sending messages! Now it’s time to focus on the other end: receiving messages.&lt;/p&gt;
&lt;h3 id=&#34;building-the-consumer&#34;&gt;Building the Consumer&lt;/h3&gt;
&lt;p&gt;Much of the consumer code, found in the &lt;a href=&#34;https://github.com/BrianMMcClain/kafka-getting-started/blob/master/java/consumer/src/main/java/com/github/brianmmcclain/kafkagettingstarted/consumer.java&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;consumer.java file&lt;/a&gt;, will look similar to the producer. Or at least setting up the connection will.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;n&#34;&gt;Properties&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;props&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Properties&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;props&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;bootstrap.servers&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;localhost:29092&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;props&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;group.id&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;kafka-getting-started&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;props&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;key.deserializer&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;org.apache.kafka.common.serialization.StringDeserializer&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;props&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;value.deserializer&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;org.apache.kafka.common.serialization.StringDeserializer&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;KafkaConsumer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;consumer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KafkaConsumer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;props&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The one additional property that’s set here is &lt;code&gt;group.id&lt;/code&gt;. This property defines which consumer group the consumer is part of. A consumer group controls how consumers are assigned partitions of a topic, and every consumer that connects with the same group ID will be placed in the same consumer group. Other than that, the other properties are the same as the emitter.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// Subscribe to the topic in Kafka
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;consumer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;subscribe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Arrays&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;asList&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TOPIC_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the consumer is created and connected, it is then subscribed to a topic. Much like the emitter, &lt;code&gt;TOPIC_NAME&lt;/code&gt; is defined earlier in the code as a string.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// Begin polling Kafka for new messages
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Waiting for messages. To exit press CTRL+C\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;records&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;consumer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;poll&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Duration&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ofMillis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;));&lt;/span&gt;

    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;record&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;records&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;record&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, the consumer begins polling Kafka for new messages. For each new message that it received, it prints it out to the console.&lt;/p&gt;
&lt;h2 id=&#34;running-the-example&#34;&gt;Running the Example&lt;/h2&gt;
&lt;p&gt;With Kafka running from earlier in the example, all that’s left is to run the emitter and the consumer. Open two terminals, one in the &lt;code&gt;java/emitter&lt;/code&gt; directory and one in the &lt;code&gt;java/consumer&lt;/code&gt; directory. To run the consumer, you can run the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./mvnw clean package
java -jar target/kafka-getting-started-consumer-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Likewise, you can run the emitter with the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./mvnw clean package
java -jar target/kafka-getting-started-emitter-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After a few moments, both will be running. You’ll be greeted with a prompt for input from the emitter, and you can start sending messages to Kafka!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Ready to send messages. Type &amp;quot;exit&amp;quot; to quit.
&amp;gt; 1
Sent &#39;1&#39;
&amp;gt; 2
Sent &#39;2&#39;
&amp;gt; 3
Sent &#39;3&#39;
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As you send messages from the emitter, you should start seeing them arrive on the consumer:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1
2
3
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;keep-learning&#34;&gt;Keep Learning&lt;/h2&gt;
&lt;p&gt;This example covers just the very basics of using Kafka in your code, but there’s a whole lot more to learn. More than anything, if you’re looking to learn more about Kafka, make sure to check out the &lt;a href=&#34;https://kafka.apache.org/documentation/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;official documentation&lt;/a&gt; and just the &lt;a href=&#34;https://kafka.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Apache Kafka&lt;/a&gt; site in general.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Videos: Spring Live: Developing fault-tolerant stream processing application with Kafka Streams and Kubernetes</title>
      
      <link>/videos/spring-live-kafka-streams/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/videos/spring-live-kafka-streams/</guid>
      <description>

        
        
      </description>
    </item>
    
    <item>
      
      <title>Samples: Getting Started with Kafka</title>
      
      <link>/samples/kafka-gs/</link>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/samples/kafka-gs/</guid>
      <description>

        
        
      </description>
    </item>
    
    <item>
      
      <title>Guides: Spring Cloud Stream Kafka</title>
      
      <link>/guides/event-streaming/spring-cloud-stream-kafka-p1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/guides/event-streaming/spring-cloud-stream-kafka-p1/</guid>
      <description>

        
        &lt;p&gt;This document provides a simple demonstration of how to implement your Java application with Kafka using the least amount of code. The goal is to achieve a lot out of the box, without having to reinvent the wheel and implement it in your Spring Boot application.&lt;/p&gt;
&lt;h2 id=&#34;audience&#34;&gt;Audience&lt;/h2&gt;
&lt;p&gt;This document has been written for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Developers with Java (intermediate), Spring Boot (basic) and Maven dependency management.&lt;/li&gt;
&lt;li&gt;Developers interested in migrating from &amp;ldquo;Java EE&amp;rdquo; (&lt;code&gt;J2EE&lt;/code&gt;, please visit &lt;a href=&#34;https://www.oracle.com/java/technologies/javase/javanaming.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt; for naming details) into modern application development (&lt;a href=&#34;https://12factor.net&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;12Factor&lt;/a&gt;) and application containerization.&lt;/li&gt;
&lt;li&gt;Basic Kafka knowledge, including Brokers, Topic, and Partitions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more about Spring Boot Background Modern Application Development or Kafka, refer to the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://spring.io/guides/gs/spring-boot/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Spring Boot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tanzu.vmware.com/content/videos/12-factor-or-cloud-native-apps-what-exactly-does-that-mean-for-spring-developers-thomas-gamble&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;12 Factor, or Cloud-Native Apps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kafka.apache.org/intro&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Kafka Introduction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;before-you-begin&#34;&gt;Before You Begin&lt;/h2&gt;
&lt;p&gt;To do this tutorial, make sure that the following software is on your workstation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Java 8 (preferably Java 11)&lt;/li&gt;
&lt;li&gt;Maven 2 or greater
&lt;ul&gt;
&lt;li&gt;(For Gradle builds: Gradle 6.0 or greater, and run &lt;code&gt;gradle init&lt;/code&gt; to convert current maven into gradle)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Java Editor such as IntelliJ or Eclipse.&lt;/li&gt;
&lt;li&gt;Docker (Docker Compose)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The complete running code for this tutorial is available in &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/tree/main/scs-099&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;spring-cloud-stream-kafka&#34;&gt;Spring Cloud Stream Kafka&lt;/h2&gt;
&lt;p&gt;This tutorial provides examples on how to enable the Apache Kafka binder with Spring Cloud Stream Kafka.&lt;/p&gt;
&lt;p&gt;The following diagram shows Spring Cloud Stream Kafka enabling Apache Kafka Binder on top of &lt;a href=&#34;https://spring.io/projects/spring-cloud-stream&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;https://spring.io/projects/spring-cloud-stream&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-099-1.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;h3 id=&#34;add-a-dependency-to-the-project&#34;&gt;Add a Dependency to the Project&lt;/h3&gt;
&lt;p&gt;For this example, we are using the following dependency: &lt;code&gt;spring-cloud-stream-binder-kafka&lt;/code&gt; (&lt;em&gt;&lt;a href=&#34;https://docs.spring.io/spring-cloud/docs/Hoxton.SR11/reference/html/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Hoxton.SR11&lt;/a&gt;&lt;/em&gt;). In later versions, the &lt;code&gt;@EnableBinding&lt;/code&gt; feature will be &lt;em&gt;&lt;del&gt;deprecated&lt;/del&gt;&lt;/em&gt; in favor of &lt;em&gt;Functional Programming&lt;/em&gt;, which we will look into later. (for more information, see &lt;a href=&#34;https://github.com/spring-cloud/spring-cloud-stream-binder-kafka&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
   &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.cloud&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
   &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-cloud-stream-binder-kafka&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;configure-the-binders&#34;&gt;Configure the Binders&lt;/h3&gt;
&lt;p&gt;The next step is to configure the binders.
For more information, see &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-099/src/main/java/com/ehsaniara/scs_kafka_intro/scs099/MyBinder.java&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;MyBinder.java&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this example, we are using a modified version of the &lt;code&gt;sink.class&lt;/code&gt; interface, rather than &lt;code&gt;@EnableBinding(sink.class)&lt;/code&gt;. Channel has also referred as &lt;code&gt;order&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;interface&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;MyBinder&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ORDER_IN&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;order-in&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ORDER_OUT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;order-out&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;

   &lt;span class=&#34;nd&#34;&gt;@Input&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ORDER_IN&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;SubscribableChannel&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;

   &lt;span class=&#34;nd&#34;&gt;@Output&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ORDER_OUT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;MessageChannel&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;orderOut&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the following example,  the order has been enabled  through &lt;code&gt;@EnableBinding(value = {MyBinder.class})&lt;/code&gt;. The schedule has also been set to create 10 messages, every 5 seconds  , and write it into our topic (for this example: “&lt;code&gt;scs-099.order&lt;/code&gt;”).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Scheduled&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;initialDelay&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;5_000&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fixedDelay&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;5_000&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;producer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;IntStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
      &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;forEach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;

         &lt;span class=&#34;n&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;TestString of %s - %s&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;counter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;myBinder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;orderOut&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
               &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;send&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MessageBuilder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;withPayload&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;

         &lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;warn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;message produced: {}&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

      &lt;span class=&#34;o&#34;&gt;});&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;counter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++;&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following code shows 10 messages publishing  in the topic and logging in the console. The code also increments the counter per every scheduler attempt to keep logs clean.&lt;/p&gt;
&lt;p&gt;You can make it a &lt;code&gt;WARN&lt;/code&gt; log. A &lt;code&gt;WARN&lt;/code&gt; log has different colors, making it stand out from other logs.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.. 08:42:19.433  WARN 47569 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 0
.. 08:42:19.434  WARN 47569 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 1
.. 08:42:19.434  WARN 47569 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 2
.. 08:42:19.435  WARN 47569 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 3
.. 08:42:19.435  WARN 47569 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 4
.. 08:42:19.435  WARN 47569 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 5
.. 08:42:19.435  WARN 47569 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 6
.. 08:42:19.436  WARN 47569 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 7
.. 08:42:19.436  WARN 47569 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 8
.. 08:42:19.436  WARN 47569 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 9
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So far, we&amp;rsquo;ve created messages on the topic. As you can see, Spring Cloud Streams make this job very easy. If you add the following line, you can publish your message.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;n&#34;&gt;myBinder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;orderOut&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;send&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MessageBuilder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;withPayload&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;“&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;…”&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now, it’s time to consume the message.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@StreamListener&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MyBinder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ORDER_IN&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;consumer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Payload&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;message consumed: {}&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here, the application subscribes to our Kafka topic and logs them in the console. Now, you also need to bind your publisher and subscriber channels to the Kafka topic using  the least amount of code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spring&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cloud.stream.bindings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;order-out.destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;scs-099.order&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Topic Name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;order-in.destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;scs-099.order&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Topic Name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;TopicName: scs-099&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;its-showtime&#34;&gt;It’s Showtime!&lt;/h2&gt;
&lt;p&gt;Make sure Kafka is running, then run the following &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/docker-compose.yml&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;docker-compose&lt;/a&gt; file in the same path where the docker-compose file is located. Address it by adding &lt;code&gt;-f path_to_docker_compose_file.yml&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Build the project:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;mvn clean package
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run the generated &lt;strong&gt;jar&lt;/strong&gt; file in the &lt;code&gt;target&lt;/code&gt; folder, Make sure you are in the same directory when you run the &lt;strong&gt;jar&lt;/strong&gt; file.  Or, give the full path.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;java -jar scs-099-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-099-2.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;The application starts to listen on port 8080. The port cannot be occupied by any other app. If it is, try to pass the following parameter before &lt;code&gt;-jar&lt;/code&gt; by adding &lt;code&gt;-Dserver.port=8081&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Now, the console shows  10 messages from the producer (when it’s producing messages) and 10 messages from the consumer.&lt;/p&gt;
&lt;p&gt;Based on the current default configuration, the consumer app has only one concurrent threat,   to consume the message: &lt;code&gt;container-0-C-1&lt;/code&gt;. Note, all messages have been produced from the same thread.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;You can simulate a busy consumer and long-running process by adding a 200ms delay.&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.. 19:31:51.475  WARN 59692 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 0
.. 19:31:51.475  WARN 59692 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 1
.. 19:31:51.476  WARN 59692 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 2
.. 19:31:51.476  WARN 59692 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 3
.. 19:31:51.476  WARN 59692 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 4
.. 19:31:51.477  WARN 59692 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 5
.. 19:31:51.477  WARN 59692 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 6
.. 19:31:51.477  WARN 59692 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 7
.. 19:31:51.477  WARN 59692 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 8
.. 19:31:51.478  WARN 59692 --- [   scheduling-1] c.e.s.scs099.PobSubService               : message produced: TestString of 0 - 9
.. 19:31:51.708 DEBUG 59692 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 0 - 0
.. 19:31:51.913 DEBUG 59692 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 0 - 1
.. 19:31:52.118 DEBUG 59692 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 0 - 2
.. 19:31:52.321 DEBUG 59692 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 0 - 3
.. 19:31:52.526 DEBUG 59692 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 0 - 4
.. 19:31:52.731 DEBUG 59692 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 0 - 5
.. 19:31:52.932 DEBUG 59692 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 0 - 6
.. 19:31:53.137 DEBUG 59692 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 0 - 7
.. 19:31:53.343 DEBUG 59692 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 0 - 8
.. 19:31:53.544 DEBUG 59692 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 0 - 9
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;single-producer-and-single-consumer-with-3-threads&#34;&gt;Single Producer and Single Consumer with 3 Threads&lt;/h2&gt;
&lt;p&gt;What if you want to use parallelism and involve more threads to consume your messages?&lt;/p&gt;
&lt;p&gt;Now you can! First, stop the previous Java process. Then, try the following code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;java -Dspring.profiles.active&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;test3 -jar scs-099-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you look at the logs now, you’ll notice this time is a bit different in the consumer log.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.. 19:36:38.380 DEBUG 59798 --- [container-1-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 1 - 0
.. 19:36:38.385 DEBUG 59798 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 1 - 2
.. 19:36:38.388 DEBUG 59798 --- [container-2-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 1 - 3
.. 19:36:38.585 DEBUG 59798 --- [container-1-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 1 - 1
.. 19:36:38.598 DEBUG 59798 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 1 - 4
.. 19:36:38.603 DEBUG 59798 --- [container-2-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 1 - 5
.. 19:36:38.805 DEBUG 59798 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 1 - 6
.. 19:36:39.010 DEBUG 59798 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 1 - 7
.. 19:36:39.216 DEBUG 59798 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 1 - 8
.. 19:36:39.422 DEBUG 59798 --- [container-0-C-1] c.e.s.scs099.PobSubService               : message consumed: TestString of 1 - 9
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;By activating a different profile (test3), a couple of more features append to the current configuration, similar to the following example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spring&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cloud.stream.bindings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Order-out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;scs-099.order&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Topic Name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;producer.partition-count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Order-in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;scs-099.order&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Topic Name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;${spring.application.name}-group&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;consumer.concurrency&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cloud.stream.kafka.binder.autoAddPartitions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;whats-happened-so-far&#34;&gt;What’s happened so far?&lt;/h3&gt;
&lt;p&gt;There are &lt;strong&gt;3 concurrent threads&lt;/strong&gt; to execute the consumer method. The partition size is sized-up (&amp;gt; consumer number) so that every consumer has its own partition to subscribe. In addition, all consumers are now  in that same consumer group to prevent duplicate processing of the same message by a different consumer (&lt;code&gt;consumerGroup: scs-099-group&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;As you see, by using Spring Cloud Stream this happened by  only adding a few lines.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-099-4.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;All messages have been consumed based on the 200ms delay introduced in the consumer. Therefore, the total number of messages cannot be fully consumed in less than 2 Seconds (200ms  X 10 = 2000ms).&lt;/p&gt;
&lt;h2 id=&#34;single-producer-and-3-consumer-app-3-separate-jvm-processes&#34;&gt;Single Producer and 3 Consumer App (3 Separate JVM Processes)&lt;/h2&gt;
&lt;p&gt;Depending on your topic traffic or consumer performance, the best way you can scale up or down is to run your consumer in a different JVM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; &lt;em&gt;In future tutorials you’ll see how to containerize and scale this application.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So now, let&amp;rsquo;s stop the previous Java process to make port 8080 available again.&lt;/p&gt;
&lt;p&gt;Run the following java application in &lt;strong&gt;3 different terminals&lt;/strong&gt; as follows:&lt;/p&gt;
&lt;p&gt;On &lt;code&gt;Terminal-1:&lt;/code&gt; This app has one producer and one consumer.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;java -Dspring.profiles.active&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;test2 -jar scs-099-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Note: I have added the port check, so you only have one producer for our Kafka topic regardless of the number of apps.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;On &lt;code&gt;Terminal-2:&lt;/code&gt; This app has only one consumer.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;java -Dspring.profiles.active&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;test2 -Dserver.port&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8081&lt;/span&gt; -jar scs-099-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;On &lt;code&gt;Terminal-3:&lt;/code&gt; This app has only one consumer.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;java -Dspring.profiles.active&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;test2 -Dserver.port&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8082&lt;/span&gt; -jar scs-099-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-099-3.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;To avoid having multiple producers, we just let only one app to create messages in the topic in the &lt;strong&gt;producer&lt;/strong&gt; method by checking the (app port == 8080)&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;whats-happening-now&#34;&gt;What’s happening now?&lt;/h3&gt;
&lt;p&gt;We only have one application running (producer and consumer on the same app). Similar to the previous example, we basically consume all messages based on the 200ms delay introduced in the consumer. Therefore, the total number of messages cannot be fully consumed in less than 2 seconds &lt;em&gt;(200ms  X 10 = 2000ms)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;However, this time it’s running in different (JVM)s. Now, it  can be decoupled out and run in different machines or containers in the future. Our primary intention is to have &lt;strong&gt;horizontal scalability&lt;/strong&gt; in the app.&lt;/p&gt;
&lt;p&gt;When you run the app in the second terminal, you basically tell Kafka to distribute the message to the newly introduced consumer app. You see the new application start consuming some produced messages, but not the same ones from the first app.&lt;/p&gt;
&lt;p&gt;At the same time, when you look at the first application you see Kafka is informing the app that a new consumer has subscribed to your topic on the given consumer group (as &lt;code&gt;INFO&lt;/code&gt; logs).&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The environments in which you have a fast producer but slower consumer are good examples and use cases for Kafka. In reality, consumers are slower. You don’t want them affecting your application producer performances.&lt;/p&gt;
&lt;p&gt;For example, you want to make a log processing system and do some keyword search in the incoming messages. On the other hand, even though your application is producing a high amount of logs, adding the log processor system should not affect your actual application performance. Also, in case of a changing amount of logs, you want your system to be able to scale up or down easily and have a failover mechanism and resiliency.&lt;/p&gt;
&lt;p&gt;The complete running code for this tutorial is available in &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/tree/main/scs-099&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What’s Next&lt;/h2&gt;
&lt;p&gt;In the next tutorial &lt;a href=&#34;/guides/event-streaming/spring-cloud-stream-kafka-p2&#34;&gt;Part 2&lt;/a&gt;, I’ll show a real life example such as the &lt;strong&gt;PubSub&lt;/strong&gt; module, multiple Kafka topics and failover handling.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Spring Cloud Stream Kafka (Part 2)</title>
      
      <link>/guides/event-streaming/spring-cloud-stream-kafka-p2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/guides/event-streaming/spring-cloud-stream-kafka-p2/</guid>
      <description>

        
        &lt;p&gt;Based on our previous demo in &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p1/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Part 1&lt;/a&gt;, you are now ready to simulate a scenario to get a better sense of what we have previously discussed. Let’s say you need to design a system where you can place an order and ship it after some verification process.
To demonstrate how &lt;code&gt;SCS&lt;/code&gt; can help you make your application development simpler, we are not going to cover all the edge or corner cases where this design can fail.&lt;/p&gt;
&lt;p&gt;NOTE: The complete running code for this tutorial is available in &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/tree/main/scs-100&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;goal&#34;&gt;Goal&lt;/h2&gt;
&lt;p&gt;In high level, you are going to experience:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Touch on an Event Driven approach - EDA (AKA: Event Driven Architecture)&lt;/li&gt;
&lt;li&gt;Asynchronous communication between applications (Services)&lt;/li&gt;
&lt;li&gt;Using Apache Kafka as broker&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this case you are going to have two &lt;strong&gt;back-end&lt;/strong&gt; checks, which are referred to as your &lt;em&gt;inventory check&lt;/em&gt; and &lt;em&gt;shipment services&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Things to consider: the back-end process for this scenario may take a long time.There is a risk that the front-end (or UI app) call may timeout throughout this path at any point.&lt;/p&gt;
&lt;p&gt;One way to move away from traditional request and response methods is to approach it with the event driven method - EDA (AKA: Event Driven Architecture). As a result, the UI can check the process through a State Store.&lt;/p&gt;
&lt;p&gt;This may be a little difficult to understand right away, but this is something you have been doing for a long time in real life.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A good example is your Mailing Service. You send a mailing envelope to a company, await a  response, and keep having to check your mailbox. In this case, your mailbox is the State Store.&lt;/p&gt;
&lt;p&gt;There are other, alternative frameworks such as &lt;a href=&#34;https://spring.io/projects/spring-integration&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Spring Integration&lt;/a&gt; or &lt;a href=&#34;https://spring.io/projects/spring-cloud-dataflow&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Spring Cloud Data-Flow&lt;/a&gt; that you can use for this use case.&lt;/p&gt;
&lt;h4 id=&#34;note-in-this-demo-state-store-is-just-a-hashmap-order-id-is-the-key&#34;&gt;Note: In this demo, State Store is just a &lt;code&gt;HashMap&lt;/code&gt;. Order ID is the key.&lt;/h4&gt;
&lt;h2 id=&#34;the-work-flow&#34;&gt;The Work Flow&lt;/h2&gt;
&lt;p&gt;In order to visualize our goal, let’s take it to as high a level as possible and see this problem in three major services, while keeping in mind the future scalability. Each service has individual responsibilities (as stateless as possible)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-100-3.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;create-an-order-request&#34;&gt;Create an Order Request&lt;/h2&gt;
&lt;p&gt;A REST call is a &lt;strong&gt;create request&lt;/strong&gt; through the controller and ordering service. It can also be a UI or any other service.&lt;/p&gt;
&lt;p&gt;Since you are expecting a series of processes and operations in the back-end, you don&amp;rsquo;t need to make the UI wait for the entire flow and keep the request thread occupied (blocked).&lt;/p&gt;
&lt;p&gt;Simply create an order ID and create a lookup operation for checking the status of the order, while waiting for the order back-end processes to finish.&lt;/p&gt;
&lt;p&gt;For the purpose of this document, you may use a simple local hash map in the application (as there is only a single application for this example).&lt;/p&gt;
&lt;h4 id=&#34;note-although-all-service-methods-are-in-the-same-service-class-they-are-distributed-in-different-methods-in-the-source-code-lets-refer-to-them-as-services-but-eventually-they-can-become-separated-services&#34;&gt;Note: Although all service methods are in the same Service class, they are distributed in different methods in the source code, let’s refer to them as services, but eventually they can become separated services.&lt;/h4&gt;
&lt;p&gt;Some ideas related to your Kafka topic responsibilities:&lt;/p&gt;
&lt;div class=&#34;table&#34;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Topic Name&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Object&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;scs-100.inventoryChecking&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Order&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Orders need to be processed for Inventory Check Operation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;scs-100.shipping&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Order&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Orders need to be shipped (Ready to go)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;scs-100.ordering_dlq&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Order&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Orders need to be canceled (For Unexpected Behaviors)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;h2 id=&#34;order-service&#34;&gt;Order Service&lt;/h2&gt;
&lt;p&gt;This is where you create the order ID — which can have simple validation checks for sanity. Having a lookup can reduce a lot of complexities and at the same time introduce new challenges that we will discuss later.&lt;/p&gt;
&lt;h4 id=&#34;note-you-will-only-have-one-write-but-many-reads-operations-at-a-time-per-order&#34;&gt;Note: You will only have one &lt;strong&gt;Write&lt;/strong&gt; but many &lt;strong&gt;Reads&lt;/strong&gt; operations at a time, per order.&lt;/h4&gt;
&lt;p&gt;Having this method of breaking the processes in the application design can have its own challenges, especially in lookup check. The lookup check process usually happens in one of the following ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The application informs the UI (end-user or order creator service) as order changes its status. It can be any one of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Unicast&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;Unicast&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://en.wikipedia.org/wiki/Multicast&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;Multicast&lt;/code&gt;&lt;/a&gt; approaches.&lt;/li&gt;
&lt;li&gt;UI or end-user calls a specific API to see the latest status of a particular order.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can choose 1 of 2 approaches, depending on the use case and implementation of the application. To keep the demo simple, the second approach is preferred.&lt;/p&gt;
&lt;p&gt;The service is putting the order into topic (&lt;code&gt;scs-100.inventoryChecking&lt;/code&gt;). It is a producer for this topic.&lt;/p&gt;
&lt;p&gt;This process is simplified by using &lt;code&gt;SCS&lt;/code&gt; (Spring Cloud Stream). You need to create a binder and its configuration only.&lt;/p&gt;
&lt;p&gt;Producer part with Initializing the Order (&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/6604387604742fc43b9afa8ff71dc3288cdefae6/scs-100/src/main/java/com/ehsaniara/scs_kafka_intro/scs100/OrderService.java#L54&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;OrderService.java&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;placeOrder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;builder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;itemName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getItemName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;())&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;orderUuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;randomUUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;())&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;orderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;PENDING&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
   &lt;span class=&#34;c1&#34;&gt;//update the status
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;orderDataBase&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderUuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
   &lt;span class=&#34;c1&#34;&gt;//send it for inventory check
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;orderBinder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;inventoryCheckingOut&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;send&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MessageBuilder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;withPayload&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;                   &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;setHeader&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MessageHeaders&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;CONTENT_TYPE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MimeTypeUtils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;APPLICATION_JSON&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;                   &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
   &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Binder part (&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/6604387604742fc43b9afa8ff71dc3288cdefae6/scs-100/src/main/java/com/ehsaniara/scs_kafka_intro/scs100/OrderBinder.java#L10&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;OrderBinder.java&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;c1&#34;&gt;//spring.cloud.stream.bindings.inventoryChecking-in
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;INVENTORY_CHECKING_IN&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;inventoryChecking-in&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;INVENTORY_CHECKING_OUT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;inventoryChecking-out&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;nd&#34;&gt;@Input&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;INVENTORY_CHECKING_IN&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;SubscribableChannel&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;inventoryCheckingIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;

&lt;span class=&#34;nd&#34;&gt;@Output&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;INVENTORY_CHECKING_OUT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;MessageChannel&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;inventoryCheckingOut&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Application Configuration part (&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100/src/main/resources/application.yml#L8&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;application.yml&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spring.cloud.stream.bindings.inventoryChecking-out.destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;scs-100.inventoryChecking&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Our expectation from this service is to create the order and produce it in the topic. You may also separate this component into different applications and scale it. Eventually, this service can also be the only point of interaction between the front-end and back-end applications. You may refer to this component as your &lt;strong&gt;Event Source&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;inventory-service&#34;&gt;Inventory Service&lt;/h2&gt;
&lt;p&gt;Inventory Service is also referred to as Event Processor. Here you have a consumer to your inventory check topic, and every message in this topic represents an order that needs to be checked for inventory. This is called an &amp;ldquo;Inventory Check&amp;rdquo; but it can vary in the real scenario, such as payments, supplier delivery, custom delivery, state tax calculator, etc.&lt;/p&gt;
&lt;p&gt;At this point, you can have multiples of these services for other purposes. Theoretically speaking, it doesn&amp;rsquo;t matter how much time this process takes since you are not blocking the original request thread.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100/src/main/java/com/ehsaniara/scs_kafka_intro/scs100/OrderService.java#L68&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;OrderService.java&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@StreamListener&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderBinder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;INVENTORY_CHECKING_IN&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nd&#34;&gt;@SneakyThrows&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;checkInventory&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Payload&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;checkInventory orderIn: {}&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;setOrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;INVENTORY_CHECKING&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;orderDataBase&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderUuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

   &lt;span class=&#34;n&#34;&gt;Thread&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;sleep&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;5_000&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//5 sec delay
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
   &lt;span class=&#34;c1&#34;&gt;// just a simulation of create exception for random orders (1 in 2) in case of inventory insufficiency
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;   &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
       &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;setOrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;OUT_OF_STOCK&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
       &lt;span class=&#34;n&#34;&gt;orderDataBase&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderUuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
       &lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;warn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Let&amp;#39;s assume we ran out of stock for item: {}&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getItemName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
       &lt;span class=&#34;n&#34;&gt;Thread&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;sleep&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;5_000&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//5 sec delay
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;       &lt;span class=&#34;k&#34;&gt;throw&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OrderFailedException&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;insufficient inventory for order: %s&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderUuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()));&lt;/span&gt;
   &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

   &lt;span class=&#34;c1&#34;&gt;//Order is good to go for shipping
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;orderBinder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;shippingOut&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;send&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MessageBuilder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;withPayload&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;                   &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;setHeader&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MessageHeaders&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;CONTENT_TYPE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MimeTypeUtils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;APPLICATION_JSON&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;                   &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;This method is the consumer and produce order event&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In this method, you’ve intentionally thrown a runtime exception to simulate one of the cool features of &lt;a href=&#34;https://github.com/spring-cloud/spring-cloud-stream-binder-kafka&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;SCS&lt;/code&gt;&lt;/a&gt; which is provided out of the box, “Retry Mechanism”. It can easily be configured in &lt;code&gt;application.yml&lt;/code&gt; with no extra coding. It also supports the “Back off and retry mechanism”. The retry value is 3 seconds, by default, and the &lt;code&gt;backoff&lt;/code&gt; value is 5 seconds, by default.&lt;/p&gt;
&lt;p&gt;Eventually, when this method throws an exception, it doesn&amp;rsquo;t immediately fail  unless it hits its built-in retry threshold.&lt;/p&gt;
&lt;p&gt;For example, let’s say, you need to call a third party service, but the call failed in the first attempt due to some networking issues or unhealthy nodes. However, you know that if you try one more time, you can get the results by hitting the healthy one. It’s recommended that you visit &lt;a href=&#34;https://cloud.spring.io/spring-cloud-static/spring-cloud-stream-binder-kafka/3.0.3.RELEASE/reference/html/spring-cloud-stream-binder-kafka.html#_kafka_binder_properties&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100/src/main/resources/application.yml#L28&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;application.yml&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spring.cloud.stream.kafka&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;bindings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;inventoryChecking-in.consumer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enableDlq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dlqName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;scs-100.ordering_dlq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;autoCommitOnError&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;AutoCommitOffset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There are many other configurations that you can apply. Go &lt;a href=&#34;https://docs.spring.io/spring-cloud-stream-binder-kafka/docs/3.0.12.RELEASE/reference/html/spring-cloud-stream-binder-kafka.html#_apache_kafka_binder&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;Potentially, you could put the order in &lt;code&gt;DLQ&lt;/code&gt; manually and exit the method immediately (“return;”) within the “if” statement, but i &lt;code&gt;SCS&lt;/code&gt; wouldn’t understand if something went wrong and that it needs to “retry” the method (throughout the document we keep referring to it as service).&lt;/p&gt;
&lt;p&gt;Keep in mind that you can configure from application.yml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;l&#34;&gt;cloud.stream.bindings.inventoryChecking-in.consumer.maxAttempts&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once you are done with the inventory check service, you can put the order into &lt;code&gt;scs-100.shipping&lt;/code&gt; topic and you are done with the service. The instance of service is ready to pick up the next order for checking, and the workflow keeps going on.&lt;/p&gt;
&lt;h2 id=&#34;shipping-service&#34;&gt;Shipping Service&lt;/h2&gt;
&lt;p&gt;This is your &lt;strong&gt;Event Sink&lt;/strong&gt; process. In your final step, you are going to ship out the order that has been passed from all the verification steps you have designed. You can mark your order as SHIPPED.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@StreamListener&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderBinder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;SHIPPING_IN&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;shipIt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Payload&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;shipIt orderIn: {}&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;setOrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;SHIPPED&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
   &lt;span class=&#34;n&#34;&gt;orderDataBase&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderUuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

   &lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;info&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;ItemID: {} has been Shipped&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderIn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderUuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Note: Any failure on this step also drives the order to your &lt;code&gt;DLQ&lt;/code&gt;, by configuration.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;cancellation-service&#34;&gt;Cancellation Service&lt;/h2&gt;
&lt;p&gt;Basically, you are handling all &lt;code&gt;DLQ&lt;/code&gt; messages (orders) in this topic. Eventually, orders which end up here should be canceled so that the canceling process applies to them.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-100-1.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;h2 id=&#34;show-time&#34;&gt;Show Time!&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s run the application now by running the following line:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;java -jar scs-100-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now, the application is running on the port 8080, as you expected. To create an order and see the flow, let’s run the following command line. Before that, make sure you have already installed the &lt;a href=&#34;https://stedolan.github.io/jq/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;jq&lt;/code&gt;&lt;/a&gt; (command-line JSON processor).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nv&#34;&gt;ORDER_UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;curl --silent -H &lt;span class=&#34;s1&#34;&gt;&amp;#39;Content-Type: application/json&amp;#39;&lt;/span&gt; -d &lt;span class=&#34;s2&#34;&gt;&amp;#34;{\&amp;#34;itemName\&amp;#34;:\&amp;#34;book\&amp;#34;}&amp;#34;&lt;/span&gt; http://localhost:8080/order &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; jq -r &lt;span class=&#34;s1&#34;&gt;&amp;#39;.orderUuid&amp;#39;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;seq &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; 15&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;curl --silent &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://localhost:8080/order/status/&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$ORDER_UUID&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; sleep 1&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here you have created an order and keep calling its status every second for a total of 15 seconds.&lt;/p&gt;
&lt;h6 id=&#34;in-case-of-inventory-available-and-order-shipped-the-results-will-be-similar-to-this&#34;&gt;In case of inventory available and order shipped, the results will be similar to this:&lt;/h6&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;INVENTORY_CHECKING&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;INVENTORY_CHECKING&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;INVENTORY_CHECKING&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;INVENTORY_CHECKING&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;INVENTORY_CHECKING&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;SHIPPED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;SHIPPED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;SHIPPED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;SHIPPED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;SHIPPED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;SHIPPED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;SHIPPED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;SHIPPED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;SHIPPED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;SHIPPED&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Eventually, once you see the “SHIPPED” status you can exit the loop.&lt;/em&gt;&lt;/p&gt;
&lt;h6 id=&#34;in-case-of-shortage-of-supply-the-results-will-be-similar-to-this&#34;&gt;In case of shortage of supply, the results will be similar to this:&lt;/h6&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;INVENTORY_CHECKING&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;INVENTORY_CHECKING&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;INVENTORY_CHECKING&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;INVENTORY_CHECKING&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;INVENTORY_CHECKING&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;OUT_OF_STOCK&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;OUT_OF_STOCK&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;OUT_OF_STOCK&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;OUT_OF_STOCK&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;OUT_OF_STOCK&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;CANCELED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;CANCELED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;CANCELED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;CANCELED&amp;#34;&lt;/span&gt;
&lt;span class=&#34;s2&#34;&gt;&amp;#34;CANCELED&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Basically, once you see the “CANCELED” status you can exit the loop. You may also notice the “OrderFailedException” on your application console, which is intentional.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Spring Cloud Stream, which is represented as the &lt;strong&gt;green layer&lt;/strong&gt; in the following diagram, helps us to focus on solving the business problem rather than taking care of plumbing issues with the application.
&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-100-2.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;The complete running code for this tutorial is available in &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/tree/main/scs-100&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;known-issues&#34;&gt;Known Issues&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;State Store Database (you just temporarily left it as &lt;code&gt;HashMap&lt;/code&gt;), which is only available for the local app, can cause issues when you horizontally scale the application instances or break the application into smaller modules.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SCS&lt;/code&gt; Binder features are &lt;del&gt;deprecated&lt;/del&gt; in the next versions of &lt;code&gt;SCS&lt;/code&gt; in favor of Functional Programming.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;whats-next&#34;&gt;What’s Next?&lt;/h3&gt;
&lt;p&gt;In the next tutorial, Part 3, you are going to learn how to overcome the known issues. You will also be introduced to topics such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;State Stores&lt;/li&gt;
&lt;li&gt;Materialized View&lt;/li&gt;
&lt;li&gt;Interactive Queries&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      
      <title>Guides: Spring Cloud Stream Kafka (Part 3) - Functional Programming</title>
      
      <link>/guides/event-streaming/spring-cloud-stream-kafka-p3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/guides/event-streaming/spring-cloud-stream-kafka-p3/</guid>
      <description>

        
        &lt;p&gt;This tutorial is going to use the same example (Ordering System) from &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p2/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Part 2&lt;/a&gt;, and craft it into a Stream Process with a modern Java Functional Programming Model by using &lt;code&gt;SCS&lt;/code&gt; (Spring Cloud Stream Kafka).&lt;/p&gt;
&lt;p&gt;The Ordering System from &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p2/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Part 2&lt;/a&gt; may not be the perfect scenario for Streaming, but the purpose of this tutorial is  to look at the problem with a Streaming approach and demonstrate how &lt;code&gt;SCS&lt;/code&gt; can be helpful during this process.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: The complete running code for this tutorial is available in &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/tree/main/scs-100-2&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Github&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Looking back to the previous tutorial &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p2/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Part 2&lt;/a&gt;, we see how it tracks the order status changes and overrides the status every time. However, there are some real-life use cases where you may need to know when  the status changed (AKA change history).&lt;/p&gt;
&lt;p&gt;For example: If someone asks you “What time is it?”, or “What is the time now?, they actually want to know the current value of the time. They are not asking  how time becomes the value.&lt;/p&gt;
&lt;p&gt;Conversely, if someone asks you “How did you get here?”, despite the fact that your current location is known, the intention is about the series of locations over time that got you here.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-1002-p0.png&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Telematics or sensor data, app logs, and similar systems are the types of structures we are going to discuss when we talk about streaming.&lt;/p&gt;
&lt;h2 id=&#34;audience&#34;&gt;Audience&lt;/h2&gt;
&lt;p&gt;This document is written for those who:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Review and understand the previous tutorials &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p1/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Part 1&lt;/a&gt; and &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p2/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Part 2&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Have good knowledge of Java Functional Programming (preferably, Java 11).&lt;/li&gt;
&lt;li&gt;Have a basic understanding of Kafka Stream and Topology, as well as &lt;a href=&#34;https://kafka.apache.org/20/documentation/streams/developer-guide/dsl-api.html#streams_concepts_kstream&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;KStream&lt;/a&gt;, &lt;a href=&#34;https://kafka.apache.org/20/documentation/streams/developer-guide/dsl-api.html#streams_concepts_ktable&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Ktable&lt;/a&gt;, &lt;a href=&#34;https://kafka.apache.org/20/documentation/streams/developer-guide/dsl-api.html#aggregating&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Aggregation&lt;/a&gt;, &lt;a href=&#34;https://kafka.apache.org/20/documentation/streams/developer-guide/dsl-api.html#joining&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Joins&lt;/a&gt; and &lt;a href=&#34;https://kafka.apache.org/20/documentation/streams/architecture.html#streams_architecture_state&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;State Store&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, now it&amp;rsquo;s the time to switch from what we used in &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p1/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Part 1&lt;/a&gt; and &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p2/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Part 2&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.cloud&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-cloud-stream-binder-kafka&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Into this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.cloud&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-cloud-stream-binder-kafka-streams&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By replacing the dependency to Spring Cloud Stream (&lt;code&gt;SCS&lt;/code&gt;) for Kafka, we include new libraries that will help make the Kafka Topology. The library already has &lt;code&gt;rocksdbjni&lt;/code&gt; and &lt;code&gt;org.apache.kafka:kafka-streams&lt;/code&gt; where we need it for &lt;code&gt;KStream&lt;/code&gt; and &lt;code&gt;KTable&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;From &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p2/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Part 2&lt;/a&gt;, here is the conversion of the Ordering System into what the Kafka Stream Topology will look like.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: There are many ways to create the Topology for this problem. The following example is not the only solution.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-1002-2.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;To overcome the &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p2/#known-issues&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Known Issues&lt;/a&gt; mentioned in the previous tutorial, we have a continued flow from the time the &amp;ldquo;order&amp;rdquo; is created and put in the Kafka topic through &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100-2/src/main/java/com/ehsaniara/scs_kafka_intro/scs1002/OrderService.java#L69&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;orderAggConsumer&lt;/code&gt;&lt;/a&gt;. This materializes the aggregate state value of the order per each &lt;code&gt;orderUuid&lt;/code&gt;, so the temporary &lt;code&gt;HashMap&lt;/code&gt; lookup can go away with it.&lt;/p&gt;
&lt;p&gt;Here is how we eventually manage our &lt;code&gt;StateStore&lt;/code&gt;. Events are flowing through this &lt;code&gt;@Bean&lt;/code&gt; every time it completes a step of it. All steps become an individual &lt;code&gt;@Bean&lt;/code&gt;, where in the next tutorial they will become individual micro-services.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100-2/src/main/java/com/ehsaniara/scs_kafka_intro/scs1002/OrderService.java#L69&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;orderAggConsumer&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Bean&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Function&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;orderAggConsumer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;uuidOrderKStream&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
       &lt;span class=&#34;n&#34;&gt;KTable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;uuidStringKTable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kStreamKTableStringFunction&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apply&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;uuidOrderKStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

       &lt;span class=&#34;c1&#34;&gt;//then join the stream with its original stream to keep the flow
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;       &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;uuidOrderKStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;leftJoin&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;uuidStringKTable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;status&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;n&#34;&gt;Joined&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;with&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Serdes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderJsonSerde&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Serdes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()));&lt;/span&gt;
   &lt;span class=&#34;o&#34;&gt;};&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is the topology to create a &lt;code&gt;KTable&lt;/code&gt; for &lt;code&gt;orderUuid&lt;/code&gt; and the latest order status as String, which materializes it in &lt;code&gt;STATE_STORE_NAME&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;n&#34;&gt;Function&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KTable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kStreamKTableStringFunction&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input&lt;/span&gt;
       &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;groupBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderUuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(),&lt;/span&gt;
               &lt;span class=&#34;n&#34;&gt;Grouped&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;with&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;JsonSerde&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ObjectMapper&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;())))&lt;/span&gt;
       &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;aggregate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;
               &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;oldStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;toString&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(),&lt;/span&gt;
               &lt;span class=&#34;n&#34;&gt;Materialized&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KeyValueStore&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Bytes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[]&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Application&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;STATE_STORE_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
                       &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;withKeySerde&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Serdes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()).&lt;/span&gt;
                       &lt;span class=&#34;n&#34;&gt;withValueSerde&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Serdes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;())&lt;/span&gt;
       &lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Note: If you run multiple of these applications on the same machine, you may have a different value for &amp;ldquo;&lt;a href=&#34;https://kafka.apache.org/10/documentation/streams/developer-guide/config-streams.html#state-dir&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;state.dir&lt;/a&gt;&amp;rdquo; in each application. You may notice &lt;code&gt;state-scs-100-2-*&lt;/code&gt; folder in the parent root directory. This is where RocksDB stores its data. It can be modified from &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100-2/src/main/resources/application.yml#L40&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;application.yml&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;With the current design, you only see the latest order status. The missing parameter here is  TIME.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-1002-0.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;KStream&lt;/p&gt;
&lt;div class=&#34;table&#34;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;code&gt;OrderUuid&lt;/code&gt; (Key)&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;code&gt;Status&lt;/code&gt; (Value)&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Timestamp (MetaData, but It can be added to Value)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;..-8064d09b661e&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;PENDING&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;00:00:00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;..-8064d09b661e&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;INVENTORY_CHECKING&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;00:00:05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;..-8064d09b661e&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;SHIPPED&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;00:00:10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;KTable&lt;/p&gt;
&lt;div class=&#34;table&#34;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;code&gt;OrderUuid&lt;/code&gt; (Key)&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;code&gt;Status&lt;/code&gt; (Value)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;..-8064d09b661e&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;SHIPPED&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Expected stream topology:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-1002-1.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;At this point, if the application wants the order status, it does a rest call to &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100-2/src/main/java/com/ehsaniara/scs_kafka_intro/scs1002/OrderController.java&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Order Controller&lt;/a&gt; and gets it from the following method:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Function&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;statusCheck&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;orderUuid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
       &lt;span class=&#34;kd&#34;&gt;final&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ReadOnlyKeyValueStore&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;store&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;
               &lt;span class=&#34;n&#34;&gt;interactiveQueryService&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getQueryableStore&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Application&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;STATE_STORE_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;QueryableStoreTypes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;keyValueStore&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;

       &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;valueOf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Optional&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ofNullable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;orderUuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
               &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;orElseThrow&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OrderNotFoundException&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Order not found&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)));&lt;/span&gt;
   &lt;span class=&#34;o&#34;&gt;};&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;However, this is not the correct way. There is a big issue with it! Basically, this only works if you have one instance of the application. When you scale up the application, your &lt;code&gt;StateStore&lt;/code&gt; may not be on the same machine where you registered it earlier, resulting in a 404 Page Not Found error to display.&lt;/p&gt;
&lt;p&gt;Let’s check the &amp;ldquo;key’s &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100-2/src/main/java/com/ehsaniara/scs_kafka_intro/scs1002/OrderService.java#L46&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Host Info&lt;/a&gt;&amp;rdquo; before calling it.&lt;/p&gt;
&lt;p&gt;Note: The key’s &lt;code&gt;HostInfo&lt;/code&gt; is stored locally in the application’s &lt;code&gt;RocksDb&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;n&#34;&gt;HostInfo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hostInfo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interactiveQueryService&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getHostInfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Application&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;STATE_STORE_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
       &lt;span class=&#34;n&#34;&gt;orderUuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;UUIDSerializer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Also, Kafka needs to know the app server information.  It’s already documented &lt;a href=&#34;https://docs.spring.io/spring-cloud-stream-binder-kafka/docs/3.1.3/reference/html/spring-cloud-stream-binder-kafka.html#_interactive_queries&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;here&lt;/a&gt;, based on the project’s cloud version).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spring.cloud.stream.kafka.streams.binder.configuration.application.server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;localhost:${server.port}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the following &lt;code&gt;@Bean&lt;/code&gt; methods, the application decides what the next stream is going to be based on the current order status.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100-2/src/main/java/com/ehsaniara/scs_kafka_intro/scs1002/OrderService.java#L96&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;@Bean (&amp;ldquo;orderProcess&amp;rdquo;)&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Bean&lt;/span&gt;
&lt;span class=&#34;nd&#34;&gt;@SuppressWarnings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;unchecked&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Function&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;[]&amp;gt;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;orderProcess&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;Predicate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;isOrderMadePredicate&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;equals&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;PENDING&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;Predicate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;isInventoryCheckedPredicate&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;equals&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;INVENTORY_CHECKING&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;Predicate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;isShippedPredicate&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;equals&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;SHIPPED&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input&lt;/span&gt;
           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;peek&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;uuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Routing Order: {} [status: {}]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;uuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getOrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()))&lt;/span&gt;
           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KeyValue&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;branch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isOrderMadePredicate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;isInventoryCheckedPredicate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;isShippedPredicate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the following, &lt;strong&gt;@Bean(s)&lt;/strong&gt; are the demonstrations of processes you may want to add in the Ordering System.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100-2/src/main/java/com/ehsaniara/scs_kafka_intro/scs1002/OrderService.java#L114&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;@Bean (&amp;ldquo;inventoryCheck&amp;rdquo;)&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Bean&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Function&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;inventoryCheck&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input&lt;/span&gt;
           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;peek&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;uuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Checking order inventory, Order: {}&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;uuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;peek&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;setOrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;INVENTORY_CHECKING&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KeyValue&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100-2/src/main/java/com/ehsaniara/scs_kafka_intro/scs1002/OrderService.java#L121&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;@Bean (&amp;ldquo;shipping&amp;rdquo;)&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Bean&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Function&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;shipping&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input&lt;/span&gt;
           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;peek&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;uuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Applying Shipping Process, Order: {}&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;uuid&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;peek&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;setOrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OrderStatus&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;SHIPPED&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KeyValue&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100-2/src/main/java/com/ehsaniara/scs_kafka_intro/scs1002/OrderService.java#L130&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;@Bean (&amp;ldquo;shippedConsumer&amp;rdquo;)&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Bean&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Consumer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KStream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Order&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;shippedConsumer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input&lt;/span&gt;
           &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;THIS IS THE END! key: {} value: {}&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;));&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Another important point in this demonstration is in (&lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/blob/main/scs-100-2/src/main/resources/application.yml#L23&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;application.yml&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;spring.cloud.stream.kafka.streams.bindings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;orderStateStoreProcessor-in-0.consumer.configuration.application.id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;${spring.application.name}-orderStateStoreProcessor&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;orderProcess-in-0.consumer.configuration.application.id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;${spring.application.name}-orderProcess&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;inventoryCheck-in-0.consumer.configuration.application.id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;${spring.application.name}-inventoryCheck&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;shipping-in-0.consumer.configuration.application.id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;${spring.application.name}-shipping&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;shippedConsumer-in-0.consumer.configuration.application.id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;${spring.application.name}-shipped&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We need it since we have all the &lt;code&gt;@Bean&lt;/code&gt;s in the same application (required for Kafka 2.6.x and later)&lt;/p&gt;
&lt;h2 id=&#34;its-showtime&#34;&gt;It’s Showtime!&lt;/h2&gt;
&lt;p&gt;Let’s build the project:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;mvn clean package
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then, run the project from the project root “scs-100-2”:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;java -jar target/scs-100-2-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After the application has started completely, this should display in the console:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;…..RocksDBTimestampedStore      : Opening store scs-100-2-order-events in regular mode
…
…
… State transition from REBALANCING to RUNNING
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now, run the test:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nv&#34;&gt;ORDER_UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;curl --silent -H &lt;span class=&#34;s1&#34;&gt;&amp;#39;Content-Type: application/json&amp;#39;&lt;/span&gt; -d &lt;span class=&#34;s2&#34;&gt;&amp;#34;{\&amp;#34;itemName\&amp;#34;:\&amp;#34;book\&amp;#34;}&amp;#34;&lt;/span&gt; http://localhost:8080/order &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; jq -r &lt;span class=&#34;s1&#34;&gt;&amp;#39;.orderUuid&amp;#39;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;seq &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; 15&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; sleep 1&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;curl --silent &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://localhost:8080/order/status/&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$ORDER_UUID&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Similar to &lt;a href=&#34;https://tanzu.vmware.com/developer/guides/event-streaming/spring-cloud-stream-kafka-p2/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Part 2&lt;/a&gt;, you create an order and check its status every second for the next 15 seconds.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&amp;#34;PENDING&amp;#34;
&amp;#34;PENDING&amp;#34;
&amp;#34;PENDING&amp;#34;
&amp;#34;PENDING&amp;#34;
&amp;#34;PENDING&amp;#34;
&amp;#34;PENDING&amp;#34;
&amp;#34;INVENTORY_CHECKING&amp;#34;
&amp;#34;INVENTORY_CHECKING&amp;#34;
&amp;#34;INVENTORY_CHECKING&amp;#34;
&amp;#34;INVENTORY_CHECKING&amp;#34;
&amp;#34;INVENTORY_CHECKING&amp;#34;
&amp;#34;SHIPPED&amp;#34;
&amp;#34;SHIPPED&amp;#34;
&amp;#34;SHIPPED&amp;#34;
&amp;#34;SHIPPED&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;running-multi-instances&#34;&gt;Running Multi-instances&lt;/h2&gt;
&lt;p&gt;Now, let’s run the same application multiple times, at the same time, to simulate the application redundancy.
Before doing that, make sure that the current application is &lt;strong&gt;not running&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/tree/main/scs-100-2&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;project code&lt;/a&gt; comes with Nginx as a Load Balancer. It’s  preconfigured to distribute the incoming traffic from port &lt;strong&gt;8080&lt;/strong&gt; and route it into &lt;em&gt;&lt;strong&gt;8081&lt;/strong&gt;&lt;/em&gt; and &lt;strong&gt;&lt;em&gt;8082&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;First, let’s start a different docker-compose from root on this project &lt;a href=&#34;https://github.com/ehsaniara/scs-kafka-intro/tree/main/scs-100-2&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;code&gt;scs-100-2&lt;/code&gt;&lt;/a&gt; as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;docker-compose -f nginx/docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Since port 8080 is already occupied by Nginx, we can run the Ordering application &lt;strong&gt;in 2 separate terminals&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Terminal 1:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;java -Dserver.port&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8081&lt;/span&gt; -jar target/scs-100-2-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Terminal 2:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;java -Dserver.port&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8082&lt;/span&gt; -jar target/scs-100-2-0.0.1-SNAPSHOT.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-1002-3.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;Then, run our curl call command again (same as the earlier one)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nv&#34;&gt;ORDER_UUID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;curl --silent -H &lt;span class=&#34;s1&#34;&gt;&amp;#39;Content-Type: application/json&amp;#39;&lt;/span&gt; -d &lt;span class=&#34;s2&#34;&gt;&amp;#34;{\&amp;#34;itemName\&amp;#34;:\&amp;#34;book\&amp;#34;}&amp;#34;&lt;/span&gt; http://localhost:8080/order &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; jq -r &lt;span class=&#34;s1&#34;&gt;&amp;#39;.orderUuid&amp;#39;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;seq &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; 15&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; sleep 1&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;curl --silent &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://localhost:8080/order/status/&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$ORDER_UUID&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/images/guides/event-streaming/kafka-events-intro-1002-4.svg&#34; alt=&#34;General Flow Diagram&#34;  /&gt;&lt;/p&gt;
&lt;p&gt;When you review the logs, you&amp;rsquo;ll notice some calls are going into App 1 and others into App 2.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s review what is happening:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Incoming Request meets the Nginx on port 8080 and gets round-robin to either Application 1 or 2.&lt;/li&gt;
&lt;li&gt;In the case of the “create order” request, depending on which application Nginx is routing the call, the order state will get materialized and stored in that instance of the application. In a real scenario, this can happen on a different machine.&lt;/li&gt;
&lt;li&gt;For the following lookup calls, the application &lt;code&gt;InteractiveQueryService&lt;/code&gt; checks the &lt;code&gt;HostInfo&lt;/code&gt; for the requested key (&lt;code&gt;orderUuid&lt;/code&gt;) and decides to look it up on its local storage or ask the counterpart application (the other instance which &lt;code&gt;HostInfo&lt;/code&gt; addressed) through the &lt;code&gt;RestTemplate&lt;/code&gt; calls.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Note: In case the hosted application instance dies (where the key is located), the KTable change logs will be Re-Aggregated during the partition re-balancing, and the results will be materialized in the newly selected application instance.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What’s Next?&lt;/h2&gt;
&lt;p&gt;We are going to break this application down into smaller micro-services and apply the Modern Application Best Practices.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
